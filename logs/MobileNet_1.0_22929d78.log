20:14:32: Namespace(batch_size=100, bench=False, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=10, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='MobileNet', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.5, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=False)
20:14:32: 


20:14:32: ================================================================================
20:14:32: 
Iteration start: 1/1

20:14:43: MobileNet(
  (features): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): ReLU(inplace=True)
    (12): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU(inplace=True)
    (15): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
    (16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (17): ReLU(inplace=True)
    (18): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (19): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): ReLU(inplace=True)
    (21): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
    (22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (23): ReLU(inplace=True)
    (24): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (25): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
    (28): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (31): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
    (34): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (35): ReLU(inplace=True)
    (36): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): ReLU(inplace=True)
    (39): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (40): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (41): ReLU(inplace=True)
    (42): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (43): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): ReLU(inplace=True)
    (45): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (46): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (47): ReLU(inplace=True)
    (48): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (49): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): ReLU(inplace=True)
    (51): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (52): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (53): ReLU(inplace=True)
    (54): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (55): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): ReLU(inplace=True)
    (57): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (58): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (59): ReLU(inplace=True)
    (60): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (61): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): ReLU(inplace=True)
    (63): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (64): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (65): ReLU(inplace=True)
    (66): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (67): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): ReLU(inplace=True)
    (69): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)
    (70): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (71): ReLU(inplace=True)
    (72): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (73): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): ReLU(inplace=True)
    (75): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)
    (76): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (77): ReLU(inplace=True)
    (78): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (79): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): ReLU(inplace=True)
    (81): AvgPool2d(kernel_size=1, stride=1, padding=0)
  )
  (fc): Linear(in_features=1024, out_features=100, bias=True)
)
20:14:43: ============================================================
20:14:43: MobileNet
20:14:43: ============================================================
20:14:43: ============================================================
20:14:43: Prune mode: magnitude
20:14:43: Growth mode: momentum
20:14:43: Redistribution mode: momentum
20:14:43: ============================================================
20:14:44: Train Epoch: 1 [0/45000 (0%)]	Loss: 4.641055
20:14:51: Train Epoch: 1 [10000/45000 (22%)]	Loss: 2.064725
20:14:57: Train Epoch: 1 [20000/45000 (44%)]	Loss: 2.014928
20:15:04: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.557050
20:15:10: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.573662
20:15:16: 
Evaluation: Average loss: 1.8374, Accuracy: 1972/5000 (39.440%)

20:15:16: Current learning rate: 0.1. Time taken for epoch: 32.67 seconds.

20:15:16: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.575566
20:15:23: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.414849
20:15:30: Train Epoch: 2 [20000/45000 (44%)]	Loss: 1.625292
20:15:36: Train Epoch: 2 [30000/45000 (67%)]	Loss: 1.323767
20:15:43: Train Epoch: 2 [40000/45000 (89%)]	Loss: 1.607041
20:15:48: 
Evaluation: Average loss: 1.4206, Accuracy: 2482/5000 (49.640%)

20:15:48: Current learning rate: 0.1. Time taken for epoch: 32.46 seconds.

20:15:49: Train Epoch: 3 [0/45000 (0%)]	Loss: 1.339017
20:15:56: Train Epoch: 3 [10000/45000 (22%)]	Loss: 1.579439
20:16:02: Train Epoch: 3 [20000/45000 (44%)]	Loss: 1.155428
20:16:08: Train Epoch: 3 [30000/45000 (67%)]	Loss: 1.418461
20:16:15: Train Epoch: 3 [40000/45000 (89%)]	Loss: 1.227181
20:16:20: 
Evaluation: Average loss: 1.2997, Accuracy: 2637/5000 (52.740%)

20:16:20: Current learning rate: 0.1. Time taken for epoch: 32.32 seconds.

20:16:21: Train Epoch: 4 [0/45000 (0%)]	Loss: 1.153819
20:16:28: Train Epoch: 4 [10000/45000 (22%)]	Loss: 1.196066
20:16:34: Train Epoch: 4 [20000/45000 (44%)]	Loss: 1.234534
20:16:41: Train Epoch: 4 [30000/45000 (67%)]	Loss: 1.234248
20:16:47: Train Epoch: 4 [40000/45000 (89%)]	Loss: 1.135692
20:16:52: 
Evaluation: Average loss: 1.2509, Accuracy: 2790/5000 (55.800%)

20:16:52: Current learning rate: 0.1. Time taken for epoch: 32.07 seconds.

20:16:53: Train Epoch: 5 [0/45000 (0%)]	Loss: 1.190758
20:17:00: Train Epoch: 5 [10000/45000 (22%)]	Loss: 1.010298
20:17:06: Train Epoch: 5 [20000/45000 (44%)]	Loss: 1.196383
20:17:13: Train Epoch: 5 [30000/45000 (67%)]	Loss: 1.140086
20:17:19: Train Epoch: 5 [40000/45000 (89%)]	Loss: 0.925884
20:17:24: 
Evaluation: Average loss: 1.2369, Accuracy: 2829/5000 (56.580%)

20:17:24: Current learning rate: 0.1. Time taken for epoch: 32.03 seconds.

20:17:25: Train Epoch: 6 [0/45000 (0%)]	Loss: 1.232216
20:17:32: Train Epoch: 6 [10000/45000 (22%)]	Loss: 1.108578
20:17:38: Train Epoch: 6 [20000/45000 (44%)]	Loss: 1.050384
20:17:45: Train Epoch: 6 [30000/45000 (67%)]	Loss: 1.154369
20:17:51: Train Epoch: 6 [40000/45000 (89%)]	Loss: 1.040110
20:17:56: 
Evaluation: Average loss: 1.5889, Accuracy: 2437/5000 (48.740%)

20:17:56: Current learning rate: 0.1. Time taken for epoch: 31.88 seconds.

20:17:57: Train Epoch: 7 [0/45000 (0%)]	Loss: 1.073304
20:18:04: Train Epoch: 7 [10000/45000 (22%)]	Loss: 1.109553
20:18:10: Train Epoch: 7 [20000/45000 (44%)]	Loss: 1.106072
20:18:17: Train Epoch: 7 [30000/45000 (67%)]	Loss: 1.199187
20:18:23: Train Epoch: 7 [40000/45000 (89%)]	Loss: 0.950121
20:18:28: 
Evaluation: Average loss: 1.2243, Accuracy: 2849/5000 (56.980%)

20:18:28: Current learning rate: 0.1. Time taken for epoch: 31.81 seconds.

20:18:29: Train Epoch: 8 [0/45000 (0%)]	Loss: 1.010954
20:18:36: Train Epoch: 8 [10000/45000 (22%)]	Loss: 0.935972
20:18:42: Train Epoch: 8 [20000/45000 (44%)]	Loss: 1.182734
20:18:48: Train Epoch: 8 [30000/45000 (67%)]	Loss: 0.974164
20:18:55: Train Epoch: 8 [40000/45000 (89%)]	Loss: 0.953196
20:19:00: 
Evaluation: Average loss: 1.0760, Accuracy: 3162/5000 (63.240%)

20:19:00: Current learning rate: 0.1. Time taken for epoch: 31.51 seconds.

20:19:01: Train Epoch: 9 [0/45000 (0%)]	Loss: 0.941062
20:19:07: Train Epoch: 9 [10000/45000 (22%)]	Loss: 0.903572
20:19:13: Train Epoch: 9 [20000/45000 (44%)]	Loss: 0.920761
20:19:20: Train Epoch: 9 [30000/45000 (67%)]	Loss: 0.827586
20:19:26: Train Epoch: 9 [40000/45000 (89%)]	Loss: 1.083519
20:19:31: 
Evaluation: Average loss: 1.0672, Accuracy: 3120/5000 (62.400%)

20:19:31: Current learning rate: 0.1. Time taken for epoch: 31.50 seconds.

20:19:32: Train Epoch: 10 [0/45000 (0%)]	Loss: 1.186678
20:19:38: Train Epoch: 10 [10000/45000 (22%)]	Loss: 1.044895
20:19:45: Train Epoch: 10 [20000/45000 (44%)]	Loss: 0.910821
20:19:51: Train Epoch: 10 [30000/45000 (67%)]	Loss: 1.092095
20:19:57: Train Epoch: 10 [40000/45000 (89%)]	Loss: 0.971316
20:20:03: 
Evaluation: Average loss: 1.0923, Accuracy: 3111/5000 (62.220%)

20:20:03: Current learning rate: 0.1. Time taken for epoch: 31.40 seconds.

20:20:05: 
Test evaluation: Average loss: 1.0820, Accuracy: 6243/10000 (62.430%)

20:20:05: 
Iteration end: 1/1

20:22:05: Namespace(batch_size=100, bench=False, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=10, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='MobileNet', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.5, redistribution='momentum', resume='model_best.pth.tar', save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=False)
20:22:05: 


20:22:05: ================================================================================
20:22:05: 
Iteration start: 1/1

20:22:06: MobileNet(
  (features): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): ReLU(inplace=True)
    (12): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU(inplace=True)
    (15): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
    (16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (17): ReLU(inplace=True)
    (18): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (19): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): ReLU(inplace=True)
    (21): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
    (22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (23): ReLU(inplace=True)
    (24): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (25): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
    (28): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (31): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
    (34): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (35): ReLU(inplace=True)
    (36): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): ReLU(inplace=True)
    (39): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (40): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (41): ReLU(inplace=True)
    (42): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (43): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): ReLU(inplace=True)
    (45): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (46): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (47): ReLU(inplace=True)
    (48): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (49): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): ReLU(inplace=True)
    (51): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (52): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (53): ReLU(inplace=True)
    (54): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (55): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): ReLU(inplace=True)
    (57): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (58): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (59): ReLU(inplace=True)
    (60): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (61): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): ReLU(inplace=True)
    (63): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (64): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (65): ReLU(inplace=True)
    (66): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (67): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): ReLU(inplace=True)
    (69): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)
    (70): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (71): ReLU(inplace=True)
    (72): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (73): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): ReLU(inplace=True)
    (75): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)
    (76): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (77): ReLU(inplace=True)
    (78): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (79): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): ReLU(inplace=True)
    (81): AvgPool2d(kernel_size=1, stride=1, padding=0)
  )
  (fc): Linear(in_features=1024, out_features=100, bias=True)
)
20:22:06: ============================================================
20:22:06: MobileNet
20:22:06: ============================================================
20:22:06: ============================================================
20:22:06: Prune mode: magnitude
20:22:06: Growth mode: momentum
20:22:06: Redistribution mode: momentum
20:22:06: ============================================================
20:22:06: => loading checkpoint: 'checkpoint/MobileNet/model_best.pth.tar'
20:22:07: => loaded checkpoint 'checkpoint/MobileNet/model_best.pth.tar' (epoch 10)
20:22:07: Testing...
20:22:10: 
Evaluation: Average loss: 0.9991, Accuracy: 6491/10000 (64.910%)

20:22:52: Train Epoch: 1 [0/45000 (0%)]	Loss: 0.981194
20:22:59: Train Epoch: 1 [10000/45000 (22%)]	Loss: 0.678569
20:23:05: Train Epoch: 1 [20000/45000 (44%)]	Loss: 1.110937
20:23:12: Train Epoch: 1 [30000/45000 (67%)]	Loss: 0.995561
20:23:18: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.107355
20:23:24: 
Evaluation: Average loss: 1.0042, Accuracy: 3303/5000 (66.060%)

20:23:24: Current learning rate: 0.1. Time taken for epoch: 32.44 seconds.

20:23:25: Train Epoch: 2 [0/45000 (0%)]	Loss: 0.944602
20:23:31: Train Epoch: 2 [10000/45000 (22%)]	Loss: 0.944080
20:23:38: Train Epoch: 2 [20000/45000 (44%)]	Loss: 0.849779
20:23:44: Train Epoch: 2 [30000/45000 (67%)]	Loss: 1.034294
20:23:50: Train Epoch: 2 [40000/45000 (89%)]	Loss: 0.811791
20:23:55: 
Evaluation: Average loss: 1.0291, Accuracy: 3249/5000 (64.980%)

20:23:56: Current learning rate: 0.1. Time taken for epoch: 31.84 seconds.

20:23:56: Train Epoch: 3 [0/45000 (0%)]	Loss: 0.850359
20:24:03: Train Epoch: 3 [10000/45000 (22%)]	Loss: 1.041651
20:24:10: Train Epoch: 3 [20000/45000 (44%)]	Loss: 0.912894
20:24:16: Train Epoch: 3 [30000/45000 (67%)]	Loss: 1.050171
20:24:22: Train Epoch: 3 [40000/45000 (89%)]	Loss: 0.796639
20:24:27: 
Evaluation: Average loss: 1.0388, Accuracy: 3173/5000 (63.460%)

20:24:28: Current learning rate: 0.1. Time taken for epoch: 32.02 seconds.

20:24:28: Train Epoch: 4 [0/45000 (0%)]	Loss: 0.857467
20:24:35: Train Epoch: 4 [10000/45000 (22%)]	Loss: 0.893621
20:24:41: Train Epoch: 4 [20000/45000 (44%)]	Loss: 1.091586
20:24:48: Train Epoch: 4 [30000/45000 (67%)]	Loss: 0.920438
20:24:54: Train Epoch: 4 [40000/45000 (89%)]	Loss: 0.676894
20:24:59: 
Evaluation: Average loss: 1.4102, Accuracy: 2738/5000 (54.760%)

20:24:59: Current learning rate: 0.1. Time taken for epoch: 31.51 seconds.

20:25:00: Train Epoch: 5 [0/45000 (0%)]	Loss: 0.917367
20:25:06: Train Epoch: 5 [10000/45000 (22%)]	Loss: 0.777552
20:25:13: Train Epoch: 5 [20000/45000 (44%)]	Loss: 0.867723
20:25:19: Train Epoch: 5 [30000/45000 (67%)]	Loss: 0.935432
20:25:25: Train Epoch: 5 [40000/45000 (89%)]	Loss: 0.832503
20:25:30: 
Evaluation: Average loss: 1.2546, Accuracy: 2896/5000 (57.920%)

20:25:30: Current learning rate: 0.1. Time taken for epoch: 31.43 seconds.

20:25:31: Train Epoch: 6 [0/45000 (0%)]	Loss: 0.934611
20:25:38: Train Epoch: 6 [10000/45000 (22%)]	Loss: 0.966375
20:25:44: Train Epoch: 6 [20000/45000 (44%)]	Loss: 0.870732
20:25:50: Train Epoch: 6 [30000/45000 (67%)]	Loss: 0.992368
20:25:57: Train Epoch: 6 [40000/45000 (89%)]	Loss: 0.717443
20:26:02: 
Evaluation: Average loss: 1.2710, Accuracy: 2847/5000 (56.940%)

20:26:02: Current learning rate: 0.1. Time taken for epoch: 31.18 seconds.

20:26:02: Train Epoch: 7 [0/45000 (0%)]	Loss: 0.871612
20:26:09: Train Epoch: 7 [10000/45000 (22%)]	Loss: 0.909100
20:26:15: Train Epoch: 7 [20000/45000 (44%)]	Loss: 1.171958
20:26:22: Train Epoch: 7 [30000/45000 (67%)]	Loss: 0.762083
20:26:28: Train Epoch: 7 [40000/45000 (89%)]	Loss: 0.694722
20:26:33: 
Evaluation: Average loss: 1.0502, Accuracy: 3248/5000 (64.960%)

20:26:33: Current learning rate: 0.1. Time taken for epoch: 31.46 seconds.

20:26:34: Train Epoch: 8 [0/45000 (0%)]	Loss: 0.759229
20:26:40: Train Epoch: 8 [10000/45000 (22%)]	Loss: 0.878967
20:26:47: Train Epoch: 8 [20000/45000 (44%)]	Loss: 0.669222
20:26:53: Train Epoch: 8 [30000/45000 (67%)]	Loss: 0.807802
20:26:59: Train Epoch: 8 [40000/45000 (89%)]	Loss: 0.929198
20:27:04: 
Evaluation: Average loss: 0.9526, Accuracy: 3358/5000 (67.160%)

20:27:04: Current learning rate: 0.1. Time taken for epoch: 31.35 seconds.

20:27:05: Train Epoch: 9 [0/45000 (0%)]	Loss: 0.914853
20:27:12: Train Epoch: 9 [10000/45000 (22%)]	Loss: 0.824988
20:27:18: Train Epoch: 9 [20000/45000 (44%)]	Loss: 0.858292
20:27:25: Train Epoch: 9 [30000/45000 (67%)]	Loss: 0.966162
20:27:31: Train Epoch: 9 [40000/45000 (89%)]	Loss: 0.871396
20:27:36: 
Evaluation: Average loss: 1.1242, Accuracy: 3195/5000 (63.900%)

20:27:36: Current learning rate: 0.1. Time taken for epoch: 31.59 seconds.

20:27:37: Train Epoch: 10 [0/45000 (0%)]	Loss: 0.948809
20:27:43: Train Epoch: 10 [10000/45000 (22%)]	Loss: 0.706470
20:27:50: Train Epoch: 10 [20000/45000 (44%)]	Loss: 0.929850
20:27:56: Train Epoch: 10 [30000/45000 (67%)]	Loss: 0.918978
20:28:02: Train Epoch: 10 [40000/45000 (89%)]	Loss: 0.709934
20:28:07: 
Evaluation: Average loss: 0.9649, Accuracy: 3385/5000 (67.700%)

20:28:07: Current learning rate: 0.1. Time taken for epoch: 31.33 seconds.

20:28:10: 
Test evaluation: Average loss: 0.9077, Accuracy: 6924/10000 (69.240%)

20:28:10: 
Iteration end: 1/1

20:37:36: Namespace(batch_size=100, bench=False, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=4, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='MobileNet', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.5, redistribution='momentum', resume='model_best.pth.tar', save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=False)
20:37:36: 


20:37:36: ================================================================================
20:37:36: 
Iteration start: 1/1

20:37:37: MobileNet(
  (features): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): ReLU(inplace=True)
    (12): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU(inplace=True)
    (15): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
    (16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (17): ReLU(inplace=True)
    (18): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (19): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): ReLU(inplace=True)
    (21): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
    (22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (23): ReLU(inplace=True)
    (24): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (25): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
    (28): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (31): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
    (34): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (35): ReLU(inplace=True)
    (36): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): ReLU(inplace=True)
    (39): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (40): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (41): ReLU(inplace=True)
    (42): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (43): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): ReLU(inplace=True)
    (45): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (46): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (47): ReLU(inplace=True)
    (48): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (49): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): ReLU(inplace=True)
    (51): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (52): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (53): ReLU(inplace=True)
    (54): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (55): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): ReLU(inplace=True)
    (57): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (58): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (59): ReLU(inplace=True)
    (60): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (61): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): ReLU(inplace=True)
    (63): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (64): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (65): ReLU(inplace=True)
    (66): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (67): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): ReLU(inplace=True)
    (69): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)
    (70): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (71): ReLU(inplace=True)
    (72): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (73): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): ReLU(inplace=True)
    (75): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)
    (76): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (77): ReLU(inplace=True)
    (78): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (79): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): ReLU(inplace=True)
    (81): AvgPool2d(kernel_size=1, stride=1, padding=0)
  )
  (fc): Linear(in_features=1024, out_features=100, bias=True)
)
20:37:37: ============================================================
20:37:37: MobileNet
20:37:37: ============================================================
20:37:37: ============================================================
20:37:37: Prune mode: magnitude
20:37:37: Growth mode: momentum
20:37:37: Redistribution mode: momentum
20:37:37: ============================================================
20:37:37: => loading checkpoint: 'checkpoint/MobileNet/model_best.pth.tar'
20:37:37: => loaded checkpoint 'checkpoint/MobileNet/model_best.pth.tar' (epoch 9)
20:37:37: Testing...
20:37:40: 
Evaluation: Average loss: 0.9171, Accuracy: 6925/10000 (69.250%)

20:38:21: Train Epoch: 1 [0/45000 (0%)]	Loss: 1.009047
20:38:27: Train Epoch: 1 [10000/45000 (22%)]	Loss: 0.808285
20:38:34: Train Epoch: 1 [20000/45000 (44%)]	Loss: 1.231176
20:38:40: Train Epoch: 1 [30000/45000 (67%)]	Loss: 0.723277
20:38:46: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.097749
20:38:52: 
Evaluation: Average loss: 1.1889, Accuracy: 3010/5000 (60.200%)

20:38:52: Current learning rate: 0.1. Time taken for epoch: 31.88 seconds.

20:38:52: Train Epoch: 2 [0/45000 (0%)]	Loss: 0.781162
20:38:59: Train Epoch: 2 [10000/45000 (22%)]	Loss: 0.862014
20:39:05: Train Epoch: 2 [20000/45000 (44%)]	Loss: 0.830214
20:39:12: Train Epoch: 2 [30000/45000 (67%)]	Loss: 0.941137
20:39:18: Train Epoch: 2 [40000/45000 (89%)]	Loss: 0.693647
20:39:24: 
Evaluation: Average loss: 1.2298, Accuracy: 2908/5000 (58.160%)

20:39:24: Current learning rate: 0.1. Time taken for epoch: 32.17 seconds.

20:39:25: Train Epoch: 3 [0/45000 (0%)]	Loss: 0.793496
20:39:31: Train Epoch: 3 [10000/45000 (22%)]	Loss: 0.879854
20:39:38: Train Epoch: 3 [20000/45000 (44%)]	Loss: 0.806600
20:39:44: Train Epoch: 3 [30000/45000 (67%)]	Loss: 0.965817
20:39:50: Train Epoch: 3 [40000/45000 (89%)]	Loss: 0.800435
20:39:56: 
Evaluation: Average loss: 1.2021, Accuracy: 2981/5000 (59.620%)

20:39:56: Current learning rate: 0.1. Time taken for epoch: 31.92 seconds.

20:39:57: Train Epoch: 4 [0/45000 (0%)]	Loss: 0.714582
20:40:03: Train Epoch: 4 [10000/45000 (22%)]	Loss: 0.790499
20:40:10: Train Epoch: 4 [20000/45000 (44%)]	Loss: 0.988429
20:40:16: Train Epoch: 4 [30000/45000 (67%)]	Loss: 0.915685
20:40:23: Train Epoch: 4 [40000/45000 (89%)]	Loss: 0.622116
20:40:28: 
Evaluation: Average loss: 1.4361, Accuracy: 2676/5000 (53.520%)

20:40:28: Current learning rate: 0.1. Time taken for epoch: 32.48 seconds.

20:40:31: 
Test evaluation: Average loss: 1.3880, Accuracy: 5540/10000 (55.400%)

20:40:31: 
Iteration end: 1/1

20:47:16: Namespace(batch_size=100, bench=False, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=4, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='MobileNet', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.5, redistribution='momentum', resume='model_best.pth.tar', save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=False)
20:47:16: 


20:47:16: ================================================================================
20:47:16: 
Iteration start: 1/1

20:47:17: MobileNet(
  (features): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): ReLU(inplace=True)
    (12): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU(inplace=True)
    (15): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
    (16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (17): ReLU(inplace=True)
    (18): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (19): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): ReLU(inplace=True)
    (21): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
    (22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (23): ReLU(inplace=True)
    (24): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (25): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
    (28): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (31): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
    (34): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (35): ReLU(inplace=True)
    (36): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): ReLU(inplace=True)
    (39): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (40): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (41): ReLU(inplace=True)
    (42): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (43): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): ReLU(inplace=True)
    (45): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (46): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (47): ReLU(inplace=True)
    (48): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (49): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): ReLU(inplace=True)
    (51): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (52): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (53): ReLU(inplace=True)
    (54): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (55): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): ReLU(inplace=True)
    (57): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (58): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (59): ReLU(inplace=True)
    (60): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (61): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): ReLU(inplace=True)
    (63): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (64): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (65): ReLU(inplace=True)
    (66): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (67): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): ReLU(inplace=True)
    (69): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)
    (70): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (71): ReLU(inplace=True)
    (72): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (73): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): ReLU(inplace=True)
    (75): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)
    (76): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (77): ReLU(inplace=True)
    (78): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (79): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): ReLU(inplace=True)
    (81): AvgPool2d(kernel_size=1, stride=1, padding=0)
  )
  (fc): Linear(in_features=1024, out_features=100, bias=True)
)
20:47:17: ============================================================
20:47:17: MobileNet
20:47:17: ============================================================
20:47:17: ============================================================
20:47:17: Prune mode: magnitude
20:47:17: Growth mode: momentum
20:47:17: Redistribution mode: momentum
20:47:17: ============================================================
20:47:17: => loading checkpoint: 'checkpoint/MobileNet/model_best.pth.tar'
20:47:17: => loaded checkpoint 'checkpoint/MobileNet/model_best.pth.tar' (epoch 9)
20:47:17: Testing...
20:47:20: 
Evaluation: Average loss: 0.9171, Accuracy: 6925/10000 (69.250%)

20:48:00: Train Epoch: 1 [0/45000 (0%)]	Loss: 1.009047
20:48:07: Train Epoch: 1 [10000/45000 (22%)]	Loss: 0.808285
20:48:13: Train Epoch: 1 [20000/45000 (44%)]	Loss: 1.231176
20:48:20: Train Epoch: 1 [30000/45000 (67%)]	Loss: 0.723277
20:48:26: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.097749
20:48:31: 
Evaluation: Average loss: 1.1889, Accuracy: 3010/5000 (60.200%)

20:48:31: Current learning rate: 0.1. Time taken for epoch: 32.13 seconds.

20:48:32: Train Epoch: 2 [0/45000 (0%)]	Loss: 0.781162
20:48:39: Train Epoch: 2 [10000/45000 (22%)]	Loss: 0.862014
20:48:45: Train Epoch: 2 [20000/45000 (44%)]	Loss: 0.830214
20:48:52: Train Epoch: 2 [30000/45000 (67%)]	Loss: 0.941137
20:48:58: Train Epoch: 2 [40000/45000 (89%)]	Loss: 0.693647
20:49:03: 
Evaluation: Average loss: 1.2298, Accuracy: 2908/5000 (58.160%)

20:49:03: Current learning rate: 0.1. Time taken for epoch: 32.04 seconds.

20:49:04: Train Epoch: 3 [0/45000 (0%)]	Loss: 0.793496
20:49:11: Train Epoch: 3 [10000/45000 (22%)]	Loss: 0.879854
20:49:17: Train Epoch: 3 [20000/45000 (44%)]	Loss: 0.806600
20:49:24: Train Epoch: 3 [30000/45000 (67%)]	Loss: 0.965817
20:49:30: Train Epoch: 3 [40000/45000 (89%)]	Loss: 0.800435
20:49:35: 
Evaluation: Average loss: 1.2021, Accuracy: 2981/5000 (59.620%)

20:49:35: Current learning rate: 0.1. Time taken for epoch: 32.03 seconds.

20:49:36: Train Epoch: 4 [0/45000 (0%)]	Loss: 0.714582
20:49:43: Train Epoch: 4 [10000/45000 (22%)]	Loss: 0.790499
20:49:49: Train Epoch: 4 [20000/45000 (44%)]	Loss: 0.988429
20:49:56: Train Epoch: 4 [30000/45000 (67%)]	Loss: 0.915685
20:50:02: Train Epoch: 4 [40000/45000 (89%)]	Loss: 0.622116
20:50:07: 
Evaluation: Average loss: 1.4361, Accuracy: 2676/5000 (53.520%)

20:50:07: Current learning rate: 0.1. Time taken for epoch: 31.73 seconds.

20:50:10: 
Test evaluation: Average loss: 1.3880, Accuracy: 5540/10000 (55.400%)

20:50:10: 
Iteration end: 1/1

