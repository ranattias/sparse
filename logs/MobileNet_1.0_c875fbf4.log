09:25:33: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='MobileNet', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
09:25:33: 


09:25:33: ================================================================================
09:25:33: 
Iteration start: 1/1

09:25:34: MobileNet(
  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (dw2_1): DepthWiseBlock(
    (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
    (bn_dw): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw2_2): DepthWiseBlock(
    (conv_dw): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
    (bn_dw): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw3_1): DepthWiseBlock(
    (conv_dw): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
    (bn_dw): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw3_2): DepthWiseBlock(
    (conv_dw): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
    (bn_dw): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw4_1): DepthWiseBlock(
    (conv_dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
    (bn_dw): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw4_2): DepthWiseBlock(
    (conv_dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
    (bn_dw): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_1): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_2): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_3): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_4): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_5): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_6): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw6): DepthWiseBlock(
    (conv_dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)
    (bn_dw): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=1)
  (fc): Linear(in_features=1024, out_features=100, bias=True)
)
09:25:34: ============================================================
09:25:34: MobileNet
09:25:34: ============================================================
09:25:34: ============================================================
09:25:34: Prune mode: magnitude
09:25:34: Growth mode: momentum
09:25:34: Redistribution mode: momentum
09:25:34: ============================================================
09:25:35: Train Epoch: 1 [0/45000 (0%)]	Loss: -0.048067
09:25:40: Train Epoch: 1 [10000/45000 (22%)]	Loss: -14982227951616.000000
09:25:44: Train Epoch: 1 [20000/45000 (44%)]	Loss: nan
09:25:48: Train Epoch: 1 [30000/45000 (67%)]	Loss: nan
09:25:53: Train Epoch: 1 [40000/45000 (89%)]	Loss: nan
09:25:57: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:25:57: Current learning rate: 0.1. Time taken for epoch: 23.15 seconds.

09:25:57: Train Epoch: 2 [0/45000 (0%)]	Loss: nan
09:26:03: Train Epoch: 2 [10000/45000 (22%)]	Loss: nan
09:26:07: Train Epoch: 2 [20000/45000 (44%)]	Loss: nan
09:26:11: Train Epoch: 2 [30000/45000 (67%)]	Loss: nan
09:26:16: Train Epoch: 2 [40000/45000 (89%)]	Loss: nan
09:26:20: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:26:20: Current learning rate: 0.1. Time taken for epoch: 23.02 seconds.

09:26:21: Train Epoch: 3 [0/45000 (0%)]	Loss: nan
09:26:25: Train Epoch: 3 [10000/45000 (22%)]	Loss: nan
09:26:30: Train Epoch: 3 [20000/45000 (44%)]	Loss: nan
09:26:34: Train Epoch: 3 [30000/45000 (67%)]	Loss: nan
09:26:38: Train Epoch: 3 [40000/45000 (89%)]	Loss: nan
09:26:42: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:26:42: Current learning rate: 0.1. Time taken for epoch: 21.97 seconds.

09:26:43: Train Epoch: 4 [0/45000 (0%)]	Loss: nan
09:26:47: Train Epoch: 4 [10000/45000 (22%)]	Loss: nan
09:26:52: Train Epoch: 4 [20000/45000 (44%)]	Loss: nan
09:26:57: Train Epoch: 4 [30000/45000 (67%)]	Loss: nan
09:27:01: Train Epoch: 4 [40000/45000 (89%)]	Loss: nan
09:27:05: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:27:05: Current learning rate: 0.1. Time taken for epoch: 23.02 seconds.

09:27:06: Train Epoch: 5 [0/45000 (0%)]	Loss: nan
09:27:10: Train Epoch: 5 [10000/45000 (22%)]	Loss: nan
09:27:15: Train Epoch: 5 [20000/45000 (44%)]	Loss: nan
09:27:20: Train Epoch: 5 [30000/45000 (67%)]	Loss: nan
09:27:24: Train Epoch: 5 [40000/45000 (89%)]	Loss: nan
09:27:28: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:27:28: Current learning rate: 0.1. Time taken for epoch: 22.47 seconds.

09:27:28: Train Epoch: 6 [0/45000 (0%)]	Loss: nan
09:27:33: Train Epoch: 6 [10000/45000 (22%)]	Loss: nan
09:27:37: Train Epoch: 6 [20000/45000 (44%)]	Loss: nan
09:27:41: Train Epoch: 6 [30000/45000 (67%)]	Loss: nan
09:27:46: Train Epoch: 6 [40000/45000 (89%)]	Loss: nan
09:27:49: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:27:50: Current learning rate: 0.1. Time taken for epoch: 21.96 seconds.

09:27:50: Train Epoch: 7 [0/45000 (0%)]	Loss: nan
09:27:55: Train Epoch: 7 [10000/45000 (22%)]	Loss: nan
09:28:00: Train Epoch: 7 [20000/45000 (44%)]	Loss: nan
09:28:04: Train Epoch: 7 [30000/45000 (67%)]	Loss: nan
09:28:09: Train Epoch: 7 [40000/45000 (89%)]	Loss: nan
09:28:13: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:28:13: Current learning rate: 0.1. Time taken for epoch: 23.19 seconds.

09:28:13: Train Epoch: 8 [0/45000 (0%)]	Loss: nan
09:28:18: Train Epoch: 8 [10000/45000 (22%)]	Loss: nan
09:28:22: Train Epoch: 8 [20000/45000 (44%)]	Loss: nan
09:28:27: Train Epoch: 8 [30000/45000 (67%)]	Loss: nan
09:28:31: Train Epoch: 8 [40000/45000 (89%)]	Loss: nan
09:28:35: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:28:35: Current learning rate: 0.1. Time taken for epoch: 21.96 seconds.

09:28:35: Train Epoch: 9 [0/45000 (0%)]	Loss: nan
09:28:40: Train Epoch: 9 [10000/45000 (22%)]	Loss: nan
09:28:44: Train Epoch: 9 [20000/45000 (44%)]	Loss: nan
09:28:49: Train Epoch: 9 [30000/45000 (67%)]	Loss: nan
09:28:53: Train Epoch: 9 [40000/45000 (89%)]	Loss: nan
09:28:57: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:28:57: Current learning rate: 0.1. Time taken for epoch: 22.67 seconds.

09:28:58: Train Epoch: 10 [0/45000 (0%)]	Loss: nan
09:29:03: Train Epoch: 10 [10000/45000 (22%)]	Loss: nan
09:29:07: Train Epoch: 10 [20000/45000 (44%)]	Loss: nan
09:29:11: Train Epoch: 10 [30000/45000 (67%)]	Loss: nan
09:29:16: Train Epoch: 10 [40000/45000 (89%)]	Loss: nan
09:29:20: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:29:20: Current learning rate: 0.1. Time taken for epoch: 22.56 seconds.

09:29:21: Train Epoch: 11 [0/45000 (0%)]	Loss: nan
09:29:25: Train Epoch: 11 [10000/45000 (22%)]	Loss: nan
09:29:29: Train Epoch: 11 [20000/45000 (44%)]	Loss: nan
09:29:34: Train Epoch: 11 [30000/45000 (67%)]	Loss: nan
09:29:38: Train Epoch: 11 [40000/45000 (89%)]	Loss: nan
09:29:42: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:29:42: Current learning rate: 0.1. Time taken for epoch: 21.89 seconds.

09:29:42: Train Epoch: 12 [0/45000 (0%)]	Loss: nan
09:29:47: Train Epoch: 12 [10000/45000 (22%)]	Loss: nan
09:29:51: Train Epoch: 12 [20000/45000 (44%)]	Loss: nan
09:29:56: Train Epoch: 12 [30000/45000 (67%)]	Loss: nan
09:30:01: Train Epoch: 12 [40000/45000 (89%)]	Loss: nan
09:30:05: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:30:05: Current learning rate: 0.1. Time taken for epoch: 23.21 seconds.

09:30:05: Train Epoch: 13 [0/45000 (0%)]	Loss: nan
09:30:10: Train Epoch: 13 [10000/45000 (22%)]	Loss: nan
09:30:15: Train Epoch: 13 [20000/45000 (44%)]	Loss: nan
09:30:19: Train Epoch: 13 [30000/45000 (67%)]	Loss: nan
09:30:24: Train Epoch: 13 [40000/45000 (89%)]	Loss: nan
09:30:27: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:30:27: Current learning rate: 0.1. Time taken for epoch: 22.35 seconds.

09:30:28: Train Epoch: 14 [0/45000 (0%)]	Loss: nan
09:30:32: Train Epoch: 14 [10000/45000 (22%)]	Loss: nan
09:30:37: Train Epoch: 14 [20000/45000 (44%)]	Loss: nan
09:30:41: Train Epoch: 14 [30000/45000 (67%)]	Loss: nan
09:30:46: Train Epoch: 14 [40000/45000 (89%)]	Loss: nan
09:30:49: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:30:49: Current learning rate: 0.1. Time taken for epoch: 21.99 seconds.

09:30:50: Train Epoch: 15 [0/45000 (0%)]	Loss: nan
09:30:55: Train Epoch: 15 [10000/45000 (22%)]	Loss: nan
09:30:59: Train Epoch: 15 [20000/45000 (44%)]	Loss: nan
09:31:04: Train Epoch: 15 [30000/45000 (67%)]	Loss: nan
09:31:08: Train Epoch: 15 [40000/45000 (89%)]	Loss: nan
09:31:13: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:31:13: Current learning rate: 0.1. Time taken for epoch: 23.20 seconds.

09:31:13: Train Epoch: 16 [0/45000 (0%)]	Loss: nan
09:31:18: Train Epoch: 16 [10000/45000 (22%)]	Loss: nan
09:31:22: Train Epoch: 16 [20000/45000 (44%)]	Loss: nan
09:31:27: Train Epoch: 16 [30000/45000 (67%)]	Loss: nan
09:31:31: Train Epoch: 16 [40000/45000 (89%)]	Loss: nan
09:31:35: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:31:35: Current learning rate: 0.1. Time taken for epoch: 22.35 seconds.

09:31:35: Train Epoch: 17 [0/45000 (0%)]	Loss: nan
09:31:40: Train Epoch: 17 [10000/45000 (22%)]	Loss: nan
09:31:44: Train Epoch: 17 [20000/45000 (44%)]	Loss: nan
09:31:49: Train Epoch: 17 [30000/45000 (67%)]	Loss: nan
09:31:53: Train Epoch: 17 [40000/45000 (89%)]	Loss: nan
09:31:57: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:31:57: Current learning rate: 0.1. Time taken for epoch: 22.55 seconds.

09:31:58: Train Epoch: 18 [0/45000 (0%)]	Loss: nan
09:32:03: Train Epoch: 18 [10000/45000 (22%)]	Loss: nan
09:32:07: Train Epoch: 18 [20000/45000 (44%)]	Loss: nan
09:32:12: Train Epoch: 18 [30000/45000 (67%)]	Loss: nan
09:32:16: Train Epoch: 18 [40000/45000 (89%)]	Loss: nan
09:32:20: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:32:20: Current learning rate: 0.1. Time taken for epoch: 22.61 seconds.

09:32:21: Train Epoch: 19 [0/45000 (0%)]	Loss: nan
09:32:25: Train Epoch: 19 [10000/45000 (22%)]	Loss: nan
09:32:30: Train Epoch: 19 [20000/45000 (44%)]	Loss: nan
09:32:34: Train Epoch: 19 [30000/45000 (67%)]	Loss: nan
09:32:38: Train Epoch: 19 [40000/45000 (89%)]	Loss: nan
09:32:42: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:32:42: Current learning rate: 0.1. Time taken for epoch: 22.10 seconds.

09:32:43: Train Epoch: 20 [0/45000 (0%)]	Loss: nan
09:32:47: Train Epoch: 20 [10000/45000 (22%)]	Loss: nan
09:32:52: Train Epoch: 20 [20000/45000 (44%)]	Loss: nan
09:32:57: Train Epoch: 20 [30000/45000 (67%)]	Loss: nan
09:33:02: Train Epoch: 20 [40000/45000 (89%)]	Loss: nan
09:33:05: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:33:05: Current learning rate: 0.1. Time taken for epoch: 23.02 seconds.

09:33:06: Train Epoch: 21 [0/45000 (0%)]	Loss: nan
09:33:10: Train Epoch: 21 [10000/45000 (22%)]	Loss: nan
09:33:15: Train Epoch: 21 [20000/45000 (44%)]	Loss: nan
09:33:19: Train Epoch: 21 [30000/45000 (67%)]	Loss: nan
09:33:24: Train Epoch: 21 [40000/45000 (89%)]	Loss: nan
09:33:27: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:33:27: Current learning rate: 0.1. Time taken for epoch: 22.29 seconds.

09:33:28: Train Epoch: 22 [0/45000 (0%)]	Loss: nan
09:33:33: Train Epoch: 22 [10000/45000 (22%)]	Loss: nan
09:33:37: Train Epoch: 22 [20000/45000 (44%)]	Loss: nan
09:33:41: Train Epoch: 22 [30000/45000 (67%)]	Loss: nan
09:33:46: Train Epoch: 22 [40000/45000 (89%)]	Loss: nan
09:33:49: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:33:49: Current learning rate: 0.1. Time taken for epoch: 21.97 seconds.

09:33:50: Train Epoch: 23 [0/45000 (0%)]	Loss: nan
09:33:55: Train Epoch: 23 [10000/45000 (22%)]	Loss: nan
09:34:00: Train Epoch: 23 [20000/45000 (44%)]	Loss: nan
09:34:04: Train Epoch: 23 [30000/45000 (67%)]	Loss: nan
09:34:09: Train Epoch: 23 [40000/45000 (89%)]	Loss: nan
09:34:13: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:34:13: Current learning rate: 0.1. Time taken for epoch: 23.33 seconds.

09:34:13: Train Epoch: 24 [0/45000 (0%)]	Loss: nan
09:34:18: Train Epoch: 24 [10000/45000 (22%)]	Loss: nan
09:34:22: Train Epoch: 24 [20000/45000 (44%)]	Loss: nan
09:34:27: Train Epoch: 24 [30000/45000 (67%)]	Loss: nan
09:34:31: Train Epoch: 24 [40000/45000 (89%)]	Loss: nan
09:34:35: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:34:35: Current learning rate: 0.1. Time taken for epoch: 21.84 seconds.

09:34:35: Train Epoch: 25 [0/45000 (0%)]	Loss: nan
09:34:40: Train Epoch: 25 [10000/45000 (22%)]	Loss: nan
09:34:44: Train Epoch: 25 [20000/45000 (44%)]	Loss: nan
09:34:49: Train Epoch: 25 [30000/45000 (67%)]	Loss: nan
09:34:53: Train Epoch: 25 [40000/45000 (89%)]	Loss: nan
09:34:57: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:34:57: Current learning rate: 0.1. Time taken for epoch: 22.56 seconds.

09:34:58: Train Epoch: 26 [0/45000 (0%)]	Loss: nan
09:35:03: Train Epoch: 26 [10000/45000 (22%)]	Loss: nan
09:35:07: Train Epoch: 26 [20000/45000 (44%)]	Loss: nan
09:35:12: Train Epoch: 26 [30000/45000 (67%)]	Loss: nan
09:35:17: Train Epoch: 26 [40000/45000 (89%)]	Loss: nan
09:35:20: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:35:20: Current learning rate: 0.1. Time taken for epoch: 23.17 seconds.

09:35:21: Train Epoch: 27 [0/45000 (0%)]	Loss: nan
09:35:26: Train Epoch: 27 [10000/45000 (22%)]	Loss: nan
09:35:30: Train Epoch: 27 [20000/45000 (44%)]	Loss: nan
09:35:34: Train Epoch: 27 [30000/45000 (67%)]	Loss: nan
09:35:38: Train Epoch: 27 [40000/45000 (89%)]	Loss: nan
09:35:42: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:35:42: Current learning rate: 0.1. Time taken for epoch: 21.88 seconds.

09:35:43: Train Epoch: 28 [0/45000 (0%)]	Loss: nan
09:35:47: Train Epoch: 28 [10000/45000 (22%)]	Loss: nan
09:35:52: Train Epoch: 28 [20000/45000 (44%)]	Loss: nan
09:35:57: Train Epoch: 28 [30000/45000 (67%)]	Loss: nan
09:36:01: Train Epoch: 28 [40000/45000 (89%)]	Loss: nan
09:36:05: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:36:05: Current learning rate: 0.1. Time taken for epoch: 22.81 seconds.

09:36:06: Train Epoch: 29 [0/45000 (0%)]	Loss: nan
09:36:10: Train Epoch: 29 [10000/45000 (22%)]	Loss: nan
09:36:15: Train Epoch: 29 [20000/45000 (44%)]	Loss: nan
09:36:19: Train Epoch: 29 [30000/45000 (67%)]	Loss: nan
09:36:24: Train Epoch: 29 [40000/45000 (89%)]	Loss: nan
09:36:27: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:36:27: Current learning rate: 0.1. Time taken for epoch: 22.19 seconds.

09:36:28: Train Epoch: 30 [0/45000 (0%)]	Loss: nan
09:36:33: Train Epoch: 30 [10000/45000 (22%)]	Loss: nan
09:36:37: Train Epoch: 30 [20000/45000 (44%)]	Loss: nan
09:36:41: Train Epoch: 30 [30000/45000 (67%)]	Loss: nan
09:36:46: Train Epoch: 30 [40000/45000 (89%)]	Loss: nan
09:36:50: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:36:50: Current learning rate: 0.1. Time taken for epoch: 22.37 seconds.

09:36:50: Train Epoch: 31 [0/45000 (0%)]	Loss: nan
09:36:55: Train Epoch: 31 [10000/45000 (22%)]	Loss: nan
09:37:00: Train Epoch: 31 [20000/45000 (44%)]	Loss: nan
09:37:04: Train Epoch: 31 [30000/45000 (67%)]	Loss: nan
09:37:09: Train Epoch: 31 [40000/45000 (89%)]	Loss: nan
09:37:13: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:37:13: Current learning rate: 0.1. Time taken for epoch: 23.23 seconds.

09:37:13: Train Epoch: 32 [0/45000 (0%)]	Loss: nan
09:37:18: Train Epoch: 32 [10000/45000 (22%)]	Loss: nan
09:37:22: Train Epoch: 32 [20000/45000 (44%)]	Loss: nan
09:37:27: Train Epoch: 32 [30000/45000 (67%)]	Loss: nan
09:37:31: Train Epoch: 32 [40000/45000 (89%)]	Loss: nan
09:37:35: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:37:35: Current learning rate: 0.1. Time taken for epoch: 21.88 seconds.

09:37:35: Train Epoch: 33 [0/45000 (0%)]	Loss: nan
09:37:40: Train Epoch: 33 [10000/45000 (22%)]	Loss: nan
09:37:44: Train Epoch: 33 [20000/45000 (44%)]	Loss: nan
09:37:49: Train Epoch: 33 [30000/45000 (67%)]	Loss: nan
09:37:53: Train Epoch: 33 [40000/45000 (89%)]	Loss: nan
09:37:57: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:37:57: Current learning rate: 0.1. Time taken for epoch: 22.65 seconds.

09:37:58: Train Epoch: 34 [0/45000 (0%)]	Loss: nan
09:38:03: Train Epoch: 34 [10000/45000 (22%)]	Loss: nan
09:38:07: Train Epoch: 34 [20000/45000 (44%)]	Loss: nan
09:38:11: Train Epoch: 34 [30000/45000 (67%)]	Loss: nan
09:38:16: Train Epoch: 34 [40000/45000 (89%)]	Loss: nan
09:38:20: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:38:20: Current learning rate: 0.1. Time taken for epoch: 22.68 seconds.

09:38:20: Train Epoch: 35 [0/45000 (0%)]	Loss: nan
09:38:25: Train Epoch: 35 [10000/45000 (22%)]	Loss: nan
09:38:30: Train Epoch: 35 [20000/45000 (44%)]	Loss: nan
09:38:34: Train Epoch: 35 [30000/45000 (67%)]	Loss: nan
09:38:38: Train Epoch: 35 [40000/45000 (89%)]	Loss: nan
09:38:42: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:38:42: Current learning rate: 0.1. Time taken for epoch: 21.89 seconds.

09:38:43: Train Epoch: 36 [0/45000 (0%)]	Loss: nan
09:38:47: Train Epoch: 36 [10000/45000 (22%)]	Loss: nan
09:38:52: Train Epoch: 36 [20000/45000 (44%)]	Loss: nan
09:38:57: Train Epoch: 36 [30000/45000 (67%)]	Loss: nan
09:39:01: Train Epoch: 36 [40000/45000 (89%)]	Loss: nan
09:39:05: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:39:05: Current learning rate: 0.1. Time taken for epoch: 23.20 seconds.

09:39:06: Train Epoch: 37 [0/45000 (0%)]	Loss: nan
09:39:10: Train Epoch: 37 [10000/45000 (22%)]	Loss: nan
09:39:15: Train Epoch: 37 [20000/45000 (44%)]	Loss: nan
09:39:20: Train Epoch: 37 [30000/45000 (67%)]	Loss: nan
09:39:24: Train Epoch: 37 [40000/45000 (89%)]	Loss: nan
09:39:28: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:39:28: Current learning rate: 0.1. Time taken for epoch: 22.73 seconds.

09:39:28: Train Epoch: 38 [0/45000 (0%)]	Loss: nan
09:39:33: Train Epoch: 38 [10000/45000 (22%)]	Loss: nan
09:39:37: Train Epoch: 38 [20000/45000 (44%)]	Loss: nan
09:39:42: Train Epoch: 38 [30000/45000 (67%)]	Loss: nan
09:39:46: Train Epoch: 38 [40000/45000 (89%)]	Loss: nan
09:39:50: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:39:50: Current learning rate: 0.1. Time taken for epoch: 22.16 seconds.

09:39:51: Train Epoch: 39 [0/45000 (0%)]	Loss: nan
09:39:56: Train Epoch: 39 [10000/45000 (22%)]	Loss: nan
09:40:00: Train Epoch: 39 [20000/45000 (44%)]	Loss: nan
09:40:05: Train Epoch: 39 [30000/45000 (67%)]	Loss: nan
09:40:09: Train Epoch: 39 [40000/45000 (89%)]	Loss: nan
09:40:13: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:40:13: Current learning rate: 0.1. Time taken for epoch: 23.38 seconds.

09:40:14: Train Epoch: 40 [0/45000 (0%)]	Loss: nan
09:40:19: Train Epoch: 40 [10000/45000 (22%)]	Loss: nan
09:40:23: Train Epoch: 40 [20000/45000 (44%)]	Loss: nan
09:40:27: Train Epoch: 40 [30000/45000 (67%)]	Loss: nan
09:40:32: Train Epoch: 40 [40000/45000 (89%)]	Loss: nan
09:40:36: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:40:36: Current learning rate: 0.1. Time taken for epoch: 22.15 seconds.

09:40:36: Train Epoch: 41 [0/45000 (0%)]	Loss: nan
09:40:41: Train Epoch: 41 [10000/45000 (22%)]	Loss: nan
09:40:45: Train Epoch: 41 [20000/45000 (44%)]	Loss: nan
09:40:50: Train Epoch: 41 [30000/45000 (67%)]	Loss: nan
09:40:54: Train Epoch: 41 [40000/45000 (89%)]	Loss: nan
09:40:58: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:40:58: Current learning rate: 0.1. Time taken for epoch: 22.81 seconds.

09:40:59: Train Epoch: 42 [0/45000 (0%)]	Loss: nan
09:41:04: Train Epoch: 42 [10000/45000 (22%)]	Loss: nan
09:41:08: Train Epoch: 42 [20000/45000 (44%)]	Loss: nan
09:41:13: Train Epoch: 42 [30000/45000 (67%)]	Loss: nan
09:41:17: Train Epoch: 42 [40000/45000 (89%)]	Loss: nan
09:41:21: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:41:21: Current learning rate: 0.1. Time taken for epoch: 22.70 seconds.

09:41:22: Train Epoch: 43 [0/45000 (0%)]	Loss: nan
09:41:26: Train Epoch: 43 [10000/45000 (22%)]	Loss: nan
09:41:31: Train Epoch: 43 [20000/45000 (44%)]	Loss: nan
09:41:35: Train Epoch: 43 [30000/45000 (67%)]	Loss: nan
09:41:39: Train Epoch: 43 [40000/45000 (89%)]	Loss: nan
09:41:43: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:41:43: Current learning rate: 0.1. Time taken for epoch: 22.18 seconds.

09:41:44: Train Epoch: 44 [0/45000 (0%)]	Loss: nan
09:41:49: Train Epoch: 44 [10000/45000 (22%)]	Loss: nan
09:41:53: Train Epoch: 44 [20000/45000 (44%)]	Loss: nan
09:42:34: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='MobileNet', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
09:42:34: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='MobileNet', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
09:42:34: 


09:42:34: 


09:42:34: ================================================================================
09:42:34: ================================================================================
09:42:34: 
Iteration start: 1/1

09:42:34: 
Iteration start: 1/1

09:42:35: MobileNet(
  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (dw2_1): DepthWiseBlock(
    (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
    (bn_dw): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw2_2): DepthWiseBlock(
    (conv_dw): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
    (bn_dw): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw3_1): DepthWiseBlock(
    (conv_dw): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
    (bn_dw): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw3_2): DepthWiseBlock(
    (conv_dw): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
    (bn_dw): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw4_1): DepthWiseBlock(
    (conv_dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
    (bn_dw): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw4_2): DepthWiseBlock(
    (conv_dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
    (bn_dw): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_1): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_2): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_3): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_4): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_5): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_6): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw6): DepthWiseBlock(
    (conv_dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)
    (bn_dw): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=1)
  (fc): Linear(in_features=1024, out_features=100, bias=True)
)
09:42:35: MobileNet(
  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (dw2_1): DepthWiseBlock(
    (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
    (bn_dw): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw2_2): DepthWiseBlock(
    (conv_dw): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
    (bn_dw): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw3_1): DepthWiseBlock(
    (conv_dw): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
    (bn_dw): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw3_2): DepthWiseBlock(
    (conv_dw): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
    (bn_dw): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw4_1): DepthWiseBlock(
    (conv_dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
    (bn_dw): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw4_2): DepthWiseBlock(
    (conv_dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
    (bn_dw): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_1): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_2): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_3): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_4): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_5): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_6): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw6): DepthWiseBlock(
    (conv_dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)
    (bn_dw): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=1)
  (fc): Linear(in_features=1024, out_features=100, bias=True)
)
09:42:35: ============================================================
09:42:35: ============================================================
09:42:35: MobileNet
09:42:35: MobileNet
09:42:35: ============================================================
09:42:35: ============================================================
09:42:35: ============================================================
09:42:35: ============================================================
09:42:35: Prune mode: magnitude
09:42:35: Prune mode: magnitude
09:42:35: Growth mode: momentum
09:42:35: Growth mode: momentum
09:42:35: Redistribution mode: momentum
09:42:35: Redistribution mode: momentum
09:42:35: ============================================================
09:42:35: ============================================================
09:42:36: Train Epoch: 1 [0/45000 (0%)]	Loss: -0.048067
09:42:36: Train Epoch: 1 [0/45000 (0%)]	Loss: -0.048067
09:42:40: Train Epoch: 1 [10000/45000 (22%)]	Loss: -14982227951616.000000
09:42:40: Train Epoch: 1 [10000/45000 (22%)]	Loss: -14982227951616.000000
09:42:45: Train Epoch: 1 [20000/45000 (44%)]	Loss: nan
09:42:45: Train Epoch: 1 [20000/45000 (44%)]	Loss: nan
09:42:49: Train Epoch: 1 [30000/45000 (67%)]	Loss: nan
09:42:49: Train Epoch: 1 [30000/45000 (67%)]	Loss: nan
09:42:53: Train Epoch: 1 [40000/45000 (89%)]	Loss: nan
09:42:53: Train Epoch: 1 [40000/45000 (89%)]	Loss: nan
09:42:58: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:42:58: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:42:58: Current learning rate: 0.1. Time taken for epoch: 22.69 seconds.

09:42:58: Current learning rate: 0.1. Time taken for epoch: 22.69 seconds.

09:42:58: Train Epoch: 2 [0/45000 (0%)]	Loss: nan
09:42:58: Train Epoch: 2 [0/45000 (0%)]	Loss: nan
09:43:03: Train Epoch: 2 [10000/45000 (22%)]	Loss: nan
09:43:03: Train Epoch: 2 [10000/45000 (22%)]	Loss: nan
09:43:08: Train Epoch: 2 [20000/45000 (44%)]	Loss: nan
09:43:08: Train Epoch: 2 [20000/45000 (44%)]	Loss: nan
09:43:12: Train Epoch: 2 [30000/45000 (67%)]	Loss: nan
09:43:12: Train Epoch: 2 [30000/45000 (67%)]	Loss: nan
09:43:17: Train Epoch: 2 [40000/45000 (89%)]	Loss: nan
09:43:17: Train Epoch: 2 [40000/45000 (89%)]	Loss: nan
09:43:21: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:43:21: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:43:21: Current learning rate: 0.1. Time taken for epoch: 22.81 seconds.

09:43:21: Current learning rate: 0.1. Time taken for epoch: 22.81 seconds.

09:43:21: Train Epoch: 3 [0/45000 (0%)]	Loss: nan
09:43:21: Train Epoch: 3 [0/45000 (0%)]	Loss: nan
09:43:26: Train Epoch: 3 [10000/45000 (22%)]	Loss: nan
09:43:26: Train Epoch: 3 [10000/45000 (22%)]	Loss: nan
09:43:30: Train Epoch: 3 [20000/45000 (44%)]	Loss: nan
09:43:30: Train Epoch: 3 [20000/45000 (44%)]	Loss: nan
09:43:34: Train Epoch: 3 [30000/45000 (67%)]	Loss: nan
09:43:34: Train Epoch: 3 [30000/45000 (67%)]	Loss: nan
09:43:39: Train Epoch: 3 [40000/45000 (89%)]	Loss: nan
09:43:39: Train Epoch: 3 [40000/45000 (89%)]	Loss: nan
09:43:43: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:43:43: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:43:43: Current learning rate: 0.1. Time taken for epoch: 22.02 seconds.

09:43:43: Current learning rate: 0.1. Time taken for epoch: 22.02 seconds.

09:43:43: Train Epoch: 4 [0/45000 (0%)]	Loss: nan
09:43:43: Train Epoch: 4 [0/45000 (0%)]	Loss: nan
09:43:48: Train Epoch: 4 [10000/45000 (22%)]	Loss: nan
09:43:48: Train Epoch: 4 [10000/45000 (22%)]	Loss: nan
09:43:52: Train Epoch: 4 [20000/45000 (44%)]	Loss: nan
09:43:52: Train Epoch: 4 [20000/45000 (44%)]	Loss: nan
09:43:57: Train Epoch: 4 [30000/45000 (67%)]	Loss: nan
09:43:57: Train Epoch: 4 [30000/45000 (67%)]	Loss: nan
09:44:02: Train Epoch: 4 [40000/45000 (89%)]	Loss: nan
09:44:02: Train Epoch: 4 [40000/45000 (89%)]	Loss: nan
09:44:05: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:44:05: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:44:05: Current learning rate: 0.1. Time taken for epoch: 22.86 seconds.

09:44:05: Current learning rate: 0.1. Time taken for epoch: 22.86 seconds.

09:44:06: Train Epoch: 5 [0/45000 (0%)]	Loss: nan
09:44:06: Train Epoch: 5 [0/45000 (0%)]	Loss: nan
09:44:11: Train Epoch: 5 [10000/45000 (22%)]	Loss: nan
09:44:11: Train Epoch: 5 [10000/45000 (22%)]	Loss: nan
09:44:15: Train Epoch: 5 [20000/45000 (44%)]	Loss: nan
09:44:15: Train Epoch: 5 [20000/45000 (44%)]	Loss: nan
09:44:20: Train Epoch: 5 [30000/45000 (67%)]	Loss: nan
09:44:20: Train Epoch: 5 [30000/45000 (67%)]	Loss: nan
09:44:24: Train Epoch: 5 [40000/45000 (89%)]	Loss: nan
09:44:24: Train Epoch: 5 [40000/45000 (89%)]	Loss: nan
09:44:28: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:44:28: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:44:28: Current learning rate: 0.1. Time taken for epoch: 22.35 seconds.

09:44:28: Current learning rate: 0.1. Time taken for epoch: 22.35 seconds.

09:44:28: Train Epoch: 6 [0/45000 (0%)]	Loss: nan
09:44:28: Train Epoch: 6 [0/45000 (0%)]	Loss: nan
09:44:33: Train Epoch: 6 [10000/45000 (22%)]	Loss: nan
09:44:33: Train Epoch: 6 [10000/45000 (22%)]	Loss: nan
09:44:37: Train Epoch: 6 [20000/45000 (44%)]	Loss: nan
09:44:37: Train Epoch: 6 [20000/45000 (44%)]	Loss: nan
09:44:42: Train Epoch: 6 [30000/45000 (67%)]	Loss: nan
09:44:42: Train Epoch: 6 [30000/45000 (67%)]	Loss: nan
09:44:46: Train Epoch: 6 [40000/45000 (89%)]	Loss: nan
09:44:46: Train Epoch: 6 [40000/45000 (89%)]	Loss: nan
09:44:50: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:44:50: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:44:50: Current learning rate: 0.1. Time taken for epoch: 22.27 seconds.

09:44:50: Current learning rate: 0.1. Time taken for epoch: 22.27 seconds.

09:44:51: Train Epoch: 7 [0/45000 (0%)]	Loss: nan
09:44:51: Train Epoch: 7 [0/45000 (0%)]	Loss: nan
09:44:56: Train Epoch: 7 [10000/45000 (22%)]	Loss: nan
09:44:56: Train Epoch: 7 [10000/45000 (22%)]	Loss: nan
09:45:00: Train Epoch: 7 [20000/45000 (44%)]	Loss: nan
09:45:00: Train Epoch: 7 [20000/45000 (44%)]	Loss: nan
09:45:05: Train Epoch: 7 [30000/45000 (67%)]	Loss: nan
09:45:05: Train Epoch: 7 [30000/45000 (67%)]	Loss: nan
09:45:09: Train Epoch: 7 [40000/45000 (89%)]	Loss: nan
09:45:09: Train Epoch: 7 [40000/45000 (89%)]	Loss: nan
09:45:13: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:45:13: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:45:13: Current learning rate: 0.1. Time taken for epoch: 23.27 seconds.

09:45:13: Current learning rate: 0.1. Time taken for epoch: 23.27 seconds.

09:45:14: Train Epoch: 8 [0/45000 (0%)]	Loss: nan
09:45:14: Train Epoch: 8 [0/45000 (0%)]	Loss: nan
09:45:19: Train Epoch: 8 [10000/45000 (22%)]	Loss: nan
09:45:19: Train Epoch: 8 [10000/45000 (22%)]	Loss: nan
09:45:23: Train Epoch: 8 [20000/45000 (44%)]	Loss: nan
09:45:23: Train Epoch: 8 [20000/45000 (44%)]	Loss: nan
09:45:27: Train Epoch: 8 [30000/45000 (67%)]	Loss: nan
09:45:27: Train Epoch: 8 [30000/45000 (67%)]	Loss: nan
09:45:32: Train Epoch: 8 [40000/45000 (89%)]	Loss: nan
09:45:32: Train Epoch: 8 [40000/45000 (89%)]	Loss: nan
09:45:35: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:45:35: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:45:35: Current learning rate: 0.1. Time taken for epoch: 22.09 seconds.

09:45:35: Current learning rate: 0.1. Time taken for epoch: 22.09 seconds.

09:45:36: Train Epoch: 9 [0/45000 (0%)]	Loss: nan
09:45:36: Train Epoch: 9 [0/45000 (0%)]	Loss: nan
09:45:41: Train Epoch: 9 [10000/45000 (22%)]	Loss: nan
09:45:41: Train Epoch: 9 [10000/45000 (22%)]	Loss: nan
09:45:45: Train Epoch: 9 [20000/45000 (44%)]	Loss: nan
09:45:45: Train Epoch: 9 [20000/45000 (44%)]	Loss: nan
09:45:49: Train Epoch: 9 [30000/45000 (67%)]	Loss: nan
09:45:49: Train Epoch: 9 [30000/45000 (67%)]	Loss: nan
09:45:54: Train Epoch: 9 [40000/45000 (89%)]	Loss: nan
09:45:54: Train Epoch: 9 [40000/45000 (89%)]	Loss: nan
09:45:58: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:45:58: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:45:58: Current learning rate: 0.1. Time taken for epoch: 22.65 seconds.

09:45:58: Current learning rate: 0.1. Time taken for epoch: 22.65 seconds.

09:45:59: Train Epoch: 10 [0/45000 (0%)]	Loss: nan
09:45:59: Train Epoch: 10 [0/45000 (0%)]	Loss: nan
09:46:04: Train Epoch: 10 [10000/45000 (22%)]	Loss: nan
09:46:04: Train Epoch: 10 [10000/45000 (22%)]	Loss: nan
09:46:08: Train Epoch: 10 [20000/45000 (44%)]	Loss: nan
09:46:08: Train Epoch: 10 [20000/45000 (44%)]	Loss: nan
09:46:13: Train Epoch: 10 [30000/45000 (67%)]	Loss: nan
09:46:13: Train Epoch: 10 [30000/45000 (67%)]	Loss: nan
09:46:17: Train Epoch: 10 [40000/45000 (89%)]	Loss: nan
09:46:17: Train Epoch: 10 [40000/45000 (89%)]	Loss: nan
09:46:21: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:46:21: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:46:21: Current learning rate: 0.1. Time taken for epoch: 22.63 seconds.

09:46:21: Current learning rate: 0.1. Time taken for epoch: 22.63 seconds.

09:46:21: Train Epoch: 11 [0/45000 (0%)]	Loss: nan
09:46:21: Train Epoch: 11 [0/45000 (0%)]	Loss: nan
09:46:26: Train Epoch: 11 [10000/45000 (22%)]	Loss: nan
09:46:26: Train Epoch: 11 [10000/45000 (22%)]	Loss: nan
09:46:30: Train Epoch: 11 [20000/45000 (44%)]	Loss: nan
09:46:30: Train Epoch: 11 [20000/45000 (44%)]	Loss: nan
09:46:35: Train Epoch: 11 [30000/45000 (67%)]	Loss: nan
09:46:35: Train Epoch: 11 [30000/45000 (67%)]	Loss: nan
09:46:39: Train Epoch: 11 [40000/45000 (89%)]	Loss: nan
09:46:39: Train Epoch: 11 [40000/45000 (89%)]	Loss: nan
09:46:43: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:46:43: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:46:43: Current learning rate: 0.1. Time taken for epoch: 22.07 seconds.

09:46:43: Current learning rate: 0.1. Time taken for epoch: 22.07 seconds.

09:46:43: Train Epoch: 12 [0/45000 (0%)]	Loss: nan
09:46:43: Train Epoch: 12 [0/45000 (0%)]	Loss: nan
09:46:48: Train Epoch: 12 [10000/45000 (22%)]	Loss: nan
09:46:48: Train Epoch: 12 [10000/45000 (22%)]	Loss: nan
09:46:52: Train Epoch: 12 [20000/45000 (44%)]	Loss: nan
09:46:52: Train Epoch: 12 [20000/45000 (44%)]	Loss: nan
09:46:58: Train Epoch: 12 [30000/45000 (67%)]	Loss: nan
09:46:58: Train Epoch: 12 [30000/45000 (67%)]	Loss: nan
09:47:02: Train Epoch: 12 [40000/45000 (89%)]	Loss: nan
09:47:02: Train Epoch: 12 [40000/45000 (89%)]	Loss: nan
09:47:06: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:47:06: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:47:06: Current learning rate: 0.1. Time taken for epoch: 23.42 seconds.

09:47:06: Current learning rate: 0.1. Time taken for epoch: 23.42 seconds.

09:47:07: Train Epoch: 13 [0/45000 (0%)]	Loss: nan
09:47:07: Train Epoch: 13 [0/45000 (0%)]	Loss: nan
09:47:11: Train Epoch: 13 [10000/45000 (22%)]	Loss: nan
09:47:11: Train Epoch: 13 [10000/45000 (22%)]	Loss: nan
09:47:16: Train Epoch: 13 [20000/45000 (44%)]	Loss: nan
09:47:16: Train Epoch: 13 [20000/45000 (44%)]	Loss: nan
09:47:21: Train Epoch: 13 [30000/45000 (67%)]	Loss: nan
09:47:21: Train Epoch: 13 [30000/45000 (67%)]	Loss: nan
09:47:25: Train Epoch: 13 [40000/45000 (89%)]	Loss: nan
09:47:25: Train Epoch: 13 [40000/45000 (89%)]	Loss: nan
09:47:29: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:47:29: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:47:29: Current learning rate: 0.1. Time taken for epoch: 22.66 seconds.

09:47:29: Current learning rate: 0.1. Time taken for epoch: 22.66 seconds.

09:47:30: Train Epoch: 14 [0/45000 (0%)]	Loss: nan
09:47:30: Train Epoch: 14 [0/45000 (0%)]	Loss: nan
09:47:34: Train Epoch: 14 [10000/45000 (22%)]	Loss: nan
09:47:34: Train Epoch: 14 [10000/45000 (22%)]	Loss: nan
09:47:38: Train Epoch: 14 [20000/45000 (44%)]	Loss: nan
09:47:38: Train Epoch: 14 [20000/45000 (44%)]	Loss: nan
09:47:43: Train Epoch: 14 [30000/45000 (67%)]	Loss: nan
09:47:43: Train Epoch: 14 [30000/45000 (67%)]	Loss: nan
09:47:47: Train Epoch: 14 [40000/45000 (89%)]	Loss: nan
09:47:47: Train Epoch: 14 [40000/45000 (89%)]	Loss: nan
09:47:51: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:47:51: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:47:51: Current learning rate: 0.1. Time taken for epoch: 22.10 seconds.

09:47:51: Current learning rate: 0.1. Time taken for epoch: 22.10 seconds.

09:47:52: Train Epoch: 15 [0/45000 (0%)]	Loss: nan
09:47:52: Train Epoch: 15 [0/45000 (0%)]	Loss: nan
09:47:57: Train Epoch: 15 [10000/45000 (22%)]	Loss: nan
09:47:57: Train Epoch: 15 [10000/45000 (22%)]	Loss: nan
09:48:01: Train Epoch: 15 [20000/45000 (44%)]	Loss: nan
09:48:01: Train Epoch: 15 [20000/45000 (44%)]	Loss: nan
09:48:06: Train Epoch: 15 [30000/45000 (67%)]	Loss: nan
09:48:06: Train Epoch: 15 [30000/45000 (67%)]	Loss: nan
09:48:10: Train Epoch: 15 [40000/45000 (89%)]	Loss: nan
09:48:10: Train Epoch: 15 [40000/45000 (89%)]	Loss: nan
09:48:14: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:48:14: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:48:14: Current learning rate: 0.1. Time taken for epoch: 23.19 seconds.

09:48:14: Current learning rate: 0.1. Time taken for epoch: 23.19 seconds.

09:48:15: Train Epoch: 16 [0/45000 (0%)]	Loss: nan
09:48:15: Train Epoch: 16 [0/45000 (0%)]	Loss: nan
09:48:19: Train Epoch: 16 [10000/45000 (22%)]	Loss: nan
09:48:19: Train Epoch: 16 [10000/45000 (22%)]	Loss: nan
09:48:24: Train Epoch: 16 [20000/45000 (44%)]	Loss: nan
09:48:24: Train Epoch: 16 [20000/45000 (44%)]	Loss: nan
09:48:28: Train Epoch: 16 [30000/45000 (67%)]	Loss: nan
09:48:28: Train Epoch: 16 [30000/45000 (67%)]	Loss: nan
09:48:32: Train Epoch: 16 [40000/45000 (89%)]	Loss: nan
09:48:32: Train Epoch: 16 [40000/45000 (89%)]	Loss: nan
09:48:36: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:48:36: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:48:36: Current learning rate: 0.1. Time taken for epoch: 21.99 seconds.

09:48:36: Current learning rate: 0.1. Time taken for epoch: 21.99 seconds.

09:48:37: Train Epoch: 17 [0/45000 (0%)]	Loss: nan
09:48:37: Train Epoch: 17 [0/45000 (0%)]	Loss: nan
09:48:42: Train Epoch: 17 [10000/45000 (22%)]	Loss: nan
09:48:42: Train Epoch: 17 [10000/45000 (22%)]	Loss: nan
09:48:46: Train Epoch: 17 [20000/45000 (44%)]	Loss: nan
09:48:46: Train Epoch: 17 [20000/45000 (44%)]	Loss: nan
09:48:50: Train Epoch: 17 [30000/45000 (67%)]	Loss: nan
09:48:50: Train Epoch: 17 [30000/45000 (67%)]	Loss: nan
09:48:55: Train Epoch: 17 [40000/45000 (89%)]	Loss: nan
09:48:55: Train Epoch: 17 [40000/45000 (89%)]	Loss: nan
09:48:59: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:48:59: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:48:59: Current learning rate: 0.1. Time taken for epoch: 22.83 seconds.

09:48:59: Current learning rate: 0.1. Time taken for epoch: 22.83 seconds.

09:49:00: Train Epoch: 18 [0/45000 (0%)]	Loss: nan
09:49:00: Train Epoch: 18 [0/45000 (0%)]	Loss: nan
09:49:04: Train Epoch: 18 [10000/45000 (22%)]	Loss: nan
09:49:04: Train Epoch: 18 [10000/45000 (22%)]	Loss: nan
09:49:09: Train Epoch: 18 [20000/45000 (44%)]	Loss: nan
09:49:09: Train Epoch: 18 [20000/45000 (44%)]	Loss: nan
09:49:14: Train Epoch: 18 [30000/45000 (67%)]	Loss: nan
09:49:14: Train Epoch: 18 [30000/45000 (67%)]	Loss: nan
09:49:18: Train Epoch: 18 [40000/45000 (89%)]	Loss: nan
09:49:18: Train Epoch: 18 [40000/45000 (89%)]	Loss: nan
09:49:22: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:49:22: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:49:22: Current learning rate: 0.1. Time taken for epoch: 22.70 seconds.

09:49:22: Current learning rate: 0.1. Time taken for epoch: 22.70 seconds.

09:49:22: Train Epoch: 19 [0/45000 (0%)]	Loss: nan
09:49:22: Train Epoch: 19 [0/45000 (0%)]	Loss: nan
09:49:27: Train Epoch: 19 [10000/45000 (22%)]	Loss: nan
09:49:27: Train Epoch: 19 [10000/45000 (22%)]	Loss: nan
09:49:31: Train Epoch: 19 [20000/45000 (44%)]	Loss: nan
09:49:31: Train Epoch: 19 [20000/45000 (44%)]	Loss: nan
09:49:36: Train Epoch: 19 [30000/45000 (67%)]	Loss: nan
09:49:36: Train Epoch: 19 [30000/45000 (67%)]	Loss: nan
09:49:40: Train Epoch: 19 [40000/45000 (89%)]	Loss: nan
09:49:40: Train Epoch: 19 [40000/45000 (89%)]	Loss: nan
09:49:44: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:49:44: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:49:44: Current learning rate: 0.1. Time taken for epoch: 21.99 seconds.

09:49:44: Current learning rate: 0.1. Time taken for epoch: 21.99 seconds.

09:49:44: Train Epoch: 20 [0/45000 (0%)]	Loss: nan
09:49:44: Train Epoch: 20 [0/45000 (0%)]	Loss: nan
09:49:49: Train Epoch: 20 [10000/45000 (22%)]	Loss: nan
09:49:49: Train Epoch: 20 [10000/45000 (22%)]	Loss: nan
09:49:53: Train Epoch: 20 [20000/45000 (44%)]	Loss: nan
09:49:53: Train Epoch: 20 [20000/45000 (44%)]	Loss: nan
09:49:58: Train Epoch: 20 [30000/45000 (67%)]	Loss: nan
09:49:58: Train Epoch: 20 [30000/45000 (67%)]	Loss: nan
09:50:03: Train Epoch: 20 [40000/45000 (89%)]	Loss: nan
09:50:03: Train Epoch: 20 [40000/45000 (89%)]	Loss: nan
09:50:07: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:50:07: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:50:07: Current learning rate: 0.1. Time taken for epoch: 22.94 seconds.

09:50:07: Current learning rate: 0.1. Time taken for epoch: 22.94 seconds.

09:50:07: Train Epoch: 21 [0/45000 (0%)]	Loss: nan
09:50:07: Train Epoch: 21 [0/45000 (0%)]	Loss: nan
09:50:12: Train Epoch: 21 [10000/45000 (22%)]	Loss: nan
09:50:12: Train Epoch: 21 [10000/45000 (22%)]	Loss: nan
09:50:16: Train Epoch: 21 [20000/45000 (44%)]	Loss: nan
09:50:16: Train Epoch: 21 [20000/45000 (44%)]	Loss: nan
09:50:21: Train Epoch: 21 [30000/45000 (67%)]	Loss: nan
09:50:21: Train Epoch: 21 [30000/45000 (67%)]	Loss: nan
09:50:25: Train Epoch: 21 [40000/45000 (89%)]	Loss: nan
09:50:25: Train Epoch: 21 [40000/45000 (89%)]	Loss: nan
09:50:29: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:50:29: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:50:29: Current learning rate: 0.1. Time taken for epoch: 22.39 seconds.

09:50:29: Current learning rate: 0.1. Time taken for epoch: 22.39 seconds.

09:50:29: Train Epoch: 22 [0/45000 (0%)]	Loss: nan
09:50:29: Train Epoch: 22 [0/45000 (0%)]	Loss: nan
09:50:34: Train Epoch: 22 [10000/45000 (22%)]	Loss: nan
09:50:34: Train Epoch: 22 [10000/45000 (22%)]	Loss: nan
09:50:38: Train Epoch: 22 [20000/45000 (44%)]	Loss: nan
09:50:38: Train Epoch: 22 [20000/45000 (44%)]	Loss: nan
09:50:43: Train Epoch: 22 [30000/45000 (67%)]	Loss: nan
09:50:43: Train Epoch: 22 [30000/45000 (67%)]	Loss: nan
09:50:47: Train Epoch: 22 [40000/45000 (89%)]	Loss: nan
09:50:47: Train Epoch: 22 [40000/45000 (89%)]	Loss: nan
09:50:51: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:50:51: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:50:51: Current learning rate: 0.1. Time taken for epoch: 22.07 seconds.

09:50:51: Current learning rate: 0.1. Time taken for epoch: 22.07 seconds.

09:50:52: Train Epoch: 23 [0/45000 (0%)]	Loss: nan
09:50:52: Train Epoch: 23 [0/45000 (0%)]	Loss: nan
09:50:57: Train Epoch: 23 [10000/45000 (22%)]	Loss: nan
09:50:57: Train Epoch: 23 [10000/45000 (22%)]	Loss: nan
09:51:01: Train Epoch: 23 [20000/45000 (44%)]	Loss: nan
09:51:01: Train Epoch: 23 [20000/45000 (44%)]	Loss: nan
09:51:06: Train Epoch: 23 [30000/45000 (67%)]	Loss: nan
09:51:06: Train Epoch: 23 [30000/45000 (67%)]	Loss: nan
09:51:10: Train Epoch: 23 [40000/45000 (89%)]	Loss: nan
09:51:10: Train Epoch: 23 [40000/45000 (89%)]	Loss: nan
09:51:14: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:51:14: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:51:14: Current learning rate: 0.1. Time taken for epoch: 23.08 seconds.

09:51:14: Current learning rate: 0.1. Time taken for epoch: 23.08 seconds.

09:51:15: Train Epoch: 24 [0/45000 (0%)]	Loss: nan
09:51:15: Train Epoch: 24 [0/45000 (0%)]	Loss: nan
09:51:19: Train Epoch: 24 [10000/45000 (22%)]	Loss: nan
09:51:19: Train Epoch: 24 [10000/45000 (22%)]	Loss: nan
09:51:24: Train Epoch: 24 [20000/45000 (44%)]	Loss: nan
09:51:24: Train Epoch: 24 [20000/45000 (44%)]	Loss: nan
09:51:28: Train Epoch: 24 [30000/45000 (67%)]	Loss: nan
09:51:28: Train Epoch: 24 [30000/45000 (67%)]	Loss: nan
09:51:33: Train Epoch: 24 [40000/45000 (89%)]	Loss: nan
09:51:33: Train Epoch: 24 [40000/45000 (89%)]	Loss: nan
09:51:36: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:51:36: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:51:36: Current learning rate: 0.1. Time taken for epoch: 22.01 seconds.

09:51:36: Current learning rate: 0.1. Time taken for epoch: 22.01 seconds.

09:51:37: Train Epoch: 25 [0/45000 (0%)]	Loss: nan
09:51:37: Train Epoch: 25 [0/45000 (0%)]	Loss: nan
09:51:41: Train Epoch: 25 [10000/45000 (22%)]	Loss: nan
09:51:41: Train Epoch: 25 [10000/45000 (22%)]	Loss: nan
09:51:46: Train Epoch: 25 [20000/45000 (44%)]	Loss: nan
09:51:46: Train Epoch: 25 [20000/45000 (44%)]	Loss: nan
09:51:50: Train Epoch: 25 [30000/45000 (67%)]	Loss: nan
09:51:50: Train Epoch: 25 [30000/45000 (67%)]	Loss: nan
09:51:55: Train Epoch: 25 [40000/45000 (89%)]	Loss: nan
09:51:55: Train Epoch: 25 [40000/45000 (89%)]	Loss: nan
09:51:59: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:51:59: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:51:59: Current learning rate: 0.1. Time taken for epoch: 22.76 seconds.

09:51:59: Current learning rate: 0.1. Time taken for epoch: 22.76 seconds.

09:51:59: Train Epoch: 26 [0/45000 (0%)]	Loss: nan
09:51:59: Train Epoch: 26 [0/45000 (0%)]	Loss: nan
09:52:04: Train Epoch: 26 [10000/45000 (22%)]	Loss: nan
09:52:04: Train Epoch: 26 [10000/45000 (22%)]	Loss: nan
09:52:09: Train Epoch: 26 [20000/45000 (44%)]	Loss: nan
09:52:09: Train Epoch: 26 [20000/45000 (44%)]	Loss: nan
09:52:14: Train Epoch: 26 [30000/45000 (67%)]	Loss: nan
09:52:14: Train Epoch: 26 [30000/45000 (67%)]	Loss: nan
09:52:18: Train Epoch: 26 [40000/45000 (89%)]	Loss: nan
09:52:18: Train Epoch: 26 [40000/45000 (89%)]	Loss: nan
09:52:22: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:52:22: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:52:22: Current learning rate: 0.1. Time taken for epoch: 22.93 seconds.

09:52:22: Current learning rate: 0.1. Time taken for epoch: 22.93 seconds.

09:52:23: Train Epoch: 27 [0/45000 (0%)]	Loss: nan
09:52:23: Train Epoch: 27 [0/45000 (0%)]	Loss: nan
09:52:27: Train Epoch: 27 [10000/45000 (22%)]	Loss: nan
09:52:27: Train Epoch: 27 [10000/45000 (22%)]	Loss: nan
09:52:31: Train Epoch: 27 [20000/45000 (44%)]	Loss: nan
09:52:31: Train Epoch: 27 [20000/45000 (44%)]	Loss: nan
09:52:36: Train Epoch: 27 [30000/45000 (67%)]	Loss: nan
09:52:36: Train Epoch: 27 [30000/45000 (67%)]	Loss: nan
09:52:40: Train Epoch: 27 [40000/45000 (89%)]	Loss: nan
09:52:40: Train Epoch: 27 [40000/45000 (89%)]	Loss: nan
09:52:44: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:52:44: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:52:44: Current learning rate: 0.1. Time taken for epoch: 22.14 seconds.

09:52:44: Current learning rate: 0.1. Time taken for epoch: 22.14 seconds.

09:52:45: Train Epoch: 28 [0/45000 (0%)]	Loss: nan
09:52:45: Train Epoch: 28 [0/45000 (0%)]	Loss: nan
09:52:49: Train Epoch: 28 [10000/45000 (22%)]	Loss: nan
09:52:49: Train Epoch: 28 [10000/45000 (22%)]	Loss: nan
09:52:54: Train Epoch: 28 [20000/45000 (44%)]	Loss: nan
09:52:54: Train Epoch: 28 [20000/45000 (44%)]	Loss: nan
09:52:58: Train Epoch: 28 [30000/45000 (67%)]	Loss: nan
09:52:58: Train Epoch: 28 [30000/45000 (67%)]	Loss: nan
09:53:03: Train Epoch: 28 [40000/45000 (89%)]	Loss: nan
09:53:03: Train Epoch: 28 [40000/45000 (89%)]	Loss: nan
09:53:07: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:53:07: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:53:07: Current learning rate: 0.1. Time taken for epoch: 22.78 seconds.

09:53:07: Current learning rate: 0.1. Time taken for epoch: 22.78 seconds.

09:53:07: Train Epoch: 29 [0/45000 (0%)]	Loss: nan
09:53:07: Train Epoch: 29 [0/45000 (0%)]	Loss: nan
09:53:12: Train Epoch: 29 [10000/45000 (22%)]	Loss: nan
09:53:12: Train Epoch: 29 [10000/45000 (22%)]	Loss: nan
09:53:17: Train Epoch: 29 [20000/45000 (44%)]	Loss: nan
09:53:17: Train Epoch: 29 [20000/45000 (44%)]	Loss: nan
09:53:21: Train Epoch: 29 [30000/45000 (67%)]	Loss: nan
09:53:21: Train Epoch: 29 [30000/45000 (67%)]	Loss: nan
09:53:25: Train Epoch: 29 [40000/45000 (89%)]	Loss: nan
09:53:25: Train Epoch: 29 [40000/45000 (89%)]	Loss: nan
09:53:29: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:53:29: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:53:29: Current learning rate: 0.1. Time taken for epoch: 22.32 seconds.

09:53:29: Current learning rate: 0.1. Time taken for epoch: 22.32 seconds.

09:53:30: Train Epoch: 30 [0/45000 (0%)]	Loss: nan
09:53:30: Train Epoch: 30 [0/45000 (0%)]	Loss: nan
09:53:34: Train Epoch: 30 [10000/45000 (22%)]	Loss: nan
09:53:34: Train Epoch: 30 [10000/45000 (22%)]	Loss: nan
09:53:39: Train Epoch: 30 [20000/45000 (44%)]	Loss: nan
09:53:39: Train Epoch: 30 [20000/45000 (44%)]	Loss: nan
09:53:43: Train Epoch: 30 [30000/45000 (67%)]	Loss: nan
09:53:43: Train Epoch: 30 [30000/45000 (67%)]	Loss: nan
09:53:47: Train Epoch: 30 [40000/45000 (89%)]	Loss: nan
09:53:47: Train Epoch: 30 [40000/45000 (89%)]	Loss: nan
09:53:51: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:53:51: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:53:51: Current learning rate: 0.1. Time taken for epoch: 22.06 seconds.

09:53:51: Current learning rate: 0.1. Time taken for epoch: 22.06 seconds.

09:53:52: Train Epoch: 31 [0/45000 (0%)]	Loss: nan
09:53:52: Train Epoch: 31 [0/45000 (0%)]	Loss: nan
09:53:57: Train Epoch: 31 [10000/45000 (22%)]	Loss: nan
09:53:57: Train Epoch: 31 [10000/45000 (22%)]	Loss: nan
09:54:02: Train Epoch: 31 [20000/45000 (44%)]	Loss: nan
09:54:02: Train Epoch: 31 [20000/45000 (44%)]	Loss: nan
09:54:06: Train Epoch: 31 [30000/45000 (67%)]	Loss: nan
09:54:06: Train Epoch: 31 [30000/45000 (67%)]	Loss: nan
09:54:10: Train Epoch: 31 [40000/45000 (89%)]	Loss: nan
09:54:10: Train Epoch: 31 [40000/45000 (89%)]	Loss: nan
09:54:14: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:54:14: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:54:14: Current learning rate: 0.1. Time taken for epoch: 23.15 seconds.

09:54:14: Current learning rate: 0.1. Time taken for epoch: 23.15 seconds.

09:54:15: Train Epoch: 32 [0/45000 (0%)]	Loss: nan
09:54:15: Train Epoch: 32 [0/45000 (0%)]	Loss: nan
09:54:19: Train Epoch: 32 [10000/45000 (22%)]	Loss: nan
09:54:19: Train Epoch: 32 [10000/45000 (22%)]	Loss: nan
09:54:24: Train Epoch: 32 [20000/45000 (44%)]	Loss: nan
09:54:24: Train Epoch: 32 [20000/45000 (44%)]	Loss: nan
09:54:28: Train Epoch: 32 [30000/45000 (67%)]	Loss: nan
09:54:28: Train Epoch: 32 [30000/45000 (67%)]	Loss: nan
09:54:32: Train Epoch: 32 [40000/45000 (89%)]	Loss: nan
09:54:32: Train Epoch: 32 [40000/45000 (89%)]	Loss: nan
09:54:36: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:54:36: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:54:36: Current learning rate: 0.1. Time taken for epoch: 21.76 seconds.

09:54:36: Current learning rate: 0.1. Time taken for epoch: 21.76 seconds.

09:54:37: Train Epoch: 33 [0/45000 (0%)]	Loss: nan
09:54:37: Train Epoch: 33 [0/45000 (0%)]	Loss: nan
09:54:41: Train Epoch: 33 [10000/45000 (22%)]	Loss: nan
09:54:41: Train Epoch: 33 [10000/45000 (22%)]	Loss: nan
09:54:46: Train Epoch: 33 [20000/45000 (44%)]	Loss: nan
09:54:46: Train Epoch: 33 [20000/45000 (44%)]	Loss: nan
09:54:50: Train Epoch: 33 [30000/45000 (67%)]	Loss: nan
09:54:50: Train Epoch: 33 [30000/45000 (67%)]	Loss: nan
09:54:55: Train Epoch: 33 [40000/45000 (89%)]	Loss: nan
09:54:55: Train Epoch: 33 [40000/45000 (89%)]	Loss: nan
09:54:59: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:54:59: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:54:59: Current learning rate: 0.1. Time taken for epoch: 22.64 seconds.

09:54:59: Current learning rate: 0.1. Time taken for epoch: 22.64 seconds.

09:54:59: Train Epoch: 34 [0/45000 (0%)]	Loss: nan
09:54:59: Train Epoch: 34 [0/45000 (0%)]	Loss: nan
09:55:04: Train Epoch: 34 [10000/45000 (22%)]	Loss: nan
09:55:04: Train Epoch: 34 [10000/45000 (22%)]	Loss: nan
09:55:08: Train Epoch: 34 [20000/45000 (44%)]	Loss: nan
09:55:08: Train Epoch: 34 [20000/45000 (44%)]	Loss: nan
09:55:13: Train Epoch: 34 [30000/45000 (67%)]	Loss: nan
09:55:13: Train Epoch: 34 [30000/45000 (67%)]	Loss: nan
09:55:18: Train Epoch: 34 [40000/45000 (89%)]	Loss: nan
09:55:18: Train Epoch: 34 [40000/45000 (89%)]	Loss: nan
09:55:21: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:55:21: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:55:21: Current learning rate: 0.1. Time taken for epoch: 22.64 seconds.

09:55:21: Current learning rate: 0.1. Time taken for epoch: 22.64 seconds.

09:55:22: Train Epoch: 35 [0/45000 (0%)]	Loss: nan
09:55:22: Train Epoch: 35 [0/45000 (0%)]	Loss: nan
09:55:27: Train Epoch: 35 [10000/45000 (22%)]	Loss: nan
09:55:27: Train Epoch: 35 [10000/45000 (22%)]	Loss: nan
09:55:31: Train Epoch: 35 [20000/45000 (44%)]	Loss: nan
09:55:31: Train Epoch: 35 [20000/45000 (44%)]	Loss: nan
09:55:35: Train Epoch: 35 [30000/45000 (67%)]	Loss: nan
09:55:35: Train Epoch: 35 [30000/45000 (67%)]	Loss: nan
09:55:40: Train Epoch: 35 [40000/45000 (89%)]	Loss: nan
09:55:40: Train Epoch: 35 [40000/45000 (89%)]	Loss: nan
09:55:43: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:55:43: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:55:44: Current learning rate: 0.1. Time taken for epoch: 22.19 seconds.

09:55:44: Current learning rate: 0.1. Time taken for epoch: 22.19 seconds.

09:55:44: Train Epoch: 36 [0/45000 (0%)]	Loss: nan
09:55:44: Train Epoch: 36 [0/45000 (0%)]	Loss: nan
09:55:49: Train Epoch: 36 [10000/45000 (22%)]	Loss: nan
09:55:49: Train Epoch: 36 [10000/45000 (22%)]	Loss: nan
09:55:53: Train Epoch: 36 [20000/45000 (44%)]	Loss: nan
09:55:53: Train Epoch: 36 [20000/45000 (44%)]	Loss: nan
09:55:58: Train Epoch: 36 [30000/45000 (67%)]	Loss: nan
09:55:58: Train Epoch: 36 [30000/45000 (67%)]	Loss: nan
09:56:03: Train Epoch: 36 [40000/45000 (89%)]	Loss: nan
09:56:03: Train Epoch: 36 [40000/45000 (89%)]	Loss: nan
09:56:06: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:56:06: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:56:06: Current learning rate: 0.1. Time taken for epoch: 22.74 seconds.

09:56:06: Current learning rate: 0.1. Time taken for epoch: 22.74 seconds.

09:56:07: Train Epoch: 37 [0/45000 (0%)]	Loss: nan
09:56:07: Train Epoch: 37 [0/45000 (0%)]	Loss: nan
09:56:11: Train Epoch: 37 [10000/45000 (22%)]	Loss: nan
09:56:11: Train Epoch: 37 [10000/45000 (22%)]	Loss: nan
09:56:16: Train Epoch: 37 [20000/45000 (44%)]	Loss: nan
09:56:16: Train Epoch: 37 [20000/45000 (44%)]	Loss: nan
09:56:20: Train Epoch: 37 [30000/45000 (67%)]	Loss: nan
09:56:20: Train Epoch: 37 [30000/45000 (67%)]	Loss: nan
09:56:25: Train Epoch: 37 [40000/45000 (89%)]	Loss: nan
09:56:25: Train Epoch: 37 [40000/45000 (89%)]	Loss: nan
09:56:28: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:56:28: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:56:29: Current learning rate: 0.1. Time taken for epoch: 22.27 seconds.

09:56:29: Current learning rate: 0.1. Time taken for epoch: 22.27 seconds.

09:56:29: Train Epoch: 38 [0/45000 (0%)]	Loss: nan
09:56:29: Train Epoch: 38 [0/45000 (0%)]	Loss: nan
09:56:34: Train Epoch: 38 [10000/45000 (22%)]	Loss: nan
09:56:34: Train Epoch: 38 [10000/45000 (22%)]	Loss: nan
09:56:38: Train Epoch: 38 [20000/45000 (44%)]	Loss: nan
09:56:38: Train Epoch: 38 [20000/45000 (44%)]	Loss: nan
09:56:43: Train Epoch: 38 [30000/45000 (67%)]	Loss: nan
09:56:43: Train Epoch: 38 [30000/45000 (67%)]	Loss: nan
09:56:47: Train Epoch: 38 [40000/45000 (89%)]	Loss: nan
09:56:47: Train Epoch: 38 [40000/45000 (89%)]	Loss: nan
09:56:51: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:56:51: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:56:51: Current learning rate: 0.1. Time taken for epoch: 22.20 seconds.

09:56:51: Current learning rate: 0.1. Time taken for epoch: 22.20 seconds.

09:56:51: Train Epoch: 39 [0/45000 (0%)]	Loss: nan
09:56:51: Train Epoch: 39 [0/45000 (0%)]	Loss: nan
09:56:57: Train Epoch: 39 [10000/45000 (22%)]	Loss: nan
09:56:57: Train Epoch: 39 [10000/45000 (22%)]	Loss: nan
09:57:01: Train Epoch: 39 [20000/45000 (44%)]	Loss: nan
09:57:01: Train Epoch: 39 [20000/45000 (44%)]	Loss: nan
09:57:05: Train Epoch: 39 [30000/45000 (67%)]	Loss: nan
09:57:05: Train Epoch: 39 [30000/45000 (67%)]	Loss: nan
09:57:10: Train Epoch: 39 [40000/45000 (89%)]	Loss: nan
09:57:10: Train Epoch: 39 [40000/45000 (89%)]	Loss: nan
09:57:14: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:57:14: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:57:14: Current learning rate: 0.1. Time taken for epoch: 23.19 seconds.

09:57:14: Current learning rate: 0.1. Time taken for epoch: 23.19 seconds.

09:57:14: Train Epoch: 40 [0/45000 (0%)]	Loss: nan
09:57:14: Train Epoch: 40 [0/45000 (0%)]	Loss: nan
09:57:19: Train Epoch: 40 [10000/45000 (22%)]	Loss: nan
09:57:19: Train Epoch: 40 [10000/45000 (22%)]	Loss: nan
09:57:24: Train Epoch: 40 [20000/45000 (44%)]	Loss: nan
09:57:24: Train Epoch: 40 [20000/45000 (44%)]	Loss: nan
09:57:28: Train Epoch: 40 [30000/45000 (67%)]	Loss: nan
09:57:28: Train Epoch: 40 [30000/45000 (67%)]	Loss: nan
09:57:32: Train Epoch: 40 [40000/45000 (89%)]	Loss: nan
09:57:32: Train Epoch: 40 [40000/45000 (89%)]	Loss: nan
09:57:36: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:57:36: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:57:36: Current learning rate: 0.1. Time taken for epoch: 22.13 seconds.

09:57:36: Current learning rate: 0.1. Time taken for epoch: 22.13 seconds.

09:57:37: Train Epoch: 41 [0/45000 (0%)]	Loss: nan
09:57:37: Train Epoch: 41 [0/45000 (0%)]	Loss: nan
09:57:41: Train Epoch: 41 [10000/45000 (22%)]	Loss: nan
09:57:41: Train Epoch: 41 [10000/45000 (22%)]	Loss: nan
09:57:46: Train Epoch: 41 [20000/45000 (44%)]	Loss: nan
09:57:46: Train Epoch: 41 [20000/45000 (44%)]	Loss: nan
09:57:50: Train Epoch: 41 [30000/45000 (67%)]	Loss: nan
09:57:50: Train Epoch: 41 [30000/45000 (67%)]	Loss: nan
09:57:55: Train Epoch: 41 [40000/45000 (89%)]	Loss: nan
09:57:55: Train Epoch: 41 [40000/45000 (89%)]	Loss: nan
09:57:59: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:57:59: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:57:59: Current learning rate: 0.1. Time taken for epoch: 22.74 seconds.

09:57:59: Current learning rate: 0.1. Time taken for epoch: 22.74 seconds.

09:57:59: Train Epoch: 42 [0/45000 (0%)]	Loss: nan
09:57:59: Train Epoch: 42 [0/45000 (0%)]	Loss: nan
09:58:04: Train Epoch: 42 [10000/45000 (22%)]	Loss: nan
09:58:04: Train Epoch: 42 [10000/45000 (22%)]	Loss: nan
09:58:09: Train Epoch: 42 [20000/45000 (44%)]	Loss: nan
09:58:09: Train Epoch: 42 [20000/45000 (44%)]	Loss: nan
09:59:03: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='MobileNet', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
09:59:03: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='MobileNet', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
09:59:03: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='MobileNet', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
09:59:03: 


09:59:03: 


09:59:03: 


09:59:03: ================================================================================
09:59:03: ================================================================================
09:59:03: ================================================================================
09:59:03: 
Iteration start: 1/1

09:59:03: 
Iteration start: 1/1

09:59:03: 
Iteration start: 1/1

09:59:04: MobileNet(
  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (dw2_1): DepthWiseBlock(
    (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
    (bn_dw): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw2_2): DepthWiseBlock(
    (conv_dw): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
    (bn_dw): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw3_1): DepthWiseBlock(
    (conv_dw): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
    (bn_dw): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw3_2): DepthWiseBlock(
    (conv_dw): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
    (bn_dw): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw4_1): DepthWiseBlock(
    (conv_dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
    (bn_dw): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw4_2): DepthWiseBlock(
    (conv_dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
    (bn_dw): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_1): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_2): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_3): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_4): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_5): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_6): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw6): DepthWiseBlock(
    (conv_dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)
    (bn_dw): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=1)
  (fc): Linear(in_features=1024, out_features=100, bias=True)
)
09:59:04: MobileNet(
  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (dw2_1): DepthWiseBlock(
    (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
    (bn_dw): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw2_2): DepthWiseBlock(
    (conv_dw): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
    (bn_dw): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw3_1): DepthWiseBlock(
    (conv_dw): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
    (bn_dw): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw3_2): DepthWiseBlock(
    (conv_dw): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
    (bn_dw): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw4_1): DepthWiseBlock(
    (conv_dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
    (bn_dw): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw4_2): DepthWiseBlock(
    (conv_dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
    (bn_dw): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_1): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_2): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_3): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_4): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_5): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_6): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw6): DepthWiseBlock(
    (conv_dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)
    (bn_dw): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=1)
  (fc): Linear(in_features=1024, out_features=100, bias=True)
)
09:59:04: MobileNet(
  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (dw2_1): DepthWiseBlock(
    (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
    (bn_dw): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw2_2): DepthWiseBlock(
    (conv_dw): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
    (bn_dw): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw3_1): DepthWiseBlock(
    (conv_dw): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
    (bn_dw): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw3_2): DepthWiseBlock(
    (conv_dw): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
    (bn_dw): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw4_1): DepthWiseBlock(
    (conv_dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
    (bn_dw): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw4_2): DepthWiseBlock(
    (conv_dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
    (bn_dw): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_1): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_2): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_3): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_4): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_5): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_6): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw6): DepthWiseBlock(
    (conv_dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)
    (bn_dw): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=1)
  (fc): Linear(in_features=1024, out_features=100, bias=True)
)
09:59:04: ============================================================
09:59:04: ============================================================
09:59:04: ============================================================
09:59:04: MobileNet
09:59:04: MobileNet
09:59:04: MobileNet
09:59:04: ============================================================
09:59:04: ============================================================
09:59:04: ============================================================
09:59:04: ============================================================
09:59:04: ============================================================
09:59:04: ============================================================
09:59:04: Prune mode: magnitude
09:59:04: Prune mode: magnitude
09:59:04: Prune mode: magnitude
09:59:04: Growth mode: momentum
09:59:04: Growth mode: momentum
09:59:04: Growth mode: momentum
09:59:04: Redistribution mode: momentum
09:59:04: Redistribution mode: momentum
09:59:04: Redistribution mode: momentum
09:59:04: ============================================================
09:59:04: ============================================================
09:59:04: ============================================================
09:59:04: Train Epoch: 1 [0/45000 (0%)]	Loss: -0.048067
09:59:04: Train Epoch: 1 [0/45000 (0%)]	Loss: -0.048067
09:59:04: Train Epoch: 1 [0/45000 (0%)]	Loss: -0.048067
09:59:09: Train Epoch: 1 [10000/45000 (22%)]	Loss: -14982227951616.000000
09:59:09: Train Epoch: 1 [10000/45000 (22%)]	Loss: -14982227951616.000000
09:59:09: Train Epoch: 1 [10000/45000 (22%)]	Loss: -14982227951616.000000
09:59:14: Train Epoch: 1 [20000/45000 (44%)]	Loss: nan
09:59:14: Train Epoch: 1 [20000/45000 (44%)]	Loss: nan
09:59:14: Train Epoch: 1 [20000/45000 (44%)]	Loss: nan
09:59:18: Train Epoch: 1 [30000/45000 (67%)]	Loss: nan
09:59:18: Train Epoch: 1 [30000/45000 (67%)]	Loss: nan
09:59:18: Train Epoch: 1 [30000/45000 (67%)]	Loss: nan
09:59:23: Train Epoch: 1 [40000/45000 (89%)]	Loss: nan
09:59:23: Train Epoch: 1 [40000/45000 (89%)]	Loss: nan
09:59:23: Train Epoch: 1 [40000/45000 (89%)]	Loss: nan
09:59:27: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:59:27: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:59:27: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:59:27: Current learning rate: 0.1. Time taken for epoch: 22.66 seconds.

09:59:27: Current learning rate: 0.1. Time taken for epoch: 22.66 seconds.

09:59:27: Current learning rate: 0.1. Time taken for epoch: 22.66 seconds.

09:59:27: Train Epoch: 2 [0/45000 (0%)]	Loss: nan
09:59:27: Train Epoch: 2 [0/45000 (0%)]	Loss: nan
09:59:27: Train Epoch: 2 [0/45000 (0%)]	Loss: nan
09:59:32: Train Epoch: 2 [10000/45000 (22%)]	Loss: nan
09:59:32: Train Epoch: 2 [10000/45000 (22%)]	Loss: nan
09:59:32: Train Epoch: 2 [10000/45000 (22%)]	Loss: nan
09:59:36: Train Epoch: 2 [20000/45000 (44%)]	Loss: nan
09:59:36: Train Epoch: 2 [20000/45000 (44%)]	Loss: nan
09:59:36: Train Epoch: 2 [20000/45000 (44%)]	Loss: nan
09:59:41: Train Epoch: 2 [30000/45000 (67%)]	Loss: nan
09:59:41: Train Epoch: 2 [30000/45000 (67%)]	Loss: nan
09:59:41: Train Epoch: 2 [30000/45000 (67%)]	Loss: nan
09:59:45: Train Epoch: 2 [40000/45000 (89%)]	Loss: nan
09:59:45: Train Epoch: 2 [40000/45000 (89%)]	Loss: nan
09:59:45: Train Epoch: 2 [40000/45000 (89%)]	Loss: nan
09:59:49: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:59:49: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:59:49: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

09:59:49: Current learning rate: 0.1. Time taken for epoch: 22.15 seconds.

09:59:49: Current learning rate: 0.1. Time taken for epoch: 22.15 seconds.

09:59:49: Current learning rate: 0.1. Time taken for epoch: 22.15 seconds.

09:59:49: Train Epoch: 3 [0/45000 (0%)]	Loss: nan
09:59:49: Train Epoch: 3 [0/45000 (0%)]	Loss: nan
09:59:49: Train Epoch: 3 [0/45000 (0%)]	Loss: nan
09:59:54: Train Epoch: 3 [10000/45000 (22%)]	Loss: nan
09:59:54: Train Epoch: 3 [10000/45000 (22%)]	Loss: nan
09:59:54: Train Epoch: 3 [10000/45000 (22%)]	Loss: nan
09:59:59: Train Epoch: 3 [20000/45000 (44%)]	Loss: nan
09:59:59: Train Epoch: 3 [20000/45000 (44%)]	Loss: nan
09:59:59: Train Epoch: 3 [20000/45000 (44%)]	Loss: nan
10:00:04: Train Epoch: 3 [30000/45000 (67%)]	Loss: nan
10:00:04: Train Epoch: 3 [30000/45000 (67%)]	Loss: nan
10:00:04: Train Epoch: 3 [30000/45000 (67%)]	Loss: nan
10:00:08: Train Epoch: 3 [40000/45000 (89%)]	Loss: nan
10:00:08: Train Epoch: 3 [40000/45000 (89%)]	Loss: nan
10:00:08: Train Epoch: 3 [40000/45000 (89%)]	Loss: nan
10:00:12: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:00:12: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:00:12: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:00:12: Current learning rate: 0.1. Time taken for epoch: 23.05 seconds.

10:00:12: Current learning rate: 0.1. Time taken for epoch: 23.05 seconds.

10:00:12: Current learning rate: 0.1. Time taken for epoch: 23.05 seconds.

10:00:13: Train Epoch: 4 [0/45000 (0%)]	Loss: nan
10:00:13: Train Epoch: 4 [0/45000 (0%)]	Loss: nan
10:00:13: Train Epoch: 4 [0/45000 (0%)]	Loss: nan
10:00:17: Train Epoch: 4 [10000/45000 (22%)]	Loss: nan
10:00:17: Train Epoch: 4 [10000/45000 (22%)]	Loss: nan
10:00:17: Train Epoch: 4 [10000/45000 (22%)]	Loss: nan
10:00:22: Train Epoch: 4 [20000/45000 (44%)]	Loss: nan
10:00:22: Train Epoch: 4 [20000/45000 (44%)]	Loss: nan
10:00:22: Train Epoch: 4 [20000/45000 (44%)]	Loss: nan
10:00:26: Train Epoch: 4 [30000/45000 (67%)]	Loss: nan
10:00:26: Train Epoch: 4 [30000/45000 (67%)]	Loss: nan
10:00:26: Train Epoch: 4 [30000/45000 (67%)]	Loss: nan
10:00:30: Train Epoch: 4 [40000/45000 (89%)]	Loss: nan
10:00:30: Train Epoch: 4 [40000/45000 (89%)]	Loss: nan
10:00:30: Train Epoch: 4 [40000/45000 (89%)]	Loss: nan
10:00:34: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:00:34: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:00:34: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:00:34: Current learning rate: 0.1. Time taken for epoch: 22.44 seconds.

10:00:34: Current learning rate: 0.1. Time taken for epoch: 22.44 seconds.

10:00:34: Current learning rate: 0.1. Time taken for epoch: 22.44 seconds.

10:00:35: Train Epoch: 5 [0/45000 (0%)]	Loss: nan
10:00:35: Train Epoch: 5 [0/45000 (0%)]	Loss: nan
10:00:35: Train Epoch: 5 [0/45000 (0%)]	Loss: nan
10:00:40: Train Epoch: 5 [10000/45000 (22%)]	Loss: nan
10:00:40: Train Epoch: 5 [10000/45000 (22%)]	Loss: nan
10:00:40: Train Epoch: 5 [10000/45000 (22%)]	Loss: nan
10:00:44: Train Epoch: 5 [20000/45000 (44%)]	Loss: nan
10:00:44: Train Epoch: 5 [20000/45000 (44%)]	Loss: nan
10:00:44: Train Epoch: 5 [20000/45000 (44%)]	Loss: nan
10:00:49: Train Epoch: 5 [30000/45000 (67%)]	Loss: nan
10:00:49: Train Epoch: 5 [30000/45000 (67%)]	Loss: nan
10:00:49: Train Epoch: 5 [30000/45000 (67%)]	Loss: nan
10:00:53: Train Epoch: 5 [40000/45000 (89%)]	Loss: nan
10:00:53: Train Epoch: 5 [40000/45000 (89%)]	Loss: nan
10:00:53: Train Epoch: 5 [40000/45000 (89%)]	Loss: nan
10:00:57: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:00:57: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:00:57: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:00:57: Current learning rate: 0.1. Time taken for epoch: 23.15 seconds.

10:00:57: Current learning rate: 0.1. Time taken for epoch: 23.15 seconds.

10:00:57: Current learning rate: 0.1. Time taken for epoch: 23.15 seconds.

10:00:58: Train Epoch: 6 [0/45000 (0%)]	Loss: nan
10:00:58: Train Epoch: 6 [0/45000 (0%)]	Loss: nan
10:00:58: Train Epoch: 6 [0/45000 (0%)]	Loss: nan
10:01:03: Train Epoch: 6 [10000/45000 (22%)]	Loss: nan
10:01:03: Train Epoch: 6 [10000/45000 (22%)]	Loss: nan
10:01:03: Train Epoch: 6 [10000/45000 (22%)]	Loss: nan
10:01:07: Train Epoch: 6 [20000/45000 (44%)]	Loss: nan
10:01:07: Train Epoch: 6 [20000/45000 (44%)]	Loss: nan
10:01:07: Train Epoch: 6 [20000/45000 (44%)]	Loss: nan
10:01:12: Train Epoch: 6 [30000/45000 (67%)]	Loss: nan
10:01:12: Train Epoch: 6 [30000/45000 (67%)]	Loss: nan
10:01:12: Train Epoch: 6 [30000/45000 (67%)]	Loss: nan
10:01:17: Train Epoch: 6 [40000/45000 (89%)]	Loss: nan
10:01:17: Train Epoch: 6 [40000/45000 (89%)]	Loss: nan
10:01:17: Train Epoch: 6 [40000/45000 (89%)]	Loss: nan
10:01:20: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:01:20: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:01:20: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:01:20: Current learning rate: 0.1. Time taken for epoch: 22.85 seconds.

10:01:20: Current learning rate: 0.1. Time taken for epoch: 22.85 seconds.

10:01:20: Current learning rate: 0.1. Time taken for epoch: 22.85 seconds.

10:01:21: Train Epoch: 7 [0/45000 (0%)]	Loss: nan
10:01:21: Train Epoch: 7 [0/45000 (0%)]	Loss: nan
10:01:21: Train Epoch: 7 [0/45000 (0%)]	Loss: nan
10:01:25: Train Epoch: 7 [10000/45000 (22%)]	Loss: nan
10:01:25: Train Epoch: 7 [10000/45000 (22%)]	Loss: nan
10:01:25: Train Epoch: 7 [10000/45000 (22%)]	Loss: nan
10:01:30: Train Epoch: 7 [20000/45000 (44%)]	Loss: nan
10:01:30: Train Epoch: 7 [20000/45000 (44%)]	Loss: nan
10:01:30: Train Epoch: 7 [20000/45000 (44%)]	Loss: nan
10:01:34: Train Epoch: 7 [30000/45000 (67%)]	Loss: nan
10:01:34: Train Epoch: 7 [30000/45000 (67%)]	Loss: nan
10:01:34: Train Epoch: 7 [30000/45000 (67%)]	Loss: nan
10:01:39: Train Epoch: 7 [40000/45000 (89%)]	Loss: nan
10:01:39: Train Epoch: 7 [40000/45000 (89%)]	Loss: nan
10:01:39: Train Epoch: 7 [40000/45000 (89%)]	Loss: nan
10:01:43: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:01:43: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:01:43: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:01:43: Current learning rate: 0.1. Time taken for epoch: 22.28 seconds.

10:01:43: Current learning rate: 0.1. Time taken for epoch: 22.28 seconds.

10:01:43: Current learning rate: 0.1. Time taken for epoch: 22.28 seconds.

10:01:43: Train Epoch: 8 [0/45000 (0%)]	Loss: nan
10:01:43: Train Epoch: 8 [0/45000 (0%)]	Loss: nan
10:01:43: Train Epoch: 8 [0/45000 (0%)]	Loss: nan
10:01:48: Train Epoch: 8 [10000/45000 (22%)]	Loss: nan
10:01:48: Train Epoch: 8 [10000/45000 (22%)]	Loss: nan
10:01:48: Train Epoch: 8 [10000/45000 (22%)]	Loss: nan
10:01:52: Train Epoch: 8 [20000/45000 (44%)]	Loss: nan
10:01:52: Train Epoch: 8 [20000/45000 (44%)]	Loss: nan
10:01:52: Train Epoch: 8 [20000/45000 (44%)]	Loss: nan
10:01:57: Train Epoch: 8 [30000/45000 (67%)]	Loss: nan
10:01:57: Train Epoch: 8 [30000/45000 (67%)]	Loss: nan
10:01:57: Train Epoch: 8 [30000/45000 (67%)]	Loss: nan
10:02:02: Train Epoch: 8 [40000/45000 (89%)]	Loss: nan
10:02:02: Train Epoch: 8 [40000/45000 (89%)]	Loss: nan
10:02:02: Train Epoch: 8 [40000/45000 (89%)]	Loss: nan
10:02:06: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:02:06: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:02:06: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:02:06: Current learning rate: 0.1. Time taken for epoch: 23.34 seconds.

10:02:06: Current learning rate: 0.1. Time taken for epoch: 23.34 seconds.

10:02:06: Current learning rate: 0.1. Time taken for epoch: 23.34 seconds.

10:02:07: Train Epoch: 9 [0/45000 (0%)]	Loss: nan
10:02:07: Train Epoch: 9 [0/45000 (0%)]	Loss: nan
10:02:07: Train Epoch: 9 [0/45000 (0%)]	Loss: nan
10:02:11: Train Epoch: 9 [10000/45000 (22%)]	Loss: nan
10:02:11: Train Epoch: 9 [10000/45000 (22%)]	Loss: nan
10:02:11: Train Epoch: 9 [10000/45000 (22%)]	Loss: nan
10:02:16: Train Epoch: 9 [20000/45000 (44%)]	Loss: nan
10:02:16: Train Epoch: 9 [20000/45000 (44%)]	Loss: nan
10:02:16: Train Epoch: 9 [20000/45000 (44%)]	Loss: nan
10:02:20: Train Epoch: 9 [30000/45000 (67%)]	Loss: nan
10:02:20: Train Epoch: 9 [30000/45000 (67%)]	Loss: nan
10:02:20: Train Epoch: 9 [30000/45000 (67%)]	Loss: nan
10:02:25: Train Epoch: 9 [40000/45000 (89%)]	Loss: nan
10:02:25: Train Epoch: 9 [40000/45000 (89%)]	Loss: nan
10:02:25: Train Epoch: 9 [40000/45000 (89%)]	Loss: nan
10:02:29: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:02:29: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:02:29: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:02:29: Current learning rate: 0.1. Time taken for epoch: 22.87 seconds.

10:02:29: Current learning rate: 0.1. Time taken for epoch: 22.87 seconds.

10:02:29: Current learning rate: 0.1. Time taken for epoch: 22.87 seconds.

10:02:30: Train Epoch: 10 [0/45000 (0%)]	Loss: nan
10:02:30: Train Epoch: 10 [0/45000 (0%)]	Loss: nan
10:02:30: Train Epoch: 10 [0/45000 (0%)]	Loss: nan
10:02:34: Train Epoch: 10 [10000/45000 (22%)]	Loss: nan
10:02:34: Train Epoch: 10 [10000/45000 (22%)]	Loss: nan
10:02:34: Train Epoch: 10 [10000/45000 (22%)]	Loss: nan
10:02:39: Train Epoch: 10 [20000/45000 (44%)]	Loss: nan
10:02:39: Train Epoch: 10 [20000/45000 (44%)]	Loss: nan
10:02:39: Train Epoch: 10 [20000/45000 (44%)]	Loss: nan
10:02:43: Train Epoch: 10 [30000/45000 (67%)]	Loss: nan
10:02:43: Train Epoch: 10 [30000/45000 (67%)]	Loss: nan
10:02:43: Train Epoch: 10 [30000/45000 (67%)]	Loss: nan
10:02:47: Train Epoch: 10 [40000/45000 (89%)]	Loss: nan
10:02:47: Train Epoch: 10 [40000/45000 (89%)]	Loss: nan
10:02:47: Train Epoch: 10 [40000/45000 (89%)]	Loss: nan
10:02:51: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:02:51: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:02:51: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:02:51: Current learning rate: 0.1. Time taken for epoch: 22.48 seconds.

10:02:51: Current learning rate: 0.1. Time taken for epoch: 22.48 seconds.

10:02:51: Current learning rate: 0.1. Time taken for epoch: 22.48 seconds.

10:02:52: Train Epoch: 11 [0/45000 (0%)]	Loss: nan
10:02:52: Train Epoch: 11 [0/45000 (0%)]	Loss: nan
10:02:52: Train Epoch: 11 [0/45000 (0%)]	Loss: nan
10:02:57: Train Epoch: 11 [10000/45000 (22%)]	Loss: nan
10:02:57: Train Epoch: 11 [10000/45000 (22%)]	Loss: nan
10:02:57: Train Epoch: 11 [10000/45000 (22%)]	Loss: nan
10:03:02: Train Epoch: 11 [20000/45000 (44%)]	Loss: nan
10:03:02: Train Epoch: 11 [20000/45000 (44%)]	Loss: nan
10:03:02: Train Epoch: 11 [20000/45000 (44%)]	Loss: nan
10:03:06: Train Epoch: 11 [30000/45000 (67%)]	Loss: nan
10:03:06: Train Epoch: 11 [30000/45000 (67%)]	Loss: nan
10:03:06: Train Epoch: 11 [30000/45000 (67%)]	Loss: nan
10:03:10: Train Epoch: 11 [40000/45000 (89%)]	Loss: nan
10:03:10: Train Epoch: 11 [40000/45000 (89%)]	Loss: nan
10:03:10: Train Epoch: 11 [40000/45000 (89%)]	Loss: nan
10:03:14: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:03:14: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:03:14: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:03:14: Current learning rate: 0.1. Time taken for epoch: 23.20 seconds.

10:03:14: Current learning rate: 0.1. Time taken for epoch: 23.20 seconds.

10:03:14: Current learning rate: 0.1. Time taken for epoch: 23.20 seconds.

10:03:15: Train Epoch: 12 [0/45000 (0%)]	Loss: nan
10:03:15: Train Epoch: 12 [0/45000 (0%)]	Loss: nan
10:03:15: Train Epoch: 12 [0/45000 (0%)]	Loss: nan
10:03:20: Train Epoch: 12 [10000/45000 (22%)]	Loss: nan
10:03:20: Train Epoch: 12 [10000/45000 (22%)]	Loss: nan
10:03:20: Train Epoch: 12 [10000/45000 (22%)]	Loss: nan
10:03:24: Train Epoch: 12 [20000/45000 (44%)]	Loss: nan
10:03:24: Train Epoch: 12 [20000/45000 (44%)]	Loss: nan
10:03:24: Train Epoch: 12 [20000/45000 (44%)]	Loss: nan
10:03:29: Train Epoch: 12 [30000/45000 (67%)]	Loss: nan
10:03:29: Train Epoch: 12 [30000/45000 (67%)]	Loss: nan
10:03:29: Train Epoch: 12 [30000/45000 (67%)]	Loss: nan
10:03:33: Train Epoch: 12 [40000/45000 (89%)]	Loss: nan
10:03:33: Train Epoch: 12 [40000/45000 (89%)]	Loss: nan
10:03:33: Train Epoch: 12 [40000/45000 (89%)]	Loss: nan
10:03:37: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:03:37: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:03:37: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:03:37: Current learning rate: 0.1. Time taken for epoch: 22.50 seconds.

10:03:37: Current learning rate: 0.1. Time taken for epoch: 22.50 seconds.

10:03:37: Current learning rate: 0.1. Time taken for epoch: 22.50 seconds.

10:03:38: Train Epoch: 13 [0/45000 (0%)]	Loss: nan
10:03:38: Train Epoch: 13 [0/45000 (0%)]	Loss: nan
10:03:38: Train Epoch: 13 [0/45000 (0%)]	Loss: nan
10:03:42: Train Epoch: 13 [10000/45000 (22%)]	Loss: nan
10:03:42: Train Epoch: 13 [10000/45000 (22%)]	Loss: nan
10:03:42: Train Epoch: 13 [10000/45000 (22%)]	Loss: nan
10:03:47: Train Epoch: 13 [20000/45000 (44%)]	Loss: nan
10:03:47: Train Epoch: 13 [20000/45000 (44%)]	Loss: nan
10:03:47: Train Epoch: 13 [20000/45000 (44%)]	Loss: nan
10:03:51: Train Epoch: 13 [30000/45000 (67%)]	Loss: nan
10:03:51: Train Epoch: 13 [30000/45000 (67%)]	Loss: nan
10:03:51: Train Epoch: 13 [30000/45000 (67%)]	Loss: nan
10:03:56: Train Epoch: 13 [40000/45000 (89%)]	Loss: nan
10:03:56: Train Epoch: 13 [40000/45000 (89%)]	Loss: nan
10:03:56: Train Epoch: 13 [40000/45000 (89%)]	Loss: nan
10:04:00: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:04:00: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:04:00: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:04:00: Current learning rate: 0.1. Time taken for epoch: 23.00 seconds.

10:04:00: Current learning rate: 0.1. Time taken for epoch: 23.00 seconds.

10:04:00: Current learning rate: 0.1. Time taken for epoch: 23.00 seconds.

10:04:01: Train Epoch: 14 [0/45000 (0%)]	Loss: nan
10:04:01: Train Epoch: 14 [0/45000 (0%)]	Loss: nan
10:04:01: Train Epoch: 14 [0/45000 (0%)]	Loss: nan
10:04:05: Train Epoch: 14 [10000/45000 (22%)]	Loss: nan
10:04:05: Train Epoch: 14 [10000/45000 (22%)]	Loss: nan
10:04:05: Train Epoch: 14 [10000/45000 (22%)]	Loss: nan
10:04:10: Train Epoch: 14 [20000/45000 (44%)]	Loss: nan
10:04:10: Train Epoch: 14 [20000/45000 (44%)]	Loss: nan
10:04:10: Train Epoch: 14 [20000/45000 (44%)]	Loss: nan
10:04:15: Train Epoch: 14 [30000/45000 (67%)]	Loss: nan
10:04:15: Train Epoch: 14 [30000/45000 (67%)]	Loss: nan
10:04:15: Train Epoch: 14 [30000/45000 (67%)]	Loss: nan
10:04:19: Train Epoch: 14 [40000/45000 (89%)]	Loss: nan
10:04:19: Train Epoch: 14 [40000/45000 (89%)]	Loss: nan
10:04:19: Train Epoch: 14 [40000/45000 (89%)]	Loss: nan
10:04:23: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:04:23: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:04:23: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:04:23: Current learning rate: 0.1. Time taken for epoch: 23.11 seconds.

10:04:23: Current learning rate: 0.1. Time taken for epoch: 23.11 seconds.

10:04:23: Current learning rate: 0.1. Time taken for epoch: 23.11 seconds.

10:04:24: Train Epoch: 15 [0/45000 (0%)]	Loss: nan
10:04:24: Train Epoch: 15 [0/45000 (0%)]	Loss: nan
10:04:24: Train Epoch: 15 [0/45000 (0%)]	Loss: nan
10:04:28: Train Epoch: 15 [10000/45000 (22%)]	Loss: nan
10:04:28: Train Epoch: 15 [10000/45000 (22%)]	Loss: nan
10:04:28: Train Epoch: 15 [10000/45000 (22%)]	Loss: nan
10:04:33: Train Epoch: 15 [20000/45000 (44%)]	Loss: nan
10:04:33: Train Epoch: 15 [20000/45000 (44%)]	Loss: nan
10:04:33: Train Epoch: 15 [20000/45000 (44%)]	Loss: nan
10:04:37: Train Epoch: 15 [30000/45000 (67%)]	Loss: nan
10:04:37: Train Epoch: 15 [30000/45000 (67%)]	Loss: nan
10:04:37: Train Epoch: 15 [30000/45000 (67%)]	Loss: nan
10:04:42: Train Epoch: 15 [40000/45000 (89%)]	Loss: nan
10:04:42: Train Epoch: 15 [40000/45000 (89%)]	Loss: nan
10:04:42: Train Epoch: 15 [40000/45000 (89%)]	Loss: nan
10:04:46: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:04:46: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:04:46: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:04:46: Current learning rate: 0.1. Time taken for epoch: 22.63 seconds.

10:04:46: Current learning rate: 0.1. Time taken for epoch: 22.63 seconds.

10:04:46: Current learning rate: 0.1. Time taken for epoch: 22.63 seconds.

10:04:46: Train Epoch: 16 [0/45000 (0%)]	Loss: nan
10:04:46: Train Epoch: 16 [0/45000 (0%)]	Loss: nan
10:04:46: Train Epoch: 16 [0/45000 (0%)]	Loss: nan
10:04:51: Train Epoch: 16 [10000/45000 (22%)]	Loss: nan
10:04:51: Train Epoch: 16 [10000/45000 (22%)]	Loss: nan
10:04:51: Train Epoch: 16 [10000/45000 (22%)]	Loss: nan
10:04:56: Train Epoch: 16 [20000/45000 (44%)]	Loss: nan
10:04:56: Train Epoch: 16 [20000/45000 (44%)]	Loss: nan
10:04:56: Train Epoch: 16 [20000/45000 (44%)]	Loss: nan
10:05:00: Train Epoch: 16 [30000/45000 (67%)]	Loss: nan
10:05:00: Train Epoch: 16 [30000/45000 (67%)]	Loss: nan
10:05:00: Train Epoch: 16 [30000/45000 (67%)]	Loss: nan
10:05:05: Train Epoch: 16 [40000/45000 (89%)]	Loss: nan
10:05:05: Train Epoch: 16 [40000/45000 (89%)]	Loss: nan
10:05:05: Train Epoch: 16 [40000/45000 (89%)]	Loss: nan
10:05:09: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:05:09: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:05:09: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:05:09: Current learning rate: 0.1. Time taken for epoch: 23.06 seconds.

10:05:09: Current learning rate: 0.1. Time taken for epoch: 23.06 seconds.

10:05:09: Current learning rate: 0.1. Time taken for epoch: 23.06 seconds.

10:05:09: Train Epoch: 17 [0/45000 (0%)]	Loss: nan
10:05:09: Train Epoch: 17 [0/45000 (0%)]	Loss: nan
10:05:09: Train Epoch: 17 [0/45000 (0%)]	Loss: nan
10:05:14: Train Epoch: 17 [10000/45000 (22%)]	Loss: nan
10:05:14: Train Epoch: 17 [10000/45000 (22%)]	Loss: nan
10:05:14: Train Epoch: 17 [10000/45000 (22%)]	Loss: nan
10:05:19: Train Epoch: 17 [20000/45000 (44%)]	Loss: nan
10:05:19: Train Epoch: 17 [20000/45000 (44%)]	Loss: nan
10:05:19: Train Epoch: 17 [20000/45000 (44%)]	Loss: nan
10:05:23: Train Epoch: 17 [30000/45000 (67%)]	Loss: nan
10:05:23: Train Epoch: 17 [30000/45000 (67%)]	Loss: nan
10:05:23: Train Epoch: 17 [30000/45000 (67%)]	Loss: nan
10:05:28: Train Epoch: 17 [40000/45000 (89%)]	Loss: nan
10:05:28: Train Epoch: 17 [40000/45000 (89%)]	Loss: nan
10:05:28: Train Epoch: 17 [40000/45000 (89%)]	Loss: nan
10:05:31: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:05:31: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:05:31: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:05:32: Current learning rate: 0.1. Time taken for epoch: 22.72 seconds.

10:05:32: Current learning rate: 0.1. Time taken for epoch: 22.72 seconds.

10:05:32: Current learning rate: 0.1. Time taken for epoch: 22.72 seconds.

10:05:32: Train Epoch: 18 [0/45000 (0%)]	Loss: nan
10:05:32: Train Epoch: 18 [0/45000 (0%)]	Loss: nan
10:05:32: Train Epoch: 18 [0/45000 (0%)]	Loss: nan
10:05:37: Train Epoch: 18 [10000/45000 (22%)]	Loss: nan
10:05:37: Train Epoch: 18 [10000/45000 (22%)]	Loss: nan
10:05:37: Train Epoch: 18 [10000/45000 (22%)]	Loss: nan
10:05:41: Train Epoch: 18 [20000/45000 (44%)]	Loss: nan
10:05:41: Train Epoch: 18 [20000/45000 (44%)]	Loss: nan
10:05:41: Train Epoch: 18 [20000/45000 (44%)]	Loss: nan
10:05:46: Train Epoch: 18 [30000/45000 (67%)]	Loss: nan
10:05:46: Train Epoch: 18 [30000/45000 (67%)]	Loss: nan
10:05:46: Train Epoch: 18 [30000/45000 (67%)]	Loss: nan
10:05:50: Train Epoch: 18 [40000/45000 (89%)]	Loss: nan
10:05:50: Train Epoch: 18 [40000/45000 (89%)]	Loss: nan
10:05:50: Train Epoch: 18 [40000/45000 (89%)]	Loss: nan
10:05:54: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:05:54: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:05:54: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:05:54: Current learning rate: 0.1. Time taken for epoch: 22.48 seconds.

10:05:54: Current learning rate: 0.1. Time taken for epoch: 22.48 seconds.

10:05:54: Current learning rate: 0.1. Time taken for epoch: 22.48 seconds.

10:05:55: Train Epoch: 19 [0/45000 (0%)]	Loss: nan
10:05:55: Train Epoch: 19 [0/45000 (0%)]	Loss: nan
10:05:55: Train Epoch: 19 [0/45000 (0%)]	Loss: nan
10:06:00: Train Epoch: 19 [10000/45000 (22%)]	Loss: nan
10:06:00: Train Epoch: 19 [10000/45000 (22%)]	Loss: nan
10:06:00: Train Epoch: 19 [10000/45000 (22%)]	Loss: nan
10:06:04: Train Epoch: 19 [20000/45000 (44%)]	Loss: nan
10:06:04: Train Epoch: 19 [20000/45000 (44%)]	Loss: nan
10:06:04: Train Epoch: 19 [20000/45000 (44%)]	Loss: nan
10:06:09: Train Epoch: 19 [30000/45000 (67%)]	Loss: nan
10:06:09: Train Epoch: 19 [30000/45000 (67%)]	Loss: nan
10:06:09: Train Epoch: 19 [30000/45000 (67%)]	Loss: nan
10:06:14: Train Epoch: 19 [40000/45000 (89%)]	Loss: nan
10:06:14: Train Epoch: 19 [40000/45000 (89%)]	Loss: nan
10:06:14: Train Epoch: 19 [40000/45000 (89%)]	Loss: nan
10:06:18: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:06:18: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:06:18: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:06:18: Current learning rate: 0.1. Time taken for epoch: 23.59 seconds.

10:06:18: Current learning rate: 0.1. Time taken for epoch: 23.59 seconds.

10:06:18: Current learning rate: 0.1. Time taken for epoch: 23.59 seconds.

10:06:18: Train Epoch: 20 [0/45000 (0%)]	Loss: nan
10:06:18: Train Epoch: 20 [0/45000 (0%)]	Loss: nan
10:06:18: Train Epoch: 20 [0/45000 (0%)]	Loss: nan
10:06:23: Train Epoch: 20 [10000/45000 (22%)]	Loss: nan
10:06:23: Train Epoch: 20 [10000/45000 (22%)]	Loss: nan
10:06:23: Train Epoch: 20 [10000/45000 (22%)]	Loss: nan
10:06:27: Train Epoch: 20 [20000/45000 (44%)]	Loss: nan
10:06:27: Train Epoch: 20 [20000/45000 (44%)]	Loss: nan
10:06:27: Train Epoch: 20 [20000/45000 (44%)]	Loss: nan
10:06:32: Train Epoch: 20 [30000/45000 (67%)]	Loss: nan
10:06:32: Train Epoch: 20 [30000/45000 (67%)]	Loss: nan
10:06:32: Train Epoch: 20 [30000/45000 (67%)]	Loss: nan
10:06:36: Train Epoch: 20 [40000/45000 (89%)]	Loss: nan
10:06:36: Train Epoch: 20 [40000/45000 (89%)]	Loss: nan
10:06:36: Train Epoch: 20 [40000/45000 (89%)]	Loss: nan
10:06:40: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:06:40: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:06:40: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:06:40: Current learning rate: 0.1. Time taken for epoch: 22.22 seconds.

10:06:40: Current learning rate: 0.1. Time taken for epoch: 22.22 seconds.

10:06:40: Current learning rate: 0.1. Time taken for epoch: 22.22 seconds.

10:06:41: Train Epoch: 21 [0/45000 (0%)]	Loss: nan
10:06:41: Train Epoch: 21 [0/45000 (0%)]	Loss: nan
10:06:41: Train Epoch: 21 [0/45000 (0%)]	Loss: nan
10:06:45: Train Epoch: 21 [10000/45000 (22%)]	Loss: nan
10:06:45: Train Epoch: 21 [10000/45000 (22%)]	Loss: nan
10:06:45: Train Epoch: 21 [10000/45000 (22%)]	Loss: nan
10:06:50: Train Epoch: 21 [20000/45000 (44%)]	Loss: nan
10:06:50: Train Epoch: 21 [20000/45000 (44%)]	Loss: nan
10:06:50: Train Epoch: 21 [20000/45000 (44%)]	Loss: nan
10:06:54: Train Epoch: 21 [30000/45000 (67%)]	Loss: nan
10:06:54: Train Epoch: 21 [30000/45000 (67%)]	Loss: nan
10:06:54: Train Epoch: 21 [30000/45000 (67%)]	Loss: nan
10:06:59: Train Epoch: 21 [40000/45000 (89%)]	Loss: nan
10:06:59: Train Epoch: 21 [40000/45000 (89%)]	Loss: nan
10:06:59: Train Epoch: 21 [40000/45000 (89%)]	Loss: nan
10:07:03: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:07:03: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:07:03: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:07:03: Current learning rate: 0.1. Time taken for epoch: 23.01 seconds.

10:07:03: Current learning rate: 0.1. Time taken for epoch: 23.01 seconds.

10:07:03: Current learning rate: 0.1. Time taken for epoch: 23.01 seconds.

10:07:04: Train Epoch: 22 [0/45000 (0%)]	Loss: nan
10:07:04: Train Epoch: 22 [0/45000 (0%)]	Loss: nan
10:07:04: Train Epoch: 22 [0/45000 (0%)]	Loss: nan
10:07:08: Train Epoch: 22 [10000/45000 (22%)]	Loss: nan
10:07:08: Train Epoch: 22 [10000/45000 (22%)]	Loss: nan
10:07:08: Train Epoch: 22 [10000/45000 (22%)]	Loss: nan
10:07:13: Train Epoch: 22 [20000/45000 (44%)]	Loss: nan
10:07:13: Train Epoch: 22 [20000/45000 (44%)]	Loss: nan
10:07:13: Train Epoch: 22 [20000/45000 (44%)]	Loss: nan
10:07:17: Train Epoch: 22 [30000/45000 (67%)]	Loss: nan
10:07:17: Train Epoch: 22 [30000/45000 (67%)]	Loss: nan
10:07:17: Train Epoch: 22 [30000/45000 (67%)]	Loss: nan
10:07:22: Train Epoch: 22 [40000/45000 (89%)]	Loss: nan
10:07:22: Train Epoch: 22 [40000/45000 (89%)]	Loss: nan
10:07:22: Train Epoch: 22 [40000/45000 (89%)]	Loss: nan
10:07:26: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:07:26: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:07:26: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:07:26: Current learning rate: 0.1. Time taken for epoch: 22.75 seconds.

10:07:26: Current learning rate: 0.1. Time taken for epoch: 22.75 seconds.

10:07:26: Current learning rate: 0.1. Time taken for epoch: 22.75 seconds.

10:07:26: Train Epoch: 23 [0/45000 (0%)]	Loss: nan
10:07:26: Train Epoch: 23 [0/45000 (0%)]	Loss: nan
10:07:26: Train Epoch: 23 [0/45000 (0%)]	Loss: nan
10:07:31: Train Epoch: 23 [10000/45000 (22%)]	Loss: nan
10:07:31: Train Epoch: 23 [10000/45000 (22%)]	Loss: nan
10:07:31: Train Epoch: 23 [10000/45000 (22%)]	Loss: nan
10:07:35: Train Epoch: 23 [20000/45000 (44%)]	Loss: nan
10:07:35: Train Epoch: 23 [20000/45000 (44%)]	Loss: nan
10:07:35: Train Epoch: 23 [20000/45000 (44%)]	Loss: nan
10:07:40: Train Epoch: 23 [30000/45000 (67%)]	Loss: nan
10:07:40: Train Epoch: 23 [30000/45000 (67%)]	Loss: nan
10:07:40: Train Epoch: 23 [30000/45000 (67%)]	Loss: nan
10:07:45: Train Epoch: 23 [40000/45000 (89%)]	Loss: nan
10:07:45: Train Epoch: 23 [40000/45000 (89%)]	Loss: nan
10:07:45: Train Epoch: 23 [40000/45000 (89%)]	Loss: nan
10:07:48: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:07:48: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:07:48: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:07:48: Current learning rate: 0.1. Time taken for epoch: 22.76 seconds.

10:07:48: Current learning rate: 0.1. Time taken for epoch: 22.76 seconds.

10:07:48: Current learning rate: 0.1. Time taken for epoch: 22.76 seconds.

10:07:49: Train Epoch: 24 [0/45000 (0%)]	Loss: nan
10:07:49: Train Epoch: 24 [0/45000 (0%)]	Loss: nan
10:07:49: Train Epoch: 24 [0/45000 (0%)]	Loss: nan
10:07:54: Train Epoch: 24 [10000/45000 (22%)]	Loss: nan
10:07:54: Train Epoch: 24 [10000/45000 (22%)]	Loss: nan
10:07:54: Train Epoch: 24 [10000/45000 (22%)]	Loss: nan
10:07:58: Train Epoch: 24 [20000/45000 (44%)]	Loss: nan
10:07:58: Train Epoch: 24 [20000/45000 (44%)]	Loss: nan
10:07:58: Train Epoch: 24 [20000/45000 (44%)]	Loss: nan
10:08:03: Train Epoch: 24 [30000/45000 (67%)]	Loss: nan
10:08:03: Train Epoch: 24 [30000/45000 (67%)]	Loss: nan
10:08:03: Train Epoch: 24 [30000/45000 (67%)]	Loss: nan
10:08:07: Train Epoch: 24 [40000/45000 (89%)]	Loss: nan
10:08:07: Train Epoch: 24 [40000/45000 (89%)]	Loss: nan
10:08:07: Train Epoch: 24 [40000/45000 (89%)]	Loss: nan
10:08:11: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:08:11: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:08:11: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:08:11: Current learning rate: 0.1. Time taken for epoch: 22.94 seconds.

10:08:11: Current learning rate: 0.1. Time taken for epoch: 22.94 seconds.

10:08:11: Current learning rate: 0.1. Time taken for epoch: 22.94 seconds.

10:08:12: Train Epoch: 25 [0/45000 (0%)]	Loss: nan
10:08:12: Train Epoch: 25 [0/45000 (0%)]	Loss: nan
10:08:12: Train Epoch: 25 [0/45000 (0%)]	Loss: nan
10:08:17: Train Epoch: 25 [10000/45000 (22%)]	Loss: nan
10:08:17: Train Epoch: 25 [10000/45000 (22%)]	Loss: nan
10:08:17: Train Epoch: 25 [10000/45000 (22%)]	Loss: nan
10:08:21: Train Epoch: 25 [20000/45000 (44%)]	Loss: nan
10:08:21: Train Epoch: 25 [20000/45000 (44%)]	Loss: nan
10:08:21: Train Epoch: 25 [20000/45000 (44%)]	Loss: nan
10:08:26: Train Epoch: 25 [30000/45000 (67%)]	Loss: nan
10:08:26: Train Epoch: 25 [30000/45000 (67%)]	Loss: nan
10:08:26: Train Epoch: 25 [30000/45000 (67%)]	Loss: nan
10:08:30: Train Epoch: 25 [40000/45000 (89%)]	Loss: nan
10:08:30: Train Epoch: 25 [40000/45000 (89%)]	Loss: nan
10:08:30: Train Epoch: 25 [40000/45000 (89%)]	Loss: nan
10:08:34: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:08:34: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:08:34: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:08:34: Current learning rate: 0.1. Time taken for epoch: 22.34 seconds.

10:08:34: Current learning rate: 0.1. Time taken for epoch: 22.34 seconds.

10:08:34: Current learning rate: 0.1. Time taken for epoch: 22.34 seconds.

10:08:34: Train Epoch: 26 [0/45000 (0%)]	Loss: nan
10:08:34: Train Epoch: 26 [0/45000 (0%)]	Loss: nan
10:08:34: Train Epoch: 26 [0/45000 (0%)]	Loss: nan
10:08:39: Train Epoch: 26 [10000/45000 (22%)]	Loss: nan
10:08:39: Train Epoch: 26 [10000/45000 (22%)]	Loss: nan
10:08:39: Train Epoch: 26 [10000/45000 (22%)]	Loss: nan
10:08:43: Train Epoch: 26 [20000/45000 (44%)]	Loss: nan
10:08:43: Train Epoch: 26 [20000/45000 (44%)]	Loss: nan
10:08:43: Train Epoch: 26 [20000/45000 (44%)]	Loss: nan
10:08:48: Train Epoch: 26 [30000/45000 (67%)]	Loss: nan
10:08:48: Train Epoch: 26 [30000/45000 (67%)]	Loss: nan
10:08:48: Train Epoch: 26 [30000/45000 (67%)]	Loss: nan
10:08:52: Train Epoch: 26 [40000/45000 (89%)]	Loss: nan
10:08:52: Train Epoch: 26 [40000/45000 (89%)]	Loss: nan
10:08:52: Train Epoch: 26 [40000/45000 (89%)]	Loss: nan
10:08:56: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:08:56: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:08:56: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:08:56: Current learning rate: 0.1. Time taken for epoch: 22.65 seconds.

10:08:56: Current learning rate: 0.1. Time taken for epoch: 22.65 seconds.

10:08:56: Current learning rate: 0.1. Time taken for epoch: 22.65 seconds.

10:08:57: Train Epoch: 27 [0/45000 (0%)]	Loss: nan
10:08:57: Train Epoch: 27 [0/45000 (0%)]	Loss: nan
10:08:57: Train Epoch: 27 [0/45000 (0%)]	Loss: nan
10:09:02: Train Epoch: 27 [10000/45000 (22%)]	Loss: nan
10:09:02: Train Epoch: 27 [10000/45000 (22%)]	Loss: nan
10:09:02: Train Epoch: 27 [10000/45000 (22%)]	Loss: nan
10:09:06: Train Epoch: 27 [20000/45000 (44%)]	Loss: nan
10:09:06: Train Epoch: 27 [20000/45000 (44%)]	Loss: nan
10:09:06: Train Epoch: 27 [20000/45000 (44%)]	Loss: nan
10:09:10: Train Epoch: 27 [30000/45000 (67%)]	Loss: nan
10:09:10: Train Epoch: 27 [30000/45000 (67%)]	Loss: nan
10:09:10: Train Epoch: 27 [30000/45000 (67%)]	Loss: nan
10:09:15: Train Epoch: 27 [40000/45000 (89%)]	Loss: nan
10:09:15: Train Epoch: 27 [40000/45000 (89%)]	Loss: nan
10:09:15: Train Epoch: 27 [40000/45000 (89%)]	Loss: nan
10:09:19: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:09:19: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:09:19: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:09:19: Current learning rate: 0.1. Time taken for epoch: 22.76 seconds.

10:09:19: Current learning rate: 0.1. Time taken for epoch: 22.76 seconds.

10:09:19: Current learning rate: 0.1. Time taken for epoch: 22.76 seconds.

10:09:19: Train Epoch: 28 [0/45000 (0%)]	Loss: nan
10:09:19: Train Epoch: 28 [0/45000 (0%)]	Loss: nan
10:09:19: Train Epoch: 28 [0/45000 (0%)]	Loss: nan
10:09:24: Train Epoch: 28 [10000/45000 (22%)]	Loss: nan
10:09:24: Train Epoch: 28 [10000/45000 (22%)]	Loss: nan
10:09:24: Train Epoch: 28 [10000/45000 (22%)]	Loss: nan
10:09:29: Train Epoch: 28 [20000/45000 (44%)]	Loss: nan
10:09:29: Train Epoch: 28 [20000/45000 (44%)]	Loss: nan
10:09:29: Train Epoch: 28 [20000/45000 (44%)]	Loss: nan
10:09:33: Train Epoch: 28 [30000/45000 (67%)]	Loss: nan
10:09:33: Train Epoch: 28 [30000/45000 (67%)]	Loss: nan
10:09:33: Train Epoch: 28 [30000/45000 (67%)]	Loss: nan
10:09:37: Train Epoch: 28 [40000/45000 (89%)]	Loss: nan
10:09:37: Train Epoch: 28 [40000/45000 (89%)]	Loss: nan
10:09:37: Train Epoch: 28 [40000/45000 (89%)]	Loss: nan
10:09:41: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:09:41: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:09:41: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:09:41: Current learning rate: 0.1. Time taken for epoch: 22.01 seconds.

10:09:41: Current learning rate: 0.1. Time taken for epoch: 22.01 seconds.

10:09:41: Current learning rate: 0.1. Time taken for epoch: 22.01 seconds.

10:09:42: Train Epoch: 29 [0/45000 (0%)]	Loss: nan
10:09:42: Train Epoch: 29 [0/45000 (0%)]	Loss: nan
10:09:42: Train Epoch: 29 [0/45000 (0%)]	Loss: nan
10:09:46: Train Epoch: 29 [10000/45000 (22%)]	Loss: nan
10:09:46: Train Epoch: 29 [10000/45000 (22%)]	Loss: nan
10:09:46: Train Epoch: 29 [10000/45000 (22%)]	Loss: nan
10:09:51: Train Epoch: 29 [20000/45000 (44%)]	Loss: nan
10:09:51: Train Epoch: 29 [20000/45000 (44%)]	Loss: nan
10:09:51: Train Epoch: 29 [20000/45000 (44%)]	Loss: nan
10:09:55: Train Epoch: 29 [30000/45000 (67%)]	Loss: nan
10:09:55: Train Epoch: 29 [30000/45000 (67%)]	Loss: nan
10:09:55: Train Epoch: 29 [30000/45000 (67%)]	Loss: nan
10:10:00: Train Epoch: 29 [40000/45000 (89%)]	Loss: nan
10:10:00: Train Epoch: 29 [40000/45000 (89%)]	Loss: nan
10:10:00: Train Epoch: 29 [40000/45000 (89%)]	Loss: nan
10:10:04: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:10:04: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:10:04: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:10:04: Current learning rate: 0.1. Time taken for epoch: 22.85 seconds.

10:10:04: Current learning rate: 0.1. Time taken for epoch: 22.85 seconds.

10:10:04: Current learning rate: 0.1. Time taken for epoch: 22.85 seconds.

10:10:04: Train Epoch: 30 [0/45000 (0%)]	Loss: nan
10:10:04: Train Epoch: 30 [0/45000 (0%)]	Loss: nan
10:10:04: Train Epoch: 30 [0/45000 (0%)]	Loss: nan
10:10:09: Train Epoch: 30 [10000/45000 (22%)]	Loss: nan
10:10:09: Train Epoch: 30 [10000/45000 (22%)]	Loss: nan
10:10:09: Train Epoch: 30 [10000/45000 (22%)]	Loss: nan
10:10:14: Train Epoch: 30 [20000/45000 (44%)]	Loss: nan
10:10:14: Train Epoch: 30 [20000/45000 (44%)]	Loss: nan
10:10:14: Train Epoch: 30 [20000/45000 (44%)]	Loss: nan
10:10:18: Train Epoch: 30 [30000/45000 (67%)]	Loss: nan
10:10:18: Train Epoch: 30 [30000/45000 (67%)]	Loss: nan
10:10:18: Train Epoch: 30 [30000/45000 (67%)]	Loss: nan
10:10:23: Train Epoch: 30 [40000/45000 (89%)]	Loss: nan
10:10:23: Train Epoch: 30 [40000/45000 (89%)]	Loss: nan
10:10:23: Train Epoch: 30 [40000/45000 (89%)]	Loss: nan
10:10:26: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:10:26: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:10:26: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:10:26: Current learning rate: 0.1. Time taken for epoch: 22.60 seconds.

10:10:26: Current learning rate: 0.1. Time taken for epoch: 22.60 seconds.

10:10:26: Current learning rate: 0.1. Time taken for epoch: 22.60 seconds.

10:10:27: Train Epoch: 31 [0/45000 (0%)]	Loss: nan
10:10:27: Train Epoch: 31 [0/45000 (0%)]	Loss: nan
10:10:27: Train Epoch: 31 [0/45000 (0%)]	Loss: nan
10:10:32: Train Epoch: 31 [10000/45000 (22%)]	Loss: nan
10:10:32: Train Epoch: 31 [10000/45000 (22%)]	Loss: nan
10:10:32: Train Epoch: 31 [10000/45000 (22%)]	Loss: nan
10:10:36: Train Epoch: 31 [20000/45000 (44%)]	Loss: nan
10:10:36: Train Epoch: 31 [20000/45000 (44%)]	Loss: nan
10:10:36: Train Epoch: 31 [20000/45000 (44%)]	Loss: nan
10:10:40: Train Epoch: 31 [30000/45000 (67%)]	Loss: nan
10:10:40: Train Epoch: 31 [30000/45000 (67%)]	Loss: nan
10:10:40: Train Epoch: 31 [30000/45000 (67%)]	Loss: nan
10:10:45: Train Epoch: 31 [40000/45000 (89%)]	Loss: nan
10:10:45: Train Epoch: 31 [40000/45000 (89%)]	Loss: nan
10:10:45: Train Epoch: 31 [40000/45000 (89%)]	Loss: nan
10:10:49: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:10:49: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:10:49: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:10:49: Current learning rate: 0.1. Time taken for epoch: 22.11 seconds.

10:10:49: Current learning rate: 0.1. Time taken for epoch: 22.11 seconds.

10:10:49: Current learning rate: 0.1. Time taken for epoch: 22.11 seconds.

10:10:49: Train Epoch: 32 [0/45000 (0%)]	Loss: nan
10:10:49: Train Epoch: 32 [0/45000 (0%)]	Loss: nan
10:10:49: Train Epoch: 32 [0/45000 (0%)]	Loss: nan
10:10:54: Train Epoch: 32 [10000/45000 (22%)]	Loss: nan
10:10:54: Train Epoch: 32 [10000/45000 (22%)]	Loss: nan
10:10:54: Train Epoch: 32 [10000/45000 (22%)]	Loss: nan
10:10:59: Train Epoch: 32 [20000/45000 (44%)]	Loss: nan
10:10:59: Train Epoch: 32 [20000/45000 (44%)]	Loss: nan
10:10:59: Train Epoch: 32 [20000/45000 (44%)]	Loss: nan
10:11:03: Train Epoch: 32 [30000/45000 (67%)]	Loss: nan
10:11:03: Train Epoch: 32 [30000/45000 (67%)]	Loss: nan
10:11:03: Train Epoch: 32 [30000/45000 (67%)]	Loss: nan
10:11:08: Train Epoch: 32 [40000/45000 (89%)]	Loss: nan
10:11:08: Train Epoch: 32 [40000/45000 (89%)]	Loss: nan
10:11:08: Train Epoch: 32 [40000/45000 (89%)]	Loss: nan
10:11:11: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:11:11: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:11:11: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:11:11: Current learning rate: 0.1. Time taken for epoch: 22.83 seconds.

10:11:11: Current learning rate: 0.1. Time taken for epoch: 22.83 seconds.

10:11:11: Current learning rate: 0.1. Time taken for epoch: 22.83 seconds.

10:11:12: Train Epoch: 33 [0/45000 (0%)]	Loss: nan
10:11:12: Train Epoch: 33 [0/45000 (0%)]	Loss: nan
10:11:12: Train Epoch: 33 [0/45000 (0%)]	Loss: nan
10:11:17: Train Epoch: 33 [10000/45000 (22%)]	Loss: nan
10:11:17: Train Epoch: 33 [10000/45000 (22%)]	Loss: nan
10:11:17: Train Epoch: 33 [10000/45000 (22%)]	Loss: nan
10:11:21: Train Epoch: 33 [20000/45000 (44%)]	Loss: nan
10:11:21: Train Epoch: 33 [20000/45000 (44%)]	Loss: nan
10:11:21: Train Epoch: 33 [20000/45000 (44%)]	Loss: nan
10:11:26: Train Epoch: 33 [30000/45000 (67%)]	Loss: nan
10:11:26: Train Epoch: 33 [30000/45000 (67%)]	Loss: nan
10:11:26: Train Epoch: 33 [30000/45000 (67%)]	Loss: nan
10:11:30: Train Epoch: 33 [40000/45000 (89%)]	Loss: nan
10:11:30: Train Epoch: 33 [40000/45000 (89%)]	Loss: nan
10:11:30: Train Epoch: 33 [40000/45000 (89%)]	Loss: nan
10:11:34: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:11:34: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:11:34: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:11:34: Current learning rate: 0.1. Time taken for epoch: 22.54 seconds.

10:11:34: Current learning rate: 0.1. Time taken for epoch: 22.54 seconds.

10:11:34: Current learning rate: 0.1. Time taken for epoch: 22.54 seconds.

10:11:35: Train Epoch: 34 [0/45000 (0%)]	Loss: nan
10:11:35: Train Epoch: 34 [0/45000 (0%)]	Loss: nan
10:11:35: Train Epoch: 34 [0/45000 (0%)]	Loss: nan
10:11:39: Train Epoch: 34 [10000/45000 (22%)]	Loss: nan
10:11:39: Train Epoch: 34 [10000/45000 (22%)]	Loss: nan
10:11:39: Train Epoch: 34 [10000/45000 (22%)]	Loss: nan
10:11:44: Train Epoch: 34 [20000/45000 (44%)]	Loss: nan
10:11:44: Train Epoch: 34 [20000/45000 (44%)]	Loss: nan
10:11:44: Train Epoch: 34 [20000/45000 (44%)]	Loss: nan
10:11:48: Train Epoch: 34 [30000/45000 (67%)]	Loss: nan
10:11:48: Train Epoch: 34 [30000/45000 (67%)]	Loss: nan
10:11:48: Train Epoch: 34 [30000/45000 (67%)]	Loss: nan
10:11:52: Train Epoch: 34 [40000/45000 (89%)]	Loss: nan
10:11:52: Train Epoch: 34 [40000/45000 (89%)]	Loss: nan
10:11:52: Train Epoch: 34 [40000/45000 (89%)]	Loss: nan
10:11:56: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:11:56: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:11:56: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:11:56: Current learning rate: 0.1. Time taken for epoch: 22.49 seconds.

10:11:56: Current learning rate: 0.1. Time taken for epoch: 22.49 seconds.

10:11:56: Current learning rate: 0.1. Time taken for epoch: 22.49 seconds.

10:11:57: Train Epoch: 35 [0/45000 (0%)]	Loss: nan
10:11:57: Train Epoch: 35 [0/45000 (0%)]	Loss: nan
10:11:57: Train Epoch: 35 [0/45000 (0%)]	Loss: nan
10:12:02: Train Epoch: 35 [10000/45000 (22%)]	Loss: nan
10:12:02: Train Epoch: 35 [10000/45000 (22%)]	Loss: nan
10:12:02: Train Epoch: 35 [10000/45000 (22%)]	Loss: nan
10:12:06: Train Epoch: 35 [20000/45000 (44%)]	Loss: nan
10:12:06: Train Epoch: 35 [20000/45000 (44%)]	Loss: nan
10:12:06: Train Epoch: 35 [20000/45000 (44%)]	Loss: nan
10:12:11: Train Epoch: 35 [30000/45000 (67%)]	Loss: nan
10:12:11: Train Epoch: 35 [30000/45000 (67%)]	Loss: nan
10:12:11: Train Epoch: 35 [30000/45000 (67%)]	Loss: nan
10:12:15: Train Epoch: 35 [40000/45000 (89%)]	Loss: nan
10:12:15: Train Epoch: 35 [40000/45000 (89%)]	Loss: nan
10:12:15: Train Epoch: 35 [40000/45000 (89%)]	Loss: nan
10:12:19: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:12:19: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:12:19: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:12:19: Current learning rate: 0.1. Time taken for epoch: 22.74 seconds.

10:12:19: Current learning rate: 0.1. Time taken for epoch: 22.74 seconds.

10:12:19: Current learning rate: 0.1. Time taken for epoch: 22.74 seconds.

10:12:20: Train Epoch: 36 [0/45000 (0%)]	Loss: nan
10:12:20: Train Epoch: 36 [0/45000 (0%)]	Loss: nan
10:12:20: Train Epoch: 36 [0/45000 (0%)]	Loss: nan
10:12:24: Train Epoch: 36 [10000/45000 (22%)]	Loss: nan
10:12:24: Train Epoch: 36 [10000/45000 (22%)]	Loss: nan
10:12:24: Train Epoch: 36 [10000/45000 (22%)]	Loss: nan
10:12:29: Train Epoch: 36 [20000/45000 (44%)]	Loss: nan
10:12:29: Train Epoch: 36 [20000/45000 (44%)]	Loss: nan
10:12:29: Train Epoch: 36 [20000/45000 (44%)]	Loss: nan
10:12:33: Train Epoch: 36 [30000/45000 (67%)]	Loss: nan
10:12:33: Train Epoch: 36 [30000/45000 (67%)]	Loss: nan
10:12:33: Train Epoch: 36 [30000/45000 (67%)]	Loss: nan
10:12:37: Train Epoch: 36 [40000/45000 (89%)]	Loss: nan
10:12:37: Train Epoch: 36 [40000/45000 (89%)]	Loss: nan
10:12:37: Train Epoch: 36 [40000/45000 (89%)]	Loss: nan
10:12:41: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:12:41: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:12:41: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:12:41: Current learning rate: 0.1. Time taken for epoch: 22.09 seconds.

10:12:41: Current learning rate: 0.1. Time taken for epoch: 22.09 seconds.

10:12:41: Current learning rate: 0.1. Time taken for epoch: 22.09 seconds.

10:12:42: Train Epoch: 37 [0/45000 (0%)]	Loss: nan
10:12:42: Train Epoch: 37 [0/45000 (0%)]	Loss: nan
10:12:42: Train Epoch: 37 [0/45000 (0%)]	Loss: nan
10:12:47: Train Epoch: 37 [10000/45000 (22%)]	Loss: nan
10:12:47: Train Epoch: 37 [10000/45000 (22%)]	Loss: nan
10:12:47: Train Epoch: 37 [10000/45000 (22%)]	Loss: nan
10:12:51: Train Epoch: 37 [20000/45000 (44%)]	Loss: nan
10:12:51: Train Epoch: 37 [20000/45000 (44%)]	Loss: nan
10:12:51: Train Epoch: 37 [20000/45000 (44%)]	Loss: nan
10:12:56: Train Epoch: 37 [30000/45000 (67%)]	Loss: nan
10:12:56: Train Epoch: 37 [30000/45000 (67%)]	Loss: nan
10:12:56: Train Epoch: 37 [30000/45000 (67%)]	Loss: nan
10:13:01: Train Epoch: 37 [40000/45000 (89%)]	Loss: nan
10:13:01: Train Epoch: 37 [40000/45000 (89%)]	Loss: nan
10:13:01: Train Epoch: 37 [40000/45000 (89%)]	Loss: nan
10:13:05: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:13:05: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:13:05: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:13:05: Current learning rate: 0.1. Time taken for epoch: 23.43 seconds.

10:13:05: Current learning rate: 0.1. Time taken for epoch: 23.43 seconds.

10:13:05: Current learning rate: 0.1. Time taken for epoch: 23.43 seconds.

10:13:05: Train Epoch: 38 [0/45000 (0%)]	Loss: nan
10:13:05: Train Epoch: 38 [0/45000 (0%)]	Loss: nan
10:13:05: Train Epoch: 38 [0/45000 (0%)]	Loss: nan
10:13:10: Train Epoch: 38 [10000/45000 (22%)]	Loss: nan
10:13:10: Train Epoch: 38 [10000/45000 (22%)]	Loss: nan
10:13:10: Train Epoch: 38 [10000/45000 (22%)]	Loss: nan
10:13:15: Train Epoch: 38 [20000/45000 (44%)]	Loss: nan
10:13:15: Train Epoch: 38 [20000/45000 (44%)]	Loss: nan
10:13:15: Train Epoch: 38 [20000/45000 (44%)]	Loss: nan
10:13:19: Train Epoch: 38 [30000/45000 (67%)]	Loss: nan
10:13:19: Train Epoch: 38 [30000/45000 (67%)]	Loss: nan
10:13:19: Train Epoch: 38 [30000/45000 (67%)]	Loss: nan
10:13:23: Train Epoch: 38 [40000/45000 (89%)]	Loss: nan
10:13:23: Train Epoch: 38 [40000/45000 (89%)]	Loss: nan
10:13:23: Train Epoch: 38 [40000/45000 (89%)]	Loss: nan
10:13:27: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:13:27: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:13:27: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:13:27: Current learning rate: 0.1. Time taken for epoch: 22.44 seconds.

10:13:27: Current learning rate: 0.1. Time taken for epoch: 22.44 seconds.

10:13:27: Current learning rate: 0.1. Time taken for epoch: 22.44 seconds.

10:13:28: Train Epoch: 39 [0/45000 (0%)]	Loss: nan
10:13:28: Train Epoch: 39 [0/45000 (0%)]	Loss: nan
10:13:28: Train Epoch: 39 [0/45000 (0%)]	Loss: nan
10:13:32: Train Epoch: 39 [10000/45000 (22%)]	Loss: nan
10:13:32: Train Epoch: 39 [10000/45000 (22%)]	Loss: nan
10:13:32: Train Epoch: 39 [10000/45000 (22%)]	Loss: nan
10:13:37: Train Epoch: 39 [20000/45000 (44%)]	Loss: nan
10:13:37: Train Epoch: 39 [20000/45000 (44%)]	Loss: nan
10:13:37: Train Epoch: 39 [20000/45000 (44%)]	Loss: nan
10:13:41: Train Epoch: 39 [30000/45000 (67%)]	Loss: nan
10:13:41: Train Epoch: 39 [30000/45000 (67%)]	Loss: nan
10:13:41: Train Epoch: 39 [30000/45000 (67%)]	Loss: nan
10:13:45: Train Epoch: 39 [40000/45000 (89%)]	Loss: nan
10:13:45: Train Epoch: 39 [40000/45000 (89%)]	Loss: nan
10:13:45: Train Epoch: 39 [40000/45000 (89%)]	Loss: nan
10:13:49: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:13:49: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:13:49: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:13:49: Current learning rate: 0.1. Time taken for epoch: 22.11 seconds.

10:13:49: Current learning rate: 0.1. Time taken for epoch: 22.11 seconds.

10:13:49: Current learning rate: 0.1. Time taken for epoch: 22.11 seconds.

10:13:50: Train Epoch: 40 [0/45000 (0%)]	Loss: nan
10:13:50: Train Epoch: 40 [0/45000 (0%)]	Loss: nan
10:13:50: Train Epoch: 40 [0/45000 (0%)]	Loss: nan
10:13:55: Train Epoch: 40 [10000/45000 (22%)]	Loss: nan
10:13:55: Train Epoch: 40 [10000/45000 (22%)]	Loss: nan
10:13:55: Train Epoch: 40 [10000/45000 (22%)]	Loss: nan
10:13:59: Train Epoch: 40 [20000/45000 (44%)]	Loss: nan
10:13:59: Train Epoch: 40 [20000/45000 (44%)]	Loss: nan
10:13:59: Train Epoch: 40 [20000/45000 (44%)]	Loss: nan
10:14:04: Train Epoch: 40 [30000/45000 (67%)]	Loss: nan
10:14:04: Train Epoch: 40 [30000/45000 (67%)]	Loss: nan
10:14:04: Train Epoch: 40 [30000/45000 (67%)]	Loss: nan
10:14:08: Train Epoch: 40 [40000/45000 (89%)]	Loss: nan
10:14:08: Train Epoch: 40 [40000/45000 (89%)]	Loss: nan
10:14:08: Train Epoch: 40 [40000/45000 (89%)]	Loss: nan
10:14:13: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:14:13: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:14:13: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:14:13: Current learning rate: 0.1. Time taken for epoch: 23.34 seconds.

10:14:13: Current learning rate: 0.1. Time taken for epoch: 23.34 seconds.

10:14:13: Current learning rate: 0.1. Time taken for epoch: 23.34 seconds.

10:14:13: Train Epoch: 41 [0/45000 (0%)]	Loss: nan
10:14:13: Train Epoch: 41 [0/45000 (0%)]	Loss: nan
10:14:13: Train Epoch: 41 [0/45000 (0%)]	Loss: nan
10:14:18: Train Epoch: 41 [10000/45000 (22%)]	Loss: nan
10:14:18: Train Epoch: 41 [10000/45000 (22%)]	Loss: nan
10:14:18: Train Epoch: 41 [10000/45000 (22%)]	Loss: nan
10:14:22: Train Epoch: 41 [20000/45000 (44%)]	Loss: nan
10:14:22: Train Epoch: 41 [20000/45000 (44%)]	Loss: nan
10:14:22: Train Epoch: 41 [20000/45000 (44%)]	Loss: nan
10:14:27: Train Epoch: 41 [30000/45000 (67%)]	Loss: nan
10:14:27: Train Epoch: 41 [30000/45000 (67%)]	Loss: nan
10:14:27: Train Epoch: 41 [30000/45000 (67%)]	Loss: nan
10:14:31: Train Epoch: 41 [40000/45000 (89%)]	Loss: nan
10:14:31: Train Epoch: 41 [40000/45000 (89%)]	Loss: nan
10:14:31: Train Epoch: 41 [40000/45000 (89%)]	Loss: nan
10:14:35: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:14:35: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:14:35: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:14:35: Current learning rate: 0.1. Time taken for epoch: 22.15 seconds.

10:14:35: Current learning rate: 0.1. Time taken for epoch: 22.15 seconds.

10:14:35: Current learning rate: 0.1. Time taken for epoch: 22.15 seconds.

10:14:35: Train Epoch: 42 [0/45000 (0%)]	Loss: nan
10:14:35: Train Epoch: 42 [0/45000 (0%)]	Loss: nan
10:14:35: Train Epoch: 42 [0/45000 (0%)]	Loss: nan
10:14:40: Train Epoch: 42 [10000/45000 (22%)]	Loss: nan
10:14:40: Train Epoch: 42 [10000/45000 (22%)]	Loss: nan
10:14:40: Train Epoch: 42 [10000/45000 (22%)]	Loss: nan
10:14:44: Train Epoch: 42 [20000/45000 (44%)]	Loss: nan
10:14:44: Train Epoch: 42 [20000/45000 (44%)]	Loss: nan
10:14:44: Train Epoch: 42 [20000/45000 (44%)]	Loss: nan
10:14:49: Train Epoch: 42 [30000/45000 (67%)]	Loss: nan
10:14:49: Train Epoch: 42 [30000/45000 (67%)]	Loss: nan
10:14:49: Train Epoch: 42 [30000/45000 (67%)]	Loss: nan
10:14:53: Train Epoch: 42 [40000/45000 (89%)]	Loss: nan
10:14:53: Train Epoch: 42 [40000/45000 (89%)]	Loss: nan
10:14:53: Train Epoch: 42 [40000/45000 (89%)]	Loss: nan
10:14:57: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:14:57: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:14:57: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:14:57: Current learning rate: 0.1. Time taken for epoch: 22.54 seconds.

10:14:57: Current learning rate: 0.1. Time taken for epoch: 22.54 seconds.

10:14:57: Current learning rate: 0.1. Time taken for epoch: 22.54 seconds.

10:14:58: Train Epoch: 43 [0/45000 (0%)]	Loss: nan
10:14:58: Train Epoch: 43 [0/45000 (0%)]	Loss: nan
10:14:58: Train Epoch: 43 [0/45000 (0%)]	Loss: nan
10:15:03: Train Epoch: 43 [10000/45000 (22%)]	Loss: nan
10:15:03: Train Epoch: 43 [10000/45000 (22%)]	Loss: nan
10:15:03: Train Epoch: 43 [10000/45000 (22%)]	Loss: nan
10:15:07: Train Epoch: 43 [20000/45000 (44%)]	Loss: nan
10:15:07: Train Epoch: 43 [20000/45000 (44%)]	Loss: nan
10:15:07: Train Epoch: 43 [20000/45000 (44%)]	Loss: nan
10:15:12: Train Epoch: 43 [30000/45000 (67%)]	Loss: nan
10:15:12: Train Epoch: 43 [30000/45000 (67%)]	Loss: nan
10:15:12: Train Epoch: 43 [30000/45000 (67%)]	Loss: nan
10:15:16: Train Epoch: 43 [40000/45000 (89%)]	Loss: nan
10:15:16: Train Epoch: 43 [40000/45000 (89%)]	Loss: nan
10:15:16: Train Epoch: 43 [40000/45000 (89%)]	Loss: nan
10:15:20: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:15:20: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:15:20: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:15:20: Current learning rate: 0.1. Time taken for epoch: 23.01 seconds.

10:15:20: Current learning rate: 0.1. Time taken for epoch: 23.01 seconds.

10:15:20: Current learning rate: 0.1. Time taken for epoch: 23.01 seconds.

10:15:21: Train Epoch: 44 [0/45000 (0%)]	Loss: nan
10:15:21: Train Epoch: 44 [0/45000 (0%)]	Loss: nan
10:15:21: Train Epoch: 44 [0/45000 (0%)]	Loss: nan
10:15:26: Train Epoch: 44 [10000/45000 (22%)]	Loss: nan
10:15:26: Train Epoch: 44 [10000/45000 (22%)]	Loss: nan
10:15:26: Train Epoch: 44 [10000/45000 (22%)]	Loss: nan
10:15:30: Train Epoch: 44 [20000/45000 (44%)]	Loss: nan
10:15:30: Train Epoch: 44 [20000/45000 (44%)]	Loss: nan
10:15:30: Train Epoch: 44 [20000/45000 (44%)]	Loss: nan
10:15:35: Train Epoch: 44 [30000/45000 (67%)]	Loss: nan
10:15:35: Train Epoch: 44 [30000/45000 (67%)]	Loss: nan
10:15:35: Train Epoch: 44 [30000/45000 (67%)]	Loss: nan
10:15:39: Train Epoch: 44 [40000/45000 (89%)]	Loss: nan
10:15:39: Train Epoch: 44 [40000/45000 (89%)]	Loss: nan
10:15:39: Train Epoch: 44 [40000/45000 (89%)]	Loss: nan
10:15:43: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:15:43: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:15:43: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:15:43: Current learning rate: 0.1. Time taken for epoch: 22.83 seconds.

10:15:43: Current learning rate: 0.1. Time taken for epoch: 22.83 seconds.

10:15:43: Current learning rate: 0.1. Time taken for epoch: 22.83 seconds.

10:15:44: Train Epoch: 45 [0/45000 (0%)]	Loss: nan
10:15:44: Train Epoch: 45 [0/45000 (0%)]	Loss: nan
10:15:44: Train Epoch: 45 [0/45000 (0%)]	Loss: nan
10:15:48: Train Epoch: 45 [10000/45000 (22%)]	Loss: nan
10:15:48: Train Epoch: 45 [10000/45000 (22%)]	Loss: nan
10:15:48: Train Epoch: 45 [10000/45000 (22%)]	Loss: nan
10:15:53: Train Epoch: 45 [20000/45000 (44%)]	Loss: nan
10:15:53: Train Epoch: 45 [20000/45000 (44%)]	Loss: nan
10:15:53: Train Epoch: 45 [20000/45000 (44%)]	Loss: nan
10:15:58: Train Epoch: 45 [30000/45000 (67%)]	Loss: nan
10:15:58: Train Epoch: 45 [30000/45000 (67%)]	Loss: nan
10:15:58: Train Epoch: 45 [30000/45000 (67%)]	Loss: nan
10:16:03: Train Epoch: 45 [40000/45000 (89%)]	Loss: nan
10:16:03: Train Epoch: 45 [40000/45000 (89%)]	Loss: nan
10:16:03: Train Epoch: 45 [40000/45000 (89%)]	Loss: nan
10:16:07: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:16:07: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:16:07: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:16:07: Current learning rate: 0.1. Time taken for epoch: 23.66 seconds.

10:16:07: Current learning rate: 0.1. Time taken for epoch: 23.66 seconds.

10:16:07: Current learning rate: 0.1. Time taken for epoch: 23.66 seconds.

10:16:07: Train Epoch: 46 [0/45000 (0%)]	Loss: nan
10:16:07: Train Epoch: 46 [0/45000 (0%)]	Loss: nan
10:16:07: Train Epoch: 46 [0/45000 (0%)]	Loss: nan
10:16:12: Train Epoch: 46 [10000/45000 (22%)]	Loss: nan
10:16:12: Train Epoch: 46 [10000/45000 (22%)]	Loss: nan
10:16:12: Train Epoch: 46 [10000/45000 (22%)]	Loss: nan
10:16:17: Train Epoch: 46 [20000/45000 (44%)]	Loss: nan
10:16:17: Train Epoch: 46 [20000/45000 (44%)]	Loss: nan
10:16:17: Train Epoch: 46 [20000/45000 (44%)]	Loss: nan
10:16:21: Train Epoch: 46 [30000/45000 (67%)]	Loss: nan
10:16:21: Train Epoch: 46 [30000/45000 (67%)]	Loss: nan
10:16:21: Train Epoch: 46 [30000/45000 (67%)]	Loss: nan
10:16:26: Train Epoch: 46 [40000/45000 (89%)]	Loss: nan
10:16:26: Train Epoch: 46 [40000/45000 (89%)]	Loss: nan
10:16:26: Train Epoch: 46 [40000/45000 (89%)]	Loss: nan
10:16:29: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:16:29: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:16:29: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:16:30: Current learning rate: 0.1. Time taken for epoch: 22.76 seconds.

10:16:30: Current learning rate: 0.1. Time taken for epoch: 22.76 seconds.

10:16:30: Current learning rate: 0.1. Time taken for epoch: 22.76 seconds.

10:16:30: Train Epoch: 47 [0/45000 (0%)]	Loss: nan
10:16:30: Train Epoch: 47 [0/45000 (0%)]	Loss: nan
10:16:30: Train Epoch: 47 [0/45000 (0%)]	Loss: nan
10:16:35: Train Epoch: 47 [10000/45000 (22%)]	Loss: nan
10:16:35: Train Epoch: 47 [10000/45000 (22%)]	Loss: nan
10:16:35: Train Epoch: 47 [10000/45000 (22%)]	Loss: nan
10:16:39: Train Epoch: 47 [20000/45000 (44%)]	Loss: nan
10:16:39: Train Epoch: 47 [20000/45000 (44%)]	Loss: nan
10:16:39: Train Epoch: 47 [20000/45000 (44%)]	Loss: nan
10:16:44: Train Epoch: 47 [30000/45000 (67%)]	Loss: nan
10:16:44: Train Epoch: 47 [30000/45000 (67%)]	Loss: nan
10:16:44: Train Epoch: 47 [30000/45000 (67%)]	Loss: nan
10:16:48: Train Epoch: 47 [40000/45000 (89%)]	Loss: nan
10:16:48: Train Epoch: 47 [40000/45000 (89%)]	Loss: nan
10:16:48: Train Epoch: 47 [40000/45000 (89%)]	Loss: nan
10:16:52: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:16:52: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:16:52: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:16:52: Current learning rate: 0.1. Time taken for epoch: 22.73 seconds.

10:16:52: Current learning rate: 0.1. Time taken for epoch: 22.73 seconds.

10:16:52: Current learning rate: 0.1. Time taken for epoch: 22.73 seconds.

10:16:53: Train Epoch: 48 [0/45000 (0%)]	Loss: nan
10:16:53: Train Epoch: 48 [0/45000 (0%)]	Loss: nan
10:16:53: Train Epoch: 48 [0/45000 (0%)]	Loss: nan
10:16:58: Train Epoch: 48 [10000/45000 (22%)]	Loss: nan
10:16:58: Train Epoch: 48 [10000/45000 (22%)]	Loss: nan
10:16:58: Train Epoch: 48 [10000/45000 (22%)]	Loss: nan
10:17:03: Train Epoch: 48 [20000/45000 (44%)]	Loss: nan
10:17:03: Train Epoch: 48 [20000/45000 (44%)]	Loss: nan
10:17:03: Train Epoch: 48 [20000/45000 (44%)]	Loss: nan
10:17:07: Train Epoch: 48 [30000/45000 (67%)]	Loss: nan
10:17:07: Train Epoch: 48 [30000/45000 (67%)]	Loss: nan
10:17:07: Train Epoch: 48 [30000/45000 (67%)]	Loss: nan
10:17:12: Train Epoch: 48 [40000/45000 (89%)]	Loss: nan
10:17:12: Train Epoch: 48 [40000/45000 (89%)]	Loss: nan
10:17:12: Train Epoch: 48 [40000/45000 (89%)]	Loss: nan
10:17:16: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:17:16: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:17:16: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:17:16: Current learning rate: 0.1. Time taken for epoch: 23.72 seconds.

10:17:16: Current learning rate: 0.1. Time taken for epoch: 23.72 seconds.

10:17:16: Current learning rate: 0.1. Time taken for epoch: 23.72 seconds.

10:17:17: Train Epoch: 49 [0/45000 (0%)]	Loss: nan
10:17:17: Train Epoch: 49 [0/45000 (0%)]	Loss: nan
10:17:17: Train Epoch: 49 [0/45000 (0%)]	Loss: nan
10:17:21: Train Epoch: 49 [10000/45000 (22%)]	Loss: nan
10:17:21: Train Epoch: 49 [10000/45000 (22%)]	Loss: nan
10:17:21: Train Epoch: 49 [10000/45000 (22%)]	Loss: nan
10:17:26: Train Epoch: 49 [20000/45000 (44%)]	Loss: nan
10:17:26: Train Epoch: 49 [20000/45000 (44%)]	Loss: nan
10:17:26: Train Epoch: 49 [20000/45000 (44%)]	Loss: nan
10:17:30: Train Epoch: 49 [30000/45000 (67%)]	Loss: nan
10:17:30: Train Epoch: 49 [30000/45000 (67%)]	Loss: nan
10:17:30: Train Epoch: 49 [30000/45000 (67%)]	Loss: nan
10:17:35: Train Epoch: 49 [40000/45000 (89%)]	Loss: nan
10:17:35: Train Epoch: 49 [40000/45000 (89%)]	Loss: nan
10:17:35: Train Epoch: 49 [40000/45000 (89%)]	Loss: nan
10:17:38: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:17:38: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:17:38: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:17:38: Current learning rate: 0.1. Time taken for epoch: 22.32 seconds.

10:17:38: Current learning rate: 0.1. Time taken for epoch: 22.32 seconds.

10:17:38: Current learning rate: 0.1. Time taken for epoch: 22.32 seconds.

10:17:39: Train Epoch: 50 [0/45000 (0%)]	Loss: nan
10:17:39: Train Epoch: 50 [0/45000 (0%)]	Loss: nan
10:17:39: Train Epoch: 50 [0/45000 (0%)]	Loss: nan
10:17:44: Train Epoch: 50 [10000/45000 (22%)]	Loss: nan
10:17:44: Train Epoch: 50 [10000/45000 (22%)]	Loss: nan
10:17:44: Train Epoch: 50 [10000/45000 (22%)]	Loss: nan
10:17:48: Train Epoch: 50 [20000/45000 (44%)]	Loss: nan
10:17:48: Train Epoch: 50 [20000/45000 (44%)]	Loss: nan
10:17:48: Train Epoch: 50 [20000/45000 (44%)]	Loss: nan
10:17:53: Train Epoch: 50 [30000/45000 (67%)]	Loss: nan
10:17:53: Train Epoch: 50 [30000/45000 (67%)]	Loss: nan
10:17:53: Train Epoch: 50 [30000/45000 (67%)]	Loss: nan
10:17:58: Train Epoch: 50 [40000/45000 (89%)]	Loss: nan
10:17:58: Train Epoch: 50 [40000/45000 (89%)]	Loss: nan
10:17:58: Train Epoch: 50 [40000/45000 (89%)]	Loss: nan
10:18:02: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:18:02: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:18:02: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:18:02: Current learning rate: 0.1. Time taken for epoch: 23.78 seconds.

10:18:02: Current learning rate: 0.1. Time taken for epoch: 23.78 seconds.

10:18:02: Current learning rate: 0.1. Time taken for epoch: 23.78 seconds.

10:18:03: Train Epoch: 51 [0/45000 (0%)]	Loss: nan
10:18:03: Train Epoch: 51 [0/45000 (0%)]	Loss: nan
10:18:03: Train Epoch: 51 [0/45000 (0%)]	Loss: nan
10:18:07: Train Epoch: 51 [10000/45000 (22%)]	Loss: nan
10:18:07: Train Epoch: 51 [10000/45000 (22%)]	Loss: nan
10:18:07: Train Epoch: 51 [10000/45000 (22%)]	Loss: nan
10:18:12: Train Epoch: 51 [20000/45000 (44%)]	Loss: nan
10:18:12: Train Epoch: 51 [20000/45000 (44%)]	Loss: nan
10:18:12: Train Epoch: 51 [20000/45000 (44%)]	Loss: nan
10:18:17: Train Epoch: 51 [30000/45000 (67%)]	Loss: nan
10:18:17: Train Epoch: 51 [30000/45000 (67%)]	Loss: nan
10:18:17: Train Epoch: 51 [30000/45000 (67%)]	Loss: nan
10:18:21: Train Epoch: 51 [40000/45000 (89%)]	Loss: nan
10:18:21: Train Epoch: 51 [40000/45000 (89%)]	Loss: nan
10:18:21: Train Epoch: 51 [40000/45000 (89%)]	Loss: nan
10:18:25: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:18:25: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:18:25: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:18:25: Current learning rate: 0.1. Time taken for epoch: 22.77 seconds.

10:18:25: Current learning rate: 0.1. Time taken for epoch: 22.77 seconds.

10:18:25: Current learning rate: 0.1. Time taken for epoch: 22.77 seconds.

10:18:25: Train Epoch: 52 [0/45000 (0%)]	Loss: nan
10:18:25: Train Epoch: 52 [0/45000 (0%)]	Loss: nan
10:18:25: Train Epoch: 52 [0/45000 (0%)]	Loss: nan
10:18:30: Train Epoch: 52 [10000/45000 (22%)]	Loss: nan
10:18:30: Train Epoch: 52 [10000/45000 (22%)]	Loss: nan
10:18:30: Train Epoch: 52 [10000/45000 (22%)]	Loss: nan
10:18:34: Train Epoch: 52 [20000/45000 (44%)]	Loss: nan
10:18:34: Train Epoch: 52 [20000/45000 (44%)]	Loss: nan
10:18:34: Train Epoch: 52 [20000/45000 (44%)]	Loss: nan
10:18:39: Train Epoch: 52 [30000/45000 (67%)]	Loss: nan
10:18:39: Train Epoch: 52 [30000/45000 (67%)]	Loss: nan
10:18:39: Train Epoch: 52 [30000/45000 (67%)]	Loss: nan
10:18:43: Train Epoch: 52 [40000/45000 (89%)]	Loss: nan
10:18:43: Train Epoch: 52 [40000/45000 (89%)]	Loss: nan
10:18:43: Train Epoch: 52 [40000/45000 (89%)]	Loss: nan
10:18:47: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:18:47: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:18:47: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:18:47: Current learning rate: 0.1. Time taken for epoch: 22.36 seconds.

10:18:47: Current learning rate: 0.1. Time taken for epoch: 22.36 seconds.

10:18:47: Current learning rate: 0.1. Time taken for epoch: 22.36 seconds.

10:18:48: Train Epoch: 53 [0/45000 (0%)]	Loss: nan
10:18:48: Train Epoch: 53 [0/45000 (0%)]	Loss: nan
10:18:48: Train Epoch: 53 [0/45000 (0%)]	Loss: nan
10:18:52: Train Epoch: 53 [10000/45000 (22%)]	Loss: nan
10:18:52: Train Epoch: 53 [10000/45000 (22%)]	Loss: nan
10:18:52: Train Epoch: 53 [10000/45000 (22%)]	Loss: nan
10:18:57: Train Epoch: 53 [20000/45000 (44%)]	Loss: nan
10:18:57: Train Epoch: 53 [20000/45000 (44%)]	Loss: nan
10:18:57: Train Epoch: 53 [20000/45000 (44%)]	Loss: nan
10:19:02: Train Epoch: 53 [30000/45000 (67%)]	Loss: nan
10:19:02: Train Epoch: 53 [30000/45000 (67%)]	Loss: nan
10:19:02: Train Epoch: 53 [30000/45000 (67%)]	Loss: nan
10:19:06: Train Epoch: 53 [40000/45000 (89%)]	Loss: nan
10:19:06: Train Epoch: 53 [40000/45000 (89%)]	Loss: nan
10:19:06: Train Epoch: 53 [40000/45000 (89%)]	Loss: nan
10:19:10: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:19:10: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:19:10: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:19:10: Current learning rate: 0.1. Time taken for epoch: 22.96 seconds.

10:19:10: Current learning rate: 0.1. Time taken for epoch: 22.96 seconds.

10:19:10: Current learning rate: 0.1. Time taken for epoch: 22.96 seconds.

10:19:11: Train Epoch: 54 [0/45000 (0%)]	Loss: nan
10:19:11: Train Epoch: 54 [0/45000 (0%)]	Loss: nan
10:19:11: Train Epoch: 54 [0/45000 (0%)]	Loss: nan
10:19:16: Train Epoch: 54 [10000/45000 (22%)]	Loss: nan
10:19:16: Train Epoch: 54 [10000/45000 (22%)]	Loss: nan
10:19:16: Train Epoch: 54 [10000/45000 (22%)]	Loss: nan
10:19:20: Train Epoch: 54 [20000/45000 (44%)]	Loss: nan
10:19:20: Train Epoch: 54 [20000/45000 (44%)]	Loss: nan
10:19:20: Train Epoch: 54 [20000/45000 (44%)]	Loss: nan
10:19:25: Train Epoch: 54 [30000/45000 (67%)]	Loss: nan
10:19:25: Train Epoch: 54 [30000/45000 (67%)]	Loss: nan
10:19:25: Train Epoch: 54 [30000/45000 (67%)]	Loss: nan
10:19:29: Train Epoch: 54 [40000/45000 (89%)]	Loss: nan
10:19:29: Train Epoch: 54 [40000/45000 (89%)]	Loss: nan
10:19:29: Train Epoch: 54 [40000/45000 (89%)]	Loss: nan
10:19:33: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:19:33: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:19:33: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:19:33: Current learning rate: 0.1. Time taken for epoch: 22.81 seconds.

10:19:33: Current learning rate: 0.1. Time taken for epoch: 22.81 seconds.

10:19:33: Current learning rate: 0.1. Time taken for epoch: 22.81 seconds.

10:19:34: Train Epoch: 55 [0/45000 (0%)]	Loss: nan
10:19:34: Train Epoch: 55 [0/45000 (0%)]	Loss: nan
10:19:34: Train Epoch: 55 [0/45000 (0%)]	Loss: nan
10:19:38: Train Epoch: 55 [10000/45000 (22%)]	Loss: nan
10:19:38: Train Epoch: 55 [10000/45000 (22%)]	Loss: nan
10:19:38: Train Epoch: 55 [10000/45000 (22%)]	Loss: nan
10:19:43: Train Epoch: 55 [20000/45000 (44%)]	Loss: nan
10:19:43: Train Epoch: 55 [20000/45000 (44%)]	Loss: nan
10:19:43: Train Epoch: 55 [20000/45000 (44%)]	Loss: nan
10:19:47: Train Epoch: 55 [30000/45000 (67%)]	Loss: nan
10:19:47: Train Epoch: 55 [30000/45000 (67%)]	Loss: nan
10:19:47: Train Epoch: 55 [30000/45000 (67%)]	Loss: nan
10:19:52: Train Epoch: 55 [40000/45000 (89%)]	Loss: nan
10:19:52: Train Epoch: 55 [40000/45000 (89%)]	Loss: nan
10:19:52: Train Epoch: 55 [40000/45000 (89%)]	Loss: nan
10:19:56: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:19:56: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:19:56: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:19:56: Current learning rate: 0.1. Time taken for epoch: 22.78 seconds.

10:19:56: Current learning rate: 0.1. Time taken for epoch: 22.78 seconds.

10:19:56: Current learning rate: 0.1. Time taken for epoch: 22.78 seconds.

10:19:57: Train Epoch: 56 [0/45000 (0%)]	Loss: nan
10:19:57: Train Epoch: 56 [0/45000 (0%)]	Loss: nan
10:19:57: Train Epoch: 56 [0/45000 (0%)]	Loss: nan
10:20:01: Train Epoch: 56 [10000/45000 (22%)]	Loss: nan
10:20:01: Train Epoch: 56 [10000/45000 (22%)]	Loss: nan
10:20:01: Train Epoch: 56 [10000/45000 (22%)]	Loss: nan
10:20:06: Train Epoch: 56 [20000/45000 (44%)]	Loss: nan
10:20:06: Train Epoch: 56 [20000/45000 (44%)]	Loss: nan
10:20:06: Train Epoch: 56 [20000/45000 (44%)]	Loss: nan
10:20:10: Train Epoch: 56 [30000/45000 (67%)]	Loss: nan
10:20:10: Train Epoch: 56 [30000/45000 (67%)]	Loss: nan
10:20:10: Train Epoch: 56 [30000/45000 (67%)]	Loss: nan
10:20:15: Train Epoch: 56 [40000/45000 (89%)]	Loss: nan
10:20:15: Train Epoch: 56 [40000/45000 (89%)]	Loss: nan
10:20:15: Train Epoch: 56 [40000/45000 (89%)]	Loss: nan
10:20:19: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:20:19: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:20:19: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:20:19: Current learning rate: 0.010000000000000002. Time taken for epoch: 23.16 seconds.

10:20:19: Current learning rate: 0.010000000000000002. Time taken for epoch: 23.16 seconds.

10:20:19: Current learning rate: 0.010000000000000002. Time taken for epoch: 23.16 seconds.

10:20:19: Train Epoch: 57 [0/45000 (0%)]	Loss: nan
10:20:19: Train Epoch: 57 [0/45000 (0%)]	Loss: nan
10:20:19: Train Epoch: 57 [0/45000 (0%)]	Loss: nan
10:20:24: Train Epoch: 57 [10000/45000 (22%)]	Loss: nan
10:20:24: Train Epoch: 57 [10000/45000 (22%)]	Loss: nan
10:20:24: Train Epoch: 57 [10000/45000 (22%)]	Loss: nan
10:20:29: Train Epoch: 57 [20000/45000 (44%)]	Loss: nan
10:20:29: Train Epoch: 57 [20000/45000 (44%)]	Loss: nan
10:20:29: Train Epoch: 57 [20000/45000 (44%)]	Loss: nan
10:20:33: Train Epoch: 57 [30000/45000 (67%)]	Loss: nan
10:20:33: Train Epoch: 57 [30000/45000 (67%)]	Loss: nan
10:20:33: Train Epoch: 57 [30000/45000 (67%)]	Loss: nan
10:20:37: Train Epoch: 57 [40000/45000 (89%)]	Loss: nan
10:20:37: Train Epoch: 57 [40000/45000 (89%)]	Loss: nan
10:20:37: Train Epoch: 57 [40000/45000 (89%)]	Loss: nan
10:20:41: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:20:41: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:20:41: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:20:41: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.29 seconds.

10:20:41: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.29 seconds.

10:20:41: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.29 seconds.

10:20:42: Train Epoch: 58 [0/45000 (0%)]	Loss: nan
10:20:42: Train Epoch: 58 [0/45000 (0%)]	Loss: nan
10:20:42: Train Epoch: 58 [0/45000 (0%)]	Loss: nan
10:20:46: Train Epoch: 58 [10000/45000 (22%)]	Loss: nan
10:20:46: Train Epoch: 58 [10000/45000 (22%)]	Loss: nan
10:20:46: Train Epoch: 58 [10000/45000 (22%)]	Loss: nan
10:20:51: Train Epoch: 58 [20000/45000 (44%)]	Loss: nan
10:20:51: Train Epoch: 58 [20000/45000 (44%)]	Loss: nan
10:20:51: Train Epoch: 58 [20000/45000 (44%)]	Loss: nan
10:20:56: Train Epoch: 58 [30000/45000 (67%)]	Loss: nan
10:20:56: Train Epoch: 58 [30000/45000 (67%)]	Loss: nan
10:20:56: Train Epoch: 58 [30000/45000 (67%)]	Loss: nan
10:21:01: Train Epoch: 58 [40000/45000 (89%)]	Loss: nan
10:21:01: Train Epoch: 58 [40000/45000 (89%)]	Loss: nan
10:21:01: Train Epoch: 58 [40000/45000 (89%)]	Loss: nan
10:21:05: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:21:05: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:21:05: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:21:05: Current learning rate: 0.010000000000000002. Time taken for epoch: 23.58 seconds.

10:21:05: Current learning rate: 0.010000000000000002. Time taken for epoch: 23.58 seconds.

10:21:05: Current learning rate: 0.010000000000000002. Time taken for epoch: 23.58 seconds.

10:21:05: Train Epoch: 59 [0/45000 (0%)]	Loss: nan
10:21:05: Train Epoch: 59 [0/45000 (0%)]	Loss: nan
10:21:05: Train Epoch: 59 [0/45000 (0%)]	Loss: nan
10:21:10: Train Epoch: 59 [10000/45000 (22%)]	Loss: nan
10:21:10: Train Epoch: 59 [10000/45000 (22%)]	Loss: nan
10:21:10: Train Epoch: 59 [10000/45000 (22%)]	Loss: nan
10:21:15: Train Epoch: 59 [20000/45000 (44%)]	Loss: nan
10:21:15: Train Epoch: 59 [20000/45000 (44%)]	Loss: nan
10:21:15: Train Epoch: 59 [20000/45000 (44%)]	Loss: nan
10:21:19: Train Epoch: 59 [30000/45000 (67%)]	Loss: nan
10:21:19: Train Epoch: 59 [30000/45000 (67%)]	Loss: nan
10:21:19: Train Epoch: 59 [30000/45000 (67%)]	Loss: nan
10:21:24: Train Epoch: 59 [40000/45000 (89%)]	Loss: nan
10:21:24: Train Epoch: 59 [40000/45000 (89%)]	Loss: nan
10:21:24: Train Epoch: 59 [40000/45000 (89%)]	Loss: nan
10:21:28: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:21:28: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:21:28: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:21:28: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.98 seconds.

10:21:28: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.98 seconds.

10:21:28: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.98 seconds.

10:21:28: Train Epoch: 60 [0/45000 (0%)]	Loss: nan
10:21:28: Train Epoch: 60 [0/45000 (0%)]	Loss: nan
10:21:28: Train Epoch: 60 [0/45000 (0%)]	Loss: nan
10:21:33: Train Epoch: 60 [10000/45000 (22%)]	Loss: nan
10:21:33: Train Epoch: 60 [10000/45000 (22%)]	Loss: nan
10:21:33: Train Epoch: 60 [10000/45000 (22%)]	Loss: nan
10:21:37: Train Epoch: 60 [20000/45000 (44%)]	Loss: nan
10:21:37: Train Epoch: 60 [20000/45000 (44%)]	Loss: nan
10:21:37: Train Epoch: 60 [20000/45000 (44%)]	Loss: nan
10:21:42: Train Epoch: 60 [30000/45000 (67%)]	Loss: nan
10:21:42: Train Epoch: 60 [30000/45000 (67%)]	Loss: nan
10:21:42: Train Epoch: 60 [30000/45000 (67%)]	Loss: nan
10:21:46: Train Epoch: 60 [40000/45000 (89%)]	Loss: nan
10:21:46: Train Epoch: 60 [40000/45000 (89%)]	Loss: nan
10:21:46: Train Epoch: 60 [40000/45000 (89%)]	Loss: nan
10:21:50: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:21:50: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:21:50: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:21:50: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.50 seconds.

10:21:50: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.50 seconds.

10:21:50: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.50 seconds.

10:21:51: Train Epoch: 61 [0/45000 (0%)]	Loss: nan
10:21:51: Train Epoch: 61 [0/45000 (0%)]	Loss: nan
10:21:51: Train Epoch: 61 [0/45000 (0%)]	Loss: nan
10:21:56: Train Epoch: 61 [10000/45000 (22%)]	Loss: nan
10:21:56: Train Epoch: 61 [10000/45000 (22%)]	Loss: nan
10:21:56: Train Epoch: 61 [10000/45000 (22%)]	Loss: nan
10:22:01: Train Epoch: 61 [20000/45000 (44%)]	Loss: nan
10:22:01: Train Epoch: 61 [20000/45000 (44%)]	Loss: nan
10:22:01: Train Epoch: 61 [20000/45000 (44%)]	Loss: nan
10:22:05: Train Epoch: 61 [30000/45000 (67%)]	Loss: nan
10:22:05: Train Epoch: 61 [30000/45000 (67%)]	Loss: nan
10:22:05: Train Epoch: 61 [30000/45000 (67%)]	Loss: nan
10:22:10: Train Epoch: 61 [40000/45000 (89%)]	Loss: nan
10:22:10: Train Epoch: 61 [40000/45000 (89%)]	Loss: nan
10:22:10: Train Epoch: 61 [40000/45000 (89%)]	Loss: nan
10:22:14: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:22:14: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:22:14: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:22:14: Current learning rate: 0.010000000000000002. Time taken for epoch: 23.65 seconds.

10:22:14: Current learning rate: 0.010000000000000002. Time taken for epoch: 23.65 seconds.

10:22:14: Current learning rate: 0.010000000000000002. Time taken for epoch: 23.65 seconds.

10:22:15: Train Epoch: 62 [0/45000 (0%)]	Loss: nan
10:22:15: Train Epoch: 62 [0/45000 (0%)]	Loss: nan
10:22:15: Train Epoch: 62 [0/45000 (0%)]	Loss: nan
10:22:19: Train Epoch: 62 [10000/45000 (22%)]	Loss: nan
10:22:19: Train Epoch: 62 [10000/45000 (22%)]	Loss: nan
10:22:19: Train Epoch: 62 [10000/45000 (22%)]	Loss: nan
10:22:24: Train Epoch: 62 [20000/45000 (44%)]	Loss: nan
10:22:24: Train Epoch: 62 [20000/45000 (44%)]	Loss: nan
10:22:24: Train Epoch: 62 [20000/45000 (44%)]	Loss: nan
10:22:28: Train Epoch: 62 [30000/45000 (67%)]	Loss: nan
10:22:28: Train Epoch: 62 [30000/45000 (67%)]	Loss: nan
10:22:28: Train Epoch: 62 [30000/45000 (67%)]	Loss: nan
10:22:32: Train Epoch: 62 [40000/45000 (89%)]	Loss: nan
10:22:32: Train Epoch: 62 [40000/45000 (89%)]	Loss: nan
10:22:32: Train Epoch: 62 [40000/45000 (89%)]	Loss: nan
10:22:36: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:22:36: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:22:36: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:22:36: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.24 seconds.

10:22:36: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.24 seconds.

10:22:36: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.24 seconds.

10:22:37: Train Epoch: 63 [0/45000 (0%)]	Loss: nan
10:22:37: Train Epoch: 63 [0/45000 (0%)]	Loss: nan
10:22:37: Train Epoch: 63 [0/45000 (0%)]	Loss: nan
10:22:41: Train Epoch: 63 [10000/45000 (22%)]	Loss: nan
10:22:41: Train Epoch: 63 [10000/45000 (22%)]	Loss: nan
10:22:41: Train Epoch: 63 [10000/45000 (22%)]	Loss: nan
10:22:46: Train Epoch: 63 [20000/45000 (44%)]	Loss: nan
10:22:46: Train Epoch: 63 [20000/45000 (44%)]	Loss: nan
10:22:46: Train Epoch: 63 [20000/45000 (44%)]	Loss: nan
10:22:50: Train Epoch: 63 [30000/45000 (67%)]	Loss: nan
10:22:50: Train Epoch: 63 [30000/45000 (67%)]	Loss: nan
10:22:50: Train Epoch: 63 [30000/45000 (67%)]	Loss: nan
10:22:55: Train Epoch: 63 [40000/45000 (89%)]	Loss: nan
10:22:55: Train Epoch: 63 [40000/45000 (89%)]	Loss: nan
10:22:55: Train Epoch: 63 [40000/45000 (89%)]	Loss: nan
10:22:59: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:22:59: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:22:59: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:22:59: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.74 seconds.

10:22:59: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.74 seconds.

10:22:59: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.74 seconds.

10:22:59: Train Epoch: 64 [0/45000 (0%)]	Loss: nan
10:22:59: Train Epoch: 64 [0/45000 (0%)]	Loss: nan
10:22:59: Train Epoch: 64 [0/45000 (0%)]	Loss: nan
10:23:04: Train Epoch: 64 [10000/45000 (22%)]	Loss: nan
10:23:04: Train Epoch: 64 [10000/45000 (22%)]	Loss: nan
10:23:04: Train Epoch: 64 [10000/45000 (22%)]	Loss: nan
10:23:09: Train Epoch: 64 [20000/45000 (44%)]	Loss: nan
10:23:09: Train Epoch: 64 [20000/45000 (44%)]	Loss: nan
10:23:09: Train Epoch: 64 [20000/45000 (44%)]	Loss: nan
10:23:14: Train Epoch: 64 [30000/45000 (67%)]	Loss: nan
10:23:14: Train Epoch: 64 [30000/45000 (67%)]	Loss: nan
10:23:14: Train Epoch: 64 [30000/45000 (67%)]	Loss: nan
10:23:18: Train Epoch: 64 [40000/45000 (89%)]	Loss: nan
10:23:18: Train Epoch: 64 [40000/45000 (89%)]	Loss: nan
10:23:18: Train Epoch: 64 [40000/45000 (89%)]	Loss: nan
10:23:22: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:23:22: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:23:22: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:23:22: Current learning rate: 0.010000000000000002. Time taken for epoch: 23.29 seconds.

10:23:22: Current learning rate: 0.010000000000000002. Time taken for epoch: 23.29 seconds.

10:23:22: Current learning rate: 0.010000000000000002. Time taken for epoch: 23.29 seconds.

10:23:23: Train Epoch: 65 [0/45000 (0%)]	Loss: nan
10:23:23: Train Epoch: 65 [0/45000 (0%)]	Loss: nan
10:23:23: Train Epoch: 65 [0/45000 (0%)]	Loss: nan
10:23:27: Train Epoch: 65 [10000/45000 (22%)]	Loss: nan
10:23:27: Train Epoch: 65 [10000/45000 (22%)]	Loss: nan
10:23:27: Train Epoch: 65 [10000/45000 (22%)]	Loss: nan
10:23:32: Train Epoch: 65 [20000/45000 (44%)]	Loss: nan
10:23:32: Train Epoch: 65 [20000/45000 (44%)]	Loss: nan
10:23:32: Train Epoch: 65 [20000/45000 (44%)]	Loss: nan
10:23:36: Train Epoch: 65 [30000/45000 (67%)]	Loss: nan
10:23:36: Train Epoch: 65 [30000/45000 (67%)]	Loss: nan
10:23:36: Train Epoch: 65 [30000/45000 (67%)]	Loss: nan
10:23:41: Train Epoch: 65 [40000/45000 (89%)]	Loss: nan
10:23:41: Train Epoch: 65 [40000/45000 (89%)]	Loss: nan
10:23:41: Train Epoch: 65 [40000/45000 (89%)]	Loss: nan
10:23:45: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:23:45: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:23:45: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:23:45: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.40 seconds.

10:23:45: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.40 seconds.

10:23:45: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.40 seconds.

10:23:45: Train Epoch: 66 [0/45000 (0%)]	Loss: nan
10:23:45: Train Epoch: 66 [0/45000 (0%)]	Loss: nan
10:23:45: Train Epoch: 66 [0/45000 (0%)]	Loss: nan
10:23:50: Train Epoch: 66 [10000/45000 (22%)]	Loss: nan
10:23:50: Train Epoch: 66 [10000/45000 (22%)]	Loss: nan
10:23:50: Train Epoch: 66 [10000/45000 (22%)]	Loss: nan
10:23:54: Train Epoch: 66 [20000/45000 (44%)]	Loss: nan
10:23:54: Train Epoch: 66 [20000/45000 (44%)]	Loss: nan
10:23:54: Train Epoch: 66 [20000/45000 (44%)]	Loss: nan
10:23:59: Train Epoch: 66 [30000/45000 (67%)]	Loss: nan
10:23:59: Train Epoch: 66 [30000/45000 (67%)]	Loss: nan
10:23:59: Train Epoch: 66 [30000/45000 (67%)]	Loss: nan
10:24:04: Train Epoch: 66 [40000/45000 (89%)]	Loss: nan
10:24:04: Train Epoch: 66 [40000/45000 (89%)]	Loss: nan
10:24:04: Train Epoch: 66 [40000/45000 (89%)]	Loss: nan
10:24:07: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:24:07: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:24:07: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:24:07: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.80 seconds.

10:24:07: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.80 seconds.

10:24:07: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.80 seconds.

10:24:08: Train Epoch: 67 [0/45000 (0%)]	Loss: nan
10:24:08: Train Epoch: 67 [0/45000 (0%)]	Loss: nan
10:24:08: Train Epoch: 67 [0/45000 (0%)]	Loss: nan
10:24:13: Train Epoch: 67 [10000/45000 (22%)]	Loss: nan
10:24:13: Train Epoch: 67 [10000/45000 (22%)]	Loss: nan
10:24:13: Train Epoch: 67 [10000/45000 (22%)]	Loss: nan
10:24:17: Train Epoch: 67 [20000/45000 (44%)]	Loss: nan
10:24:17: Train Epoch: 67 [20000/45000 (44%)]	Loss: nan
10:24:17: Train Epoch: 67 [20000/45000 (44%)]	Loss: nan
10:24:22: Train Epoch: 67 [30000/45000 (67%)]	Loss: nan
10:24:22: Train Epoch: 67 [30000/45000 (67%)]	Loss: nan
10:24:22: Train Epoch: 67 [30000/45000 (67%)]	Loss: nan
10:24:26: Train Epoch: 67 [40000/45000 (89%)]	Loss: nan
10:24:26: Train Epoch: 67 [40000/45000 (89%)]	Loss: nan
10:24:26: Train Epoch: 67 [40000/45000 (89%)]	Loss: nan
10:24:30: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:24:30: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:24:30: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:24:30: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.37 seconds.

10:24:30: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.37 seconds.

10:24:30: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.37 seconds.

10:24:30: Train Epoch: 68 [0/45000 (0%)]	Loss: nan
10:24:30: Train Epoch: 68 [0/45000 (0%)]	Loss: nan
10:24:30: Train Epoch: 68 [0/45000 (0%)]	Loss: nan
10:24:35: Train Epoch: 68 [10000/45000 (22%)]	Loss: nan
10:24:35: Train Epoch: 68 [10000/45000 (22%)]	Loss: nan
10:24:35: Train Epoch: 68 [10000/45000 (22%)]	Loss: nan
10:24:39: Train Epoch: 68 [20000/45000 (44%)]	Loss: nan
10:24:39: Train Epoch: 68 [20000/45000 (44%)]	Loss: nan
10:24:39: Train Epoch: 68 [20000/45000 (44%)]	Loss: nan
10:24:44: Train Epoch: 68 [30000/45000 (67%)]	Loss: nan
10:24:44: Train Epoch: 68 [30000/45000 (67%)]	Loss: nan
10:24:44: Train Epoch: 68 [30000/45000 (67%)]	Loss: nan
10:24:48: Train Epoch: 68 [40000/45000 (89%)]	Loss: nan
10:24:48: Train Epoch: 68 [40000/45000 (89%)]	Loss: nan
10:24:48: Train Epoch: 68 [40000/45000 (89%)]	Loss: nan
10:24:52: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:24:52: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:24:52: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:24:52: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.35 seconds.

10:24:52: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.35 seconds.

10:24:52: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.35 seconds.

10:24:53: Train Epoch: 69 [0/45000 (0%)]	Loss: nan
10:24:53: Train Epoch: 69 [0/45000 (0%)]	Loss: nan
10:24:53: Train Epoch: 69 [0/45000 (0%)]	Loss: nan
10:24:58: Train Epoch: 69 [10000/45000 (22%)]	Loss: nan
10:24:58: Train Epoch: 69 [10000/45000 (22%)]	Loss: nan
10:24:58: Train Epoch: 69 [10000/45000 (22%)]	Loss: nan
10:25:03: Train Epoch: 69 [20000/45000 (44%)]	Loss: nan
10:25:03: Train Epoch: 69 [20000/45000 (44%)]	Loss: nan
10:25:03: Train Epoch: 69 [20000/45000 (44%)]	Loss: nan
10:25:07: Train Epoch: 69 [30000/45000 (67%)]	Loss: nan
10:25:07: Train Epoch: 69 [30000/45000 (67%)]	Loss: nan
10:25:07: Train Epoch: 69 [30000/45000 (67%)]	Loss: nan
10:25:11: Train Epoch: 69 [40000/45000 (89%)]	Loss: nan
10:25:11: Train Epoch: 69 [40000/45000 (89%)]	Loss: nan
10:25:11: Train Epoch: 69 [40000/45000 (89%)]	Loss: nan
10:25:15: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:25:15: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:25:15: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:25:15: Current learning rate: 0.010000000000000002. Time taken for epoch: 23.37 seconds.

10:25:15: Current learning rate: 0.010000000000000002. Time taken for epoch: 23.37 seconds.

10:25:15: Current learning rate: 0.010000000000000002. Time taken for epoch: 23.37 seconds.

10:25:16: Train Epoch: 70 [0/45000 (0%)]	Loss: nan
10:25:16: Train Epoch: 70 [0/45000 (0%)]	Loss: nan
10:25:16: Train Epoch: 70 [0/45000 (0%)]	Loss: nan
10:25:21: Train Epoch: 70 [10000/45000 (22%)]	Loss: nan
10:25:21: Train Epoch: 70 [10000/45000 (22%)]	Loss: nan
10:25:21: Train Epoch: 70 [10000/45000 (22%)]	Loss: nan
10:25:25: Train Epoch: 70 [20000/45000 (44%)]	Loss: nan
10:25:25: Train Epoch: 70 [20000/45000 (44%)]	Loss: nan
10:25:25: Train Epoch: 70 [20000/45000 (44%)]	Loss: nan
10:25:29: Train Epoch: 70 [30000/45000 (67%)]	Loss: nan
10:25:29: Train Epoch: 70 [30000/45000 (67%)]	Loss: nan
10:25:29: Train Epoch: 70 [30000/45000 (67%)]	Loss: nan
10:25:34: Train Epoch: 70 [40000/45000 (89%)]	Loss: nan
10:25:34: Train Epoch: 70 [40000/45000 (89%)]	Loss: nan
10:25:34: Train Epoch: 70 [40000/45000 (89%)]	Loss: nan
10:25:37: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:25:37: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:25:37: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:25:37: Current learning rate: 0.010000000000000002. Time taken for epoch: 21.97 seconds.

10:25:37: Current learning rate: 0.010000000000000002. Time taken for epoch: 21.97 seconds.

10:25:37: Current learning rate: 0.010000000000000002. Time taken for epoch: 21.97 seconds.

10:25:38: Train Epoch: 71 [0/45000 (0%)]	Loss: nan
10:25:38: Train Epoch: 71 [0/45000 (0%)]	Loss: nan
10:25:38: Train Epoch: 71 [0/45000 (0%)]	Loss: nan
10:25:43: Train Epoch: 71 [10000/45000 (22%)]	Loss: nan
10:25:43: Train Epoch: 71 [10000/45000 (22%)]	Loss: nan
10:25:43: Train Epoch: 71 [10000/45000 (22%)]	Loss: nan
10:25:47: Train Epoch: 71 [20000/45000 (44%)]	Loss: nan
10:25:47: Train Epoch: 71 [20000/45000 (44%)]	Loss: nan
10:25:47: Train Epoch: 71 [20000/45000 (44%)]	Loss: nan
10:25:52: Train Epoch: 71 [30000/45000 (67%)]	Loss: nan
10:25:52: Train Epoch: 71 [30000/45000 (67%)]	Loss: nan
10:25:52: Train Epoch: 71 [30000/45000 (67%)]	Loss: nan
10:25:56: Train Epoch: 71 [40000/45000 (89%)]	Loss: nan
10:25:56: Train Epoch: 71 [40000/45000 (89%)]	Loss: nan
10:25:56: Train Epoch: 71 [40000/45000 (89%)]	Loss: nan
10:26:00: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:26:00: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:26:00: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:26:00: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.76 seconds.

10:26:00: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.76 seconds.

10:26:00: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.76 seconds.

10:26:01: Train Epoch: 72 [0/45000 (0%)]	Loss: nan
10:26:01: Train Epoch: 72 [0/45000 (0%)]	Loss: nan
10:26:01: Train Epoch: 72 [0/45000 (0%)]	Loss: nan
10:26:06: Train Epoch: 72 [10000/45000 (22%)]	Loss: nan
10:26:06: Train Epoch: 72 [10000/45000 (22%)]	Loss: nan
10:26:06: Train Epoch: 72 [10000/45000 (22%)]	Loss: nan
10:26:10: Train Epoch: 72 [20000/45000 (44%)]	Loss: nan
10:26:10: Train Epoch: 72 [20000/45000 (44%)]	Loss: nan
10:26:10: Train Epoch: 72 [20000/45000 (44%)]	Loss: nan
10:26:15: Train Epoch: 72 [30000/45000 (67%)]	Loss: nan
10:26:15: Train Epoch: 72 [30000/45000 (67%)]	Loss: nan
10:26:15: Train Epoch: 72 [30000/45000 (67%)]	Loss: nan
10:26:19: Train Epoch: 72 [40000/45000 (89%)]	Loss: nan
10:26:19: Train Epoch: 72 [40000/45000 (89%)]	Loss: nan
10:26:19: Train Epoch: 72 [40000/45000 (89%)]	Loss: nan
10:26:23: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:26:23: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:26:23: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:26:23: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.93 seconds.

10:26:23: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.93 seconds.

10:26:23: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.93 seconds.

10:26:24: Train Epoch: 73 [0/45000 (0%)]	Loss: nan
10:26:24: Train Epoch: 73 [0/45000 (0%)]	Loss: nan
10:26:24: Train Epoch: 73 [0/45000 (0%)]	Loss: nan
10:26:28: Train Epoch: 73 [10000/45000 (22%)]	Loss: nan
10:26:28: Train Epoch: 73 [10000/45000 (22%)]	Loss: nan
10:26:28: Train Epoch: 73 [10000/45000 (22%)]	Loss: nan
10:26:33: Train Epoch: 73 [20000/45000 (44%)]	Loss: nan
10:26:33: Train Epoch: 73 [20000/45000 (44%)]	Loss: nan
10:26:33: Train Epoch: 73 [20000/45000 (44%)]	Loss: nan
10:26:37: Train Epoch: 73 [30000/45000 (67%)]	Loss: nan
10:26:37: Train Epoch: 73 [30000/45000 (67%)]	Loss: nan
10:26:37: Train Epoch: 73 [30000/45000 (67%)]	Loss: nan
10:26:41: Train Epoch: 73 [40000/45000 (89%)]	Loss: nan
10:26:41: Train Epoch: 73 [40000/45000 (89%)]	Loss: nan
10:26:41: Train Epoch: 73 [40000/45000 (89%)]	Loss: nan
10:26:45: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:26:45: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:26:45: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:26:45: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.26 seconds.

10:26:45: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.26 seconds.

10:26:45: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.26 seconds.

10:26:46: Train Epoch: 74 [0/45000 (0%)]	Loss: nan
10:26:46: Train Epoch: 74 [0/45000 (0%)]	Loss: nan
10:26:46: Train Epoch: 74 [0/45000 (0%)]	Loss: nan
10:26:50: Train Epoch: 74 [10000/45000 (22%)]	Loss: nan
10:26:50: Train Epoch: 74 [10000/45000 (22%)]	Loss: nan
10:26:50: Train Epoch: 74 [10000/45000 (22%)]	Loss: nan
10:26:55: Train Epoch: 74 [20000/45000 (44%)]	Loss: nan
10:26:55: Train Epoch: 74 [20000/45000 (44%)]	Loss: nan
10:26:55: Train Epoch: 74 [20000/45000 (44%)]	Loss: nan
10:27:00: Train Epoch: 74 [30000/45000 (67%)]	Loss: nan
10:27:00: Train Epoch: 74 [30000/45000 (67%)]	Loss: nan
10:27:00: Train Epoch: 74 [30000/45000 (67%)]	Loss: nan
10:27:04: Train Epoch: 74 [40000/45000 (89%)]	Loss: nan
10:27:04: Train Epoch: 74 [40000/45000 (89%)]	Loss: nan
10:27:04: Train Epoch: 74 [40000/45000 (89%)]	Loss: nan
10:27:08: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:27:08: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:27:08: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:27:08: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.77 seconds.

10:27:08: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.77 seconds.

10:27:08: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.77 seconds.

10:27:09: Train Epoch: 75 [0/45000 (0%)]	Loss: nan
10:27:09: Train Epoch: 75 [0/45000 (0%)]	Loss: nan
10:27:09: Train Epoch: 75 [0/45000 (0%)]	Loss: nan
10:27:14: Train Epoch: 75 [10000/45000 (22%)]	Loss: nan
10:27:14: Train Epoch: 75 [10000/45000 (22%)]	Loss: nan
10:27:14: Train Epoch: 75 [10000/45000 (22%)]	Loss: nan
10:27:18: Train Epoch: 75 [20000/45000 (44%)]	Loss: nan
10:27:18: Train Epoch: 75 [20000/45000 (44%)]	Loss: nan
10:27:18: Train Epoch: 75 [20000/45000 (44%)]	Loss: nan
10:27:23: Train Epoch: 75 [30000/45000 (67%)]	Loss: nan
10:27:23: Train Epoch: 75 [30000/45000 (67%)]	Loss: nan
10:27:23: Train Epoch: 75 [30000/45000 (67%)]	Loss: nan
10:27:27: Train Epoch: 75 [40000/45000 (89%)]	Loss: nan
10:27:27: Train Epoch: 75 [40000/45000 (89%)]	Loss: nan
10:27:27: Train Epoch: 75 [40000/45000 (89%)]	Loss: nan
10:27:31: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:27:31: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:27:31: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:27:31: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.49 seconds.

10:27:31: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.49 seconds.

10:27:31: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.49 seconds.

10:27:31: Train Epoch: 76 [0/45000 (0%)]	Loss: nan
10:27:31: Train Epoch: 76 [0/45000 (0%)]	Loss: nan
10:27:31: Train Epoch: 76 [0/45000 (0%)]	Loss: nan
10:27:36: Train Epoch: 76 [10000/45000 (22%)]	Loss: nan
10:27:36: Train Epoch: 76 [10000/45000 (22%)]	Loss: nan
10:27:36: Train Epoch: 76 [10000/45000 (22%)]	Loss: nan
10:27:40: Train Epoch: 76 [20000/45000 (44%)]	Loss: nan
10:27:40: Train Epoch: 76 [20000/45000 (44%)]	Loss: nan
10:27:40: Train Epoch: 76 [20000/45000 (44%)]	Loss: nan
10:27:45: Train Epoch: 76 [30000/45000 (67%)]	Loss: nan
10:27:45: Train Epoch: 76 [30000/45000 (67%)]	Loss: nan
10:27:45: Train Epoch: 76 [30000/45000 (67%)]	Loss: nan
10:27:49: Train Epoch: 76 [40000/45000 (89%)]	Loss: nan
10:27:49: Train Epoch: 76 [40000/45000 (89%)]	Loss: nan
10:27:49: Train Epoch: 76 [40000/45000 (89%)]	Loss: nan
10:27:53: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:27:53: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:27:53: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:27:53: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.40 seconds.

10:27:53: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.40 seconds.

10:27:53: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.40 seconds.

10:27:54: Train Epoch: 77 [0/45000 (0%)]	Loss: nan
10:27:54: Train Epoch: 77 [0/45000 (0%)]	Loss: nan
10:27:54: Train Epoch: 77 [0/45000 (0%)]	Loss: nan
10:27:59: Train Epoch: 77 [10000/45000 (22%)]	Loss: nan
10:27:59: Train Epoch: 77 [10000/45000 (22%)]	Loss: nan
10:27:59: Train Epoch: 77 [10000/45000 (22%)]	Loss: nan
10:28:03: Train Epoch: 77 [20000/45000 (44%)]	Loss: nan
10:28:03: Train Epoch: 77 [20000/45000 (44%)]	Loss: nan
10:28:03: Train Epoch: 77 [20000/45000 (44%)]	Loss: nan
10:28:08: Train Epoch: 77 [30000/45000 (67%)]	Loss: nan
10:28:08: Train Epoch: 77 [30000/45000 (67%)]	Loss: nan
10:28:08: Train Epoch: 77 [30000/45000 (67%)]	Loss: nan
10:28:12: Train Epoch: 77 [40000/45000 (89%)]	Loss: nan
10:28:12: Train Epoch: 77 [40000/45000 (89%)]	Loss: nan
10:28:12: Train Epoch: 77 [40000/45000 (89%)]	Loss: nan
10:28:16: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:28:16: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:28:16: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:28:16: Current learning rate: 0.010000000000000002. Time taken for epoch: 23.35 seconds.

10:28:16: Current learning rate: 0.010000000000000002. Time taken for epoch: 23.35 seconds.

10:28:16: Current learning rate: 0.010000000000000002. Time taken for epoch: 23.35 seconds.

10:28:17: Train Epoch: 78 [0/45000 (0%)]	Loss: nan
10:28:17: Train Epoch: 78 [0/45000 (0%)]	Loss: nan
10:28:17: Train Epoch: 78 [0/45000 (0%)]	Loss: nan
10:28:22: Train Epoch: 78 [10000/45000 (22%)]	Loss: nan
10:28:22: Train Epoch: 78 [10000/45000 (22%)]	Loss: nan
10:28:22: Train Epoch: 78 [10000/45000 (22%)]	Loss: nan
10:28:26: Train Epoch: 78 [20000/45000 (44%)]	Loss: nan
10:28:26: Train Epoch: 78 [20000/45000 (44%)]	Loss: nan
10:28:26: Train Epoch: 78 [20000/45000 (44%)]	Loss: nan
10:28:30: Train Epoch: 78 [30000/45000 (67%)]	Loss: nan
10:28:30: Train Epoch: 78 [30000/45000 (67%)]	Loss: nan
10:28:30: Train Epoch: 78 [30000/45000 (67%)]	Loss: nan
10:28:35: Train Epoch: 78 [40000/45000 (89%)]	Loss: nan
10:28:35: Train Epoch: 78 [40000/45000 (89%)]	Loss: nan
10:28:35: Train Epoch: 78 [40000/45000 (89%)]	Loss: nan
10:28:38: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:28:38: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:28:38: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:28:38: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.03 seconds.

10:28:38: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.03 seconds.

10:28:38: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.03 seconds.

10:28:39: Train Epoch: 79 [0/45000 (0%)]	Loss: nan
10:28:39: Train Epoch: 79 [0/45000 (0%)]	Loss: nan
10:28:39: Train Epoch: 79 [0/45000 (0%)]	Loss: nan
10:28:44: Train Epoch: 79 [10000/45000 (22%)]	Loss: nan
10:28:44: Train Epoch: 79 [10000/45000 (22%)]	Loss: nan
10:28:44: Train Epoch: 79 [10000/45000 (22%)]	Loss: nan
10:28:48: Train Epoch: 79 [20000/45000 (44%)]	Loss: nan
10:28:48: Train Epoch: 79 [20000/45000 (44%)]	Loss: nan
10:28:48: Train Epoch: 79 [20000/45000 (44%)]	Loss: nan
10:28:53: Train Epoch: 79 [30000/45000 (67%)]	Loss: nan
10:28:53: Train Epoch: 79 [30000/45000 (67%)]	Loss: nan
10:28:53: Train Epoch: 79 [30000/45000 (67%)]	Loss: nan
10:28:57: Train Epoch: 79 [40000/45000 (89%)]	Loss: nan
10:28:57: Train Epoch: 79 [40000/45000 (89%)]	Loss: nan
10:28:57: Train Epoch: 79 [40000/45000 (89%)]	Loss: nan
10:29:02: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:29:02: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:29:02: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:29:02: Current learning rate: 0.010000000000000002. Time taken for epoch: 23.16 seconds.

10:29:02: Current learning rate: 0.010000000000000002. Time taken for epoch: 23.16 seconds.

10:29:02: Current learning rate: 0.010000000000000002. Time taken for epoch: 23.16 seconds.

10:29:02: Train Epoch: 80 [0/45000 (0%)]	Loss: nan
10:29:02: Train Epoch: 80 [0/45000 (0%)]	Loss: nan
10:29:02: Train Epoch: 80 [0/45000 (0%)]	Loss: nan
10:29:07: Train Epoch: 80 [10000/45000 (22%)]	Loss: nan
10:29:07: Train Epoch: 80 [10000/45000 (22%)]	Loss: nan
10:29:07: Train Epoch: 80 [10000/45000 (22%)]	Loss: nan
10:29:11: Train Epoch: 80 [20000/45000 (44%)]	Loss: nan
10:29:11: Train Epoch: 80 [20000/45000 (44%)]	Loss: nan
10:29:11: Train Epoch: 80 [20000/45000 (44%)]	Loss: nan
10:29:16: Train Epoch: 80 [30000/45000 (67%)]	Loss: nan
10:29:16: Train Epoch: 80 [30000/45000 (67%)]	Loss: nan
10:29:16: Train Epoch: 80 [30000/45000 (67%)]	Loss: nan
10:29:20: Train Epoch: 80 [40000/45000 (89%)]	Loss: nan
10:29:20: Train Epoch: 80 [40000/45000 (89%)]	Loss: nan
10:29:20: Train Epoch: 80 [40000/45000 (89%)]	Loss: nan
10:29:24: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:29:24: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:29:24: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:29:24: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.60 seconds.

10:29:24: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.60 seconds.

10:29:24: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.60 seconds.

10:29:25: Train Epoch: 81 [0/45000 (0%)]	Loss: nan
10:29:25: Train Epoch: 81 [0/45000 (0%)]	Loss: nan
10:29:25: Train Epoch: 81 [0/45000 (0%)]	Loss: nan
10:29:29: Train Epoch: 81 [10000/45000 (22%)]	Loss: nan
10:29:29: Train Epoch: 81 [10000/45000 (22%)]	Loss: nan
10:29:29: Train Epoch: 81 [10000/45000 (22%)]	Loss: nan
10:29:34: Train Epoch: 81 [20000/45000 (44%)]	Loss: nan
10:29:34: Train Epoch: 81 [20000/45000 (44%)]	Loss: nan
10:29:34: Train Epoch: 81 [20000/45000 (44%)]	Loss: nan
10:29:38: Train Epoch: 81 [30000/45000 (67%)]	Loss: nan
10:29:38: Train Epoch: 81 [30000/45000 (67%)]	Loss: nan
10:29:38: Train Epoch: 81 [30000/45000 (67%)]	Loss: nan
10:29:43: Train Epoch: 81 [40000/45000 (89%)]	Loss: nan
10:29:43: Train Epoch: 81 [40000/45000 (89%)]	Loss: nan
10:29:43: Train Epoch: 81 [40000/45000 (89%)]	Loss: nan
10:29:46: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:29:46: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:29:46: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:29:46: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.22 seconds.

10:29:46: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.22 seconds.

10:29:46: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.22 seconds.

10:29:47: Train Epoch: 82 [0/45000 (0%)]	Loss: nan
10:29:47: Train Epoch: 82 [0/45000 (0%)]	Loss: nan
10:29:47: Train Epoch: 82 [0/45000 (0%)]	Loss: nan
10:29:52: Train Epoch: 82 [10000/45000 (22%)]	Loss: nan
10:29:52: Train Epoch: 82 [10000/45000 (22%)]	Loss: nan
10:29:52: Train Epoch: 82 [10000/45000 (22%)]	Loss: nan
10:29:56: Train Epoch: 82 [20000/45000 (44%)]	Loss: nan
10:29:56: Train Epoch: 82 [20000/45000 (44%)]	Loss: nan
10:29:56: Train Epoch: 82 [20000/45000 (44%)]	Loss: nan
10:30:01: Train Epoch: 82 [30000/45000 (67%)]	Loss: nan
10:30:01: Train Epoch: 82 [30000/45000 (67%)]	Loss: nan
10:30:01: Train Epoch: 82 [30000/45000 (67%)]	Loss: nan
10:30:06: Train Epoch: 82 [40000/45000 (89%)]	Loss: nan
10:30:06: Train Epoch: 82 [40000/45000 (89%)]	Loss: nan
10:30:06: Train Epoch: 82 [40000/45000 (89%)]	Loss: nan
10:30:09: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:30:09: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:30:09: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:30:09: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.88 seconds.

10:30:09: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.88 seconds.

10:30:09: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.88 seconds.

10:30:10: Train Epoch: 83 [0/45000 (0%)]	Loss: nan
10:30:10: Train Epoch: 83 [0/45000 (0%)]	Loss: nan
10:30:10: Train Epoch: 83 [0/45000 (0%)]	Loss: nan
10:30:15: Train Epoch: 83 [10000/45000 (22%)]	Loss: nan
10:30:15: Train Epoch: 83 [10000/45000 (22%)]	Loss: nan
10:30:15: Train Epoch: 83 [10000/45000 (22%)]	Loss: nan
10:30:19: Train Epoch: 83 [20000/45000 (44%)]	Loss: nan
10:30:19: Train Epoch: 83 [20000/45000 (44%)]	Loss: nan
10:30:19: Train Epoch: 83 [20000/45000 (44%)]	Loss: nan
10:30:24: Train Epoch: 83 [30000/45000 (67%)]	Loss: nan
10:30:24: Train Epoch: 83 [30000/45000 (67%)]	Loss: nan
10:30:24: Train Epoch: 83 [30000/45000 (67%)]	Loss: nan
10:30:28: Train Epoch: 83 [40000/45000 (89%)]	Loss: nan
10:30:28: Train Epoch: 83 [40000/45000 (89%)]	Loss: nan
10:30:28: Train Epoch: 83 [40000/45000 (89%)]	Loss: nan
10:30:32: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:30:32: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:30:32: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:30:32: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.50 seconds.

10:30:32: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.50 seconds.

10:30:32: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.50 seconds.

10:30:32: Train Epoch: 84 [0/45000 (0%)]	Loss: nan
10:30:32: Train Epoch: 84 [0/45000 (0%)]	Loss: nan
10:30:32: Train Epoch: 84 [0/45000 (0%)]	Loss: nan
10:30:37: Train Epoch: 84 [10000/45000 (22%)]	Loss: nan
10:30:37: Train Epoch: 84 [10000/45000 (22%)]	Loss: nan
10:30:37: Train Epoch: 84 [10000/45000 (22%)]	Loss: nan
10:30:41: Train Epoch: 84 [20000/45000 (44%)]	Loss: nan
10:30:41: Train Epoch: 84 [20000/45000 (44%)]	Loss: nan
10:30:41: Train Epoch: 84 [20000/45000 (44%)]	Loss: nan
10:30:46: Train Epoch: 84 [30000/45000 (67%)]	Loss: nan
10:30:46: Train Epoch: 84 [30000/45000 (67%)]	Loss: nan
10:30:46: Train Epoch: 84 [30000/45000 (67%)]	Loss: nan
10:30:50: Train Epoch: 84 [40000/45000 (89%)]	Loss: nan
10:30:50: Train Epoch: 84 [40000/45000 (89%)]	Loss: nan
10:30:50: Train Epoch: 84 [40000/45000 (89%)]	Loss: nan
10:30:54: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:30:54: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:30:54: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:30:54: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.18 seconds.

10:30:54: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.18 seconds.

10:30:54: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.18 seconds.

10:30:55: Train Epoch: 85 [0/45000 (0%)]	Loss: nan
10:30:55: Train Epoch: 85 [0/45000 (0%)]	Loss: nan
10:30:55: Train Epoch: 85 [0/45000 (0%)]	Loss: nan
10:31:00: Train Epoch: 85 [10000/45000 (22%)]	Loss: nan
10:31:00: Train Epoch: 85 [10000/45000 (22%)]	Loss: nan
10:31:00: Train Epoch: 85 [10000/45000 (22%)]	Loss: nan
10:31:04: Train Epoch: 85 [20000/45000 (44%)]	Loss: nan
10:31:04: Train Epoch: 85 [20000/45000 (44%)]	Loss: nan
10:31:04: Train Epoch: 85 [20000/45000 (44%)]	Loss: nan
10:31:09: Train Epoch: 85 [30000/45000 (67%)]	Loss: nan
10:31:09: Train Epoch: 85 [30000/45000 (67%)]	Loss: nan
10:31:09: Train Epoch: 85 [30000/45000 (67%)]	Loss: nan
10:31:14: Train Epoch: 85 [40000/45000 (89%)]	Loss: nan
10:31:14: Train Epoch: 85 [40000/45000 (89%)]	Loss: nan
10:31:14: Train Epoch: 85 [40000/45000 (89%)]	Loss: nan
10:31:17: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:31:17: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:31:17: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:31:18: Current learning rate: 0.010000000000000002. Time taken for epoch: 23.55 seconds.

10:31:18: Current learning rate: 0.010000000000000002. Time taken for epoch: 23.55 seconds.

10:31:18: Current learning rate: 0.010000000000000002. Time taken for epoch: 23.55 seconds.

10:31:18: Train Epoch: 86 [0/45000 (0%)]	Loss: nan
10:31:18: Train Epoch: 86 [0/45000 (0%)]	Loss: nan
10:31:18: Train Epoch: 86 [0/45000 (0%)]	Loss: nan
10:31:23: Train Epoch: 86 [10000/45000 (22%)]	Loss: nan
10:31:23: Train Epoch: 86 [10000/45000 (22%)]	Loss: nan
10:31:23: Train Epoch: 86 [10000/45000 (22%)]	Loss: nan
10:31:27: Train Epoch: 86 [20000/45000 (44%)]	Loss: nan
10:31:27: Train Epoch: 86 [20000/45000 (44%)]	Loss: nan
10:31:27: Train Epoch: 86 [20000/45000 (44%)]	Loss: nan
10:31:31: Train Epoch: 86 [30000/45000 (67%)]	Loss: nan
10:31:31: Train Epoch: 86 [30000/45000 (67%)]	Loss: nan
10:31:31: Train Epoch: 86 [30000/45000 (67%)]	Loss: nan
10:31:36: Train Epoch: 86 [40000/45000 (89%)]	Loss: nan
10:31:36: Train Epoch: 86 [40000/45000 (89%)]	Loss: nan
10:31:36: Train Epoch: 86 [40000/45000 (89%)]	Loss: nan
10:31:40: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:31:40: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:31:40: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:31:40: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.14 seconds.

10:31:40: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.14 seconds.

10:31:40: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.14 seconds.

10:31:40: Train Epoch: 87 [0/45000 (0%)]	Loss: nan
10:31:40: Train Epoch: 87 [0/45000 (0%)]	Loss: nan
10:31:40: Train Epoch: 87 [0/45000 (0%)]	Loss: nan
10:31:45: Train Epoch: 87 [10000/45000 (22%)]	Loss: nan
10:31:45: Train Epoch: 87 [10000/45000 (22%)]	Loss: nan
10:31:45: Train Epoch: 87 [10000/45000 (22%)]	Loss: nan
10:31:49: Train Epoch: 87 [20000/45000 (44%)]	Loss: nan
10:31:49: Train Epoch: 87 [20000/45000 (44%)]	Loss: nan
10:31:49: Train Epoch: 87 [20000/45000 (44%)]	Loss: nan
10:31:54: Train Epoch: 87 [30000/45000 (67%)]	Loss: nan
10:31:54: Train Epoch: 87 [30000/45000 (67%)]	Loss: nan
10:31:54: Train Epoch: 87 [30000/45000 (67%)]	Loss: nan
10:31:59: Train Epoch: 87 [40000/45000 (89%)]	Loss: nan
10:31:59: Train Epoch: 87 [40000/45000 (89%)]	Loss: nan
10:31:59: Train Epoch: 87 [40000/45000 (89%)]	Loss: nan
10:32:03: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:32:03: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:32:03: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:32:03: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.98 seconds.

10:32:03: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.98 seconds.

10:32:03: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.98 seconds.

10:32:03: Train Epoch: 88 [0/45000 (0%)]	Loss: nan
10:32:03: Train Epoch: 88 [0/45000 (0%)]	Loss: nan
10:32:03: Train Epoch: 88 [0/45000 (0%)]	Loss: nan
10:32:08: Train Epoch: 88 [10000/45000 (22%)]	Loss: nan
10:32:08: Train Epoch: 88 [10000/45000 (22%)]	Loss: nan
10:32:08: Train Epoch: 88 [10000/45000 (22%)]	Loss: nan
10:32:12: Train Epoch: 88 [20000/45000 (44%)]	Loss: nan
10:32:12: Train Epoch: 88 [20000/45000 (44%)]	Loss: nan
10:32:12: Train Epoch: 88 [20000/45000 (44%)]	Loss: nan
10:32:17: Train Epoch: 88 [30000/45000 (67%)]	Loss: nan
10:32:17: Train Epoch: 88 [30000/45000 (67%)]	Loss: nan
10:32:17: Train Epoch: 88 [30000/45000 (67%)]	Loss: nan
10:32:21: Train Epoch: 88 [40000/45000 (89%)]	Loss: nan
10:32:21: Train Epoch: 88 [40000/45000 (89%)]	Loss: nan
10:32:21: Train Epoch: 88 [40000/45000 (89%)]	Loss: nan
10:32:25: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:32:25: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:32:25: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:32:25: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.39 seconds.

10:32:25: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.39 seconds.

10:32:25: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.39 seconds.

10:32:26: Train Epoch: 89 [0/45000 (0%)]	Loss: nan
10:32:26: Train Epoch: 89 [0/45000 (0%)]	Loss: nan
10:32:26: Train Epoch: 89 [0/45000 (0%)]	Loss: nan
10:32:30: Train Epoch: 89 [10000/45000 (22%)]	Loss: nan
10:32:30: Train Epoch: 89 [10000/45000 (22%)]	Loss: nan
10:32:30: Train Epoch: 89 [10000/45000 (22%)]	Loss: nan
10:32:35: Train Epoch: 89 [20000/45000 (44%)]	Loss: nan
10:32:35: Train Epoch: 89 [20000/45000 (44%)]	Loss: nan
10:32:35: Train Epoch: 89 [20000/45000 (44%)]	Loss: nan
10:32:39: Train Epoch: 89 [30000/45000 (67%)]	Loss: nan
10:32:39: Train Epoch: 89 [30000/45000 (67%)]	Loss: nan
10:32:39: Train Epoch: 89 [30000/45000 (67%)]	Loss: nan
10:32:43: Train Epoch: 89 [40000/45000 (89%)]	Loss: nan
10:32:43: Train Epoch: 89 [40000/45000 (89%)]	Loss: nan
10:32:43: Train Epoch: 89 [40000/45000 (89%)]	Loss: nan
10:32:47: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:32:47: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:32:47: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:32:47: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.18 seconds.

10:32:47: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.18 seconds.

10:32:47: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.18 seconds.

10:32:48: Train Epoch: 90 [0/45000 (0%)]	Loss: nan
10:32:48: Train Epoch: 90 [0/45000 (0%)]	Loss: nan
10:32:48: Train Epoch: 90 [0/45000 (0%)]	Loss: nan
10:32:52: Train Epoch: 90 [10000/45000 (22%)]	Loss: nan
10:32:52: Train Epoch: 90 [10000/45000 (22%)]	Loss: nan
10:32:52: Train Epoch: 90 [10000/45000 (22%)]	Loss: nan
10:32:57: Train Epoch: 90 [20000/45000 (44%)]	Loss: nan
10:32:57: Train Epoch: 90 [20000/45000 (44%)]	Loss: nan
10:32:57: Train Epoch: 90 [20000/45000 (44%)]	Loss: nan
10:33:02: Train Epoch: 90 [30000/45000 (67%)]	Loss: nan
10:33:02: Train Epoch: 90 [30000/45000 (67%)]	Loss: nan
10:33:02: Train Epoch: 90 [30000/45000 (67%)]	Loss: nan
10:33:06: Train Epoch: 90 [40000/45000 (89%)]	Loss: nan
10:33:06: Train Epoch: 90 [40000/45000 (89%)]	Loss: nan
10:33:06: Train Epoch: 90 [40000/45000 (89%)]	Loss: nan
10:33:10: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:33:10: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:33:10: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:33:10: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.99 seconds.

10:33:10: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.99 seconds.

10:33:10: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.99 seconds.

10:33:11: Train Epoch: 91 [0/45000 (0%)]	Loss: nan
10:33:11: Train Epoch: 91 [0/45000 (0%)]	Loss: nan
10:33:11: Train Epoch: 91 [0/45000 (0%)]	Loss: nan
10:33:16: Train Epoch: 91 [10000/45000 (22%)]	Loss: nan
10:33:16: Train Epoch: 91 [10000/45000 (22%)]	Loss: nan
10:33:16: Train Epoch: 91 [10000/45000 (22%)]	Loss: nan
10:33:20: Train Epoch: 91 [20000/45000 (44%)]	Loss: nan
10:33:20: Train Epoch: 91 [20000/45000 (44%)]	Loss: nan
10:33:20: Train Epoch: 91 [20000/45000 (44%)]	Loss: nan
10:33:25: Train Epoch: 91 [30000/45000 (67%)]	Loss: nan
10:33:25: Train Epoch: 91 [30000/45000 (67%)]	Loss: nan
10:33:25: Train Epoch: 91 [30000/45000 (67%)]	Loss: nan
10:33:29: Train Epoch: 91 [40000/45000 (89%)]	Loss: nan
10:33:29: Train Epoch: 91 [40000/45000 (89%)]	Loss: nan
10:33:29: Train Epoch: 91 [40000/45000 (89%)]	Loss: nan
10:33:33: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:33:33: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:33:33: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:33:33: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.59 seconds.

10:33:33: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.59 seconds.

10:33:33: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.59 seconds.

10:33:33: Train Epoch: 92 [0/45000 (0%)]	Loss: nan
10:33:33: Train Epoch: 92 [0/45000 (0%)]	Loss: nan
10:33:33: Train Epoch: 92 [0/45000 (0%)]	Loss: nan
10:33:38: Train Epoch: 92 [10000/45000 (22%)]	Loss: nan
10:33:38: Train Epoch: 92 [10000/45000 (22%)]	Loss: nan
10:33:38: Train Epoch: 92 [10000/45000 (22%)]	Loss: nan
10:33:43: Train Epoch: 92 [20000/45000 (44%)]	Loss: nan
10:33:43: Train Epoch: 92 [20000/45000 (44%)]	Loss: nan
10:33:43: Train Epoch: 92 [20000/45000 (44%)]	Loss: nan
10:33:47: Train Epoch: 92 [30000/45000 (67%)]	Loss: nan
10:33:47: Train Epoch: 92 [30000/45000 (67%)]	Loss: nan
10:33:47: Train Epoch: 92 [30000/45000 (67%)]	Loss: nan
10:33:51: Train Epoch: 92 [40000/45000 (89%)]	Loss: nan
10:33:51: Train Epoch: 92 [40000/45000 (89%)]	Loss: nan
10:33:51: Train Epoch: 92 [40000/45000 (89%)]	Loss: nan
10:33:55: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:33:55: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:33:55: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:33:55: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.63 seconds.

10:33:55: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.63 seconds.

10:33:55: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.63 seconds.

10:33:56: Train Epoch: 93 [0/45000 (0%)]	Loss: nan
10:33:56: Train Epoch: 93 [0/45000 (0%)]	Loss: nan
10:33:56: Train Epoch: 93 [0/45000 (0%)]	Loss: nan
10:34:01: Train Epoch: 93 [10000/45000 (22%)]	Loss: nan
10:34:01: Train Epoch: 93 [10000/45000 (22%)]	Loss: nan
10:34:01: Train Epoch: 93 [10000/45000 (22%)]	Loss: nan
10:34:05: Train Epoch: 93 [20000/45000 (44%)]	Loss: nan
10:34:05: Train Epoch: 93 [20000/45000 (44%)]	Loss: nan
10:34:05: Train Epoch: 93 [20000/45000 (44%)]	Loss: nan
10:34:10: Train Epoch: 93 [30000/45000 (67%)]	Loss: nan
10:34:10: Train Epoch: 93 [30000/45000 (67%)]	Loss: nan
10:34:10: Train Epoch: 93 [30000/45000 (67%)]	Loss: nan
10:34:15: Train Epoch: 93 [40000/45000 (89%)]	Loss: nan
10:34:15: Train Epoch: 93 [40000/45000 (89%)]	Loss: nan
10:34:15: Train Epoch: 93 [40000/45000 (89%)]	Loss: nan
10:34:18: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:34:18: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:34:18: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:34:18: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.92 seconds.

10:34:18: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.92 seconds.

10:34:18: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.92 seconds.

10:34:19: Train Epoch: 94 [0/45000 (0%)]	Loss: nan
10:34:19: Train Epoch: 94 [0/45000 (0%)]	Loss: nan
10:34:19: Train Epoch: 94 [0/45000 (0%)]	Loss: nan
10:34:23: Train Epoch: 94 [10000/45000 (22%)]	Loss: nan
10:34:23: Train Epoch: 94 [10000/45000 (22%)]	Loss: nan
10:34:23: Train Epoch: 94 [10000/45000 (22%)]	Loss: nan
10:34:28: Train Epoch: 94 [20000/45000 (44%)]	Loss: nan
10:34:28: Train Epoch: 94 [20000/45000 (44%)]	Loss: nan
10:34:28: Train Epoch: 94 [20000/45000 (44%)]	Loss: nan
10:34:32: Train Epoch: 94 [30000/45000 (67%)]	Loss: nan
10:34:32: Train Epoch: 94 [30000/45000 (67%)]	Loss: nan
10:34:32: Train Epoch: 94 [30000/45000 (67%)]	Loss: nan
10:34:37: Train Epoch: 94 [40000/45000 (89%)]	Loss: nan
10:34:37: Train Epoch: 94 [40000/45000 (89%)]	Loss: nan
10:34:37: Train Epoch: 94 [40000/45000 (89%)]	Loss: nan
10:34:40: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:34:40: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:34:40: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:34:40: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.01 seconds.

10:34:40: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.01 seconds.

10:34:40: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.01 seconds.

10:34:41: Train Epoch: 95 [0/45000 (0%)]	Loss: nan
10:34:41: Train Epoch: 95 [0/45000 (0%)]	Loss: nan
10:34:41: Train Epoch: 95 [0/45000 (0%)]	Loss: nan
10:34:46: Train Epoch: 95 [10000/45000 (22%)]	Loss: nan
10:34:46: Train Epoch: 95 [10000/45000 (22%)]	Loss: nan
10:34:46: Train Epoch: 95 [10000/45000 (22%)]	Loss: nan
10:34:50: Train Epoch: 95 [20000/45000 (44%)]	Loss: nan
10:34:50: Train Epoch: 95 [20000/45000 (44%)]	Loss: nan
10:34:50: Train Epoch: 95 [20000/45000 (44%)]	Loss: nan
10:34:54: Train Epoch: 95 [30000/45000 (67%)]	Loss: nan
10:34:54: Train Epoch: 95 [30000/45000 (67%)]	Loss: nan
10:34:54: Train Epoch: 95 [30000/45000 (67%)]	Loss: nan
10:34:59: Train Epoch: 95 [40000/45000 (89%)]	Loss: nan
10:34:59: Train Epoch: 95 [40000/45000 (89%)]	Loss: nan
10:34:59: Train Epoch: 95 [40000/45000 (89%)]	Loss: nan
10:35:03: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:35:03: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:35:03: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:35:03: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.90 seconds.

10:35:03: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.90 seconds.

10:35:03: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.90 seconds.

10:35:04: Train Epoch: 96 [0/45000 (0%)]	Loss: nan
10:35:04: Train Epoch: 96 [0/45000 (0%)]	Loss: nan
10:35:04: Train Epoch: 96 [0/45000 (0%)]	Loss: nan
10:35:08: Train Epoch: 96 [10000/45000 (22%)]	Loss: nan
10:35:08: Train Epoch: 96 [10000/45000 (22%)]	Loss: nan
10:35:08: Train Epoch: 96 [10000/45000 (22%)]	Loss: nan
10:35:13: Train Epoch: 96 [20000/45000 (44%)]	Loss: nan
10:35:13: Train Epoch: 96 [20000/45000 (44%)]	Loss: nan
10:35:13: Train Epoch: 96 [20000/45000 (44%)]	Loss: nan
10:35:18: Train Epoch: 96 [30000/45000 (67%)]	Loss: nan
10:35:18: Train Epoch: 96 [30000/45000 (67%)]	Loss: nan
10:35:18: Train Epoch: 96 [30000/45000 (67%)]	Loss: nan
10:35:22: Train Epoch: 96 [40000/45000 (89%)]	Loss: nan
10:35:22: Train Epoch: 96 [40000/45000 (89%)]	Loss: nan
10:35:22: Train Epoch: 96 [40000/45000 (89%)]	Loss: nan
10:35:26: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:35:26: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:35:26: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:35:26: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.51 seconds.

10:35:26: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.51 seconds.

10:35:26: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.51 seconds.

10:35:26: Train Epoch: 97 [0/45000 (0%)]	Loss: nan
10:35:26: Train Epoch: 97 [0/45000 (0%)]	Loss: nan
10:35:26: Train Epoch: 97 [0/45000 (0%)]	Loss: nan
10:35:31: Train Epoch: 97 [10000/45000 (22%)]	Loss: nan
10:35:31: Train Epoch: 97 [10000/45000 (22%)]	Loss: nan
10:35:31: Train Epoch: 97 [10000/45000 (22%)]	Loss: nan
10:35:35: Train Epoch: 97 [20000/45000 (44%)]	Loss: nan
10:35:35: Train Epoch: 97 [20000/45000 (44%)]	Loss: nan
10:35:35: Train Epoch: 97 [20000/45000 (44%)]	Loss: nan
10:35:40: Train Epoch: 97 [30000/45000 (67%)]	Loss: nan
10:35:40: Train Epoch: 97 [30000/45000 (67%)]	Loss: nan
10:35:40: Train Epoch: 97 [30000/45000 (67%)]	Loss: nan
10:35:44: Train Epoch: 97 [40000/45000 (89%)]	Loss: nan
10:35:44: Train Epoch: 97 [40000/45000 (89%)]	Loss: nan
10:35:44: Train Epoch: 97 [40000/45000 (89%)]	Loss: nan
10:35:48: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:35:48: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:35:48: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:35:48: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.34 seconds.

10:35:48: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.34 seconds.

10:35:48: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.34 seconds.

10:35:49: Train Epoch: 98 [0/45000 (0%)]	Loss: nan
10:35:49: Train Epoch: 98 [0/45000 (0%)]	Loss: nan
10:35:49: Train Epoch: 98 [0/45000 (0%)]	Loss: nan
10:35:53: Train Epoch: 98 [10000/45000 (22%)]	Loss: nan
10:35:53: Train Epoch: 98 [10000/45000 (22%)]	Loss: nan
10:35:53: Train Epoch: 98 [10000/45000 (22%)]	Loss: nan
10:35:58: Train Epoch: 98 [20000/45000 (44%)]	Loss: nan
10:35:58: Train Epoch: 98 [20000/45000 (44%)]	Loss: nan
10:35:58: Train Epoch: 98 [20000/45000 (44%)]	Loss: nan
10:36:03: Train Epoch: 98 [30000/45000 (67%)]	Loss: nan
10:36:03: Train Epoch: 98 [30000/45000 (67%)]	Loss: nan
10:36:03: Train Epoch: 98 [30000/45000 (67%)]	Loss: nan
10:36:07: Train Epoch: 98 [40000/45000 (89%)]	Loss: nan
10:36:07: Train Epoch: 98 [40000/45000 (89%)]	Loss: nan
10:36:07: Train Epoch: 98 [40000/45000 (89%)]	Loss: nan
10:36:11: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:36:11: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:36:11: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:36:11: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.92 seconds.

10:36:11: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.92 seconds.

10:36:11: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.92 seconds.

10:36:11: Train Epoch: 99 [0/45000 (0%)]	Loss: nan
10:36:11: Train Epoch: 99 [0/45000 (0%)]	Loss: nan
10:36:11: Train Epoch: 99 [0/45000 (0%)]	Loss: nan
10:36:17: Train Epoch: 99 [10000/45000 (22%)]	Loss: nan
10:36:17: Train Epoch: 99 [10000/45000 (22%)]	Loss: nan
10:36:17: Train Epoch: 99 [10000/45000 (22%)]	Loss: nan
10:36:21: Train Epoch: 99 [20000/45000 (44%)]	Loss: nan
10:36:21: Train Epoch: 99 [20000/45000 (44%)]	Loss: nan
10:36:21: Train Epoch: 99 [20000/45000 (44%)]	Loss: nan
10:36:26: Train Epoch: 99 [30000/45000 (67%)]	Loss: nan
10:36:26: Train Epoch: 99 [30000/45000 (67%)]	Loss: nan
10:36:26: Train Epoch: 99 [30000/45000 (67%)]	Loss: nan
10:36:30: Train Epoch: 99 [40000/45000 (89%)]	Loss: nan
10:36:30: Train Epoch: 99 [40000/45000 (89%)]	Loss: nan
10:36:30: Train Epoch: 99 [40000/45000 (89%)]	Loss: nan
10:36:34: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:36:34: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:36:34: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:36:34: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.64 seconds.

10:36:34: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.64 seconds.

10:36:34: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.64 seconds.

10:36:34: Train Epoch: 100 [0/45000 (0%)]	Loss: nan
10:36:34: Train Epoch: 100 [0/45000 (0%)]	Loss: nan
10:36:34: Train Epoch: 100 [0/45000 (0%)]	Loss: nan
10:36:39: Train Epoch: 100 [10000/45000 (22%)]	Loss: nan
10:36:39: Train Epoch: 100 [10000/45000 (22%)]	Loss: nan
10:36:39: Train Epoch: 100 [10000/45000 (22%)]	Loss: nan
10:36:43: Train Epoch: 100 [20000/45000 (44%)]	Loss: nan
10:36:43: Train Epoch: 100 [20000/45000 (44%)]	Loss: nan
10:36:43: Train Epoch: 100 [20000/45000 (44%)]	Loss: nan
10:36:48: Train Epoch: 100 [30000/45000 (67%)]	Loss: nan
10:36:48: Train Epoch: 100 [30000/45000 (67%)]	Loss: nan
10:36:48: Train Epoch: 100 [30000/45000 (67%)]	Loss: nan
10:36:52: Train Epoch: 100 [40000/45000 (89%)]	Loss: nan
10:36:52: Train Epoch: 100 [40000/45000 (89%)]	Loss: nan
10:36:52: Train Epoch: 100 [40000/45000 (89%)]	Loss: nan
10:36:57: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:36:57: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:36:57: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

10:36:57: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.98 seconds.

10:36:57: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.98 seconds.

10:36:57: Current learning rate: 0.010000000000000002. Time taken for epoch: 22.98 seconds.

10:36:59: 
Test evaluation: Average loss: nan, Accuracy: 1000/10000 (10.000%)

10:36:59: 
Test evaluation: Average loss: nan, Accuracy: 1000/10000 (10.000%)

10:36:59: 
Test evaluation: Average loss: nan, Accuracy: 1000/10000 (10.000%)

10:36:59: 
Iteration end: 1/1

10:36:59: 
Iteration end: 1/1

10:36:59: 
Iteration end: 1/1

