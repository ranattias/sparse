18:34:29: Namespace(batch_size=100, bench=False, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='MobileNet', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.5, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=False)
18:34:29: 


18:34:29: ================================================================================
18:34:29: 
Iteration start: 1/1

18:34:41: MobileNet(
  (features): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): ReLU(inplace=True)
    (12): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU(inplace=True)
    (15): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
    (16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (17): ReLU(inplace=True)
    (18): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (19): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): ReLU(inplace=True)
    (21): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
    (22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (23): ReLU(inplace=True)
    (24): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (25): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
    (28): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (31): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
    (34): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (35): ReLU(inplace=True)
    (36): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): ReLU(inplace=True)
    (39): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (40): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (41): ReLU(inplace=True)
    (42): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (43): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): ReLU(inplace=True)
    (45): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (46): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (47): ReLU(inplace=True)
    (48): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (49): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): ReLU(inplace=True)
    (51): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (52): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (53): ReLU(inplace=True)
    (54): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (55): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): ReLU(inplace=True)
    (57): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (58): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (59): ReLU(inplace=True)
    (60): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (61): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): ReLU(inplace=True)
    (63): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (64): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (65): ReLU(inplace=True)
    (66): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (67): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): ReLU(inplace=True)
    (69): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)
    (70): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (71): ReLU(inplace=True)
    (72): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (73): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): ReLU(inplace=True)
    (75): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)
    (76): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (77): ReLU(inplace=True)
    (78): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (79): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): ReLU(inplace=True)
    (81): AvgPool2d(kernel_size=1, stride=1, padding=0)
  )
  (fc): Linear(in_features=1024, out_features=100, bias=True)
)
18:34:41: ============================================================
18:34:41: MobileNet
18:34:41: ============================================================
18:34:41: ============================================================
18:34:41: Prune mode: magnitude
18:34:41: Growth mode: momentum
18:34:41: Redistribution mode: momentum
18:34:41: ============================================================
18:50:51: Namespace(batch_size=100, bench=False, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='MobileNet', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.5, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=False)
18:50:51: Namespace(batch_size=100, bench=False, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='MobileNet', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.5, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=False)
18:50:51: 


18:50:51: 


18:50:51: ================================================================================
18:50:51: ================================================================================
18:50:51: 
Iteration start: 1/1

18:50:51: 
Iteration start: 1/1

18:50:52: MobileNet(
  (features): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): ReLU(inplace=True)
    (12): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU(inplace=True)
    (15): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
    (16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (17): ReLU(inplace=True)
    (18): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (19): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): ReLU(inplace=True)
    (21): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
    (22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (23): ReLU(inplace=True)
    (24): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (25): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
    (28): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (31): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
    (34): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (35): ReLU(inplace=True)
    (36): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): ReLU(inplace=True)
    (39): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (40): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (41): ReLU(inplace=True)
    (42): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (43): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): ReLU(inplace=True)
    (45): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (46): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (47): ReLU(inplace=True)
    (48): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (49): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): ReLU(inplace=True)
    (51): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (52): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (53): ReLU(inplace=True)
    (54): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (55): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): ReLU(inplace=True)
    (57): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (58): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (59): ReLU(inplace=True)
    (60): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (61): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): ReLU(inplace=True)
    (63): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (64): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (65): ReLU(inplace=True)
    (66): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (67): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): ReLU(inplace=True)
    (69): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)
    (70): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (71): ReLU(inplace=True)
    (72): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (73): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): ReLU(inplace=True)
    (75): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)
    (76): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (77): ReLU(inplace=True)
    (78): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (79): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): ReLU(inplace=True)
    (81): AvgPool2d(kernel_size=1, stride=1, padding=0)
  )
  (fc): Linear(in_features=1024, out_features=100, bias=True)
)
18:50:52: MobileNet(
  (features): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): ReLU(inplace=True)
    (12): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU(inplace=True)
    (15): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
    (16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (17): ReLU(inplace=True)
    (18): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (19): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): ReLU(inplace=True)
    (21): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
    (22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (23): ReLU(inplace=True)
    (24): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (25): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
    (28): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (31): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
    (34): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (35): ReLU(inplace=True)
    (36): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): ReLU(inplace=True)
    (39): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (40): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (41): ReLU(inplace=True)
    (42): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (43): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): ReLU(inplace=True)
    (45): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (46): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (47): ReLU(inplace=True)
    (48): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (49): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): ReLU(inplace=True)
    (51): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (52): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (53): ReLU(inplace=True)
    (54): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (55): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): ReLU(inplace=True)
    (57): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (58): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (59): ReLU(inplace=True)
    (60): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (61): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): ReLU(inplace=True)
    (63): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (64): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (65): ReLU(inplace=True)
    (66): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (67): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): ReLU(inplace=True)
    (69): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)
    (70): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (71): ReLU(inplace=True)
    (72): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (73): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): ReLU(inplace=True)
    (75): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)
    (76): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (77): ReLU(inplace=True)
    (78): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (79): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): ReLU(inplace=True)
    (81): AvgPool2d(kernel_size=1, stride=1, padding=0)
  )
  (fc): Linear(in_features=1024, out_features=100, bias=True)
)
18:50:52: ============================================================
18:50:52: ============================================================
18:50:52: MobileNet
18:50:52: MobileNet
18:50:52: ============================================================
18:50:52: ============================================================
18:50:52: ============================================================
18:50:52: ============================================================
18:50:52: Prune mode: magnitude
18:50:52: Prune mode: magnitude
18:50:52: Growth mode: momentum
18:50:52: Growth mode: momentum
18:50:52: Redistribution mode: momentum
18:50:52: Redistribution mode: momentum
18:50:52: ============================================================
18:50:52: ============================================================
18:52:22: Namespace(batch_size=100, bench=False, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='MobileNet', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.5, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=False)
18:52:22: Namespace(batch_size=100, bench=False, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='MobileNet', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.5, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=False)
18:52:22: Namespace(batch_size=100, bench=False, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='MobileNet', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.5, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=False)
18:52:22: 


18:52:22: 


18:52:22: 


18:52:22: ================================================================================
18:52:22: ================================================================================
18:52:22: ================================================================================
18:52:22: 
Iteration start: 1/1

18:52:22: 
Iteration start: 1/1

18:52:22: 
Iteration start: 1/1

18:52:23: MobileNet(
  (features): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): ReLU(inplace=True)
    (12): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU(inplace=True)
    (15): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
    (16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (17): ReLU(inplace=True)
    (18): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (19): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): ReLU(inplace=True)
    (21): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
    (22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (23): ReLU(inplace=True)
    (24): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (25): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
    (28): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (31): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
    (34): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (35): ReLU(inplace=True)
    (36): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): ReLU(inplace=True)
    (39): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (40): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (41): ReLU(inplace=True)
    (42): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (43): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): ReLU(inplace=True)
    (45): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (46): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (47): ReLU(inplace=True)
    (48): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (49): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): ReLU(inplace=True)
    (51): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (52): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (53): ReLU(inplace=True)
    (54): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (55): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): ReLU(inplace=True)
    (57): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (58): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (59): ReLU(inplace=True)
    (60): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (61): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): ReLU(inplace=True)
    (63): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (64): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (65): ReLU(inplace=True)
    (66): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (67): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): ReLU(inplace=True)
    (69): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)
    (70): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (71): ReLU(inplace=True)
    (72): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (73): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): ReLU(inplace=True)
    (75): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)
    (76): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (77): ReLU(inplace=True)
    (78): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (79): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): ReLU(inplace=True)
    (81): AvgPool2d(kernel_size=1, stride=1, padding=0)
  )
  (fc): Linear(in_features=1024, out_features=100, bias=True)
)
18:52:23: MobileNet(
  (features): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): ReLU(inplace=True)
    (12): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU(inplace=True)
    (15): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
    (16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (17): ReLU(inplace=True)
    (18): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (19): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): ReLU(inplace=True)
    (21): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
    (22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (23): ReLU(inplace=True)
    (24): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (25): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
    (28): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (31): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
    (34): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (35): ReLU(inplace=True)
    (36): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): ReLU(inplace=True)
    (39): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (40): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (41): ReLU(inplace=True)
    (42): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (43): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): ReLU(inplace=True)
    (45): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (46): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (47): ReLU(inplace=True)
    (48): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (49): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): ReLU(inplace=True)
    (51): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (52): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (53): ReLU(inplace=True)
    (54): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (55): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): ReLU(inplace=True)
    (57): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (58): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (59): ReLU(inplace=True)
    (60): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (61): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): ReLU(inplace=True)
    (63): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (64): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (65): ReLU(inplace=True)
    (66): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (67): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): ReLU(inplace=True)
    (69): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)
    (70): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (71): ReLU(inplace=True)
    (72): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (73): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): ReLU(inplace=True)
    (75): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)
    (76): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (77): ReLU(inplace=True)
    (78): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (79): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): ReLU(inplace=True)
    (81): AvgPool2d(kernel_size=1, stride=1, padding=0)
  )
  (fc): Linear(in_features=1024, out_features=100, bias=True)
)
18:52:23: MobileNet(
  (features): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): ReLU(inplace=True)
    (12): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU(inplace=True)
    (15): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
    (16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (17): ReLU(inplace=True)
    (18): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (19): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): ReLU(inplace=True)
    (21): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
    (22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (23): ReLU(inplace=True)
    (24): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (25): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
    (28): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (31): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
    (34): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (35): ReLU(inplace=True)
    (36): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): ReLU(inplace=True)
    (39): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (40): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (41): ReLU(inplace=True)
    (42): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (43): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): ReLU(inplace=True)
    (45): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (46): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (47): ReLU(inplace=True)
    (48): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (49): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): ReLU(inplace=True)
    (51): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (52): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (53): ReLU(inplace=True)
    (54): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (55): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): ReLU(inplace=True)
    (57): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (58): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (59): ReLU(inplace=True)
    (60): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (61): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): ReLU(inplace=True)
    (63): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (64): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (65): ReLU(inplace=True)
    (66): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (67): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): ReLU(inplace=True)
    (69): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)
    (70): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (71): ReLU(inplace=True)
    (72): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (73): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): ReLU(inplace=True)
    (75): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)
    (76): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (77): ReLU(inplace=True)
    (78): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (79): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): ReLU(inplace=True)
    (81): AvgPool2d(kernel_size=1, stride=1, padding=0)
  )
  (fc): Linear(in_features=1024, out_features=100, bias=True)
)
18:52:23: ============================================================
18:52:23: ============================================================
18:52:23: ============================================================
18:52:23: MobileNet
18:52:23: MobileNet
18:52:23: MobileNet
18:52:23: ============================================================
18:52:23: ============================================================
18:52:23: ============================================================
18:52:23: ============================================================
18:52:23: ============================================================
18:52:23: ============================================================
18:52:23: Prune mode: magnitude
18:52:23: Prune mode: magnitude
18:52:23: Prune mode: magnitude
18:52:23: Growth mode: momentum
18:52:23: Growth mode: momentum
18:52:23: Growth mode: momentum
18:52:23: Redistribution mode: momentum
18:52:23: Redistribution mode: momentum
18:52:23: Redistribution mode: momentum
18:52:23: ============================================================
18:52:23: ============================================================
18:52:23: ============================================================
18:52:25: Train Epoch: 1 [0/45000 (0%)]	Loss: 4.641055
18:52:25: Train Epoch: 1 [0/45000 (0%)]	Loss: 4.641055
18:52:25: Train Epoch: 1 [0/45000 (0%)]	Loss: 4.641055
18:52:30: Train Epoch: 1 [10000/45000 (22%)]	Loss: 2.070999
18:52:30: Train Epoch: 1 [10000/45000 (22%)]	Loss: 2.070999
18:52:30: Train Epoch: 1 [10000/45000 (22%)]	Loss: 2.070999
18:52:36: Train Epoch: 1 [20000/45000 (44%)]	Loss: 2.191387
18:52:36: Train Epoch: 1 [20000/45000 (44%)]	Loss: 2.191387
18:52:36: Train Epoch: 1 [20000/45000 (44%)]	Loss: 2.191387
18:52:41: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.572804
18:52:41: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.572804
18:52:41: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.572804
18:52:47: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.645447
18:52:47: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.645447
18:52:47: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.645447
18:52:52: 
Evaluation: Average loss: 1.6791, Accuracy: 1916/5000 (38.320%)

18:52:52: 
Evaluation: Average loss: 1.6791, Accuracy: 1916/5000 (38.320%)

18:52:52: 
Evaluation: Average loss: 1.6791, Accuracy: 1916/5000 (38.320%)

18:52:52: Current learning rate: 0.1. Time taken for epoch: 28.55 seconds.

18:52:52: Current learning rate: 0.1. Time taken for epoch: 28.55 seconds.

18:52:52: Current learning rate: 0.1. Time taken for epoch: 28.55 seconds.

18:52:52: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.539217
18:52:52: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.539217
18:52:52: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.539217
18:52:58: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.506656
18:52:58: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.506656
18:52:58: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.506656
18:53:04: Train Epoch: 2 [20000/45000 (44%)]	Loss: 1.660257
18:53:04: Train Epoch: 2 [20000/45000 (44%)]	Loss: 1.660257
18:53:04: Train Epoch: 2 [20000/45000 (44%)]	Loss: 1.660257
18:53:09: Train Epoch: 2 [30000/45000 (67%)]	Loss: 1.391268
18:53:09: Train Epoch: 2 [30000/45000 (67%)]	Loss: 1.391268
18:53:09: Train Epoch: 2 [30000/45000 (67%)]	Loss: 1.391268
18:53:15: Train Epoch: 2 [40000/45000 (89%)]	Loss: 1.605617
18:53:15: Train Epoch: 2 [40000/45000 (89%)]	Loss: 1.605617
18:53:15: Train Epoch: 2 [40000/45000 (89%)]	Loss: 1.605617
18:53:19: 
Evaluation: Average loss: 1.5501, Accuracy: 2206/5000 (44.120%)

18:53:19: 
Evaluation: Average loss: 1.5501, Accuracy: 2206/5000 (44.120%)

18:53:19: 
Evaluation: Average loss: 1.5501, Accuracy: 2206/5000 (44.120%)

18:53:19: Current learning rate: 0.1. Time taken for epoch: 27.43 seconds.

18:53:19: Current learning rate: 0.1. Time taken for epoch: 27.43 seconds.

18:53:19: Current learning rate: 0.1. Time taken for epoch: 27.43 seconds.

18:53:20: Train Epoch: 3 [0/45000 (0%)]	Loss: 1.405193
18:53:20: Train Epoch: 3 [0/45000 (0%)]	Loss: 1.405193
18:53:20: Train Epoch: 3 [0/45000 (0%)]	Loss: 1.405193
18:53:26: Train Epoch: 3 [10000/45000 (22%)]	Loss: 1.692926
18:53:26: Train Epoch: 3 [10000/45000 (22%)]	Loss: 1.692926
18:53:26: Train Epoch: 3 [10000/45000 (22%)]	Loss: 1.692926
18:53:31: Train Epoch: 3 [20000/45000 (44%)]	Loss: 1.380153
18:53:31: Train Epoch: 3 [20000/45000 (44%)]	Loss: 1.380153
18:53:31: Train Epoch: 3 [20000/45000 (44%)]	Loss: 1.380153
18:53:37: Train Epoch: 3 [30000/45000 (67%)]	Loss: 1.360908
18:53:37: Train Epoch: 3 [30000/45000 (67%)]	Loss: 1.360908
18:53:37: Train Epoch: 3 [30000/45000 (67%)]	Loss: 1.360908
18:53:42: Train Epoch: 3 [40000/45000 (89%)]	Loss: 1.352115
18:53:42: Train Epoch: 3 [40000/45000 (89%)]	Loss: 1.352115
18:53:42: Train Epoch: 3 [40000/45000 (89%)]	Loss: 1.352115
18:53:47: 
Evaluation: Average loss: 1.3758, Accuracy: 2511/5000 (50.220%)

18:53:47: 
Evaluation: Average loss: 1.3758, Accuracy: 2511/5000 (50.220%)

18:53:47: 
Evaluation: Average loss: 1.3758, Accuracy: 2511/5000 (50.220%)

18:53:47: Current learning rate: 0.1. Time taken for epoch: 27.95 seconds.

18:53:47: Current learning rate: 0.1. Time taken for epoch: 27.95 seconds.

18:53:47: Current learning rate: 0.1. Time taken for epoch: 27.95 seconds.

18:53:48: Train Epoch: 4 [0/45000 (0%)]	Loss: 1.296323
18:53:48: Train Epoch: 4 [0/45000 (0%)]	Loss: 1.296323
18:53:48: Train Epoch: 4 [0/45000 (0%)]	Loss: 1.296323
18:53:53: Train Epoch: 4 [10000/45000 (22%)]	Loss: 1.222319
18:53:53: Train Epoch: 4 [10000/45000 (22%)]	Loss: 1.222319
18:53:53: Train Epoch: 4 [10000/45000 (22%)]	Loss: 1.222319
18:53:59: Train Epoch: 4 [20000/45000 (44%)]	Loss: 1.121193
18:53:59: Train Epoch: 4 [20000/45000 (44%)]	Loss: 1.121193
18:53:59: Train Epoch: 4 [20000/45000 (44%)]	Loss: 1.121193
18:54:04: Train Epoch: 4 [30000/45000 (67%)]	Loss: 1.495911
18:54:04: Train Epoch: 4 [30000/45000 (67%)]	Loss: 1.495911
18:54:04: Train Epoch: 4 [30000/45000 (67%)]	Loss: 1.495911
18:54:10: Train Epoch: 4 [40000/45000 (89%)]	Loss: 1.157913
18:54:10: Train Epoch: 4 [40000/45000 (89%)]	Loss: 1.157913
18:54:10: Train Epoch: 4 [40000/45000 (89%)]	Loss: 1.157913
18:54:14: 
Evaluation: Average loss: 1.3226, Accuracy: 2618/5000 (52.360%)

18:54:14: 
Evaluation: Average loss: 1.3226, Accuracy: 2618/5000 (52.360%)

18:54:14: 
Evaluation: Average loss: 1.3226, Accuracy: 2618/5000 (52.360%)

18:54:14: Current learning rate: 0.1. Time taken for epoch: 27.37 seconds.

18:54:14: Current learning rate: 0.1. Time taken for epoch: 27.37 seconds.

18:54:14: Current learning rate: 0.1. Time taken for epoch: 27.37 seconds.

18:54:15: Train Epoch: 5 [0/45000 (0%)]	Loss: 1.220667
18:54:15: Train Epoch: 5 [0/45000 (0%)]	Loss: 1.220667
18:54:15: Train Epoch: 5 [0/45000 (0%)]	Loss: 1.220667
18:54:21: Train Epoch: 5 [10000/45000 (22%)]	Loss: 1.145001
18:54:21: Train Epoch: 5 [10000/45000 (22%)]	Loss: 1.145001
18:54:21: Train Epoch: 5 [10000/45000 (22%)]	Loss: 1.145001
18:54:26: Train Epoch: 5 [20000/45000 (44%)]	Loss: 1.251591
18:54:26: Train Epoch: 5 [20000/45000 (44%)]	Loss: 1.251591
18:54:26: Train Epoch: 5 [20000/45000 (44%)]	Loss: 1.251591
18:54:32: Train Epoch: 5 [30000/45000 (67%)]	Loss: 1.225516
18:54:32: Train Epoch: 5 [30000/45000 (67%)]	Loss: 1.225516
18:54:32: Train Epoch: 5 [30000/45000 (67%)]	Loss: 1.225516
18:54:37: Train Epoch: 5 [40000/45000 (89%)]	Loss: 1.051940
18:54:37: Train Epoch: 5 [40000/45000 (89%)]	Loss: 1.051940
18:54:37: Train Epoch: 5 [40000/45000 (89%)]	Loss: 1.051940
18:54:42: 
Evaluation: Average loss: 1.2107, Accuracy: 2835/5000 (56.700%)

18:54:42: 
Evaluation: Average loss: 1.2107, Accuracy: 2835/5000 (56.700%)

18:54:42: 
Evaluation: Average loss: 1.2107, Accuracy: 2835/5000 (56.700%)

18:54:42: Current learning rate: 0.1. Time taken for epoch: 27.60 seconds.

18:54:42: Current learning rate: 0.1. Time taken for epoch: 27.60 seconds.

18:54:42: Current learning rate: 0.1. Time taken for epoch: 27.60 seconds.

18:54:43: Train Epoch: 6 [0/45000 (0%)]	Loss: 1.173297
18:54:43: Train Epoch: 6 [0/45000 (0%)]	Loss: 1.173297
18:54:43: Train Epoch: 6 [0/45000 (0%)]	Loss: 1.173297
18:54:49: Train Epoch: 6 [10000/45000 (22%)]	Loss: 1.195373
18:54:49: Train Epoch: 6 [10000/45000 (22%)]	Loss: 1.195373
18:54:49: Train Epoch: 6 [10000/45000 (22%)]	Loss: 1.195373
18:54:54: Train Epoch: 6 [20000/45000 (44%)]	Loss: 1.166446
18:54:54: Train Epoch: 6 [20000/45000 (44%)]	Loss: 1.166446
18:54:54: Train Epoch: 6 [20000/45000 (44%)]	Loss: 1.166446
18:55:00: Train Epoch: 6 [30000/45000 (67%)]	Loss: 1.066273
18:55:00: Train Epoch: 6 [30000/45000 (67%)]	Loss: 1.066273
18:55:00: Train Epoch: 6 [30000/45000 (67%)]	Loss: 1.066273
18:55:06: Train Epoch: 6 [40000/45000 (89%)]	Loss: 1.092280
18:55:06: Train Epoch: 6 [40000/45000 (89%)]	Loss: 1.092280
18:55:06: Train Epoch: 6 [40000/45000 (89%)]	Loss: 1.092280
18:55:11: 
Evaluation: Average loss: 1.1751, Accuracy: 2941/5000 (58.820%)

18:55:11: 
Evaluation: Average loss: 1.1751, Accuracy: 2941/5000 (58.820%)

18:55:11: 
Evaluation: Average loss: 1.1751, Accuracy: 2941/5000 (58.820%)

18:55:11: Current learning rate: 0.1. Time taken for epoch: 28.65 seconds.

18:55:11: Current learning rate: 0.1. Time taken for epoch: 28.65 seconds.

18:55:11: Current learning rate: 0.1. Time taken for epoch: 28.65 seconds.

18:55:11: Train Epoch: 7 [0/45000 (0%)]	Loss: 1.209516
18:55:11: Train Epoch: 7 [0/45000 (0%)]	Loss: 1.209516
18:55:11: Train Epoch: 7 [0/45000 (0%)]	Loss: 1.209516
18:55:17: Train Epoch: 7 [10000/45000 (22%)]	Loss: 1.300370
18:55:17: Train Epoch: 7 [10000/45000 (22%)]	Loss: 1.300370
18:55:17: Train Epoch: 7 [10000/45000 (22%)]	Loss: 1.300370
18:55:23: Train Epoch: 7 [20000/45000 (44%)]	Loss: 1.019166
18:55:23: Train Epoch: 7 [20000/45000 (44%)]	Loss: 1.019166
18:55:23: Train Epoch: 7 [20000/45000 (44%)]	Loss: 1.019166
18:55:29: Train Epoch: 7 [30000/45000 (67%)]	Loss: 1.229778
18:55:29: Train Epoch: 7 [30000/45000 (67%)]	Loss: 1.229778
18:55:29: Train Epoch: 7 [30000/45000 (67%)]	Loss: 1.229778
18:55:34: Train Epoch: 7 [40000/45000 (89%)]	Loss: 0.902035
18:55:34: Train Epoch: 7 [40000/45000 (89%)]	Loss: 0.902035
18:55:34: Train Epoch: 7 [40000/45000 (89%)]	Loss: 0.902035
18:55:39: 
Evaluation: Average loss: 1.1967, Accuracy: 2861/5000 (57.220%)

18:55:39: 
Evaluation: Average loss: 1.1967, Accuracy: 2861/5000 (57.220%)

18:55:39: 
Evaluation: Average loss: 1.1967, Accuracy: 2861/5000 (57.220%)

18:55:39: Current learning rate: 0.1. Time taken for epoch: 28.41 seconds.

18:55:39: Current learning rate: 0.1. Time taken for epoch: 28.41 seconds.

18:55:39: Current learning rate: 0.1. Time taken for epoch: 28.41 seconds.

18:55:40: Train Epoch: 8 [0/45000 (0%)]	Loss: 1.122509
18:55:40: Train Epoch: 8 [0/45000 (0%)]	Loss: 1.122509
18:55:40: Train Epoch: 8 [0/45000 (0%)]	Loss: 1.122509
18:55:46: Train Epoch: 8 [10000/45000 (22%)]	Loss: 1.098168
18:55:46: Train Epoch: 8 [10000/45000 (22%)]	Loss: 1.098168
18:55:46: Train Epoch: 8 [10000/45000 (22%)]	Loss: 1.098168
18:55:51: Train Epoch: 8 [20000/45000 (44%)]	Loss: 1.152307
18:55:51: Train Epoch: 8 [20000/45000 (44%)]	Loss: 1.152307
18:55:51: Train Epoch: 8 [20000/45000 (44%)]	Loss: 1.152307
18:55:57: Train Epoch: 8 [30000/45000 (67%)]	Loss: 0.939621
18:55:57: Train Epoch: 8 [30000/45000 (67%)]	Loss: 0.939621
18:55:57: Train Epoch: 8 [30000/45000 (67%)]	Loss: 0.939621
18:56:03: Train Epoch: 8 [40000/45000 (89%)]	Loss: 0.934100
18:56:03: Train Epoch: 8 [40000/45000 (89%)]	Loss: 0.934100
18:56:03: Train Epoch: 8 [40000/45000 (89%)]	Loss: 0.934100
18:56:08: 
Evaluation: Average loss: 1.0184, Accuracy: 3246/5000 (64.920%)

18:56:08: 
Evaluation: Average loss: 1.0184, Accuracy: 3246/5000 (64.920%)

18:56:08: 
Evaluation: Average loss: 1.0184, Accuracy: 3246/5000 (64.920%)

18:56:08: Current learning rate: 0.1. Time taken for epoch: 28.54 seconds.

18:56:08: Current learning rate: 0.1. Time taken for epoch: 28.54 seconds.

18:56:08: Current learning rate: 0.1. Time taken for epoch: 28.54 seconds.

18:56:09: Train Epoch: 9 [0/45000 (0%)]	Loss: 1.052353
18:56:09: Train Epoch: 9 [0/45000 (0%)]	Loss: 1.052353
18:56:09: Train Epoch: 9 [0/45000 (0%)]	Loss: 1.052353
18:56:15: Train Epoch: 9 [10000/45000 (22%)]	Loss: 0.864117
18:56:15: Train Epoch: 9 [10000/45000 (22%)]	Loss: 0.864117
18:56:15: Train Epoch: 9 [10000/45000 (22%)]	Loss: 0.864117
18:56:21: Train Epoch: 9 [20000/45000 (44%)]	Loss: 0.877453
18:56:21: Train Epoch: 9 [20000/45000 (44%)]	Loss: 0.877453
18:56:21: Train Epoch: 9 [20000/45000 (44%)]	Loss: 0.877453
18:56:27: Train Epoch: 9 [30000/45000 (67%)]	Loss: 0.865385
18:56:27: Train Epoch: 9 [30000/45000 (67%)]	Loss: 0.865385
18:56:27: Train Epoch: 9 [30000/45000 (67%)]	Loss: 0.865385
18:56:32: Train Epoch: 9 [40000/45000 (89%)]	Loss: 1.255493
18:56:32: Train Epoch: 9 [40000/45000 (89%)]	Loss: 1.255493
18:56:32: Train Epoch: 9 [40000/45000 (89%)]	Loss: 1.255493
18:56:37: 
Evaluation: Average loss: 1.0353, Accuracy: 3197/5000 (63.940%)

18:56:37: 
Evaluation: Average loss: 1.0353, Accuracy: 3197/5000 (63.940%)

18:56:37: 
Evaluation: Average loss: 1.0353, Accuracy: 3197/5000 (63.940%)

18:56:37: Current learning rate: 0.1. Time taken for epoch: 29.63 seconds.

18:56:37: Current learning rate: 0.1. Time taken for epoch: 29.63 seconds.

18:56:37: Current learning rate: 0.1. Time taken for epoch: 29.63 seconds.

18:56:38: Train Epoch: 10 [0/45000 (0%)]	Loss: 1.041793
18:56:38: Train Epoch: 10 [0/45000 (0%)]	Loss: 1.041793
18:56:38: Train Epoch: 10 [0/45000 (0%)]	Loss: 1.041793
18:56:44: Train Epoch: 10 [10000/45000 (22%)]	Loss: 1.026022
18:56:44: Train Epoch: 10 [10000/45000 (22%)]	Loss: 1.026022
18:56:44: Train Epoch: 10 [10000/45000 (22%)]	Loss: 1.026022
18:56:50: Train Epoch: 10 [20000/45000 (44%)]	Loss: 0.984909
18:56:50: Train Epoch: 10 [20000/45000 (44%)]	Loss: 0.984909
18:56:50: Train Epoch: 10 [20000/45000 (44%)]	Loss: 0.984909
18:56:56: Train Epoch: 10 [30000/45000 (67%)]	Loss: 1.070504
18:56:56: Train Epoch: 10 [30000/45000 (67%)]	Loss: 1.070504
18:56:56: Train Epoch: 10 [30000/45000 (67%)]	Loss: 1.070504
18:57:02: Train Epoch: 10 [40000/45000 (89%)]	Loss: 1.037909
18:57:02: Train Epoch: 10 [40000/45000 (89%)]	Loss: 1.037909
18:57:02: Train Epoch: 10 [40000/45000 (89%)]	Loss: 1.037909
18:57:07: 
Evaluation: Average loss: 1.2003, Accuracy: 2935/5000 (58.700%)

18:57:07: 
Evaluation: Average loss: 1.2003, Accuracy: 2935/5000 (58.700%)

18:57:07: 
Evaluation: Average loss: 1.2003, Accuracy: 2935/5000 (58.700%)

18:57:07: Current learning rate: 0.1. Time taken for epoch: 29.46 seconds.

18:57:07: Current learning rate: 0.1. Time taken for epoch: 29.46 seconds.

18:57:07: Current learning rate: 0.1. Time taken for epoch: 29.46 seconds.

18:57:07: Train Epoch: 11 [0/45000 (0%)]	Loss: 0.903475
18:57:07: Train Epoch: 11 [0/45000 (0%)]	Loss: 0.903475
18:57:07: Train Epoch: 11 [0/45000 (0%)]	Loss: 0.903475
18:57:14: Train Epoch: 11 [10000/45000 (22%)]	Loss: 0.917096
18:57:14: Train Epoch: 11 [10000/45000 (22%)]	Loss: 0.917096
18:57:14: Train Epoch: 11 [10000/45000 (22%)]	Loss: 0.917096
18:57:20: Train Epoch: 11 [20000/45000 (44%)]	Loss: 1.066228
18:57:20: Train Epoch: 11 [20000/45000 (44%)]	Loss: 1.066228
18:57:20: Train Epoch: 11 [20000/45000 (44%)]	Loss: 1.066228
18:57:26: Train Epoch: 11 [30000/45000 (67%)]	Loss: 1.015116
18:57:26: Train Epoch: 11 [30000/45000 (67%)]	Loss: 1.015116
18:57:26: Train Epoch: 11 [30000/45000 (67%)]	Loss: 1.015116
18:57:32: Train Epoch: 11 [40000/45000 (89%)]	Loss: 0.892001
18:57:32: Train Epoch: 11 [40000/45000 (89%)]	Loss: 0.892001
18:57:32: Train Epoch: 11 [40000/45000 (89%)]	Loss: 0.892001
18:57:36: 
Evaluation: Average loss: 1.0260, Accuracy: 3232/5000 (64.640%)

18:57:36: 
Evaluation: Average loss: 1.0260, Accuracy: 3232/5000 (64.640%)

18:57:36: 
Evaluation: Average loss: 1.0260, Accuracy: 3232/5000 (64.640%)

18:57:37: Current learning rate: 0.1. Time taken for epoch: 29.84 seconds.

18:57:37: Current learning rate: 0.1. Time taken for epoch: 29.84 seconds.

18:57:37: Current learning rate: 0.1. Time taken for epoch: 29.84 seconds.

18:57:37: Train Epoch: 12 [0/45000 (0%)]	Loss: 0.896391
18:57:37: Train Epoch: 12 [0/45000 (0%)]	Loss: 0.896391
18:57:37: Train Epoch: 12 [0/45000 (0%)]	Loss: 0.896391
18:57:43: Train Epoch: 12 [10000/45000 (22%)]	Loss: 1.040409
18:57:43: Train Epoch: 12 [10000/45000 (22%)]	Loss: 1.040409
18:57:43: Train Epoch: 12 [10000/45000 (22%)]	Loss: 1.040409
18:57:49: Train Epoch: 12 [20000/45000 (44%)]	Loss: 0.872414
18:57:49: Train Epoch: 12 [20000/45000 (44%)]	Loss: 0.872414
18:57:49: Train Epoch: 12 [20000/45000 (44%)]	Loss: 0.872414
18:57:55: Train Epoch: 12 [30000/45000 (67%)]	Loss: 0.968072
18:57:55: Train Epoch: 12 [30000/45000 (67%)]	Loss: 0.968072
18:57:55: Train Epoch: 12 [30000/45000 (67%)]	Loss: 0.968072
18:58:01: Train Epoch: 12 [40000/45000 (89%)]	Loss: 0.936087
18:58:01: Train Epoch: 12 [40000/45000 (89%)]	Loss: 0.936087
18:58:01: Train Epoch: 12 [40000/45000 (89%)]	Loss: 0.936087
18:58:06: 
Evaluation: Average loss: 1.0197, Accuracy: 3245/5000 (64.900%)

18:58:06: 
Evaluation: Average loss: 1.0197, Accuracy: 3245/5000 (64.900%)

18:58:06: 
Evaluation: Average loss: 1.0197, Accuracy: 3245/5000 (64.900%)

18:58:06: Current learning rate: 0.1. Time taken for epoch: 29.28 seconds.

18:58:06: Current learning rate: 0.1. Time taken for epoch: 29.28 seconds.

18:58:06: Current learning rate: 0.1. Time taken for epoch: 29.28 seconds.

18:58:06: Train Epoch: 13 [0/45000 (0%)]	Loss: 0.952147
18:58:06: Train Epoch: 13 [0/45000 (0%)]	Loss: 0.952147
18:58:06: Train Epoch: 13 [0/45000 (0%)]	Loss: 0.952147
18:58:13: Train Epoch: 13 [10000/45000 (22%)]	Loss: 1.037147
18:58:13: Train Epoch: 13 [10000/45000 (22%)]	Loss: 1.037147
18:58:13: Train Epoch: 13 [10000/45000 (22%)]	Loss: 1.037147
18:58:19: Train Epoch: 13 [20000/45000 (44%)]	Loss: 0.859045
18:58:19: Train Epoch: 13 [20000/45000 (44%)]	Loss: 0.859045
18:58:19: Train Epoch: 13 [20000/45000 (44%)]	Loss: 0.859045
18:58:25: Train Epoch: 13 [30000/45000 (67%)]	Loss: 0.726019
18:58:25: Train Epoch: 13 [30000/45000 (67%)]	Loss: 0.726019
18:58:25: Train Epoch: 13 [30000/45000 (67%)]	Loss: 0.726019
18:58:30: Train Epoch: 13 [40000/45000 (89%)]	Loss: 0.897180
18:58:30: Train Epoch: 13 [40000/45000 (89%)]	Loss: 0.897180
18:58:30: Train Epoch: 13 [40000/45000 (89%)]	Loss: 0.897180
18:58:35: 
Evaluation: Average loss: 1.1144, Accuracy: 3078/5000 (61.560%)

18:58:35: 
Evaluation: Average loss: 1.1144, Accuracy: 3078/5000 (61.560%)

18:58:35: 
Evaluation: Average loss: 1.1144, Accuracy: 3078/5000 (61.560%)

18:58:35: Current learning rate: 0.1. Time taken for epoch: 29.56 seconds.

18:58:35: Current learning rate: 0.1. Time taken for epoch: 29.56 seconds.

18:58:35: Current learning rate: 0.1. Time taken for epoch: 29.56 seconds.

18:58:36: Train Epoch: 14 [0/45000 (0%)]	Loss: 1.077231
18:58:36: Train Epoch: 14 [0/45000 (0%)]	Loss: 1.077231
18:58:36: Train Epoch: 14 [0/45000 (0%)]	Loss: 1.077231
18:58:42: Train Epoch: 14 [10000/45000 (22%)]	Loss: 0.973345
18:58:42: Train Epoch: 14 [10000/45000 (22%)]	Loss: 0.973345
18:58:42: Train Epoch: 14 [10000/45000 (22%)]	Loss: 0.973345
18:58:48: Train Epoch: 14 [20000/45000 (44%)]	Loss: 0.934396
18:58:48: Train Epoch: 14 [20000/45000 (44%)]	Loss: 0.934396
18:58:48: Train Epoch: 14 [20000/45000 (44%)]	Loss: 0.934396
18:58:53: Train Epoch: 14 [30000/45000 (67%)]	Loss: 0.761494
18:58:53: Train Epoch: 14 [30000/45000 (67%)]	Loss: 0.761494
18:58:53: Train Epoch: 14 [30000/45000 (67%)]	Loss: 0.761494
18:58:59: Train Epoch: 14 [40000/45000 (89%)]	Loss: 0.946728
18:58:59: Train Epoch: 14 [40000/45000 (89%)]	Loss: 0.946728
18:58:59: Train Epoch: 14 [40000/45000 (89%)]	Loss: 0.946728
18:59:04: 
Evaluation: Average loss: 0.9687, Accuracy: 3311/5000 (66.220%)

18:59:04: 
Evaluation: Average loss: 0.9687, Accuracy: 3311/5000 (66.220%)

18:59:04: 
Evaluation: Average loss: 0.9687, Accuracy: 3311/5000 (66.220%)

18:59:04: Current learning rate: 0.1. Time taken for epoch: 28.37 seconds.

18:59:04: Current learning rate: 0.1. Time taken for epoch: 28.37 seconds.

18:59:04: Current learning rate: 0.1. Time taken for epoch: 28.37 seconds.

18:59:05: Train Epoch: 15 [0/45000 (0%)]	Loss: 0.837940
18:59:05: Train Epoch: 15 [0/45000 (0%)]	Loss: 0.837940
18:59:05: Train Epoch: 15 [0/45000 (0%)]	Loss: 0.837940
18:59:11: Train Epoch: 15 [10000/45000 (22%)]	Loss: 0.951340
18:59:11: Train Epoch: 15 [10000/45000 (22%)]	Loss: 0.951340
18:59:11: Train Epoch: 15 [10000/45000 (22%)]	Loss: 0.951340
18:59:16: Train Epoch: 15 [20000/45000 (44%)]	Loss: 0.859055
18:59:16: Train Epoch: 15 [20000/45000 (44%)]	Loss: 0.859055
18:59:16: Train Epoch: 15 [20000/45000 (44%)]	Loss: 0.859055
18:59:22: Train Epoch: 15 [30000/45000 (67%)]	Loss: 0.914733
18:59:22: Train Epoch: 15 [30000/45000 (67%)]	Loss: 0.914733
18:59:22: Train Epoch: 15 [30000/45000 (67%)]	Loss: 0.914733
18:59:28: Train Epoch: 15 [40000/45000 (89%)]	Loss: 0.820461
18:59:28: Train Epoch: 15 [40000/45000 (89%)]	Loss: 0.820461
18:59:28: Train Epoch: 15 [40000/45000 (89%)]	Loss: 0.820461
18:59:33: 
Evaluation: Average loss: 1.0832, Accuracy: 3138/5000 (62.760%)

18:59:33: 
Evaluation: Average loss: 1.0832, Accuracy: 3138/5000 (62.760%)

18:59:33: 
Evaluation: Average loss: 1.0832, Accuracy: 3138/5000 (62.760%)

18:59:33: Current learning rate: 0.1. Time taken for epoch: 29.29 seconds.

18:59:33: Current learning rate: 0.1. Time taken for epoch: 29.29 seconds.

18:59:33: Current learning rate: 0.1. Time taken for epoch: 29.29 seconds.

18:59:34: Train Epoch: 16 [0/45000 (0%)]	Loss: 0.949087
18:59:34: Train Epoch: 16 [0/45000 (0%)]	Loss: 0.949087
18:59:34: Train Epoch: 16 [0/45000 (0%)]	Loss: 0.949087
18:59:40: Train Epoch: 16 [10000/45000 (22%)]	Loss: 1.030977
18:59:40: Train Epoch: 16 [10000/45000 (22%)]	Loss: 1.030977
18:59:40: Train Epoch: 16 [10000/45000 (22%)]	Loss: 1.030977
18:59:46: Train Epoch: 16 [20000/45000 (44%)]	Loss: 1.101172
18:59:46: Train Epoch: 16 [20000/45000 (44%)]	Loss: 1.101172
18:59:46: Train Epoch: 16 [20000/45000 (44%)]	Loss: 1.101172
18:59:51: Train Epoch: 16 [30000/45000 (67%)]	Loss: 0.774793
18:59:51: Train Epoch: 16 [30000/45000 (67%)]	Loss: 0.774793
18:59:51: Train Epoch: 16 [30000/45000 (67%)]	Loss: 0.774793
18:59:57: Train Epoch: 16 [40000/45000 (89%)]	Loss: 1.014955
18:59:57: Train Epoch: 16 [40000/45000 (89%)]	Loss: 1.014955
18:59:57: Train Epoch: 16 [40000/45000 (89%)]	Loss: 1.014955
19:00:01: 
Evaluation: Average loss: 1.0565, Accuracy: 3270/5000 (65.400%)

19:00:01: 
Evaluation: Average loss: 1.0565, Accuracy: 3270/5000 (65.400%)

19:00:01: 
Evaluation: Average loss: 1.0565, Accuracy: 3270/5000 (65.400%)

19:00:01: Current learning rate: 0.1. Time taken for epoch: 28.43 seconds.

19:00:01: Current learning rate: 0.1. Time taken for epoch: 28.43 seconds.

19:00:01: Current learning rate: 0.1. Time taken for epoch: 28.43 seconds.

19:00:02: Train Epoch: 17 [0/45000 (0%)]	Loss: 0.911990
19:00:02: Train Epoch: 17 [0/45000 (0%)]	Loss: 0.911990
19:00:02: Train Epoch: 17 [0/45000 (0%)]	Loss: 0.911990
19:00:08: Train Epoch: 17 [10000/45000 (22%)]	Loss: 1.022918
19:00:08: Train Epoch: 17 [10000/45000 (22%)]	Loss: 1.022918
19:00:08: Train Epoch: 17 [10000/45000 (22%)]	Loss: 1.022918
19:00:14: Train Epoch: 17 [20000/45000 (44%)]	Loss: 0.746091
19:00:14: Train Epoch: 17 [20000/45000 (44%)]	Loss: 0.746091
19:00:14: Train Epoch: 17 [20000/45000 (44%)]	Loss: 0.746091
19:00:19: Train Epoch: 17 [30000/45000 (67%)]	Loss: 1.168708
19:00:19: Train Epoch: 17 [30000/45000 (67%)]	Loss: 1.168708
19:00:19: Train Epoch: 17 [30000/45000 (67%)]	Loss: 1.168708
19:00:25: Train Epoch: 17 [40000/45000 (89%)]	Loss: 0.960175
19:00:25: Train Epoch: 17 [40000/45000 (89%)]	Loss: 0.960175
19:00:25: Train Epoch: 17 [40000/45000 (89%)]	Loss: 0.960175
19:00:30: 
Evaluation: Average loss: 1.0176, Accuracy: 3340/5000 (66.800%)

19:00:30: 
Evaluation: Average loss: 1.0176, Accuracy: 3340/5000 (66.800%)

19:00:30: 
Evaluation: Average loss: 1.0176, Accuracy: 3340/5000 (66.800%)

19:00:30: Current learning rate: 0.1. Time taken for epoch: 29.01 seconds.

19:00:30: Current learning rate: 0.1. Time taken for epoch: 29.01 seconds.

19:00:30: Current learning rate: 0.1. Time taken for epoch: 29.01 seconds.

19:00:31: Train Epoch: 18 [0/45000 (0%)]	Loss: 0.910733
19:00:31: Train Epoch: 18 [0/45000 (0%)]	Loss: 0.910733
19:00:31: Train Epoch: 18 [0/45000 (0%)]	Loss: 0.910733
19:00:37: Train Epoch: 18 [10000/45000 (22%)]	Loss: 0.963349
19:00:37: Train Epoch: 18 [10000/45000 (22%)]	Loss: 0.963349
19:00:37: Train Epoch: 18 [10000/45000 (22%)]	Loss: 0.963349
19:00:43: Train Epoch: 18 [20000/45000 (44%)]	Loss: 0.970611
19:00:43: Train Epoch: 18 [20000/45000 (44%)]	Loss: 0.970611
19:00:43: Train Epoch: 18 [20000/45000 (44%)]	Loss: 0.970611
19:00:49: Train Epoch: 18 [30000/45000 (67%)]	Loss: 0.635672
19:00:49: Train Epoch: 18 [30000/45000 (67%)]	Loss: 0.635672
19:00:49: Train Epoch: 18 [30000/45000 (67%)]	Loss: 0.635672
19:00:55: Train Epoch: 18 [40000/45000 (89%)]	Loss: 0.885292
19:00:55: Train Epoch: 18 [40000/45000 (89%)]	Loss: 0.885292
19:00:55: Train Epoch: 18 [40000/45000 (89%)]	Loss: 0.885292
19:00:59: 
Evaluation: Average loss: 1.0887, Accuracy: 3197/5000 (63.940%)

19:00:59: 
Evaluation: Average loss: 1.0887, Accuracy: 3197/5000 (63.940%)

19:00:59: 
Evaluation: Average loss: 1.0887, Accuracy: 3197/5000 (63.940%)

19:00:59: Current learning rate: 0.1. Time taken for epoch: 29.01 seconds.

19:00:59: Current learning rate: 0.1. Time taken for epoch: 29.01 seconds.

19:00:59: Current learning rate: 0.1. Time taken for epoch: 29.01 seconds.

19:01:00: Train Epoch: 19 [0/45000 (0%)]	Loss: 0.665436
19:01:00: Train Epoch: 19 [0/45000 (0%)]	Loss: 0.665436
19:01:00: Train Epoch: 19 [0/45000 (0%)]	Loss: 0.665436
19:01:06: Train Epoch: 19 [10000/45000 (22%)]	Loss: 0.843730
19:01:06: Train Epoch: 19 [10000/45000 (22%)]	Loss: 0.843730
19:01:06: Train Epoch: 19 [10000/45000 (22%)]	Loss: 0.843730
19:01:12: Train Epoch: 19 [20000/45000 (44%)]	Loss: 1.012961
19:01:12: Train Epoch: 19 [20000/45000 (44%)]	Loss: 1.012961
19:01:12: Train Epoch: 19 [20000/45000 (44%)]	Loss: 1.012961
19:01:18: Train Epoch: 19 [30000/45000 (67%)]	Loss: 1.097223
19:01:18: Train Epoch: 19 [30000/45000 (67%)]	Loss: 1.097223
19:01:18: Train Epoch: 19 [30000/45000 (67%)]	Loss: 1.097223
19:01:24: Train Epoch: 19 [40000/45000 (89%)]	Loss: 0.896979
19:01:24: Train Epoch: 19 [40000/45000 (89%)]	Loss: 0.896979
19:01:24: Train Epoch: 19 [40000/45000 (89%)]	Loss: 0.896979
19:01:29: 
Evaluation: Average loss: 1.0212, Accuracy: 3267/5000 (65.340%)

19:01:29: 
Evaluation: Average loss: 1.0212, Accuracy: 3267/5000 (65.340%)

19:01:29: 
Evaluation: Average loss: 1.0212, Accuracy: 3267/5000 (65.340%)

19:01:29: Current learning rate: 0.1. Time taken for epoch: 29.82 seconds.

19:01:29: Current learning rate: 0.1. Time taken for epoch: 29.82 seconds.

19:01:29: Current learning rate: 0.1. Time taken for epoch: 29.82 seconds.

19:01:30: Train Epoch: 20 [0/45000 (0%)]	Loss: 0.907050
19:01:30: Train Epoch: 20 [0/45000 (0%)]	Loss: 0.907050
19:01:30: Train Epoch: 20 [0/45000 (0%)]	Loss: 0.907050
19:01:36: Train Epoch: 20 [10000/45000 (22%)]	Loss: 0.844941
19:01:36: Train Epoch: 20 [10000/45000 (22%)]	Loss: 0.844941
19:01:36: Train Epoch: 20 [10000/45000 (22%)]	Loss: 0.844941
19:01:42: Train Epoch: 20 [20000/45000 (44%)]	Loss: 0.865420
19:01:42: Train Epoch: 20 [20000/45000 (44%)]	Loss: 0.865420
19:01:42: Train Epoch: 20 [20000/45000 (44%)]	Loss: 0.865420
19:01:48: Train Epoch: 20 [30000/45000 (67%)]	Loss: 0.913547
19:01:48: Train Epoch: 20 [30000/45000 (67%)]	Loss: 0.913547
19:01:48: Train Epoch: 20 [30000/45000 (67%)]	Loss: 0.913547
19:01:54: Train Epoch: 20 [40000/45000 (89%)]	Loss: 0.710975
19:01:54: Train Epoch: 20 [40000/45000 (89%)]	Loss: 0.710975
19:01:54: Train Epoch: 20 [40000/45000 (89%)]	Loss: 0.710975
19:01:59: 
Evaluation: Average loss: 1.0812, Accuracy: 3258/5000 (65.160%)

19:01:59: 
Evaluation: Average loss: 1.0812, Accuracy: 3258/5000 (65.160%)

19:01:59: 
Evaluation: Average loss: 1.0812, Accuracy: 3258/5000 (65.160%)

19:01:59: Current learning rate: 0.1. Time taken for epoch: 29.47 seconds.

19:01:59: Current learning rate: 0.1. Time taken for epoch: 29.47 seconds.

19:01:59: Current learning rate: 0.1. Time taken for epoch: 29.47 seconds.

19:02:00: Train Epoch: 21 [0/45000 (0%)]	Loss: 0.837515
19:02:00: Train Epoch: 21 [0/45000 (0%)]	Loss: 0.837515
19:02:00: Train Epoch: 21 [0/45000 (0%)]	Loss: 0.837515
19:02:05: Train Epoch: 21 [10000/45000 (22%)]	Loss: 0.916667
19:02:05: Train Epoch: 21 [10000/45000 (22%)]	Loss: 0.916667
19:02:05: Train Epoch: 21 [10000/45000 (22%)]	Loss: 0.916667
19:02:11: Train Epoch: 21 [20000/45000 (44%)]	Loss: 0.918610
19:02:11: Train Epoch: 21 [20000/45000 (44%)]	Loss: 0.918610
19:02:11: Train Epoch: 21 [20000/45000 (44%)]	Loss: 0.918610
19:02:16: Train Epoch: 21 [30000/45000 (67%)]	Loss: 0.798182
19:02:16: Train Epoch: 21 [30000/45000 (67%)]	Loss: 0.798182
19:02:16: Train Epoch: 21 [30000/45000 (67%)]	Loss: 0.798182
19:02:22: Train Epoch: 21 [40000/45000 (89%)]	Loss: 0.962809
19:02:22: Train Epoch: 21 [40000/45000 (89%)]	Loss: 0.962809
19:02:22: Train Epoch: 21 [40000/45000 (89%)]	Loss: 0.962809
19:02:26: 
Evaluation: Average loss: 1.0134, Accuracy: 3228/5000 (64.560%)

19:02:26: 
Evaluation: Average loss: 1.0134, Accuracy: 3228/5000 (64.560%)

19:02:26: 
Evaluation: Average loss: 1.0134, Accuracy: 3228/5000 (64.560%)

19:02:27: Current learning rate: 0.1. Time taken for epoch: 27.76 seconds.

19:02:27: Current learning rate: 0.1. Time taken for epoch: 27.76 seconds.

19:02:27: Current learning rate: 0.1. Time taken for epoch: 27.76 seconds.

19:02:27: Train Epoch: 22 [0/45000 (0%)]	Loss: 0.833723
19:02:27: Train Epoch: 22 [0/45000 (0%)]	Loss: 0.833723
19:02:27: Train Epoch: 22 [0/45000 (0%)]	Loss: 0.833723
19:02:33: Train Epoch: 22 [10000/45000 (22%)]	Loss: 0.836489
19:02:33: Train Epoch: 22 [10000/45000 (22%)]	Loss: 0.836489
19:02:33: Train Epoch: 22 [10000/45000 (22%)]	Loss: 0.836489
19:02:39: Train Epoch: 22 [20000/45000 (44%)]	Loss: 1.052675
19:02:39: Train Epoch: 22 [20000/45000 (44%)]	Loss: 1.052675
19:02:39: Train Epoch: 22 [20000/45000 (44%)]	Loss: 1.052675
19:02:44: Train Epoch: 22 [30000/45000 (67%)]	Loss: 0.899131
19:02:44: Train Epoch: 22 [30000/45000 (67%)]	Loss: 0.899131
19:02:44: Train Epoch: 22 [30000/45000 (67%)]	Loss: 0.899131
19:02:50: Train Epoch: 22 [40000/45000 (89%)]	Loss: 0.845989
19:02:50: Train Epoch: 22 [40000/45000 (89%)]	Loss: 0.845989
19:02:50: Train Epoch: 22 [40000/45000 (89%)]	Loss: 0.845989
19:02:55: 
Evaluation: Average loss: 0.9583, Accuracy: 3328/5000 (66.560%)

19:02:55: 
Evaluation: Average loss: 0.9583, Accuracy: 3328/5000 (66.560%)

19:02:55: 
Evaluation: Average loss: 0.9583, Accuracy: 3328/5000 (66.560%)

19:02:55: Current learning rate: 0.1. Time taken for epoch: 28.46 seconds.

19:02:55: Current learning rate: 0.1. Time taken for epoch: 28.46 seconds.

19:02:55: Current learning rate: 0.1. Time taken for epoch: 28.46 seconds.

19:02:56: Train Epoch: 23 [0/45000 (0%)]	Loss: 0.881526
19:02:56: Train Epoch: 23 [0/45000 (0%)]	Loss: 0.881526
19:02:56: Train Epoch: 23 [0/45000 (0%)]	Loss: 0.881526
19:03:02: Train Epoch: 23 [10000/45000 (22%)]	Loss: 0.890483
19:03:02: Train Epoch: 23 [10000/45000 (22%)]	Loss: 0.890483
19:03:02: Train Epoch: 23 [10000/45000 (22%)]	Loss: 0.890483
19:03:08: Train Epoch: 23 [20000/45000 (44%)]	Loss: 0.833632
19:03:08: Train Epoch: 23 [20000/45000 (44%)]	Loss: 0.833632
19:03:08: Train Epoch: 23 [20000/45000 (44%)]	Loss: 0.833632
19:03:14: Train Epoch: 23 [30000/45000 (67%)]	Loss: 0.922766
19:03:14: Train Epoch: 23 [30000/45000 (67%)]	Loss: 0.922766
19:03:14: Train Epoch: 23 [30000/45000 (67%)]	Loss: 0.922766
19:03:19: Train Epoch: 23 [40000/45000 (89%)]	Loss: 0.823278
19:03:19: Train Epoch: 23 [40000/45000 (89%)]	Loss: 0.823278
19:03:19: Train Epoch: 23 [40000/45000 (89%)]	Loss: 0.823278
19:03:24: 
Evaluation: Average loss: 1.0581, Accuracy: 3141/5000 (62.820%)

19:03:24: 
Evaluation: Average loss: 1.0581, Accuracy: 3141/5000 (62.820%)

19:03:24: 
Evaluation: Average loss: 1.0581, Accuracy: 3141/5000 (62.820%)

19:03:24: Current learning rate: 0.1. Time taken for epoch: 29.37 seconds.

19:03:24: Current learning rate: 0.1. Time taken for epoch: 29.37 seconds.

19:03:24: Current learning rate: 0.1. Time taken for epoch: 29.37 seconds.

19:03:25: Train Epoch: 24 [0/45000 (0%)]	Loss: 0.845918
19:03:25: Train Epoch: 24 [0/45000 (0%)]	Loss: 0.845918
19:03:25: Train Epoch: 24 [0/45000 (0%)]	Loss: 0.845918
19:03:31: Train Epoch: 24 [10000/45000 (22%)]	Loss: 0.945922
19:03:31: Train Epoch: 24 [10000/45000 (22%)]	Loss: 0.945922
19:03:31: Train Epoch: 24 [10000/45000 (22%)]	Loss: 0.945922
19:03:37: Train Epoch: 24 [20000/45000 (44%)]	Loss: 0.831198
19:03:37: Train Epoch: 24 [20000/45000 (44%)]	Loss: 0.831198
19:03:37: Train Epoch: 24 [20000/45000 (44%)]	Loss: 0.831198
19:03:43: Train Epoch: 24 [30000/45000 (67%)]	Loss: 0.755331
19:03:43: Train Epoch: 24 [30000/45000 (67%)]	Loss: 0.755331
19:03:43: Train Epoch: 24 [30000/45000 (67%)]	Loss: 0.755331
19:03:49: Train Epoch: 24 [40000/45000 (89%)]	Loss: 0.951326
19:03:49: Train Epoch: 24 [40000/45000 (89%)]	Loss: 0.951326
19:03:49: Train Epoch: 24 [40000/45000 (89%)]	Loss: 0.951326
19:03:53: 
Evaluation: Average loss: 0.9488, Accuracy: 3447/5000 (68.940%)

19:03:53: 
Evaluation: Average loss: 0.9488, Accuracy: 3447/5000 (68.940%)

19:03:53: 
Evaluation: Average loss: 0.9488, Accuracy: 3447/5000 (68.940%)

19:03:53: Current learning rate: 0.1. Time taken for epoch: 29.02 seconds.

19:03:53: Current learning rate: 0.1. Time taken for epoch: 29.02 seconds.

19:03:53: Current learning rate: 0.1. Time taken for epoch: 29.02 seconds.

19:03:54: Train Epoch: 25 [0/45000 (0%)]	Loss: 0.792527
19:03:54: Train Epoch: 25 [0/45000 (0%)]	Loss: 0.792527
19:03:54: Train Epoch: 25 [0/45000 (0%)]	Loss: 0.792527
19:04:00: Train Epoch: 25 [10000/45000 (22%)]	Loss: 0.658052
19:04:00: Train Epoch: 25 [10000/45000 (22%)]	Loss: 0.658052
19:04:00: Train Epoch: 25 [10000/45000 (22%)]	Loss: 0.658052
19:04:06: Train Epoch: 25 [20000/45000 (44%)]	Loss: 0.789372
19:04:06: Train Epoch: 25 [20000/45000 (44%)]	Loss: 0.789372
19:04:06: Train Epoch: 25 [20000/45000 (44%)]	Loss: 0.789372
19:04:12: Train Epoch: 25 [30000/45000 (67%)]	Loss: 1.022682
19:04:12: Train Epoch: 25 [30000/45000 (67%)]	Loss: 1.022682
19:04:12: Train Epoch: 25 [30000/45000 (67%)]	Loss: 1.022682
19:04:17: Train Epoch: 25 [40000/45000 (89%)]	Loss: 0.875415
19:04:17: Train Epoch: 25 [40000/45000 (89%)]	Loss: 0.875415
19:04:17: Train Epoch: 25 [40000/45000 (89%)]	Loss: 0.875415
19:04:22: 
Evaluation: Average loss: 1.1451, Accuracy: 3017/5000 (60.340%)

19:04:22: 
Evaluation: Average loss: 1.1451, Accuracy: 3017/5000 (60.340%)

19:04:22: 
Evaluation: Average loss: 1.1451, Accuracy: 3017/5000 (60.340%)

19:04:22: Current learning rate: 0.1. Time taken for epoch: 28.68 seconds.

19:04:22: Current learning rate: 0.1. Time taken for epoch: 28.68 seconds.

19:04:22: Current learning rate: 0.1. Time taken for epoch: 28.68 seconds.

19:04:23: Train Epoch: 26 [0/45000 (0%)]	Loss: 0.738042
19:04:23: Train Epoch: 26 [0/45000 (0%)]	Loss: 0.738042
19:04:23: Train Epoch: 26 [0/45000 (0%)]	Loss: 0.738042
19:04:29: Train Epoch: 26 [10000/45000 (22%)]	Loss: 0.909108
19:04:29: Train Epoch: 26 [10000/45000 (22%)]	Loss: 0.909108
19:04:29: Train Epoch: 26 [10000/45000 (22%)]	Loss: 0.909108
19:04:34: Train Epoch: 26 [20000/45000 (44%)]	Loss: 0.734611
19:04:34: Train Epoch: 26 [20000/45000 (44%)]	Loss: 0.734611
19:04:34: Train Epoch: 26 [20000/45000 (44%)]	Loss: 0.734611
19:04:40: Train Epoch: 26 [30000/45000 (67%)]	Loss: 0.771405
19:04:40: Train Epoch: 26 [30000/45000 (67%)]	Loss: 0.771405
19:04:40: Train Epoch: 26 [30000/45000 (67%)]	Loss: 0.771405
19:04:46: Train Epoch: 26 [40000/45000 (89%)]	Loss: 0.839975
19:04:46: Train Epoch: 26 [40000/45000 (89%)]	Loss: 0.839975
19:04:46: Train Epoch: 26 [40000/45000 (89%)]	Loss: 0.839975
19:04:50: 
Evaluation: Average loss: 1.5178, Accuracy: 2669/5000 (53.380%)

19:04:50: 
Evaluation: Average loss: 1.5178, Accuracy: 2669/5000 (53.380%)

19:04:50: 
Evaluation: Average loss: 1.5178, Accuracy: 2669/5000 (53.380%)

19:04:50: Current learning rate: 0.1. Time taken for epoch: 28.39 seconds.

19:04:50: Current learning rate: 0.1. Time taken for epoch: 28.39 seconds.

19:04:50: Current learning rate: 0.1. Time taken for epoch: 28.39 seconds.

19:04:51: Train Epoch: 27 [0/45000 (0%)]	Loss: 0.917115
19:04:51: Train Epoch: 27 [0/45000 (0%)]	Loss: 0.917115
19:04:51: Train Epoch: 27 [0/45000 (0%)]	Loss: 0.917115
19:04:57: Train Epoch: 27 [10000/45000 (22%)]	Loss: 0.851246
19:04:57: Train Epoch: 27 [10000/45000 (22%)]	Loss: 0.851246
19:04:57: Train Epoch: 27 [10000/45000 (22%)]	Loss: 0.851246
19:05:03: Train Epoch: 27 [20000/45000 (44%)]	Loss: 0.709013
19:05:03: Train Epoch: 27 [20000/45000 (44%)]	Loss: 0.709013
19:05:03: Train Epoch: 27 [20000/45000 (44%)]	Loss: 0.709013
19:05:08: Train Epoch: 27 [30000/45000 (67%)]	Loss: 0.699592
19:05:08: Train Epoch: 27 [30000/45000 (67%)]	Loss: 0.699592
19:05:08: Train Epoch: 27 [30000/45000 (67%)]	Loss: 0.699592
19:05:14: Train Epoch: 27 [40000/45000 (89%)]	Loss: 0.905364
19:05:14: Train Epoch: 27 [40000/45000 (89%)]	Loss: 0.905364
19:05:14: Train Epoch: 27 [40000/45000 (89%)]	Loss: 0.905364
19:05:19: 
Evaluation: Average loss: 1.3645, Accuracy: 2722/5000 (54.440%)

19:05:19: 
Evaluation: Average loss: 1.3645, Accuracy: 2722/5000 (54.440%)

19:05:19: 
Evaluation: Average loss: 1.3645, Accuracy: 2722/5000 (54.440%)

19:05:19: Current learning rate: 0.1. Time taken for epoch: 28.56 seconds.

19:05:19: Current learning rate: 0.1. Time taken for epoch: 28.56 seconds.

19:05:19: Current learning rate: 0.1. Time taken for epoch: 28.56 seconds.

19:05:20: Train Epoch: 28 [0/45000 (0%)]	Loss: 0.787978
19:05:20: Train Epoch: 28 [0/45000 (0%)]	Loss: 0.787978
19:05:20: Train Epoch: 28 [0/45000 (0%)]	Loss: 0.787978
19:05:26: Train Epoch: 28 [10000/45000 (22%)]	Loss: 0.935257
19:05:26: Train Epoch: 28 [10000/45000 (22%)]	Loss: 0.935257
19:05:26: Train Epoch: 28 [10000/45000 (22%)]	Loss: 0.935257
19:05:31: Train Epoch: 28 [20000/45000 (44%)]	Loss: 0.883613
19:05:31: Train Epoch: 28 [20000/45000 (44%)]	Loss: 0.883613
19:05:31: Train Epoch: 28 [20000/45000 (44%)]	Loss: 0.883613
19:05:37: Train Epoch: 28 [30000/45000 (67%)]	Loss: 0.972525
19:05:37: Train Epoch: 28 [30000/45000 (67%)]	Loss: 0.972525
19:05:37: Train Epoch: 28 [30000/45000 (67%)]	Loss: 0.972525
19:05:43: Train Epoch: 28 [40000/45000 (89%)]	Loss: 0.794681
19:05:43: Train Epoch: 28 [40000/45000 (89%)]	Loss: 0.794681
19:05:43: Train Epoch: 28 [40000/45000 (89%)]	Loss: 0.794681
19:05:47: 
Evaluation: Average loss: 1.6294, Accuracy: 2750/5000 (55.000%)

19:05:47: 
Evaluation: Average loss: 1.6294, Accuracy: 2750/5000 (55.000%)

19:05:47: 
Evaluation: Average loss: 1.6294, Accuracy: 2750/5000 (55.000%)

19:05:47: Current learning rate: 0.1. Time taken for epoch: 28.44 seconds.

19:05:47: Current learning rate: 0.1. Time taken for epoch: 28.44 seconds.

19:05:47: Current learning rate: 0.1. Time taken for epoch: 28.44 seconds.

19:05:48: Train Epoch: 29 [0/45000 (0%)]	Loss: 0.833611
19:05:48: Train Epoch: 29 [0/45000 (0%)]	Loss: 0.833611
19:05:48: Train Epoch: 29 [0/45000 (0%)]	Loss: 0.833611
19:05:54: Train Epoch: 29 [10000/45000 (22%)]	Loss: 0.692330
19:05:54: Train Epoch: 29 [10000/45000 (22%)]	Loss: 0.692330
19:05:54: Train Epoch: 29 [10000/45000 (22%)]	Loss: 0.692330
19:06:00: Train Epoch: 29 [20000/45000 (44%)]	Loss: 0.827153
19:06:00: Train Epoch: 29 [20000/45000 (44%)]	Loss: 0.827153
19:06:00: Train Epoch: 29 [20000/45000 (44%)]	Loss: 0.827153
19:06:05: Train Epoch: 29 [30000/45000 (67%)]	Loss: 0.932952
19:06:05: Train Epoch: 29 [30000/45000 (67%)]	Loss: 0.932952
19:06:05: Train Epoch: 29 [30000/45000 (67%)]	Loss: 0.932952
19:06:11: Train Epoch: 29 [40000/45000 (89%)]	Loss: 0.940653
19:06:11: Train Epoch: 29 [40000/45000 (89%)]	Loss: 0.940653
19:06:11: Train Epoch: 29 [40000/45000 (89%)]	Loss: 0.940653
19:06:16: 
Evaluation: Average loss: 1.0555, Accuracy: 3263/5000 (65.260%)

19:06:16: 
Evaluation: Average loss: 1.0555, Accuracy: 3263/5000 (65.260%)

19:06:16: 
Evaluation: Average loss: 1.0555, Accuracy: 3263/5000 (65.260%)

19:06:16: Current learning rate: 0.1. Time taken for epoch: 28.60 seconds.

19:06:16: Current learning rate: 0.1. Time taken for epoch: 28.60 seconds.

19:06:16: Current learning rate: 0.1. Time taken for epoch: 28.60 seconds.

19:06:17: Train Epoch: 30 [0/45000 (0%)]	Loss: 0.937819
19:06:17: Train Epoch: 30 [0/45000 (0%)]	Loss: 0.937819
19:06:17: Train Epoch: 30 [0/45000 (0%)]	Loss: 0.937819
19:06:23: Train Epoch: 30 [10000/45000 (22%)]	Loss: 0.857799
19:06:23: Train Epoch: 30 [10000/45000 (22%)]	Loss: 0.857799
19:06:23: Train Epoch: 30 [10000/45000 (22%)]	Loss: 0.857799
19:06:28: Train Epoch: 30 [20000/45000 (44%)]	Loss: 1.163558
19:06:28: Train Epoch: 30 [20000/45000 (44%)]	Loss: 1.163558
19:06:28: Train Epoch: 30 [20000/45000 (44%)]	Loss: 1.163558
19:06:34: Train Epoch: 30 [30000/45000 (67%)]	Loss: 0.833850
19:06:34: Train Epoch: 30 [30000/45000 (67%)]	Loss: 0.833850
19:06:34: Train Epoch: 30 [30000/45000 (67%)]	Loss: 0.833850
19:06:40: Train Epoch: 30 [40000/45000 (89%)]	Loss: 0.885407
19:06:40: Train Epoch: 30 [40000/45000 (89%)]	Loss: 0.885407
19:06:40: Train Epoch: 30 [40000/45000 (89%)]	Loss: 0.885407
19:06:44: 
Evaluation: Average loss: 0.9215, Accuracy: 3470/5000 (69.400%)

19:06:44: 
Evaluation: Average loss: 0.9215, Accuracy: 3470/5000 (69.400%)

19:06:44: 
Evaluation: Average loss: 0.9215, Accuracy: 3470/5000 (69.400%)

19:06:44: Current learning rate: 0.1. Time taken for epoch: 28.27 seconds.

19:06:44: Current learning rate: 0.1. Time taken for epoch: 28.27 seconds.

19:06:44: Current learning rate: 0.1. Time taken for epoch: 28.27 seconds.

19:06:45: Train Epoch: 31 [0/45000 (0%)]	Loss: 0.871370
19:06:45: Train Epoch: 31 [0/45000 (0%)]	Loss: 0.871370
19:06:45: Train Epoch: 31 [0/45000 (0%)]	Loss: 0.871370
19:06:51: Train Epoch: 31 [10000/45000 (22%)]	Loss: 0.671322
19:06:51: Train Epoch: 31 [10000/45000 (22%)]	Loss: 0.671322
19:06:51: Train Epoch: 31 [10000/45000 (22%)]	Loss: 0.671322
19:06:57: Train Epoch: 31 [20000/45000 (44%)]	Loss: 1.013191
19:06:57: Train Epoch: 31 [20000/45000 (44%)]	Loss: 1.013191
19:06:57: Train Epoch: 31 [20000/45000 (44%)]	Loss: 1.013191
19:07:02: Train Epoch: 31 [30000/45000 (67%)]	Loss: 0.843251
19:07:02: Train Epoch: 31 [30000/45000 (67%)]	Loss: 0.843251
19:07:02: Train Epoch: 31 [30000/45000 (67%)]	Loss: 0.843251
19:07:08: Train Epoch: 31 [40000/45000 (89%)]	Loss: 0.784754
19:07:08: Train Epoch: 31 [40000/45000 (89%)]	Loss: 0.784754
19:07:08: Train Epoch: 31 [40000/45000 (89%)]	Loss: 0.784754
19:07:13: 
Evaluation: Average loss: 1.0235, Accuracy: 3294/5000 (65.880%)

19:07:13: 
Evaluation: Average loss: 1.0235, Accuracy: 3294/5000 (65.880%)

19:07:13: 
Evaluation: Average loss: 1.0235, Accuracy: 3294/5000 (65.880%)

19:07:13: Current learning rate: 0.1. Time taken for epoch: 28.34 seconds.

19:07:13: Current learning rate: 0.1. Time taken for epoch: 28.34 seconds.

19:07:13: Current learning rate: 0.1. Time taken for epoch: 28.34 seconds.

19:07:14: Train Epoch: 32 [0/45000 (0%)]	Loss: 0.599605
19:07:14: Train Epoch: 32 [0/45000 (0%)]	Loss: 0.599605
19:07:14: Train Epoch: 32 [0/45000 (0%)]	Loss: 0.599605
19:07:19: Train Epoch: 32 [10000/45000 (22%)]	Loss: 0.847491
19:07:19: Train Epoch: 32 [10000/45000 (22%)]	Loss: 0.847491
19:07:19: Train Epoch: 32 [10000/45000 (22%)]	Loss: 0.847491
19:07:25: Train Epoch: 32 [20000/45000 (44%)]	Loss: 0.777141
19:07:25: Train Epoch: 32 [20000/45000 (44%)]	Loss: 0.777141
19:07:25: Train Epoch: 32 [20000/45000 (44%)]	Loss: 0.777141
19:07:30: Train Epoch: 32 [30000/45000 (67%)]	Loss: 0.759699
19:07:30: Train Epoch: 32 [30000/45000 (67%)]	Loss: 0.759699
19:07:30: Train Epoch: 32 [30000/45000 (67%)]	Loss: 0.759699
19:07:36: Train Epoch: 32 [40000/45000 (89%)]	Loss: 0.827045
19:07:36: Train Epoch: 32 [40000/45000 (89%)]	Loss: 0.827045
19:07:36: Train Epoch: 32 [40000/45000 (89%)]	Loss: 0.827045
19:07:41: 
Evaluation: Average loss: 1.0509, Accuracy: 3271/5000 (65.420%)

19:07:41: 
Evaluation: Average loss: 1.0509, Accuracy: 3271/5000 (65.420%)

19:07:41: 
Evaluation: Average loss: 1.0509, Accuracy: 3271/5000 (65.420%)

19:07:41: Current learning rate: 0.1. Time taken for epoch: 27.93 seconds.

19:07:41: Current learning rate: 0.1. Time taken for epoch: 27.93 seconds.

19:07:41: Current learning rate: 0.1. Time taken for epoch: 27.93 seconds.

19:07:41: Train Epoch: 33 [0/45000 (0%)]	Loss: 0.873183
19:07:41: Train Epoch: 33 [0/45000 (0%)]	Loss: 0.873183
19:07:41: Train Epoch: 33 [0/45000 (0%)]	Loss: 0.873183
19:07:47: Train Epoch: 33 [10000/45000 (22%)]	Loss: 0.757277
19:07:47: Train Epoch: 33 [10000/45000 (22%)]	Loss: 0.757277
19:07:47: Train Epoch: 33 [10000/45000 (22%)]	Loss: 0.757277
19:07:53: Train Epoch: 33 [20000/45000 (44%)]	Loss: 1.135375
19:07:53: Train Epoch: 33 [20000/45000 (44%)]	Loss: 1.135375
19:07:53: Train Epoch: 33 [20000/45000 (44%)]	Loss: 1.135375
19:07:58: Train Epoch: 33 [30000/45000 (67%)]	Loss: 0.679234
19:07:58: Train Epoch: 33 [30000/45000 (67%)]	Loss: 0.679234
19:07:58: Train Epoch: 33 [30000/45000 (67%)]	Loss: 0.679234
19:08:04: Train Epoch: 33 [40000/45000 (89%)]	Loss: 1.003927
19:08:04: Train Epoch: 33 [40000/45000 (89%)]	Loss: 1.003927
19:08:04: Train Epoch: 33 [40000/45000 (89%)]	Loss: 1.003927
19:08:09: 
Evaluation: Average loss: 1.0543, Accuracy: 3241/5000 (64.820%)

19:08:09: 
Evaluation: Average loss: 1.0543, Accuracy: 3241/5000 (64.820%)

19:08:09: 
Evaluation: Average loss: 1.0543, Accuracy: 3241/5000 (64.820%)

19:08:09: Current learning rate: 0.1. Time taken for epoch: 28.33 seconds.

19:08:09: Current learning rate: 0.1. Time taken for epoch: 28.33 seconds.

19:08:09: Current learning rate: 0.1. Time taken for epoch: 28.33 seconds.

19:08:10: Train Epoch: 34 [0/45000 (0%)]	Loss: 0.932820
19:08:10: Train Epoch: 34 [0/45000 (0%)]	Loss: 0.932820
19:08:10: Train Epoch: 34 [0/45000 (0%)]	Loss: 0.932820
19:08:16: Train Epoch: 34 [10000/45000 (22%)]	Loss: 0.730107
19:08:16: Train Epoch: 34 [10000/45000 (22%)]	Loss: 0.730107
19:08:16: Train Epoch: 34 [10000/45000 (22%)]	Loss: 0.730107
19:08:21: Train Epoch: 34 [20000/45000 (44%)]	Loss: 0.683252
19:08:21: Train Epoch: 34 [20000/45000 (44%)]	Loss: 0.683252
19:08:21: Train Epoch: 34 [20000/45000 (44%)]	Loss: 0.683252
19:08:27: Train Epoch: 34 [30000/45000 (67%)]	Loss: 0.946380
19:08:27: Train Epoch: 34 [30000/45000 (67%)]	Loss: 0.946380
19:08:27: Train Epoch: 34 [30000/45000 (67%)]	Loss: 0.946380
19:08:33: Train Epoch: 34 [40000/45000 (89%)]	Loss: 1.063204
19:08:33: Train Epoch: 34 [40000/45000 (89%)]	Loss: 1.063204
19:08:33: Train Epoch: 34 [40000/45000 (89%)]	Loss: 1.063204
19:08:37: 
Evaluation: Average loss: 1.3214, Accuracy: 2810/5000 (56.200%)

19:08:37: 
Evaluation: Average loss: 1.3214, Accuracy: 2810/5000 (56.200%)

19:08:37: 
Evaluation: Average loss: 1.3214, Accuracy: 2810/5000 (56.200%)

19:08:37: Current learning rate: 0.1. Time taken for epoch: 28.34 seconds.

19:08:37: Current learning rate: 0.1. Time taken for epoch: 28.34 seconds.

19:08:37: Current learning rate: 0.1. Time taken for epoch: 28.34 seconds.

19:08:38: Train Epoch: 35 [0/45000 (0%)]	Loss: 0.794502
19:08:38: Train Epoch: 35 [0/45000 (0%)]	Loss: 0.794502
19:08:38: Train Epoch: 35 [0/45000 (0%)]	Loss: 0.794502
19:08:44: Train Epoch: 35 [10000/45000 (22%)]	Loss: 0.838742
19:08:44: Train Epoch: 35 [10000/45000 (22%)]	Loss: 0.838742
19:08:44: Train Epoch: 35 [10000/45000 (22%)]	Loss: 0.838742
19:08:50: Train Epoch: 35 [20000/45000 (44%)]	Loss: 0.837833
19:08:50: Train Epoch: 35 [20000/45000 (44%)]	Loss: 0.837833
19:08:50: Train Epoch: 35 [20000/45000 (44%)]	Loss: 0.837833
19:08:55: Train Epoch: 35 [30000/45000 (67%)]	Loss: 0.934575
19:08:55: Train Epoch: 35 [30000/45000 (67%)]	Loss: 0.934575
19:08:55: Train Epoch: 35 [30000/45000 (67%)]	Loss: 0.934575
19:09:01: Train Epoch: 35 [40000/45000 (89%)]	Loss: 0.818465
19:09:01: Train Epoch: 35 [40000/45000 (89%)]	Loss: 0.818465
19:09:01: Train Epoch: 35 [40000/45000 (89%)]	Loss: 0.818465
19:09:05: 
Evaluation: Average loss: 1.2256, Accuracy: 3072/5000 (61.440%)

19:09:05: 
Evaluation: Average loss: 1.2256, Accuracy: 3072/5000 (61.440%)

19:09:05: 
Evaluation: Average loss: 1.2256, Accuracy: 3072/5000 (61.440%)

19:09:05: Current learning rate: 0.1. Time taken for epoch: 28.19 seconds.

19:09:05: Current learning rate: 0.1. Time taken for epoch: 28.19 seconds.

19:09:05: Current learning rate: 0.1. Time taken for epoch: 28.19 seconds.

19:09:06: Train Epoch: 36 [0/45000 (0%)]	Loss: 0.823507
19:09:06: Train Epoch: 36 [0/45000 (0%)]	Loss: 0.823507
19:09:06: Train Epoch: 36 [0/45000 (0%)]	Loss: 0.823507
19:09:12: Train Epoch: 36 [10000/45000 (22%)]	Loss: 0.691665
19:09:12: Train Epoch: 36 [10000/45000 (22%)]	Loss: 0.691665
19:09:12: Train Epoch: 36 [10000/45000 (22%)]	Loss: 0.691665
19:09:18: Train Epoch: 36 [20000/45000 (44%)]	Loss: 1.036543
19:09:18: Train Epoch: 36 [20000/45000 (44%)]	Loss: 1.036543
19:09:18: Train Epoch: 36 [20000/45000 (44%)]	Loss: 1.036543
19:09:24: Train Epoch: 36 [30000/45000 (67%)]	Loss: 0.988652
19:09:24: Train Epoch: 36 [30000/45000 (67%)]	Loss: 0.988652
19:09:24: Train Epoch: 36 [30000/45000 (67%)]	Loss: 0.988652
19:09:29: Train Epoch: 36 [40000/45000 (89%)]	Loss: 0.859677
19:09:29: Train Epoch: 36 [40000/45000 (89%)]	Loss: 0.859677
19:09:29: Train Epoch: 36 [40000/45000 (89%)]	Loss: 0.859677
19:09:34: 
Evaluation: Average loss: 1.1308, Accuracy: 3162/5000 (63.240%)

19:09:34: 
Evaluation: Average loss: 1.1308, Accuracy: 3162/5000 (63.240%)

19:09:34: 
Evaluation: Average loss: 1.1308, Accuracy: 3162/5000 (63.240%)

19:09:34: Current learning rate: 0.1. Time taken for epoch: 28.53 seconds.

19:09:34: Current learning rate: 0.1. Time taken for epoch: 28.53 seconds.

19:09:34: Current learning rate: 0.1. Time taken for epoch: 28.53 seconds.

19:09:35: Train Epoch: 37 [0/45000 (0%)]	Loss: 0.901618
19:09:35: Train Epoch: 37 [0/45000 (0%)]	Loss: 0.901618
19:09:35: Train Epoch: 37 [0/45000 (0%)]	Loss: 0.901618
19:09:40: Train Epoch: 37 [10000/45000 (22%)]	Loss: 0.931756
19:09:40: Train Epoch: 37 [10000/45000 (22%)]	Loss: 0.931756
19:09:40: Train Epoch: 37 [10000/45000 (22%)]	Loss: 0.931756
19:09:46: Train Epoch: 37 [20000/45000 (44%)]	Loss: 0.716700
19:09:46: Train Epoch: 37 [20000/45000 (44%)]	Loss: 0.716700
19:09:46: Train Epoch: 37 [20000/45000 (44%)]	Loss: 0.716700
19:09:52: Train Epoch: 37 [30000/45000 (67%)]	Loss: 1.002655
19:09:52: Train Epoch: 37 [30000/45000 (67%)]	Loss: 1.002655
19:09:52: Train Epoch: 37 [30000/45000 (67%)]	Loss: 1.002655
19:09:57: Train Epoch: 37 [40000/45000 (89%)]	Loss: 0.882712
19:09:57: Train Epoch: 37 [40000/45000 (89%)]	Loss: 0.882712
19:09:57: Train Epoch: 37 [40000/45000 (89%)]	Loss: 0.882712
19:10:02: 
Evaluation: Average loss: 1.0383, Accuracy: 3207/5000 (64.140%)

19:10:02: 
Evaluation: Average loss: 1.0383, Accuracy: 3207/5000 (64.140%)

19:10:02: 
Evaluation: Average loss: 1.0383, Accuracy: 3207/5000 (64.140%)

19:10:02: Current learning rate: 0.1. Time taken for epoch: 28.14 seconds.

19:10:02: Current learning rate: 0.1. Time taken for epoch: 28.14 seconds.

19:10:02: Current learning rate: 0.1. Time taken for epoch: 28.14 seconds.

19:10:03: Train Epoch: 38 [0/45000 (0%)]	Loss: 0.899268
19:10:03: Train Epoch: 38 [0/45000 (0%)]	Loss: 0.899268
19:10:03: Train Epoch: 38 [0/45000 (0%)]	Loss: 0.899268
19:10:09: Train Epoch: 38 [10000/45000 (22%)]	Loss: 0.759776
19:10:09: Train Epoch: 38 [10000/45000 (22%)]	Loss: 0.759776
19:10:09: Train Epoch: 38 [10000/45000 (22%)]	Loss: 0.759776
19:10:15: Train Epoch: 38 [20000/45000 (44%)]	Loss: 0.896081
19:10:15: Train Epoch: 38 [20000/45000 (44%)]	Loss: 0.896081
19:10:15: Train Epoch: 38 [20000/45000 (44%)]	Loss: 0.896081
19:10:20: Train Epoch: 38 [30000/45000 (67%)]	Loss: 0.849068
19:10:20: Train Epoch: 38 [30000/45000 (67%)]	Loss: 0.849068
19:10:20: Train Epoch: 38 [30000/45000 (67%)]	Loss: 0.849068
19:10:26: Train Epoch: 38 [40000/45000 (89%)]	Loss: 0.715200
19:10:26: Train Epoch: 38 [40000/45000 (89%)]	Loss: 0.715200
19:10:26: Train Epoch: 38 [40000/45000 (89%)]	Loss: 0.715200
19:10:30: 
Evaluation: Average loss: 0.9476, Accuracy: 3373/5000 (67.460%)

19:10:30: 
Evaluation: Average loss: 0.9476, Accuracy: 3373/5000 (67.460%)

19:10:30: 
Evaluation: Average loss: 0.9476, Accuracy: 3373/5000 (67.460%)

19:10:30: Current learning rate: 0.1. Time taken for epoch: 28.06 seconds.

19:10:30: Current learning rate: 0.1. Time taken for epoch: 28.06 seconds.

19:10:30: Current learning rate: 0.1. Time taken for epoch: 28.06 seconds.

19:10:31: Train Epoch: 39 [0/45000 (0%)]	Loss: 1.055743
19:10:31: Train Epoch: 39 [0/45000 (0%)]	Loss: 1.055743
19:10:31: Train Epoch: 39 [0/45000 (0%)]	Loss: 1.055743
19:10:37: Train Epoch: 39 [10000/45000 (22%)]	Loss: 0.834283
19:10:37: Train Epoch: 39 [10000/45000 (22%)]	Loss: 0.834283
19:10:37: Train Epoch: 39 [10000/45000 (22%)]	Loss: 0.834283
19:10:42: Train Epoch: 39 [20000/45000 (44%)]	Loss: 0.817829
19:10:42: Train Epoch: 39 [20000/45000 (44%)]	Loss: 0.817829
19:10:42: Train Epoch: 39 [20000/45000 (44%)]	Loss: 0.817829
19:10:48: Train Epoch: 39 [30000/45000 (67%)]	Loss: 0.617335
19:10:48: Train Epoch: 39 [30000/45000 (67%)]	Loss: 0.617335
19:10:48: Train Epoch: 39 [30000/45000 (67%)]	Loss: 0.617335
19:10:53: Train Epoch: 39 [40000/45000 (89%)]	Loss: 0.853859
19:10:53: Train Epoch: 39 [40000/45000 (89%)]	Loss: 0.853859
19:10:53: Train Epoch: 39 [40000/45000 (89%)]	Loss: 0.853859
19:10:57: 
Evaluation: Average loss: 1.0300, Accuracy: 3272/5000 (65.440%)

19:10:57: 
Evaluation: Average loss: 1.0300, Accuracy: 3272/5000 (65.440%)

19:10:57: 
Evaluation: Average loss: 1.0300, Accuracy: 3272/5000 (65.440%)

19:10:57: Current learning rate: 0.1. Time taken for epoch: 27.29 seconds.

19:10:57: Current learning rate: 0.1. Time taken for epoch: 27.29 seconds.

19:10:57: Current learning rate: 0.1. Time taken for epoch: 27.29 seconds.

19:10:58: Train Epoch: 40 [0/45000 (0%)]	Loss: 0.808496
19:10:58: Train Epoch: 40 [0/45000 (0%)]	Loss: 0.808496
19:10:58: Train Epoch: 40 [0/45000 (0%)]	Loss: 0.808496
19:11:04: Train Epoch: 40 [10000/45000 (22%)]	Loss: 0.699672
19:11:04: Train Epoch: 40 [10000/45000 (22%)]	Loss: 0.699672
19:11:04: Train Epoch: 40 [10000/45000 (22%)]	Loss: 0.699672
19:11:09: Train Epoch: 40 [20000/45000 (44%)]	Loss: 0.895852
19:11:09: Train Epoch: 40 [20000/45000 (44%)]	Loss: 0.895852
19:11:09: Train Epoch: 40 [20000/45000 (44%)]	Loss: 0.895852
19:11:15: Train Epoch: 40 [30000/45000 (67%)]	Loss: 0.890089
19:11:15: Train Epoch: 40 [30000/45000 (67%)]	Loss: 0.890089
19:11:15: Train Epoch: 40 [30000/45000 (67%)]	Loss: 0.890089
19:11:20: Train Epoch: 40 [40000/45000 (89%)]	Loss: 0.652685
19:11:20: Train Epoch: 40 [40000/45000 (89%)]	Loss: 0.652685
19:11:20: Train Epoch: 40 [40000/45000 (89%)]	Loss: 0.652685
19:11:25: 
Evaluation: Average loss: 1.0630, Accuracy: 3224/5000 (64.480%)

19:11:25: 
Evaluation: Average loss: 1.0630, Accuracy: 3224/5000 (64.480%)

19:11:25: 
Evaluation: Average loss: 1.0630, Accuracy: 3224/5000 (64.480%)

19:11:25: Current learning rate: 0.1. Time taken for epoch: 27.25 seconds.

19:11:25: Current learning rate: 0.1. Time taken for epoch: 27.25 seconds.

19:11:25: Current learning rate: 0.1. Time taken for epoch: 27.25 seconds.

19:11:25: Train Epoch: 41 [0/45000 (0%)]	Loss: 0.729517
19:11:25: Train Epoch: 41 [0/45000 (0%)]	Loss: 0.729517
19:11:25: Train Epoch: 41 [0/45000 (0%)]	Loss: 0.729517
19:11:31: Train Epoch: 41 [10000/45000 (22%)]	Loss: 0.804201
19:11:31: Train Epoch: 41 [10000/45000 (22%)]	Loss: 0.804201
19:11:31: Train Epoch: 41 [10000/45000 (22%)]	Loss: 0.804201
19:11:36: Train Epoch: 41 [20000/45000 (44%)]	Loss: 0.814223
19:11:36: Train Epoch: 41 [20000/45000 (44%)]	Loss: 0.814223
19:11:36: Train Epoch: 41 [20000/45000 (44%)]	Loss: 0.814223
19:11:42: Train Epoch: 41 [30000/45000 (67%)]	Loss: 0.870869
19:11:42: Train Epoch: 41 [30000/45000 (67%)]	Loss: 0.870869
19:11:42: Train Epoch: 41 [30000/45000 (67%)]	Loss: 0.870869
19:11:47: Train Epoch: 41 [40000/45000 (89%)]	Loss: 0.798965
19:11:47: Train Epoch: 41 [40000/45000 (89%)]	Loss: 0.798965
19:11:47: Train Epoch: 41 [40000/45000 (89%)]	Loss: 0.798965
19:11:52: 
Evaluation: Average loss: 1.0703, Accuracy: 3162/5000 (63.240%)

19:11:52: 
Evaluation: Average loss: 1.0703, Accuracy: 3162/5000 (63.240%)

19:11:52: 
Evaluation: Average loss: 1.0703, Accuracy: 3162/5000 (63.240%)

19:11:52: Current learning rate: 0.1. Time taken for epoch: 26.95 seconds.

19:11:52: Current learning rate: 0.1. Time taken for epoch: 26.95 seconds.

19:11:52: Current learning rate: 0.1. Time taken for epoch: 26.95 seconds.

19:11:53: Train Epoch: 42 [0/45000 (0%)]	Loss: 0.761838
19:11:53: Train Epoch: 42 [0/45000 (0%)]	Loss: 0.761838
19:11:53: Train Epoch: 42 [0/45000 (0%)]	Loss: 0.761838
19:11:58: Train Epoch: 42 [10000/45000 (22%)]	Loss: 0.842254
19:11:58: Train Epoch: 42 [10000/45000 (22%)]	Loss: 0.842254
19:11:58: Train Epoch: 42 [10000/45000 (22%)]	Loss: 0.842254
19:12:03: Train Epoch: 42 [20000/45000 (44%)]	Loss: 0.804861
19:12:03: Train Epoch: 42 [20000/45000 (44%)]	Loss: 0.804861
19:12:03: Train Epoch: 42 [20000/45000 (44%)]	Loss: 0.804861
19:12:09: Train Epoch: 42 [30000/45000 (67%)]	Loss: 0.765744
19:12:09: Train Epoch: 42 [30000/45000 (67%)]	Loss: 0.765744
19:12:09: Train Epoch: 42 [30000/45000 (67%)]	Loss: 0.765744
19:12:14: Train Epoch: 42 [40000/45000 (89%)]	Loss: 0.947836
19:12:14: Train Epoch: 42 [40000/45000 (89%)]	Loss: 0.947836
19:12:14: Train Epoch: 42 [40000/45000 (89%)]	Loss: 0.947836
19:12:19: 
Evaluation: Average loss: 1.1206, Accuracy: 3135/5000 (62.700%)

19:12:19: 
Evaluation: Average loss: 1.1206, Accuracy: 3135/5000 (62.700%)

19:12:19: 
Evaluation: Average loss: 1.1206, Accuracy: 3135/5000 (62.700%)

19:12:19: Current learning rate: 0.1. Time taken for epoch: 27.29 seconds.

19:12:19: Current learning rate: 0.1. Time taken for epoch: 27.29 seconds.

19:12:19: Current learning rate: 0.1. Time taken for epoch: 27.29 seconds.

19:12:20: Train Epoch: 43 [0/45000 (0%)]	Loss: 0.722403
19:12:20: Train Epoch: 43 [0/45000 (0%)]	Loss: 0.722403
19:12:20: Train Epoch: 43 [0/45000 (0%)]	Loss: 0.722403
19:12:26: Train Epoch: 43 [10000/45000 (22%)]	Loss: 0.782312
19:12:26: Train Epoch: 43 [10000/45000 (22%)]	Loss: 0.782312
19:12:26: Train Epoch: 43 [10000/45000 (22%)]	Loss: 0.782312
19:12:31: Train Epoch: 43 [20000/45000 (44%)]	Loss: 0.860266
19:12:31: Train Epoch: 43 [20000/45000 (44%)]	Loss: 0.860266
19:12:31: Train Epoch: 43 [20000/45000 (44%)]	Loss: 0.860266
19:12:37: Train Epoch: 43 [30000/45000 (67%)]	Loss: 0.763400
19:12:37: Train Epoch: 43 [30000/45000 (67%)]	Loss: 0.763400
19:12:37: Train Epoch: 43 [30000/45000 (67%)]	Loss: 0.763400
19:12:42: Train Epoch: 43 [40000/45000 (89%)]	Loss: 0.831771
19:12:42: Train Epoch: 43 [40000/45000 (89%)]	Loss: 0.831771
19:12:42: Train Epoch: 43 [40000/45000 (89%)]	Loss: 0.831771
19:12:47: 
Evaluation: Average loss: 0.9561, Accuracy: 3411/5000 (68.220%)

19:12:47: 
Evaluation: Average loss: 0.9561, Accuracy: 3411/5000 (68.220%)

19:12:47: 
Evaluation: Average loss: 0.9561, Accuracy: 3411/5000 (68.220%)

19:12:47: Current learning rate: 0.1. Time taken for epoch: 28.37 seconds.

19:12:47: Current learning rate: 0.1. Time taken for epoch: 28.37 seconds.

19:12:47: Current learning rate: 0.1. Time taken for epoch: 28.37 seconds.

19:12:48: Train Epoch: 44 [0/45000 (0%)]	Loss: 0.796684
19:12:48: Train Epoch: 44 [0/45000 (0%)]	Loss: 0.796684
19:12:48: Train Epoch: 44 [0/45000 (0%)]	Loss: 0.796684
19:12:54: Train Epoch: 44 [10000/45000 (22%)]	Loss: 0.834370
19:12:54: Train Epoch: 44 [10000/45000 (22%)]	Loss: 0.834370
19:12:54: Train Epoch: 44 [10000/45000 (22%)]	Loss: 0.834370
19:13:00: Train Epoch: 44 [20000/45000 (44%)]	Loss: 0.680265
19:13:00: Train Epoch: 44 [20000/45000 (44%)]	Loss: 0.680265
19:13:00: Train Epoch: 44 [20000/45000 (44%)]	Loss: 0.680265
19:13:06: Train Epoch: 44 [30000/45000 (67%)]	Loss: 0.812426
19:13:06: Train Epoch: 44 [30000/45000 (67%)]	Loss: 0.812426
19:13:06: Train Epoch: 44 [30000/45000 (67%)]	Loss: 0.812426
19:13:12: Train Epoch: 44 [40000/45000 (89%)]	Loss: 0.894662
19:13:12: Train Epoch: 44 [40000/45000 (89%)]	Loss: 0.894662
19:13:12: Train Epoch: 44 [40000/45000 (89%)]	Loss: 0.894662
19:13:17: 
Evaluation: Average loss: 1.0208, Accuracy: 3290/5000 (65.800%)

19:13:17: 
Evaluation: Average loss: 1.0208, Accuracy: 3290/5000 (65.800%)

19:13:17: 
Evaluation: Average loss: 1.0208, Accuracy: 3290/5000 (65.800%)

19:13:17: Current learning rate: 0.1. Time taken for epoch: 29.49 seconds.

19:13:17: Current learning rate: 0.1. Time taken for epoch: 29.49 seconds.

19:13:17: Current learning rate: 0.1. Time taken for epoch: 29.49 seconds.

19:13:18: Train Epoch: 45 [0/45000 (0%)]	Loss: 0.772931
19:13:18: Train Epoch: 45 [0/45000 (0%)]	Loss: 0.772931
19:13:18: Train Epoch: 45 [0/45000 (0%)]	Loss: 0.772931
19:13:24: Train Epoch: 45 [10000/45000 (22%)]	Loss: 0.717635
19:13:24: Train Epoch: 45 [10000/45000 (22%)]	Loss: 0.717635
19:13:24: Train Epoch: 45 [10000/45000 (22%)]	Loss: 0.717635
19:13:30: Train Epoch: 45 [20000/45000 (44%)]	Loss: 0.881490
19:13:30: Train Epoch: 45 [20000/45000 (44%)]	Loss: 0.881490
19:13:30: Train Epoch: 45 [20000/45000 (44%)]	Loss: 0.881490
19:13:35: Train Epoch: 45 [30000/45000 (67%)]	Loss: 1.073661
19:13:35: Train Epoch: 45 [30000/45000 (67%)]	Loss: 1.073661
19:13:35: Train Epoch: 45 [30000/45000 (67%)]	Loss: 1.073661
19:13:41: Train Epoch: 45 [40000/45000 (89%)]	Loss: 0.798676
19:13:41: Train Epoch: 45 [40000/45000 (89%)]	Loss: 0.798676
19:13:41: Train Epoch: 45 [40000/45000 (89%)]	Loss: 0.798676
19:13:46: 
Evaluation: Average loss: 1.0708, Accuracy: 3192/5000 (63.840%)

19:13:46: 
Evaluation: Average loss: 1.0708, Accuracy: 3192/5000 (63.840%)

19:13:46: 
Evaluation: Average loss: 1.0708, Accuracy: 3192/5000 (63.840%)

19:13:46: Current learning rate: 0.1. Time taken for epoch: 29.28 seconds.

19:13:46: Current learning rate: 0.1. Time taken for epoch: 29.28 seconds.

19:13:46: Current learning rate: 0.1. Time taken for epoch: 29.28 seconds.

19:13:47: Train Epoch: 46 [0/45000 (0%)]	Loss: 0.831712
19:13:47: Train Epoch: 46 [0/45000 (0%)]	Loss: 0.831712
19:13:47: Train Epoch: 46 [0/45000 (0%)]	Loss: 0.831712
19:13:53: Train Epoch: 46 [10000/45000 (22%)]	Loss: 0.870676
19:13:53: Train Epoch: 46 [10000/45000 (22%)]	Loss: 0.870676
19:13:53: Train Epoch: 46 [10000/45000 (22%)]	Loss: 0.870676
19:13:59: Train Epoch: 46 [20000/45000 (44%)]	Loss: 0.873074
19:13:59: Train Epoch: 46 [20000/45000 (44%)]	Loss: 0.873074
19:13:59: Train Epoch: 46 [20000/45000 (44%)]	Loss: 0.873074
19:14:05: Train Epoch: 46 [30000/45000 (67%)]	Loss: 0.706044
19:14:05: Train Epoch: 46 [30000/45000 (67%)]	Loss: 0.706044
19:14:05: Train Epoch: 46 [30000/45000 (67%)]	Loss: 0.706044
19:14:11: Train Epoch: 46 [40000/45000 (89%)]	Loss: 0.759745
19:14:11: Train Epoch: 46 [40000/45000 (89%)]	Loss: 0.759745
19:14:11: Train Epoch: 46 [40000/45000 (89%)]	Loss: 0.759745
19:14:16: 
Evaluation: Average loss: 1.2555, Accuracy: 2967/5000 (59.340%)

19:14:16: 
Evaluation: Average loss: 1.2555, Accuracy: 2967/5000 (59.340%)

19:14:16: 
Evaluation: Average loss: 1.2555, Accuracy: 2967/5000 (59.340%)

19:14:16: Current learning rate: 0.1. Time taken for epoch: 29.52 seconds.

19:14:16: Current learning rate: 0.1. Time taken for epoch: 29.52 seconds.

19:14:16: Current learning rate: 0.1. Time taken for epoch: 29.52 seconds.

19:14:16: Train Epoch: 47 [0/45000 (0%)]	Loss: 0.827818
19:14:16: Train Epoch: 47 [0/45000 (0%)]	Loss: 0.827818
19:14:16: Train Epoch: 47 [0/45000 (0%)]	Loss: 0.827818
19:14:23: Train Epoch: 47 [10000/45000 (22%)]	Loss: 1.092931
19:14:23: Train Epoch: 47 [10000/45000 (22%)]	Loss: 1.092931
19:14:23: Train Epoch: 47 [10000/45000 (22%)]	Loss: 1.092931
19:14:29: Train Epoch: 47 [20000/45000 (44%)]	Loss: 0.951133
19:14:29: Train Epoch: 47 [20000/45000 (44%)]	Loss: 0.951133
19:14:29: Train Epoch: 47 [20000/45000 (44%)]	Loss: 0.951133
19:14:34: Train Epoch: 47 [30000/45000 (67%)]	Loss: 0.862689
19:14:34: Train Epoch: 47 [30000/45000 (67%)]	Loss: 0.862689
19:14:34: Train Epoch: 47 [30000/45000 (67%)]	Loss: 0.862689
19:14:40: Train Epoch: 47 [40000/45000 (89%)]	Loss: 0.699109
19:14:40: Train Epoch: 47 [40000/45000 (89%)]	Loss: 0.699109
19:14:40: Train Epoch: 47 [40000/45000 (89%)]	Loss: 0.699109
19:14:44: 
Evaluation: Average loss: 1.0058, Accuracy: 3319/5000 (66.380%)

19:14:44: 
Evaluation: Average loss: 1.0058, Accuracy: 3319/5000 (66.380%)

19:14:44: 
Evaluation: Average loss: 1.0058, Accuracy: 3319/5000 (66.380%)

19:14:45: Current learning rate: 0.1. Time taken for epoch: 28.90 seconds.

19:14:45: Current learning rate: 0.1. Time taken for epoch: 28.90 seconds.

19:14:45: Current learning rate: 0.1. Time taken for epoch: 28.90 seconds.

19:14:45: Train Epoch: 48 [0/45000 (0%)]	Loss: 0.702721
19:14:45: Train Epoch: 48 [0/45000 (0%)]	Loss: 0.702721
19:14:45: Train Epoch: 48 [0/45000 (0%)]	Loss: 0.702721
19:14:51: Train Epoch: 48 [10000/45000 (22%)]	Loss: 0.678853
19:14:51: Train Epoch: 48 [10000/45000 (22%)]	Loss: 0.678853
19:14:51: Train Epoch: 48 [10000/45000 (22%)]	Loss: 0.678853
19:14:57: Train Epoch: 48 [20000/45000 (44%)]	Loss: 0.904146
19:14:57: Train Epoch: 48 [20000/45000 (44%)]	Loss: 0.904146
19:14:57: Train Epoch: 48 [20000/45000 (44%)]	Loss: 0.904146
19:15:03: Train Epoch: 48 [30000/45000 (67%)]	Loss: 0.956339
19:15:03: Train Epoch: 48 [30000/45000 (67%)]	Loss: 0.956339
19:15:03: Train Epoch: 48 [30000/45000 (67%)]	Loss: 0.956339
19:15:09: Train Epoch: 48 [40000/45000 (89%)]	Loss: 0.842904
19:15:09: Train Epoch: 48 [40000/45000 (89%)]	Loss: 0.842904
19:15:09: Train Epoch: 48 [40000/45000 (89%)]	Loss: 0.842904
19:15:14: 
Evaluation: Average loss: 1.0603, Accuracy: 3183/5000 (63.660%)

19:15:14: 
Evaluation: Average loss: 1.0603, Accuracy: 3183/5000 (63.660%)

19:15:14: 
Evaluation: Average loss: 1.0603, Accuracy: 3183/5000 (63.660%)

19:15:14: Current learning rate: 0.1. Time taken for epoch: 29.05 seconds.

19:15:14: Current learning rate: 0.1. Time taken for epoch: 29.05 seconds.

19:15:14: Current learning rate: 0.1. Time taken for epoch: 29.05 seconds.

19:15:14: Train Epoch: 49 [0/45000 (0%)]	Loss: 0.968836
19:15:14: Train Epoch: 49 [0/45000 (0%)]	Loss: 0.968836
19:15:14: Train Epoch: 49 [0/45000 (0%)]	Loss: 0.968836
19:15:20: Train Epoch: 49 [10000/45000 (22%)]	Loss: 0.849136
19:15:20: Train Epoch: 49 [10000/45000 (22%)]	Loss: 0.849136
19:15:20: Train Epoch: 49 [10000/45000 (22%)]	Loss: 0.849136
19:15:26: Train Epoch: 49 [20000/45000 (44%)]	Loss: 0.810968
19:15:26: Train Epoch: 49 [20000/45000 (44%)]	Loss: 0.810968
19:15:26: Train Epoch: 49 [20000/45000 (44%)]	Loss: 0.810968
19:15:32: Train Epoch: 49 [30000/45000 (67%)]	Loss: 0.692862
19:15:32: Train Epoch: 49 [30000/45000 (67%)]	Loss: 0.692862
19:15:32: Train Epoch: 49 [30000/45000 (67%)]	Loss: 0.692862
19:15:38: Train Epoch: 49 [40000/45000 (89%)]	Loss: 0.884590
19:15:38: Train Epoch: 49 [40000/45000 (89%)]	Loss: 0.884590
19:15:38: Train Epoch: 49 [40000/45000 (89%)]	Loss: 0.884590
19:15:42: 
Evaluation: Average loss: 0.9095, Accuracy: 3487/5000 (69.740%)

19:15:42: 
Evaluation: Average loss: 0.9095, Accuracy: 3487/5000 (69.740%)

19:15:42: 
Evaluation: Average loss: 0.9095, Accuracy: 3487/5000 (69.740%)

19:15:42: Current learning rate: 0.1. Time taken for epoch: 28.80 seconds.

19:15:42: Current learning rate: 0.1. Time taken for epoch: 28.80 seconds.

19:15:42: Current learning rate: 0.1. Time taken for epoch: 28.80 seconds.

19:15:43: Train Epoch: 50 [0/45000 (0%)]	Loss: 1.013162
19:15:43: Train Epoch: 50 [0/45000 (0%)]	Loss: 1.013162
19:15:43: Train Epoch: 50 [0/45000 (0%)]	Loss: 1.013162
19:15:49: Train Epoch: 50 [10000/45000 (22%)]	Loss: 0.799088
19:15:49: Train Epoch: 50 [10000/45000 (22%)]	Loss: 0.799088
19:15:49: Train Epoch: 50 [10000/45000 (22%)]	Loss: 0.799088
19:15:55: Train Epoch: 50 [20000/45000 (44%)]	Loss: 0.718768
19:15:55: Train Epoch: 50 [20000/45000 (44%)]	Loss: 0.718768
19:15:55: Train Epoch: 50 [20000/45000 (44%)]	Loss: 0.718768
19:16:01: Train Epoch: 50 [30000/45000 (67%)]	Loss: 0.724173
19:16:01: Train Epoch: 50 [30000/45000 (67%)]	Loss: 0.724173
19:16:01: Train Epoch: 50 [30000/45000 (67%)]	Loss: 0.724173
19:16:07: Train Epoch: 50 [40000/45000 (89%)]	Loss: 1.014933
19:16:07: Train Epoch: 50 [40000/45000 (89%)]	Loss: 1.014933
19:16:07: Train Epoch: 50 [40000/45000 (89%)]	Loss: 1.014933
19:16:12: 
Evaluation: Average loss: 0.9671, Accuracy: 3325/5000 (66.500%)

19:16:12: 
Evaluation: Average loss: 0.9671, Accuracy: 3325/5000 (66.500%)

19:16:12: 
Evaluation: Average loss: 0.9671, Accuracy: 3325/5000 (66.500%)

19:16:12: Current learning rate: 0.1. Time taken for epoch: 29.75 seconds.

19:16:12: Current learning rate: 0.1. Time taken for epoch: 29.75 seconds.

19:16:12: Current learning rate: 0.1. Time taken for epoch: 29.75 seconds.

19:16:13: Train Epoch: 51 [0/45000 (0%)]	Loss: 0.809999
19:16:13: Train Epoch: 51 [0/45000 (0%)]	Loss: 0.809999
19:16:13: Train Epoch: 51 [0/45000 (0%)]	Loss: 0.809999
19:16:19: Train Epoch: 51 [10000/45000 (22%)]	Loss: 0.915864
19:16:19: Train Epoch: 51 [10000/45000 (22%)]	Loss: 0.915864
19:16:19: Train Epoch: 51 [10000/45000 (22%)]	Loss: 0.915864
19:16:25: Train Epoch: 51 [20000/45000 (44%)]	Loss: 0.975752
19:16:25: Train Epoch: 51 [20000/45000 (44%)]	Loss: 0.975752
19:16:25: Train Epoch: 51 [20000/45000 (44%)]	Loss: 0.975752
19:16:31: Train Epoch: 51 [30000/45000 (67%)]	Loss: 0.982616
19:16:31: Train Epoch: 51 [30000/45000 (67%)]	Loss: 0.982616
19:16:31: Train Epoch: 51 [30000/45000 (67%)]	Loss: 0.982616
19:16:37: Train Epoch: 51 [40000/45000 (89%)]	Loss: 0.790018
19:16:37: Train Epoch: 51 [40000/45000 (89%)]	Loss: 0.790018
19:16:37: Train Epoch: 51 [40000/45000 (89%)]	Loss: 0.790018
19:16:41: 
Evaluation: Average loss: 0.9363, Accuracy: 3412/5000 (68.240%)

19:16:41: 
Evaluation: Average loss: 0.9363, Accuracy: 3412/5000 (68.240%)

19:16:41: 
Evaluation: Average loss: 0.9363, Accuracy: 3412/5000 (68.240%)

19:16:41: Current learning rate: 0.1. Time taken for epoch: 29.28 seconds.

19:16:41: Current learning rate: 0.1. Time taken for epoch: 29.28 seconds.

19:16:41: Current learning rate: 0.1. Time taken for epoch: 29.28 seconds.

19:16:42: Train Epoch: 52 [0/45000 (0%)]	Loss: 0.979719
19:16:42: Train Epoch: 52 [0/45000 (0%)]	Loss: 0.979719
19:16:42: Train Epoch: 52 [0/45000 (0%)]	Loss: 0.979719
19:16:49: Train Epoch: 52 [10000/45000 (22%)]	Loss: 0.630918
19:16:49: Train Epoch: 52 [10000/45000 (22%)]	Loss: 0.630918
19:16:49: Train Epoch: 52 [10000/45000 (22%)]	Loss: 0.630918
19:16:54: Train Epoch: 52 [20000/45000 (44%)]	Loss: 0.803056
19:16:54: Train Epoch: 52 [20000/45000 (44%)]	Loss: 0.803056
19:16:54: Train Epoch: 52 [20000/45000 (44%)]	Loss: 0.803056
19:17:00: Train Epoch: 52 [30000/45000 (67%)]	Loss: 1.067648
19:17:00: Train Epoch: 52 [30000/45000 (67%)]	Loss: 1.067648
19:17:00: Train Epoch: 52 [30000/45000 (67%)]	Loss: 1.067648
19:17:05: Train Epoch: 52 [40000/45000 (89%)]	Loss: 0.974786
19:17:05: Train Epoch: 52 [40000/45000 (89%)]	Loss: 0.974786
19:17:05: Train Epoch: 52 [40000/45000 (89%)]	Loss: 0.974786
19:17:10: 
Evaluation: Average loss: 1.1103, Accuracy: 3075/5000 (61.500%)

19:17:10: 
Evaluation: Average loss: 1.1103, Accuracy: 3075/5000 (61.500%)

19:17:10: 
Evaluation: Average loss: 1.1103, Accuracy: 3075/5000 (61.500%)

19:17:10: Current learning rate: 0.1. Time taken for epoch: 28.38 seconds.

19:17:10: Current learning rate: 0.1. Time taken for epoch: 28.38 seconds.

19:17:10: Current learning rate: 0.1. Time taken for epoch: 28.38 seconds.

19:17:10: Train Epoch: 53 [0/45000 (0%)]	Loss: 1.056797
19:17:10: Train Epoch: 53 [0/45000 (0%)]	Loss: 1.056797
19:17:10: Train Epoch: 53 [0/45000 (0%)]	Loss: 1.056797
19:17:16: Train Epoch: 53 [10000/45000 (22%)]	Loss: 0.923104
19:17:16: Train Epoch: 53 [10000/45000 (22%)]	Loss: 0.923104
19:17:16: Train Epoch: 53 [10000/45000 (22%)]	Loss: 0.923104
19:17:22: Train Epoch: 53 [20000/45000 (44%)]	Loss: 1.043985
19:17:22: Train Epoch: 53 [20000/45000 (44%)]	Loss: 1.043985
19:17:22: Train Epoch: 53 [20000/45000 (44%)]	Loss: 1.043985
19:17:28: Train Epoch: 53 [30000/45000 (67%)]	Loss: 1.213677
19:17:28: Train Epoch: 53 [30000/45000 (67%)]	Loss: 1.213677
19:17:28: Train Epoch: 53 [30000/45000 (67%)]	Loss: 1.213677
19:17:33: Train Epoch: 53 [40000/45000 (89%)]	Loss: 0.704834
19:17:33: Train Epoch: 53 [40000/45000 (89%)]	Loss: 0.704834
19:17:33: Train Epoch: 53 [40000/45000 (89%)]	Loss: 0.704834
19:17:37: 
Evaluation: Average loss: 1.1160, Accuracy: 3113/5000 (62.260%)

19:17:37: 
Evaluation: Average loss: 1.1160, Accuracy: 3113/5000 (62.260%)

19:17:37: 
Evaluation: Average loss: 1.1160, Accuracy: 3113/5000 (62.260%)

19:17:37: Current learning rate: 0.1. Time taken for epoch: 27.49 seconds.

19:17:37: Current learning rate: 0.1. Time taken for epoch: 27.49 seconds.

19:17:37: Current learning rate: 0.1. Time taken for epoch: 27.49 seconds.

19:17:38: Train Epoch: 54 [0/45000 (0%)]	Loss: 0.795203
19:17:38: Train Epoch: 54 [0/45000 (0%)]	Loss: 0.795203
19:17:38: Train Epoch: 54 [0/45000 (0%)]	Loss: 0.795203
19:17:44: Train Epoch: 54 [10000/45000 (22%)]	Loss: 0.776334
19:17:44: Train Epoch: 54 [10000/45000 (22%)]	Loss: 0.776334
19:17:44: Train Epoch: 54 [10000/45000 (22%)]	Loss: 0.776334
19:17:49: Train Epoch: 54 [20000/45000 (44%)]	Loss: 0.834865
19:17:49: Train Epoch: 54 [20000/45000 (44%)]	Loss: 0.834865
19:17:49: Train Epoch: 54 [20000/45000 (44%)]	Loss: 0.834865
19:17:55: Train Epoch: 54 [30000/45000 (67%)]	Loss: 0.682831
19:17:55: Train Epoch: 54 [30000/45000 (67%)]	Loss: 0.682831
19:17:55: Train Epoch: 54 [30000/45000 (67%)]	Loss: 0.682831
19:18:00: Train Epoch: 54 [40000/45000 (89%)]	Loss: 0.792435
19:18:00: Train Epoch: 54 [40000/45000 (89%)]	Loss: 0.792435
19:18:00: Train Epoch: 54 [40000/45000 (89%)]	Loss: 0.792435
19:18:05: 
Evaluation: Average loss: 1.1598, Accuracy: 3148/5000 (62.960%)

19:18:05: 
Evaluation: Average loss: 1.1598, Accuracy: 3148/5000 (62.960%)

19:18:05: 
Evaluation: Average loss: 1.1598, Accuracy: 3148/5000 (62.960%)

19:18:05: Current learning rate: 0.1. Time taken for epoch: 27.58 seconds.

19:18:05: Current learning rate: 0.1. Time taken for epoch: 27.58 seconds.

19:18:05: Current learning rate: 0.1. Time taken for epoch: 27.58 seconds.

19:18:06: Train Epoch: 55 [0/45000 (0%)]	Loss: 0.900107
19:18:06: Train Epoch: 55 [0/45000 (0%)]	Loss: 0.900107
19:18:06: Train Epoch: 55 [0/45000 (0%)]	Loss: 0.900107
19:18:12: Train Epoch: 55 [10000/45000 (22%)]	Loss: 0.823159
19:18:12: Train Epoch: 55 [10000/45000 (22%)]	Loss: 0.823159
19:18:12: Train Epoch: 55 [10000/45000 (22%)]	Loss: 0.823159
19:18:17: Train Epoch: 55 [20000/45000 (44%)]	Loss: 0.772552
19:18:17: Train Epoch: 55 [20000/45000 (44%)]	Loss: 0.772552
19:18:17: Train Epoch: 55 [20000/45000 (44%)]	Loss: 0.772552
19:18:23: Train Epoch: 55 [30000/45000 (67%)]	Loss: 1.022007
19:18:23: Train Epoch: 55 [30000/45000 (67%)]	Loss: 1.022007
19:18:23: Train Epoch: 55 [30000/45000 (67%)]	Loss: 1.022007
19:18:29: Train Epoch: 55 [40000/45000 (89%)]	Loss: 0.820592
19:18:29: Train Epoch: 55 [40000/45000 (89%)]	Loss: 0.820592
19:18:29: Train Epoch: 55 [40000/45000 (89%)]	Loss: 0.820592
19:18:34: 
Evaluation: Average loss: 1.0842, Accuracy: 3215/5000 (64.300%)

19:18:34: 
Evaluation: Average loss: 1.0842, Accuracy: 3215/5000 (64.300%)

19:18:34: 
Evaluation: Average loss: 1.0842, Accuracy: 3215/5000 (64.300%)

19:18:34: Current learning rate: 0.1. Time taken for epoch: 28.82 seconds.

19:18:34: Current learning rate: 0.1. Time taken for epoch: 28.82 seconds.

19:18:34: Current learning rate: 0.1. Time taken for epoch: 28.82 seconds.

19:18:34: Train Epoch: 56 [0/45000 (0%)]	Loss: 0.947375
19:18:34: Train Epoch: 56 [0/45000 (0%)]	Loss: 0.947375
19:18:34: Train Epoch: 56 [0/45000 (0%)]	Loss: 0.947375
19:18:40: Train Epoch: 56 [10000/45000 (22%)]	Loss: 1.065654
19:18:40: Train Epoch: 56 [10000/45000 (22%)]	Loss: 1.065654
19:18:40: Train Epoch: 56 [10000/45000 (22%)]	Loss: 1.065654
19:18:46: Train Epoch: 56 [20000/45000 (44%)]	Loss: 0.785336
19:18:46: Train Epoch: 56 [20000/45000 (44%)]	Loss: 0.785336
19:18:46: Train Epoch: 56 [20000/45000 (44%)]	Loss: 0.785336
19:18:52: Train Epoch: 56 [30000/45000 (67%)]	Loss: 0.735297
19:18:52: Train Epoch: 56 [30000/45000 (67%)]	Loss: 0.735297
19:18:52: Train Epoch: 56 [30000/45000 (67%)]	Loss: 0.735297
19:18:57: Train Epoch: 56 [40000/45000 (89%)]	Loss: 0.692828
19:18:57: Train Epoch: 56 [40000/45000 (89%)]	Loss: 0.692828
19:18:57: Train Epoch: 56 [40000/45000 (89%)]	Loss: 0.692828
19:19:02: 
Evaluation: Average loss: 0.6437, Accuracy: 3910/5000 (78.200%)

19:19:02: 
Evaluation: Average loss: 0.6437, Accuracy: 3910/5000 (78.200%)

19:19:02: 
Evaluation: Average loss: 0.6437, Accuracy: 3910/5000 (78.200%)

19:19:02: Current learning rate: 0.010000000000000002. Time taken for epoch: 28.21 seconds.

19:19:02: Current learning rate: 0.010000000000000002. Time taken for epoch: 28.21 seconds.

19:19:02: Current learning rate: 0.010000000000000002. Time taken for epoch: 28.21 seconds.

19:19:03: Train Epoch: 57 [0/45000 (0%)]	Loss: 0.583791
19:19:03: Train Epoch: 57 [0/45000 (0%)]	Loss: 0.583791
19:19:03: Train Epoch: 57 [0/45000 (0%)]	Loss: 0.583791
19:19:08: Train Epoch: 57 [10000/45000 (22%)]	Loss: 0.610727
19:19:08: Train Epoch: 57 [10000/45000 (22%)]	Loss: 0.610727
19:19:08: Train Epoch: 57 [10000/45000 (22%)]	Loss: 0.610727
19:19:14: Train Epoch: 57 [20000/45000 (44%)]	Loss: 0.820201
19:19:14: Train Epoch: 57 [20000/45000 (44%)]	Loss: 0.820201
19:19:14: Train Epoch: 57 [20000/45000 (44%)]	Loss: 0.820201
19:19:19: Train Epoch: 57 [30000/45000 (67%)]	Loss: 0.676615
19:19:19: Train Epoch: 57 [30000/45000 (67%)]	Loss: 0.676615
19:19:19: Train Epoch: 57 [30000/45000 (67%)]	Loss: 0.676615
19:19:25: Train Epoch: 57 [40000/45000 (89%)]	Loss: 0.602517
19:19:25: Train Epoch: 57 [40000/45000 (89%)]	Loss: 0.602517
19:19:25: Train Epoch: 57 [40000/45000 (89%)]	Loss: 0.602517
19:19:29: 
Evaluation: Average loss: 0.6045, Accuracy: 3969/5000 (79.380%)

19:19:29: 
Evaluation: Average loss: 0.6045, Accuracy: 3969/5000 (79.380%)

19:19:29: 
Evaluation: Average loss: 0.6045, Accuracy: 3969/5000 (79.380%)

19:19:29: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.59 seconds.

19:19:29: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.59 seconds.

19:19:29: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.59 seconds.

19:19:30: Train Epoch: 58 [0/45000 (0%)]	Loss: 0.492001
19:19:30: Train Epoch: 58 [0/45000 (0%)]	Loss: 0.492001
19:19:30: Train Epoch: 58 [0/45000 (0%)]	Loss: 0.492001
19:19:36: Train Epoch: 58 [10000/45000 (22%)]	Loss: 0.495505
19:19:36: Train Epoch: 58 [10000/45000 (22%)]	Loss: 0.495505
19:19:36: Train Epoch: 58 [10000/45000 (22%)]	Loss: 0.495505
19:19:42: Train Epoch: 58 [20000/45000 (44%)]	Loss: 0.896689
19:19:42: Train Epoch: 58 [20000/45000 (44%)]	Loss: 0.896689
19:19:42: Train Epoch: 58 [20000/45000 (44%)]	Loss: 0.896689
19:19:47: Train Epoch: 58 [30000/45000 (67%)]	Loss: 0.674426
19:19:47: Train Epoch: 58 [30000/45000 (67%)]	Loss: 0.674426
19:19:47: Train Epoch: 58 [30000/45000 (67%)]	Loss: 0.674426
19:19:53: Train Epoch: 58 [40000/45000 (89%)]	Loss: 0.851511
19:19:53: Train Epoch: 58 [40000/45000 (89%)]	Loss: 0.851511
19:19:53: Train Epoch: 58 [40000/45000 (89%)]	Loss: 0.851511
19:19:58: 
Evaluation: Average loss: 0.5928, Accuracy: 3957/5000 (79.140%)

19:19:58: 
Evaluation: Average loss: 0.5928, Accuracy: 3957/5000 (79.140%)

19:19:58: 
Evaluation: Average loss: 0.5928, Accuracy: 3957/5000 (79.140%)

19:19:58: Current learning rate: 0.010000000000000002. Time taken for epoch: 28.17 seconds.

19:19:58: Current learning rate: 0.010000000000000002. Time taken for epoch: 28.17 seconds.

19:19:58: Current learning rate: 0.010000000000000002. Time taken for epoch: 28.17 seconds.

19:19:59: Train Epoch: 59 [0/45000 (0%)]	Loss: 0.581436
19:19:59: Train Epoch: 59 [0/45000 (0%)]	Loss: 0.581436
19:19:59: Train Epoch: 59 [0/45000 (0%)]	Loss: 0.581436
19:20:04: Train Epoch: 59 [10000/45000 (22%)]	Loss: 0.599435
19:20:04: Train Epoch: 59 [10000/45000 (22%)]	Loss: 0.599435
19:20:04: Train Epoch: 59 [10000/45000 (22%)]	Loss: 0.599435
19:20:10: Train Epoch: 59 [20000/45000 (44%)]	Loss: 0.584830
19:20:10: Train Epoch: 59 [20000/45000 (44%)]	Loss: 0.584830
19:20:10: Train Epoch: 59 [20000/45000 (44%)]	Loss: 0.584830
19:20:15: Train Epoch: 59 [30000/45000 (67%)]	Loss: 0.397078
19:20:15: Train Epoch: 59 [30000/45000 (67%)]	Loss: 0.397078
19:20:15: Train Epoch: 59 [30000/45000 (67%)]	Loss: 0.397078
19:20:21: Train Epoch: 59 [40000/45000 (89%)]	Loss: 0.483286
19:20:21: Train Epoch: 59 [40000/45000 (89%)]	Loss: 0.483286
19:20:21: Train Epoch: 59 [40000/45000 (89%)]	Loss: 0.483286
19:20:26: 
Evaluation: Average loss: 0.5706, Accuracy: 4048/5000 (80.960%)

19:20:26: 
Evaluation: Average loss: 0.5706, Accuracy: 4048/5000 (80.960%)

19:20:26: 
Evaluation: Average loss: 0.5706, Accuracy: 4048/5000 (80.960%)

19:20:26: Current learning rate: 0.010000000000000002. Time taken for epoch: 28.21 seconds.

19:20:26: Current learning rate: 0.010000000000000002. Time taken for epoch: 28.21 seconds.

19:20:26: Current learning rate: 0.010000000000000002. Time taken for epoch: 28.21 seconds.

19:20:26: Train Epoch: 60 [0/45000 (0%)]	Loss: 0.640749
19:20:26: Train Epoch: 60 [0/45000 (0%)]	Loss: 0.640749
19:20:26: Train Epoch: 60 [0/45000 (0%)]	Loss: 0.640749
19:20:32: Train Epoch: 60 [10000/45000 (22%)]	Loss: 0.433853
19:20:32: Train Epoch: 60 [10000/45000 (22%)]	Loss: 0.433853
19:20:32: Train Epoch: 60 [10000/45000 (22%)]	Loss: 0.433853
19:20:38: Train Epoch: 60 [20000/45000 (44%)]	Loss: 0.619624
19:20:38: Train Epoch: 60 [20000/45000 (44%)]	Loss: 0.619624
19:20:38: Train Epoch: 60 [20000/45000 (44%)]	Loss: 0.619624
19:20:43: Train Epoch: 60 [30000/45000 (67%)]	Loss: 0.614465
19:20:43: Train Epoch: 60 [30000/45000 (67%)]	Loss: 0.614465
19:20:43: Train Epoch: 60 [30000/45000 (67%)]	Loss: 0.614465
19:20:49: Train Epoch: 60 [40000/45000 (89%)]	Loss: 0.805747
19:20:49: Train Epoch: 60 [40000/45000 (89%)]	Loss: 0.805747
19:20:49: Train Epoch: 60 [40000/45000 (89%)]	Loss: 0.805747
19:20:54: 
Evaluation: Average loss: 0.5692, Accuracy: 4019/5000 (80.380%)

19:20:54: 
Evaluation: Average loss: 0.5692, Accuracy: 4019/5000 (80.380%)

19:20:54: 
Evaluation: Average loss: 0.5692, Accuracy: 4019/5000 (80.380%)

19:20:54: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.86 seconds.

19:20:54: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.86 seconds.

19:20:54: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.86 seconds.

19:20:55: Train Epoch: 61 [0/45000 (0%)]	Loss: 0.486132
19:20:55: Train Epoch: 61 [0/45000 (0%)]	Loss: 0.486132
19:20:55: Train Epoch: 61 [0/45000 (0%)]	Loss: 0.486132
19:21:00: Train Epoch: 61 [10000/45000 (22%)]	Loss: 0.629847
19:21:00: Train Epoch: 61 [10000/45000 (22%)]	Loss: 0.629847
19:21:00: Train Epoch: 61 [10000/45000 (22%)]	Loss: 0.629847
19:21:06: Train Epoch: 61 [20000/45000 (44%)]	Loss: 0.510730
19:21:06: Train Epoch: 61 [20000/45000 (44%)]	Loss: 0.510730
19:21:06: Train Epoch: 61 [20000/45000 (44%)]	Loss: 0.510730
19:21:12: Train Epoch: 61 [30000/45000 (67%)]	Loss: 0.728454
19:21:12: Train Epoch: 61 [30000/45000 (67%)]	Loss: 0.728454
19:21:12: Train Epoch: 61 [30000/45000 (67%)]	Loss: 0.728454
19:21:17: Train Epoch: 61 [40000/45000 (89%)]	Loss: 0.620467
19:21:17: Train Epoch: 61 [40000/45000 (89%)]	Loss: 0.620467
19:21:17: Train Epoch: 61 [40000/45000 (89%)]	Loss: 0.620467
19:21:22: 
Evaluation: Average loss: 0.5809, Accuracy: 4009/5000 (80.180%)

19:21:22: 
Evaluation: Average loss: 0.5809, Accuracy: 4009/5000 (80.180%)

19:21:22: 
Evaluation: Average loss: 0.5809, Accuracy: 4009/5000 (80.180%)

19:21:22: Current learning rate: 0.010000000000000002. Time taken for epoch: 28.31 seconds.

19:21:22: Current learning rate: 0.010000000000000002. Time taken for epoch: 28.31 seconds.

19:21:22: Current learning rate: 0.010000000000000002. Time taken for epoch: 28.31 seconds.

19:21:23: Train Epoch: 62 [0/45000 (0%)]	Loss: 0.451859
19:21:23: Train Epoch: 62 [0/45000 (0%)]	Loss: 0.451859
19:21:23: Train Epoch: 62 [0/45000 (0%)]	Loss: 0.451859
19:21:29: Train Epoch: 62 [10000/45000 (22%)]	Loss: 0.392848
19:21:29: Train Epoch: 62 [10000/45000 (22%)]	Loss: 0.392848
19:21:29: Train Epoch: 62 [10000/45000 (22%)]	Loss: 0.392848
19:21:34: Train Epoch: 62 [20000/45000 (44%)]	Loss: 0.755310
19:21:34: Train Epoch: 62 [20000/45000 (44%)]	Loss: 0.755310
19:21:34: Train Epoch: 62 [20000/45000 (44%)]	Loss: 0.755310
19:21:40: Train Epoch: 62 [30000/45000 (67%)]	Loss: 0.565164
19:21:40: Train Epoch: 62 [30000/45000 (67%)]	Loss: 0.565164
19:21:40: Train Epoch: 62 [30000/45000 (67%)]	Loss: 0.565164
19:21:46: Train Epoch: 62 [40000/45000 (89%)]	Loss: 0.787594
19:21:46: Train Epoch: 62 [40000/45000 (89%)]	Loss: 0.787594
19:21:46: Train Epoch: 62 [40000/45000 (89%)]	Loss: 0.787594
19:21:50: 
Evaluation: Average loss: 0.5669, Accuracy: 4011/5000 (80.220%)

19:21:50: 
Evaluation: Average loss: 0.5669, Accuracy: 4011/5000 (80.220%)

19:21:50: 
Evaluation: Average loss: 0.5669, Accuracy: 4011/5000 (80.220%)

19:21:50: Current learning rate: 0.010000000000000002. Time taken for epoch: 28.42 seconds.

19:21:50: Current learning rate: 0.010000000000000002. Time taken for epoch: 28.42 seconds.

19:21:50: Current learning rate: 0.010000000000000002. Time taken for epoch: 28.42 seconds.

19:21:51: Train Epoch: 63 [0/45000 (0%)]	Loss: 0.529918
19:21:51: Train Epoch: 63 [0/45000 (0%)]	Loss: 0.529918
19:21:51: Train Epoch: 63 [0/45000 (0%)]	Loss: 0.529918
19:21:57: Train Epoch: 63 [10000/45000 (22%)]	Loss: 0.652862
19:21:57: Train Epoch: 63 [10000/45000 (22%)]	Loss: 0.652862
19:21:57: Train Epoch: 63 [10000/45000 (22%)]	Loss: 0.652862
19:22:02: Train Epoch: 63 [20000/45000 (44%)]	Loss: 0.339425
19:22:02: Train Epoch: 63 [20000/45000 (44%)]	Loss: 0.339425
19:22:02: Train Epoch: 63 [20000/45000 (44%)]	Loss: 0.339425
19:22:08: Train Epoch: 63 [30000/45000 (67%)]	Loss: 0.498719
19:22:08: Train Epoch: 63 [30000/45000 (67%)]	Loss: 0.498719
19:22:08: Train Epoch: 63 [30000/45000 (67%)]	Loss: 0.498719
19:22:14: Train Epoch: 63 [40000/45000 (89%)]	Loss: 0.614959
19:22:14: Train Epoch: 63 [40000/45000 (89%)]	Loss: 0.614959
19:22:14: Train Epoch: 63 [40000/45000 (89%)]	Loss: 0.614959
19:22:19: 
Evaluation: Average loss: 0.5519, Accuracy: 4052/5000 (81.040%)

19:22:19: 
Evaluation: Average loss: 0.5519, Accuracy: 4052/5000 (81.040%)

19:22:19: 
Evaluation: Average loss: 0.5519, Accuracy: 4052/5000 (81.040%)

19:22:19: Current learning rate: 0.010000000000000002. Time taken for epoch: 28.40 seconds.

19:22:19: Current learning rate: 0.010000000000000002. Time taken for epoch: 28.40 seconds.

19:22:19: Current learning rate: 0.010000000000000002. Time taken for epoch: 28.40 seconds.

19:22:19: Train Epoch: 64 [0/45000 (0%)]	Loss: 0.577086
19:22:19: Train Epoch: 64 [0/45000 (0%)]	Loss: 0.577086
19:22:19: Train Epoch: 64 [0/45000 (0%)]	Loss: 0.577086
19:22:26: Train Epoch: 64 [10000/45000 (22%)]	Loss: 0.727477
19:22:26: Train Epoch: 64 [10000/45000 (22%)]	Loss: 0.727477
19:22:26: Train Epoch: 64 [10000/45000 (22%)]	Loss: 0.727477
19:22:31: Train Epoch: 64 [20000/45000 (44%)]	Loss: 0.549417
19:22:31: Train Epoch: 64 [20000/45000 (44%)]	Loss: 0.549417
19:22:31: Train Epoch: 64 [20000/45000 (44%)]	Loss: 0.549417
19:22:37: Train Epoch: 64 [30000/45000 (67%)]	Loss: 0.643668
19:22:37: Train Epoch: 64 [30000/45000 (67%)]	Loss: 0.643668
19:22:37: Train Epoch: 64 [30000/45000 (67%)]	Loss: 0.643668
19:22:42: Train Epoch: 64 [40000/45000 (89%)]	Loss: 0.642414
19:22:42: Train Epoch: 64 [40000/45000 (89%)]	Loss: 0.642414
19:22:42: Train Epoch: 64 [40000/45000 (89%)]	Loss: 0.642414
19:22:47: 
Evaluation: Average loss: 0.5556, Accuracy: 4039/5000 (80.780%)

19:22:47: 
Evaluation: Average loss: 0.5556, Accuracy: 4039/5000 (80.780%)

19:22:47: 
Evaluation: Average loss: 0.5556, Accuracy: 4039/5000 (80.780%)

19:22:47: Current learning rate: 0.010000000000000002. Time taken for epoch: 28.03 seconds.

19:22:47: Current learning rate: 0.010000000000000002. Time taken for epoch: 28.03 seconds.

19:22:47: Current learning rate: 0.010000000000000002. Time taken for epoch: 28.03 seconds.

19:22:48: Train Epoch: 65 [0/45000 (0%)]	Loss: 0.537754
19:22:48: Train Epoch: 65 [0/45000 (0%)]	Loss: 0.537754
19:22:48: Train Epoch: 65 [0/45000 (0%)]	Loss: 0.537754
19:22:54: Train Epoch: 65 [10000/45000 (22%)]	Loss: 0.521063
19:22:54: Train Epoch: 65 [10000/45000 (22%)]	Loss: 0.521063
19:22:54: Train Epoch: 65 [10000/45000 (22%)]	Loss: 0.521063
19:22:59: Train Epoch: 65 [20000/45000 (44%)]	Loss: 0.461598
19:22:59: Train Epoch: 65 [20000/45000 (44%)]	Loss: 0.461598
19:22:59: Train Epoch: 65 [20000/45000 (44%)]	Loss: 0.461598
19:23:05: Train Epoch: 65 [30000/45000 (67%)]	Loss: 0.606288
19:23:05: Train Epoch: 65 [30000/45000 (67%)]	Loss: 0.606288
19:23:05: Train Epoch: 65 [30000/45000 (67%)]	Loss: 0.606288
19:23:11: Train Epoch: 65 [40000/45000 (89%)]	Loss: 0.512658
19:23:11: Train Epoch: 65 [40000/45000 (89%)]	Loss: 0.512658
19:23:11: Train Epoch: 65 [40000/45000 (89%)]	Loss: 0.512658
19:23:15: 
Evaluation: Average loss: 0.5554, Accuracy: 4022/5000 (80.440%)

19:23:15: 
Evaluation: Average loss: 0.5554, Accuracy: 4022/5000 (80.440%)

19:23:15: 
Evaluation: Average loss: 0.5554, Accuracy: 4022/5000 (80.440%)

19:23:15: Current learning rate: 0.010000000000000002. Time taken for epoch: 28.55 seconds.

19:23:15: Current learning rate: 0.010000000000000002. Time taken for epoch: 28.55 seconds.

19:23:15: Current learning rate: 0.010000000000000002. Time taken for epoch: 28.55 seconds.

19:23:16: Train Epoch: 66 [0/45000 (0%)]	Loss: 0.605291
19:23:16: Train Epoch: 66 [0/45000 (0%)]	Loss: 0.605291
19:23:16: Train Epoch: 66 [0/45000 (0%)]	Loss: 0.605291
19:23:22: Train Epoch: 66 [10000/45000 (22%)]	Loss: 0.421721
19:23:22: Train Epoch: 66 [10000/45000 (22%)]	Loss: 0.421721
19:23:22: Train Epoch: 66 [10000/45000 (22%)]	Loss: 0.421721
19:23:28: Train Epoch: 66 [20000/45000 (44%)]	Loss: 0.617288
19:23:28: Train Epoch: 66 [20000/45000 (44%)]	Loss: 0.617288
19:23:28: Train Epoch: 66 [20000/45000 (44%)]	Loss: 0.617288
19:23:33: Train Epoch: 66 [30000/45000 (67%)]	Loss: 0.643846
19:23:33: Train Epoch: 66 [30000/45000 (67%)]	Loss: 0.643846
19:23:33: Train Epoch: 66 [30000/45000 (67%)]	Loss: 0.643846
19:23:39: Train Epoch: 66 [40000/45000 (89%)]	Loss: 0.609619
19:23:39: Train Epoch: 66 [40000/45000 (89%)]	Loss: 0.609619
19:23:39: Train Epoch: 66 [40000/45000 (89%)]	Loss: 0.609619
19:23:44: 
Evaluation: Average loss: 0.5548, Accuracy: 4055/5000 (81.100%)

19:23:44: 
Evaluation: Average loss: 0.5548, Accuracy: 4055/5000 (81.100%)

19:23:44: 
Evaluation: Average loss: 0.5548, Accuracy: 4055/5000 (81.100%)

19:23:44: Current learning rate: 0.010000000000000002. Time taken for epoch: 28.56 seconds.

19:23:44: Current learning rate: 0.010000000000000002. Time taken for epoch: 28.56 seconds.

19:23:44: Current learning rate: 0.010000000000000002. Time taken for epoch: 28.56 seconds.

19:23:45: Train Epoch: 67 [0/45000 (0%)]	Loss: 0.384435
19:23:45: Train Epoch: 67 [0/45000 (0%)]	Loss: 0.384435
19:23:45: Train Epoch: 67 [0/45000 (0%)]	Loss: 0.384435
19:23:51: Train Epoch: 67 [10000/45000 (22%)]	Loss: 0.460006
19:23:51: Train Epoch: 67 [10000/45000 (22%)]	Loss: 0.460006
19:23:51: Train Epoch: 67 [10000/45000 (22%)]	Loss: 0.460006
19:23:57: Train Epoch: 67 [20000/45000 (44%)]	Loss: 0.633705
19:23:57: Train Epoch: 67 [20000/45000 (44%)]	Loss: 0.633705
19:23:57: Train Epoch: 67 [20000/45000 (44%)]	Loss: 0.633705
19:24:03: Train Epoch: 67 [30000/45000 (67%)]	Loss: 0.383606
19:24:03: Train Epoch: 67 [30000/45000 (67%)]	Loss: 0.383606
19:24:03: Train Epoch: 67 [30000/45000 (67%)]	Loss: 0.383606
19:24:09: Train Epoch: 67 [40000/45000 (89%)]	Loss: 0.560009
19:24:09: Train Epoch: 67 [40000/45000 (89%)]	Loss: 0.560009
19:24:09: Train Epoch: 67 [40000/45000 (89%)]	Loss: 0.560009
19:24:14: 
Evaluation: Average loss: 0.5476, Accuracy: 4030/5000 (80.600%)

19:24:14: 
Evaluation: Average loss: 0.5476, Accuracy: 4030/5000 (80.600%)

19:24:14: 
Evaluation: Average loss: 0.5476, Accuracy: 4030/5000 (80.600%)

19:24:14: Current learning rate: 0.010000000000000002. Time taken for epoch: 29.58 seconds.

19:24:14: Current learning rate: 0.010000000000000002. Time taken for epoch: 29.58 seconds.

19:24:14: Current learning rate: 0.010000000000000002. Time taken for epoch: 29.58 seconds.

19:24:14: Train Epoch: 68 [0/45000 (0%)]	Loss: 0.463185
19:24:14: Train Epoch: 68 [0/45000 (0%)]	Loss: 0.463185
19:24:14: Train Epoch: 68 [0/45000 (0%)]	Loss: 0.463185
19:24:20: Train Epoch: 68 [10000/45000 (22%)]	Loss: 0.561657
19:24:20: Train Epoch: 68 [10000/45000 (22%)]	Loss: 0.561657
19:24:20: Train Epoch: 68 [10000/45000 (22%)]	Loss: 0.561657
19:24:26: Train Epoch: 68 [20000/45000 (44%)]	Loss: 0.457468
19:24:26: Train Epoch: 68 [20000/45000 (44%)]	Loss: 0.457468
19:24:26: Train Epoch: 68 [20000/45000 (44%)]	Loss: 0.457468
19:24:32: Train Epoch: 68 [30000/45000 (67%)]	Loss: 0.596860
19:24:32: Train Epoch: 68 [30000/45000 (67%)]	Loss: 0.596860
19:24:32: Train Epoch: 68 [30000/45000 (67%)]	Loss: 0.596860
19:24:38: Train Epoch: 68 [40000/45000 (89%)]	Loss: 0.590753
19:24:38: Train Epoch: 68 [40000/45000 (89%)]	Loss: 0.590753
19:24:38: Train Epoch: 68 [40000/45000 (89%)]	Loss: 0.590753
19:24:43: 
Evaluation: Average loss: 0.5466, Accuracy: 4055/5000 (81.100%)

19:24:43: 
Evaluation: Average loss: 0.5466, Accuracy: 4055/5000 (81.100%)

19:24:43: 
Evaluation: Average loss: 0.5466, Accuracy: 4055/5000 (81.100%)

19:24:43: Current learning rate: 0.010000000000000002. Time taken for epoch: 29.20 seconds.

19:24:43: Current learning rate: 0.010000000000000002. Time taken for epoch: 29.20 seconds.

19:24:43: Current learning rate: 0.010000000000000002. Time taken for epoch: 29.20 seconds.

19:24:44: Train Epoch: 69 [0/45000 (0%)]	Loss: 0.640822
19:24:44: Train Epoch: 69 [0/45000 (0%)]	Loss: 0.640822
19:24:44: Train Epoch: 69 [0/45000 (0%)]	Loss: 0.640822
19:24:50: Train Epoch: 69 [10000/45000 (22%)]	Loss: 0.482310
19:24:50: Train Epoch: 69 [10000/45000 (22%)]	Loss: 0.482310
19:24:50: Train Epoch: 69 [10000/45000 (22%)]	Loss: 0.482310
19:24:55: Train Epoch: 69 [20000/45000 (44%)]	Loss: 0.746504
19:24:55: Train Epoch: 69 [20000/45000 (44%)]	Loss: 0.746504
19:24:55: Train Epoch: 69 [20000/45000 (44%)]	Loss: 0.746504
19:25:01: Train Epoch: 69 [30000/45000 (67%)]	Loss: 0.469187
19:25:01: Train Epoch: 69 [30000/45000 (67%)]	Loss: 0.469187
19:25:01: Train Epoch: 69 [30000/45000 (67%)]	Loss: 0.469187
19:25:07: Train Epoch: 69 [40000/45000 (89%)]	Loss: 0.432705
19:25:07: Train Epoch: 69 [40000/45000 (89%)]	Loss: 0.432705
19:25:07: Train Epoch: 69 [40000/45000 (89%)]	Loss: 0.432705
19:25:12: 
Evaluation: Average loss: 0.5450, Accuracy: 4079/5000 (81.580%)

19:25:12: 
Evaluation: Average loss: 0.5450, Accuracy: 4079/5000 (81.580%)

19:25:12: 
Evaluation: Average loss: 0.5450, Accuracy: 4079/5000 (81.580%)

19:25:12: Current learning rate: 0.010000000000000002. Time taken for epoch: 29.17 seconds.

19:25:12: Current learning rate: 0.010000000000000002. Time taken for epoch: 29.17 seconds.

19:25:12: Current learning rate: 0.010000000000000002. Time taken for epoch: 29.17 seconds.

19:25:13: Train Epoch: 70 [0/45000 (0%)]	Loss: 0.341194
19:25:13: Train Epoch: 70 [0/45000 (0%)]	Loss: 0.341194
19:25:13: Train Epoch: 70 [0/45000 (0%)]	Loss: 0.341194
19:25:19: Train Epoch: 70 [10000/45000 (22%)]	Loss: 0.417211
19:25:19: Train Epoch: 70 [10000/45000 (22%)]	Loss: 0.417211
19:25:19: Train Epoch: 70 [10000/45000 (22%)]	Loss: 0.417211
19:25:25: Train Epoch: 70 [20000/45000 (44%)]	Loss: 0.549300
19:25:25: Train Epoch: 70 [20000/45000 (44%)]	Loss: 0.549300
19:25:25: Train Epoch: 70 [20000/45000 (44%)]	Loss: 0.549300
19:25:30: Train Epoch: 70 [30000/45000 (67%)]	Loss: 0.609718
19:25:30: Train Epoch: 70 [30000/45000 (67%)]	Loss: 0.609718
19:25:30: Train Epoch: 70 [30000/45000 (67%)]	Loss: 0.609718
19:25:36: Train Epoch: 70 [40000/45000 (89%)]	Loss: 0.504609
19:25:36: Train Epoch: 70 [40000/45000 (89%)]	Loss: 0.504609
19:25:36: Train Epoch: 70 [40000/45000 (89%)]	Loss: 0.504609
19:25:41: 
Evaluation: Average loss: 0.5453, Accuracy: 4067/5000 (81.340%)

19:25:41: 
Evaluation: Average loss: 0.5453, Accuracy: 4067/5000 (81.340%)

19:25:41: 
Evaluation: Average loss: 0.5453, Accuracy: 4067/5000 (81.340%)

19:25:41: Current learning rate: 0.010000000000000002. Time taken for epoch: 28.75 seconds.

19:25:41: Current learning rate: 0.010000000000000002. Time taken for epoch: 28.75 seconds.

19:25:41: Current learning rate: 0.010000000000000002. Time taken for epoch: 28.75 seconds.

19:25:42: Train Epoch: 71 [0/45000 (0%)]	Loss: 0.401327
19:25:42: Train Epoch: 71 [0/45000 (0%)]	Loss: 0.401327
19:25:42: Train Epoch: 71 [0/45000 (0%)]	Loss: 0.401327
19:25:47: Train Epoch: 71 [10000/45000 (22%)]	Loss: 0.349390
19:25:47: Train Epoch: 71 [10000/45000 (22%)]	Loss: 0.349390
19:25:47: Train Epoch: 71 [10000/45000 (22%)]	Loss: 0.349390
19:25:53: Train Epoch: 71 [20000/45000 (44%)]	Loss: 0.533454
19:25:53: Train Epoch: 71 [20000/45000 (44%)]	Loss: 0.533454
19:25:53: Train Epoch: 71 [20000/45000 (44%)]	Loss: 0.533454
19:25:59: Train Epoch: 71 [30000/45000 (67%)]	Loss: 0.538099
19:25:59: Train Epoch: 71 [30000/45000 (67%)]	Loss: 0.538099
19:25:59: Train Epoch: 71 [30000/45000 (67%)]	Loss: 0.538099
19:26:04: Train Epoch: 71 [40000/45000 (89%)]	Loss: 0.718706
19:26:04: Train Epoch: 71 [40000/45000 (89%)]	Loss: 0.718706
19:26:04: Train Epoch: 71 [40000/45000 (89%)]	Loss: 0.718706
19:26:09: 
Evaluation: Average loss: 0.5623, Accuracy: 4025/5000 (80.500%)

19:26:09: 
Evaluation: Average loss: 0.5623, Accuracy: 4025/5000 (80.500%)

19:26:09: 
Evaluation: Average loss: 0.5623, Accuracy: 4025/5000 (80.500%)

19:26:09: Current learning rate: 0.010000000000000002. Time taken for epoch: 28.66 seconds.

19:26:09: Current learning rate: 0.010000000000000002. Time taken for epoch: 28.66 seconds.

19:26:09: Current learning rate: 0.010000000000000002. Time taken for epoch: 28.66 seconds.

19:26:10: Train Epoch: 72 [0/45000 (0%)]	Loss: 0.461353
19:26:10: Train Epoch: 72 [0/45000 (0%)]	Loss: 0.461353
19:26:10: Train Epoch: 72 [0/45000 (0%)]	Loss: 0.461353
19:26:16: Train Epoch: 72 [10000/45000 (22%)]	Loss: 0.563096
19:26:16: Train Epoch: 72 [10000/45000 (22%)]	Loss: 0.563096
19:26:16: Train Epoch: 72 [10000/45000 (22%)]	Loss: 0.563096
19:26:22: Train Epoch: 72 [20000/45000 (44%)]	Loss: 0.569688
19:26:22: Train Epoch: 72 [20000/45000 (44%)]	Loss: 0.569688
19:26:22: Train Epoch: 72 [20000/45000 (44%)]	Loss: 0.569688
19:26:28: Train Epoch: 72 [30000/45000 (67%)]	Loss: 0.483049
19:26:28: Train Epoch: 72 [30000/45000 (67%)]	Loss: 0.483049
19:26:28: Train Epoch: 72 [30000/45000 (67%)]	Loss: 0.483049
19:26:34: Train Epoch: 72 [40000/45000 (89%)]	Loss: 0.377638
19:26:34: Train Epoch: 72 [40000/45000 (89%)]	Loss: 0.377638
19:26:34: Train Epoch: 72 [40000/45000 (89%)]	Loss: 0.377638
19:26:39: 
Evaluation: Average loss: 0.5675, Accuracy: 4031/5000 (80.620%)

19:26:39: 
Evaluation: Average loss: 0.5675, Accuracy: 4031/5000 (80.620%)

19:26:39: 
Evaluation: Average loss: 0.5675, Accuracy: 4031/5000 (80.620%)

19:26:39: Current learning rate: 0.010000000000000002. Time taken for epoch: 29.21 seconds.

19:26:39: Current learning rate: 0.010000000000000002. Time taken for epoch: 29.21 seconds.

19:26:39: Current learning rate: 0.010000000000000002. Time taken for epoch: 29.21 seconds.

19:26:39: Train Epoch: 73 [0/45000 (0%)]	Loss: 0.367784
19:26:39: Train Epoch: 73 [0/45000 (0%)]	Loss: 0.367784
19:26:39: Train Epoch: 73 [0/45000 (0%)]	Loss: 0.367784
19:26:45: Train Epoch: 73 [10000/45000 (22%)]	Loss: 0.520718
19:26:45: Train Epoch: 73 [10000/45000 (22%)]	Loss: 0.520718
19:26:45: Train Epoch: 73 [10000/45000 (22%)]	Loss: 0.520718
19:26:51: Train Epoch: 73 [20000/45000 (44%)]	Loss: 0.492455
19:26:51: Train Epoch: 73 [20000/45000 (44%)]	Loss: 0.492455
19:26:51: Train Epoch: 73 [20000/45000 (44%)]	Loss: 0.492455
19:26:57: Train Epoch: 73 [30000/45000 (67%)]	Loss: 0.619479
19:26:57: Train Epoch: 73 [30000/45000 (67%)]	Loss: 0.619479
19:26:57: Train Epoch: 73 [30000/45000 (67%)]	Loss: 0.619479
19:27:03: Train Epoch: 73 [40000/45000 (89%)]	Loss: 0.534110
19:27:03: Train Epoch: 73 [40000/45000 (89%)]	Loss: 0.534110
19:27:03: Train Epoch: 73 [40000/45000 (89%)]	Loss: 0.534110
19:27:08: 
Evaluation: Average loss: 0.5398, Accuracy: 4078/5000 (81.560%)

19:27:08: 
Evaluation: Average loss: 0.5398, Accuracy: 4078/5000 (81.560%)

19:27:08: 
Evaluation: Average loss: 0.5398, Accuracy: 4078/5000 (81.560%)

19:27:08: Current learning rate: 0.010000000000000002. Time taken for epoch: 29.31 seconds.

19:27:08: Current learning rate: 0.010000000000000002. Time taken for epoch: 29.31 seconds.

19:27:08: Current learning rate: 0.010000000000000002. Time taken for epoch: 29.31 seconds.

19:27:09: Train Epoch: 74 [0/45000 (0%)]	Loss: 0.434684
19:27:09: Train Epoch: 74 [0/45000 (0%)]	Loss: 0.434684
19:27:09: Train Epoch: 74 [0/45000 (0%)]	Loss: 0.434684
19:27:15: Train Epoch: 74 [10000/45000 (22%)]	Loss: 0.495098
19:27:15: Train Epoch: 74 [10000/45000 (22%)]	Loss: 0.495098
19:27:15: Train Epoch: 74 [10000/45000 (22%)]	Loss: 0.495098
19:27:20: Train Epoch: 74 [20000/45000 (44%)]	Loss: 0.490578
19:27:20: Train Epoch: 74 [20000/45000 (44%)]	Loss: 0.490578
19:27:20: Train Epoch: 74 [20000/45000 (44%)]	Loss: 0.490578
19:27:26: Train Epoch: 74 [30000/45000 (67%)]	Loss: 0.607585
19:27:26: Train Epoch: 74 [30000/45000 (67%)]	Loss: 0.607585
19:27:26: Train Epoch: 74 [30000/45000 (67%)]	Loss: 0.607585
19:27:31: Train Epoch: 74 [40000/45000 (89%)]	Loss: 0.689729
19:27:31: Train Epoch: 74 [40000/45000 (89%)]	Loss: 0.689729
19:27:31: Train Epoch: 74 [40000/45000 (89%)]	Loss: 0.689729
19:27:36: 
Evaluation: Average loss: 0.5381, Accuracy: 4052/5000 (81.040%)

19:27:36: 
Evaluation: Average loss: 0.5381, Accuracy: 4052/5000 (81.040%)

19:27:36: 
Evaluation: Average loss: 0.5381, Accuracy: 4052/5000 (81.040%)

19:27:36: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.89 seconds.

19:27:36: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.89 seconds.

19:27:36: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.89 seconds.

19:27:36: Train Epoch: 75 [0/45000 (0%)]	Loss: 0.407369
19:27:36: Train Epoch: 75 [0/45000 (0%)]	Loss: 0.407369
19:27:36: Train Epoch: 75 [0/45000 (0%)]	Loss: 0.407369
19:27:42: Train Epoch: 75 [10000/45000 (22%)]	Loss: 0.571946
19:27:42: Train Epoch: 75 [10000/45000 (22%)]	Loss: 0.571946
19:27:42: Train Epoch: 75 [10000/45000 (22%)]	Loss: 0.571946
19:27:48: Train Epoch: 75 [20000/45000 (44%)]	Loss: 0.502725
19:27:48: Train Epoch: 75 [20000/45000 (44%)]	Loss: 0.502725
19:27:48: Train Epoch: 75 [20000/45000 (44%)]	Loss: 0.502725
19:27:53: Train Epoch: 75 [30000/45000 (67%)]	Loss: 0.543659
19:27:53: Train Epoch: 75 [30000/45000 (67%)]	Loss: 0.543659
19:27:53: Train Epoch: 75 [30000/45000 (67%)]	Loss: 0.543659
19:27:59: Train Epoch: 75 [40000/45000 (89%)]	Loss: 0.432488
19:27:59: Train Epoch: 75 [40000/45000 (89%)]	Loss: 0.432488
19:27:59: Train Epoch: 75 [40000/45000 (89%)]	Loss: 0.432488
19:28:04: 
Evaluation: Average loss: 0.5562, Accuracy: 4029/5000 (80.580%)

19:28:04: 
Evaluation: Average loss: 0.5562, Accuracy: 4029/5000 (80.580%)

19:28:04: 
Evaluation: Average loss: 0.5562, Accuracy: 4029/5000 (80.580%)

19:28:04: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.81 seconds.

19:28:04: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.81 seconds.

19:28:04: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.81 seconds.

19:28:04: Train Epoch: 76 [0/45000 (0%)]	Loss: 0.422704
19:28:04: Train Epoch: 76 [0/45000 (0%)]	Loss: 0.422704
19:28:04: Train Epoch: 76 [0/45000 (0%)]	Loss: 0.422704
19:28:10: Train Epoch: 76 [10000/45000 (22%)]	Loss: 0.579334
19:28:10: Train Epoch: 76 [10000/45000 (22%)]	Loss: 0.579334
19:28:10: Train Epoch: 76 [10000/45000 (22%)]	Loss: 0.579334
19:28:16: Train Epoch: 76 [20000/45000 (44%)]	Loss: 0.507109
19:28:16: Train Epoch: 76 [20000/45000 (44%)]	Loss: 0.507109
19:28:16: Train Epoch: 76 [20000/45000 (44%)]	Loss: 0.507109
19:28:21: Train Epoch: 76 [30000/45000 (67%)]	Loss: 0.411414
19:28:21: Train Epoch: 76 [30000/45000 (67%)]	Loss: 0.411414
19:28:21: Train Epoch: 76 [30000/45000 (67%)]	Loss: 0.411414
19:28:27: Train Epoch: 76 [40000/45000 (89%)]	Loss: 0.769988
19:28:27: Train Epoch: 76 [40000/45000 (89%)]	Loss: 0.769988
19:28:27: Train Epoch: 76 [40000/45000 (89%)]	Loss: 0.769988
19:28:31: 
Evaluation: Average loss: 0.5716, Accuracy: 3996/5000 (79.920%)

19:28:31: 
Evaluation: Average loss: 0.5716, Accuracy: 3996/5000 (79.920%)

19:28:31: 
Evaluation: Average loss: 0.5716, Accuracy: 3996/5000 (79.920%)

19:28:31: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.87 seconds.

19:28:31: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.87 seconds.

19:28:31: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.87 seconds.

19:28:32: Train Epoch: 77 [0/45000 (0%)]	Loss: 0.394493
19:28:32: Train Epoch: 77 [0/45000 (0%)]	Loss: 0.394493
19:28:32: Train Epoch: 77 [0/45000 (0%)]	Loss: 0.394493
19:28:38: Train Epoch: 77 [10000/45000 (22%)]	Loss: 0.488260
19:28:38: Train Epoch: 77 [10000/45000 (22%)]	Loss: 0.488260
19:28:38: Train Epoch: 77 [10000/45000 (22%)]	Loss: 0.488260
19:28:43: Train Epoch: 77 [20000/45000 (44%)]	Loss: 0.449688
19:28:43: Train Epoch: 77 [20000/45000 (44%)]	Loss: 0.449688
19:28:43: Train Epoch: 77 [20000/45000 (44%)]	Loss: 0.449688
19:28:49: Train Epoch: 77 [30000/45000 (67%)]	Loss: 0.440614
19:28:49: Train Epoch: 77 [30000/45000 (67%)]	Loss: 0.440614
19:28:49: Train Epoch: 77 [30000/45000 (67%)]	Loss: 0.440614
19:28:54: Train Epoch: 77 [40000/45000 (89%)]	Loss: 0.411205
19:28:54: Train Epoch: 77 [40000/45000 (89%)]	Loss: 0.411205
19:28:54: Train Epoch: 77 [40000/45000 (89%)]	Loss: 0.411205
19:28:59: 
Evaluation: Average loss: 0.5457, Accuracy: 4050/5000 (81.000%)

19:28:59: 
Evaluation: Average loss: 0.5457, Accuracy: 4050/5000 (81.000%)

19:28:59: 
Evaluation: Average loss: 0.5457, Accuracy: 4050/5000 (81.000%)

19:28:59: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.26 seconds.

19:28:59: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.26 seconds.

19:28:59: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.26 seconds.

19:28:59: Train Epoch: 78 [0/45000 (0%)]	Loss: 0.484380
19:28:59: Train Epoch: 78 [0/45000 (0%)]	Loss: 0.484380
19:28:59: Train Epoch: 78 [0/45000 (0%)]	Loss: 0.484380
19:29:05: Train Epoch: 78 [10000/45000 (22%)]	Loss: 0.486632
19:29:05: Train Epoch: 78 [10000/45000 (22%)]	Loss: 0.486632
19:29:05: Train Epoch: 78 [10000/45000 (22%)]	Loss: 0.486632
19:29:11: Train Epoch: 78 [20000/45000 (44%)]	Loss: 0.501275
19:29:11: Train Epoch: 78 [20000/45000 (44%)]	Loss: 0.501275
19:29:11: Train Epoch: 78 [20000/45000 (44%)]	Loss: 0.501275
19:29:16: Train Epoch: 78 [30000/45000 (67%)]	Loss: 0.435507
19:29:16: Train Epoch: 78 [30000/45000 (67%)]	Loss: 0.435507
19:29:16: Train Epoch: 78 [30000/45000 (67%)]	Loss: 0.435507
19:29:21: Train Epoch: 78 [40000/45000 (89%)]	Loss: 0.628320
19:29:21: Train Epoch: 78 [40000/45000 (89%)]	Loss: 0.628320
19:29:21: Train Epoch: 78 [40000/45000 (89%)]	Loss: 0.628320
19:29:26: 
Evaluation: Average loss: 0.5759, Accuracy: 4007/5000 (80.140%)

19:29:26: 
Evaluation: Average loss: 0.5759, Accuracy: 4007/5000 (80.140%)

19:29:26: 
Evaluation: Average loss: 0.5759, Accuracy: 4007/5000 (80.140%)

19:29:26: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.41 seconds.

19:29:26: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.41 seconds.

19:29:26: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.41 seconds.

19:29:27: Train Epoch: 79 [0/45000 (0%)]	Loss: 0.536366
19:29:27: Train Epoch: 79 [0/45000 (0%)]	Loss: 0.536366
19:29:27: Train Epoch: 79 [0/45000 (0%)]	Loss: 0.536366
19:29:32: Train Epoch: 79 [10000/45000 (22%)]	Loss: 0.542151
19:29:32: Train Epoch: 79 [10000/45000 (22%)]	Loss: 0.542151
19:29:32: Train Epoch: 79 [10000/45000 (22%)]	Loss: 0.542151
19:29:38: Train Epoch: 79 [20000/45000 (44%)]	Loss: 0.461753
19:29:38: Train Epoch: 79 [20000/45000 (44%)]	Loss: 0.461753
19:29:38: Train Epoch: 79 [20000/45000 (44%)]	Loss: 0.461753
19:29:43: Train Epoch: 79 [30000/45000 (67%)]	Loss: 0.615222
19:29:43: Train Epoch: 79 [30000/45000 (67%)]	Loss: 0.615222
19:29:43: Train Epoch: 79 [30000/45000 (67%)]	Loss: 0.615222
19:29:49: Train Epoch: 79 [40000/45000 (89%)]	Loss: 0.641577
19:29:49: Train Epoch: 79 [40000/45000 (89%)]	Loss: 0.641577
19:29:49: Train Epoch: 79 [40000/45000 (89%)]	Loss: 0.641577
19:29:53: 
Evaluation: Average loss: 0.5529, Accuracy: 4052/5000 (81.040%)

19:29:53: 
Evaluation: Average loss: 0.5529, Accuracy: 4052/5000 (81.040%)

19:29:53: 
Evaluation: Average loss: 0.5529, Accuracy: 4052/5000 (81.040%)

19:29:54: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.40 seconds.

19:29:54: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.40 seconds.

19:29:54: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.40 seconds.

19:29:54: Train Epoch: 80 [0/45000 (0%)]	Loss: 0.504757
19:29:54: Train Epoch: 80 [0/45000 (0%)]	Loss: 0.504757
19:29:54: Train Epoch: 80 [0/45000 (0%)]	Loss: 0.504757
19:30:00: Train Epoch: 80 [10000/45000 (22%)]	Loss: 0.408265
19:30:00: Train Epoch: 80 [10000/45000 (22%)]	Loss: 0.408265
19:30:00: Train Epoch: 80 [10000/45000 (22%)]	Loss: 0.408265
19:30:05: Train Epoch: 80 [20000/45000 (44%)]	Loss: 0.615605
19:30:05: Train Epoch: 80 [20000/45000 (44%)]	Loss: 0.615605
19:30:05: Train Epoch: 80 [20000/45000 (44%)]	Loss: 0.615605
19:30:11: Train Epoch: 80 [30000/45000 (67%)]	Loss: 0.494923
19:30:11: Train Epoch: 80 [30000/45000 (67%)]	Loss: 0.494923
19:30:11: Train Epoch: 80 [30000/45000 (67%)]	Loss: 0.494923
19:30:17: Train Epoch: 80 [40000/45000 (89%)]	Loss: 0.445864
19:30:17: Train Epoch: 80 [40000/45000 (89%)]	Loss: 0.445864
19:30:17: Train Epoch: 80 [40000/45000 (89%)]	Loss: 0.445864
19:30:21: 
Evaluation: Average loss: 0.5646, Accuracy: 4013/5000 (80.260%)

19:30:21: 
Evaluation: Average loss: 0.5646, Accuracy: 4013/5000 (80.260%)

19:30:21: 
Evaluation: Average loss: 0.5646, Accuracy: 4013/5000 (80.260%)

19:30:21: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.52 seconds.

19:30:21: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.52 seconds.

19:30:21: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.52 seconds.

19:30:22: Train Epoch: 81 [0/45000 (0%)]	Loss: 0.378788
19:30:22: Train Epoch: 81 [0/45000 (0%)]	Loss: 0.378788
19:30:22: Train Epoch: 81 [0/45000 (0%)]	Loss: 0.378788
19:30:28: Train Epoch: 81 [10000/45000 (22%)]	Loss: 0.471908
19:30:28: Train Epoch: 81 [10000/45000 (22%)]	Loss: 0.471908
19:30:28: Train Epoch: 81 [10000/45000 (22%)]	Loss: 0.471908
19:30:33: Train Epoch: 81 [20000/45000 (44%)]	Loss: 0.584665
19:30:33: Train Epoch: 81 [20000/45000 (44%)]	Loss: 0.584665
19:30:33: Train Epoch: 81 [20000/45000 (44%)]	Loss: 0.584665
19:30:38: Train Epoch: 81 [30000/45000 (67%)]	Loss: 0.496690
19:30:38: Train Epoch: 81 [30000/45000 (67%)]	Loss: 0.496690
19:30:38: Train Epoch: 81 [30000/45000 (67%)]	Loss: 0.496690
19:30:44: Train Epoch: 81 [40000/45000 (89%)]	Loss: 0.380599
19:30:44: Train Epoch: 81 [40000/45000 (89%)]	Loss: 0.380599
19:30:44: Train Epoch: 81 [40000/45000 (89%)]	Loss: 0.380599
19:30:48: 
Evaluation: Average loss: 0.5941, Accuracy: 3975/5000 (79.500%)

19:30:48: 
Evaluation: Average loss: 0.5941, Accuracy: 3975/5000 (79.500%)

19:30:48: 
Evaluation: Average loss: 0.5941, Accuracy: 3975/5000 (79.500%)

19:30:48: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.40 seconds.

19:30:48: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.40 seconds.

19:30:48: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.40 seconds.

19:30:49: Train Epoch: 82 [0/45000 (0%)]	Loss: 0.519852
19:30:49: Train Epoch: 82 [0/45000 (0%)]	Loss: 0.519852
19:30:49: Train Epoch: 82 [0/45000 (0%)]	Loss: 0.519852
19:30:55: Train Epoch: 82 [10000/45000 (22%)]	Loss: 0.664890
19:30:55: Train Epoch: 82 [10000/45000 (22%)]	Loss: 0.664890
19:30:55: Train Epoch: 82 [10000/45000 (22%)]	Loss: 0.664890
19:31:00: Train Epoch: 82 [20000/45000 (44%)]	Loss: 0.502063
19:31:00: Train Epoch: 82 [20000/45000 (44%)]	Loss: 0.502063
19:31:00: Train Epoch: 82 [20000/45000 (44%)]	Loss: 0.502063
19:31:05: Train Epoch: 82 [30000/45000 (67%)]	Loss: 0.340471
19:31:05: Train Epoch: 82 [30000/45000 (67%)]	Loss: 0.340471
19:31:05: Train Epoch: 82 [30000/45000 (67%)]	Loss: 0.340471
19:31:11: Train Epoch: 82 [40000/45000 (89%)]	Loss: 0.691184
19:31:11: Train Epoch: 82 [40000/45000 (89%)]	Loss: 0.691184
19:31:11: Train Epoch: 82 [40000/45000 (89%)]	Loss: 0.691184
19:31:16: 
Evaluation: Average loss: 0.5409, Accuracy: 4069/5000 (81.380%)

19:31:16: 
Evaluation: Average loss: 0.5409, Accuracy: 4069/5000 (81.380%)

19:31:16: 
Evaluation: Average loss: 0.5409, Accuracy: 4069/5000 (81.380%)

19:31:16: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.37 seconds.

19:31:16: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.37 seconds.

19:31:16: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.37 seconds.

19:31:17: Train Epoch: 83 [0/45000 (0%)]	Loss: 0.577453
19:31:17: Train Epoch: 83 [0/45000 (0%)]	Loss: 0.577453
19:31:17: Train Epoch: 83 [0/45000 (0%)]	Loss: 0.577453
19:31:22: Train Epoch: 83 [10000/45000 (22%)]	Loss: 0.414960
19:31:22: Train Epoch: 83 [10000/45000 (22%)]	Loss: 0.414960
19:31:22: Train Epoch: 83 [10000/45000 (22%)]	Loss: 0.414960
19:31:28: Train Epoch: 83 [20000/45000 (44%)]	Loss: 0.523018
19:31:28: Train Epoch: 83 [20000/45000 (44%)]	Loss: 0.523018
19:31:28: Train Epoch: 83 [20000/45000 (44%)]	Loss: 0.523018
19:31:33: Train Epoch: 83 [30000/45000 (67%)]	Loss: 0.491507
19:31:33: Train Epoch: 83 [30000/45000 (67%)]	Loss: 0.491507
19:31:33: Train Epoch: 83 [30000/45000 (67%)]	Loss: 0.491507
19:31:38: Train Epoch: 83 [40000/45000 (89%)]	Loss: 0.705093
19:31:38: Train Epoch: 83 [40000/45000 (89%)]	Loss: 0.705093
19:31:38: Train Epoch: 83 [40000/45000 (89%)]	Loss: 0.705093
19:31:43: 
Evaluation: Average loss: 0.5871, Accuracy: 3983/5000 (79.660%)

19:31:43: 
Evaluation: Average loss: 0.5871, Accuracy: 3983/5000 (79.660%)

19:31:43: 
Evaluation: Average loss: 0.5871, Accuracy: 3983/5000 (79.660%)

19:31:43: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.09 seconds.

19:31:43: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.09 seconds.

19:31:43: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.09 seconds.

19:31:43: Train Epoch: 84 [0/45000 (0%)]	Loss: 0.697139
19:31:43: Train Epoch: 84 [0/45000 (0%)]	Loss: 0.697139
19:31:43: Train Epoch: 84 [0/45000 (0%)]	Loss: 0.697139
19:31:49: Train Epoch: 84 [10000/45000 (22%)]	Loss: 0.411445
19:31:49: Train Epoch: 84 [10000/45000 (22%)]	Loss: 0.411445
19:31:49: Train Epoch: 84 [10000/45000 (22%)]	Loss: 0.411445
19:31:55: Train Epoch: 84 [20000/45000 (44%)]	Loss: 0.404508
19:31:55: Train Epoch: 84 [20000/45000 (44%)]	Loss: 0.404508
19:31:55: Train Epoch: 84 [20000/45000 (44%)]	Loss: 0.404508
19:32:00: Train Epoch: 84 [30000/45000 (67%)]	Loss: 0.813503
19:32:00: Train Epoch: 84 [30000/45000 (67%)]	Loss: 0.813503
19:32:00: Train Epoch: 84 [30000/45000 (67%)]	Loss: 0.813503
19:32:05: Train Epoch: 84 [40000/45000 (89%)]	Loss: 0.444083
19:32:05: Train Epoch: 84 [40000/45000 (89%)]	Loss: 0.444083
19:32:05: Train Epoch: 84 [40000/45000 (89%)]	Loss: 0.444083
19:32:10: 
Evaluation: Average loss: 0.5764, Accuracy: 4026/5000 (80.520%)

19:32:10: 
Evaluation: Average loss: 0.5764, Accuracy: 4026/5000 (80.520%)

19:32:10: 
Evaluation: Average loss: 0.5764, Accuracy: 4026/5000 (80.520%)

19:32:10: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.33 seconds.

19:32:10: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.33 seconds.

19:32:10: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.33 seconds.

19:32:11: Train Epoch: 85 [0/45000 (0%)]	Loss: 0.387804
19:32:11: Train Epoch: 85 [0/45000 (0%)]	Loss: 0.387804
19:32:11: Train Epoch: 85 [0/45000 (0%)]	Loss: 0.387804
19:32:17: Train Epoch: 85 [10000/45000 (22%)]	Loss: 0.423696
19:32:17: Train Epoch: 85 [10000/45000 (22%)]	Loss: 0.423696
19:32:17: Train Epoch: 85 [10000/45000 (22%)]	Loss: 0.423696
19:32:23: Train Epoch: 85 [20000/45000 (44%)]	Loss: 0.452612
19:32:23: Train Epoch: 85 [20000/45000 (44%)]	Loss: 0.452612
19:32:23: Train Epoch: 85 [20000/45000 (44%)]	Loss: 0.452612
19:32:29: Train Epoch: 85 [30000/45000 (67%)]	Loss: 0.326870
19:32:29: Train Epoch: 85 [30000/45000 (67%)]	Loss: 0.326870
19:32:29: Train Epoch: 85 [30000/45000 (67%)]	Loss: 0.326870
19:32:35: Train Epoch: 85 [40000/45000 (89%)]	Loss: 0.633443
19:32:35: Train Epoch: 85 [40000/45000 (89%)]	Loss: 0.633443
19:32:35: Train Epoch: 85 [40000/45000 (89%)]	Loss: 0.633443
19:32:39: 
Evaluation: Average loss: 0.5607, Accuracy: 4039/5000 (80.780%)

19:32:39: 
Evaluation: Average loss: 0.5607, Accuracy: 4039/5000 (80.780%)

19:32:39: 
Evaluation: Average loss: 0.5607, Accuracy: 4039/5000 (80.780%)

19:32:39: Current learning rate: 0.010000000000000002. Time taken for epoch: 29.00 seconds.

19:32:39: Current learning rate: 0.010000000000000002. Time taken for epoch: 29.00 seconds.

19:32:39: Current learning rate: 0.010000000000000002. Time taken for epoch: 29.00 seconds.

19:32:40: Train Epoch: 86 [0/45000 (0%)]	Loss: 0.403101
19:32:40: Train Epoch: 86 [0/45000 (0%)]	Loss: 0.403101
19:32:40: Train Epoch: 86 [0/45000 (0%)]	Loss: 0.403101
19:32:46: Train Epoch: 86 [10000/45000 (22%)]	Loss: 0.623949
19:32:46: Train Epoch: 86 [10000/45000 (22%)]	Loss: 0.623949
19:32:46: Train Epoch: 86 [10000/45000 (22%)]	Loss: 0.623949
19:32:52: Train Epoch: 86 [20000/45000 (44%)]	Loss: 0.523925
19:32:52: Train Epoch: 86 [20000/45000 (44%)]	Loss: 0.523925
19:32:52: Train Epoch: 86 [20000/45000 (44%)]	Loss: 0.523925
19:32:58: Train Epoch: 86 [30000/45000 (67%)]	Loss: 0.616334
19:32:58: Train Epoch: 86 [30000/45000 (67%)]	Loss: 0.616334
19:32:58: Train Epoch: 86 [30000/45000 (67%)]	Loss: 0.616334
19:33:03: Train Epoch: 86 [40000/45000 (89%)]	Loss: 0.554088
19:33:03: Train Epoch: 86 [40000/45000 (89%)]	Loss: 0.554088
19:33:03: Train Epoch: 86 [40000/45000 (89%)]	Loss: 0.554088
19:33:08: 
Evaluation: Average loss: 0.5675, Accuracy: 4011/5000 (80.220%)

19:33:08: 
Evaluation: Average loss: 0.5675, Accuracy: 4011/5000 (80.220%)

19:33:08: 
Evaluation: Average loss: 0.5675, Accuracy: 4011/5000 (80.220%)

19:33:08: Current learning rate: 0.010000000000000002. Time taken for epoch: 28.96 seconds.

19:33:08: Current learning rate: 0.010000000000000002. Time taken for epoch: 28.96 seconds.

19:33:08: Current learning rate: 0.010000000000000002. Time taken for epoch: 28.96 seconds.

19:33:09: Train Epoch: 87 [0/45000 (0%)]	Loss: 0.343066
19:33:09: Train Epoch: 87 [0/45000 (0%)]	Loss: 0.343066
19:33:09: Train Epoch: 87 [0/45000 (0%)]	Loss: 0.343066
19:33:15: Train Epoch: 87 [10000/45000 (22%)]	Loss: 0.572756
19:33:15: Train Epoch: 87 [10000/45000 (22%)]	Loss: 0.572756
19:33:15: Train Epoch: 87 [10000/45000 (22%)]	Loss: 0.572756
19:33:21: Train Epoch: 87 [20000/45000 (44%)]	Loss: 0.492405
19:33:21: Train Epoch: 87 [20000/45000 (44%)]	Loss: 0.492405
19:33:21: Train Epoch: 87 [20000/45000 (44%)]	Loss: 0.492405
19:33:26: Train Epoch: 87 [30000/45000 (67%)]	Loss: 0.589418
19:33:26: Train Epoch: 87 [30000/45000 (67%)]	Loss: 0.589418
19:33:26: Train Epoch: 87 [30000/45000 (67%)]	Loss: 0.589418
19:33:32: Train Epoch: 87 [40000/45000 (89%)]	Loss: 0.499916
19:33:32: Train Epoch: 87 [40000/45000 (89%)]	Loss: 0.499916
19:33:32: Train Epoch: 87 [40000/45000 (89%)]	Loss: 0.499916
19:33:36: 
Evaluation: Average loss: 0.5787, Accuracy: 4014/5000 (80.280%)

19:33:36: 
Evaluation: Average loss: 0.5787, Accuracy: 4014/5000 (80.280%)

19:33:36: 
Evaluation: Average loss: 0.5787, Accuracy: 4014/5000 (80.280%)

19:33:36: Current learning rate: 0.010000000000000002. Time taken for epoch: 28.28 seconds.

19:33:36: Current learning rate: 0.010000000000000002. Time taken for epoch: 28.28 seconds.

19:33:36: Current learning rate: 0.010000000000000002. Time taken for epoch: 28.28 seconds.

19:33:37: Train Epoch: 88 [0/45000 (0%)]	Loss: 0.486705
19:33:37: Train Epoch: 88 [0/45000 (0%)]	Loss: 0.486705
19:33:37: Train Epoch: 88 [0/45000 (0%)]	Loss: 0.486705
19:33:43: Train Epoch: 88 [10000/45000 (22%)]	Loss: 0.469551
19:33:43: Train Epoch: 88 [10000/45000 (22%)]	Loss: 0.469551
19:33:43: Train Epoch: 88 [10000/45000 (22%)]	Loss: 0.469551
19:33:49: Train Epoch: 88 [20000/45000 (44%)]	Loss: 0.664535
19:33:49: Train Epoch: 88 [20000/45000 (44%)]	Loss: 0.664535
19:33:49: Train Epoch: 88 [20000/45000 (44%)]	Loss: 0.664535
19:33:55: Train Epoch: 88 [30000/45000 (67%)]	Loss: 0.696349
19:33:55: Train Epoch: 88 [30000/45000 (67%)]	Loss: 0.696349
19:33:55: Train Epoch: 88 [30000/45000 (67%)]	Loss: 0.696349
19:34:00: Train Epoch: 88 [40000/45000 (89%)]	Loss: 0.559893
19:34:00: Train Epoch: 88 [40000/45000 (89%)]	Loss: 0.559893
19:34:00: Train Epoch: 88 [40000/45000 (89%)]	Loss: 0.559893
19:34:05: 
Evaluation: Average loss: 0.5698, Accuracy: 4042/5000 (80.840%)

19:34:05: 
Evaluation: Average loss: 0.5698, Accuracy: 4042/5000 (80.840%)

19:34:05: 
Evaluation: Average loss: 0.5698, Accuracy: 4042/5000 (80.840%)

19:34:05: Current learning rate: 0.010000000000000002. Time taken for epoch: 28.20 seconds.

19:34:05: Current learning rate: 0.010000000000000002. Time taken for epoch: 28.20 seconds.

19:34:05: Current learning rate: 0.010000000000000002. Time taken for epoch: 28.20 seconds.

19:34:05: Train Epoch: 89 [0/45000 (0%)]	Loss: 0.751724
19:34:05: Train Epoch: 89 [0/45000 (0%)]	Loss: 0.751724
19:34:05: Train Epoch: 89 [0/45000 (0%)]	Loss: 0.751724
19:34:11: Train Epoch: 89 [10000/45000 (22%)]	Loss: 0.383828
19:34:11: Train Epoch: 89 [10000/45000 (22%)]	Loss: 0.383828
19:34:11: Train Epoch: 89 [10000/45000 (22%)]	Loss: 0.383828
19:34:16: Train Epoch: 89 [20000/45000 (44%)]	Loss: 0.659308
19:34:16: Train Epoch: 89 [20000/45000 (44%)]	Loss: 0.659308
19:34:16: Train Epoch: 89 [20000/45000 (44%)]	Loss: 0.659308
19:34:21: Train Epoch: 89 [30000/45000 (67%)]	Loss: 0.433164
19:34:21: Train Epoch: 89 [30000/45000 (67%)]	Loss: 0.433164
19:34:21: Train Epoch: 89 [30000/45000 (67%)]	Loss: 0.433164
19:34:27: Train Epoch: 89 [40000/45000 (89%)]	Loss: 0.435577
19:34:27: Train Epoch: 89 [40000/45000 (89%)]	Loss: 0.435577
19:34:27: Train Epoch: 89 [40000/45000 (89%)]	Loss: 0.435577
19:34:31: 
Evaluation: Average loss: 0.5711, Accuracy: 4032/5000 (80.640%)

19:34:31: 
Evaluation: Average loss: 0.5711, Accuracy: 4032/5000 (80.640%)

19:34:31: 
Evaluation: Average loss: 0.5711, Accuracy: 4032/5000 (80.640%)

19:34:31: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.60 seconds.

19:34:31: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.60 seconds.

19:34:31: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.60 seconds.

19:34:32: Train Epoch: 90 [0/45000 (0%)]	Loss: 0.478370
19:34:32: Train Epoch: 90 [0/45000 (0%)]	Loss: 0.478370
19:34:32: Train Epoch: 90 [0/45000 (0%)]	Loss: 0.478370
19:34:38: Train Epoch: 90 [10000/45000 (22%)]	Loss: 0.598984
19:34:38: Train Epoch: 90 [10000/45000 (22%)]	Loss: 0.598984
19:34:38: Train Epoch: 90 [10000/45000 (22%)]	Loss: 0.598984
19:34:43: Train Epoch: 90 [20000/45000 (44%)]	Loss: 0.333060
19:34:43: Train Epoch: 90 [20000/45000 (44%)]	Loss: 0.333060
19:34:43: Train Epoch: 90 [20000/45000 (44%)]	Loss: 0.333060
19:34:48: Train Epoch: 90 [30000/45000 (67%)]	Loss: 0.492867
19:34:48: Train Epoch: 90 [30000/45000 (67%)]	Loss: 0.492867
19:34:48: Train Epoch: 90 [30000/45000 (67%)]	Loss: 0.492867
19:34:53: Train Epoch: 90 [40000/45000 (89%)]	Loss: 0.594300
19:34:53: Train Epoch: 90 [40000/45000 (89%)]	Loss: 0.594300
19:34:53: Train Epoch: 90 [40000/45000 (89%)]	Loss: 0.594300
19:34:58: 
Evaluation: Average loss: 0.5661, Accuracy: 4042/5000 (80.840%)

19:34:58: 
Evaluation: Average loss: 0.5661, Accuracy: 4042/5000 (80.840%)

19:34:58: 
Evaluation: Average loss: 0.5661, Accuracy: 4042/5000 (80.840%)

19:34:58: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.78 seconds.

19:34:58: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.78 seconds.

19:34:58: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.78 seconds.

19:34:59: Train Epoch: 91 [0/45000 (0%)]	Loss: 0.509566
19:34:59: Train Epoch: 91 [0/45000 (0%)]	Loss: 0.509566
19:34:59: Train Epoch: 91 [0/45000 (0%)]	Loss: 0.509566
19:35:04: Train Epoch: 91 [10000/45000 (22%)]	Loss: 0.505443
19:35:04: Train Epoch: 91 [10000/45000 (22%)]	Loss: 0.505443
19:35:04: Train Epoch: 91 [10000/45000 (22%)]	Loss: 0.505443
19:35:10: Train Epoch: 91 [20000/45000 (44%)]	Loss: 0.401623
19:35:10: Train Epoch: 91 [20000/45000 (44%)]	Loss: 0.401623
19:35:10: Train Epoch: 91 [20000/45000 (44%)]	Loss: 0.401623
19:35:15: Train Epoch: 91 [30000/45000 (67%)]	Loss: 0.543174
19:35:15: Train Epoch: 91 [30000/45000 (67%)]	Loss: 0.543174
19:35:15: Train Epoch: 91 [30000/45000 (67%)]	Loss: 0.543174
19:35:20: Train Epoch: 91 [40000/45000 (89%)]	Loss: 0.572450
19:35:20: Train Epoch: 91 [40000/45000 (89%)]	Loss: 0.572450
19:35:20: Train Epoch: 91 [40000/45000 (89%)]	Loss: 0.572450
19:35:25: 
Evaluation: Average loss: 0.5774, Accuracy: 3978/5000 (79.560%)

19:35:25: 
Evaluation: Average loss: 0.5774, Accuracy: 3978/5000 (79.560%)

19:35:25: 
Evaluation: Average loss: 0.5774, Accuracy: 3978/5000 (79.560%)

19:35:25: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.70 seconds.

19:35:25: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.70 seconds.

19:35:25: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.70 seconds.

19:35:25: Train Epoch: 92 [0/45000 (0%)]	Loss: 0.475910
19:35:25: Train Epoch: 92 [0/45000 (0%)]	Loss: 0.475910
19:35:25: Train Epoch: 92 [0/45000 (0%)]	Loss: 0.475910
19:35:31: Train Epoch: 92 [10000/45000 (22%)]	Loss: 0.529942
19:35:31: Train Epoch: 92 [10000/45000 (22%)]	Loss: 0.529942
19:35:31: Train Epoch: 92 [10000/45000 (22%)]	Loss: 0.529942
19:35:36: Train Epoch: 92 [20000/45000 (44%)]	Loss: 0.420506
19:35:36: Train Epoch: 92 [20000/45000 (44%)]	Loss: 0.420506
19:35:36: Train Epoch: 92 [20000/45000 (44%)]	Loss: 0.420506
19:35:41: Train Epoch: 92 [30000/45000 (67%)]	Loss: 0.473290
19:35:41: Train Epoch: 92 [30000/45000 (67%)]	Loss: 0.473290
19:35:41: Train Epoch: 92 [30000/45000 (67%)]	Loss: 0.473290
19:35:47: Train Epoch: 92 [40000/45000 (89%)]	Loss: 0.443720
19:35:47: Train Epoch: 92 [40000/45000 (89%)]	Loss: 0.443720
19:35:47: Train Epoch: 92 [40000/45000 (89%)]	Loss: 0.443720
19:35:52: 
Evaluation: Average loss: 0.6174, Accuracy: 3973/5000 (79.460%)

19:35:52: 
Evaluation: Average loss: 0.6174, Accuracy: 3973/5000 (79.460%)

19:35:52: 
Evaluation: Average loss: 0.6174, Accuracy: 3973/5000 (79.460%)

19:35:52: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.92 seconds.

19:35:52: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.92 seconds.

19:35:52: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.92 seconds.

19:35:52: Train Epoch: 93 [0/45000 (0%)]	Loss: 0.569682
19:35:52: Train Epoch: 93 [0/45000 (0%)]	Loss: 0.569682
19:35:52: Train Epoch: 93 [0/45000 (0%)]	Loss: 0.569682
19:35:58: Train Epoch: 93 [10000/45000 (22%)]	Loss: 0.471302
19:35:58: Train Epoch: 93 [10000/45000 (22%)]	Loss: 0.471302
19:35:58: Train Epoch: 93 [10000/45000 (22%)]	Loss: 0.471302
19:36:03: Train Epoch: 93 [20000/45000 (44%)]	Loss: 0.482904
19:36:03: Train Epoch: 93 [20000/45000 (44%)]	Loss: 0.482904
19:36:03: Train Epoch: 93 [20000/45000 (44%)]	Loss: 0.482904
19:36:09: Train Epoch: 93 [30000/45000 (67%)]	Loss: 0.649148
19:36:09: Train Epoch: 93 [30000/45000 (67%)]	Loss: 0.649148
19:36:09: Train Epoch: 93 [30000/45000 (67%)]	Loss: 0.649148
19:36:14: Train Epoch: 93 [40000/45000 (89%)]	Loss: 0.490077
19:36:14: Train Epoch: 93 [40000/45000 (89%)]	Loss: 0.490077
19:36:14: Train Epoch: 93 [40000/45000 (89%)]	Loss: 0.490077
19:36:19: 
Evaluation: Average loss: 0.5595, Accuracy: 4023/5000 (80.460%)

19:36:19: 
Evaluation: Average loss: 0.5595, Accuracy: 4023/5000 (80.460%)

19:36:19: 
Evaluation: Average loss: 0.5595, Accuracy: 4023/5000 (80.460%)

19:36:19: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.04 seconds.

19:36:19: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.04 seconds.

19:36:19: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.04 seconds.

19:36:20: Train Epoch: 94 [0/45000 (0%)]	Loss: 0.531129
19:36:20: Train Epoch: 94 [0/45000 (0%)]	Loss: 0.531129
19:36:20: Train Epoch: 94 [0/45000 (0%)]	Loss: 0.531129
19:36:25: Train Epoch: 94 [10000/45000 (22%)]	Loss: 0.402649
19:36:25: Train Epoch: 94 [10000/45000 (22%)]	Loss: 0.402649
19:36:25: Train Epoch: 94 [10000/45000 (22%)]	Loss: 0.402649
19:36:31: Train Epoch: 94 [20000/45000 (44%)]	Loss: 0.598096
19:36:31: Train Epoch: 94 [20000/45000 (44%)]	Loss: 0.598096
19:36:31: Train Epoch: 94 [20000/45000 (44%)]	Loss: 0.598096
19:36:36: Train Epoch: 94 [30000/45000 (67%)]	Loss: 0.377462
19:36:36: Train Epoch: 94 [30000/45000 (67%)]	Loss: 0.377462
19:36:36: Train Epoch: 94 [30000/45000 (67%)]	Loss: 0.377462
19:36:41: Train Epoch: 94 [40000/45000 (89%)]	Loss: 0.579531
19:36:41: Train Epoch: 94 [40000/45000 (89%)]	Loss: 0.579531
19:36:41: Train Epoch: 94 [40000/45000 (89%)]	Loss: 0.579531
19:36:46: 
Evaluation: Average loss: 0.5928, Accuracy: 3988/5000 (79.760%)

19:36:46: 
Evaluation: Average loss: 0.5928, Accuracy: 3988/5000 (79.760%)

19:36:46: 
Evaluation: Average loss: 0.5928, Accuracy: 3988/5000 (79.760%)

19:36:46: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.17 seconds.

19:36:46: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.17 seconds.

19:36:46: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.17 seconds.

19:36:47: Train Epoch: 95 [0/45000 (0%)]	Loss: 0.430056
19:36:47: Train Epoch: 95 [0/45000 (0%)]	Loss: 0.430056
19:36:47: Train Epoch: 95 [0/45000 (0%)]	Loss: 0.430056
19:36:52: Train Epoch: 95 [10000/45000 (22%)]	Loss: 0.579389
19:36:52: Train Epoch: 95 [10000/45000 (22%)]	Loss: 0.579389
19:36:52: Train Epoch: 95 [10000/45000 (22%)]	Loss: 0.579389
19:36:58: Train Epoch: 95 [20000/45000 (44%)]	Loss: 0.428335
19:36:58: Train Epoch: 95 [20000/45000 (44%)]	Loss: 0.428335
19:36:58: Train Epoch: 95 [20000/45000 (44%)]	Loss: 0.428335
19:37:03: Train Epoch: 95 [30000/45000 (67%)]	Loss: 0.366472
19:37:03: Train Epoch: 95 [30000/45000 (67%)]	Loss: 0.366472
19:37:03: Train Epoch: 95 [30000/45000 (67%)]	Loss: 0.366472
19:37:08: Train Epoch: 95 [40000/45000 (89%)]	Loss: 0.571695
19:37:08: Train Epoch: 95 [40000/45000 (89%)]	Loss: 0.571695
19:37:08: Train Epoch: 95 [40000/45000 (89%)]	Loss: 0.571695
19:37:13: 
Evaluation: Average loss: 0.5603, Accuracy: 4024/5000 (80.480%)

19:37:13: 
Evaluation: Average loss: 0.5603, Accuracy: 4024/5000 (80.480%)

19:37:13: 
Evaluation: Average loss: 0.5603, Accuracy: 4024/5000 (80.480%)

19:37:13: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.11 seconds.

19:37:13: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.11 seconds.

19:37:13: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.11 seconds.

19:37:14: Train Epoch: 96 [0/45000 (0%)]	Loss: 0.598104
19:37:14: Train Epoch: 96 [0/45000 (0%)]	Loss: 0.598104
19:37:14: Train Epoch: 96 [0/45000 (0%)]	Loss: 0.598104
19:37:19: Train Epoch: 96 [10000/45000 (22%)]	Loss: 0.430543
19:37:19: Train Epoch: 96 [10000/45000 (22%)]	Loss: 0.430543
19:37:19: Train Epoch: 96 [10000/45000 (22%)]	Loss: 0.430543
19:37:25: Train Epoch: 96 [20000/45000 (44%)]	Loss: 0.425732
19:37:25: Train Epoch: 96 [20000/45000 (44%)]	Loss: 0.425732
19:37:25: Train Epoch: 96 [20000/45000 (44%)]	Loss: 0.425732
19:37:30: Train Epoch: 96 [30000/45000 (67%)]	Loss: 0.572051
19:37:30: Train Epoch: 96 [30000/45000 (67%)]	Loss: 0.572051
19:37:30: Train Epoch: 96 [30000/45000 (67%)]	Loss: 0.572051
19:37:35: Train Epoch: 96 [40000/45000 (89%)]	Loss: 0.456477
19:37:35: Train Epoch: 96 [40000/45000 (89%)]	Loss: 0.456477
19:37:35: Train Epoch: 96 [40000/45000 (89%)]	Loss: 0.456477
19:37:40: 
Evaluation: Average loss: 0.5942, Accuracy: 4008/5000 (80.160%)

19:37:40: 
Evaluation: Average loss: 0.5942, Accuracy: 4008/5000 (80.160%)

19:37:40: 
Evaluation: Average loss: 0.5942, Accuracy: 4008/5000 (80.160%)

19:37:40: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.86 seconds.

19:37:40: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.86 seconds.

19:37:40: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.86 seconds.

19:37:41: Train Epoch: 97 [0/45000 (0%)]	Loss: 0.394244
19:37:41: Train Epoch: 97 [0/45000 (0%)]	Loss: 0.394244
19:37:41: Train Epoch: 97 [0/45000 (0%)]	Loss: 0.394244
19:37:46: Train Epoch: 97 [10000/45000 (22%)]	Loss: 0.617254
19:37:46: Train Epoch: 97 [10000/45000 (22%)]	Loss: 0.617254
19:37:46: Train Epoch: 97 [10000/45000 (22%)]	Loss: 0.617254
19:37:52: Train Epoch: 97 [20000/45000 (44%)]	Loss: 0.442932
19:37:52: Train Epoch: 97 [20000/45000 (44%)]	Loss: 0.442932
19:37:52: Train Epoch: 97 [20000/45000 (44%)]	Loss: 0.442932
19:37:58: Train Epoch: 97 [30000/45000 (67%)]	Loss: 0.528680
19:37:58: Train Epoch: 97 [30000/45000 (67%)]	Loss: 0.528680
19:37:58: Train Epoch: 97 [30000/45000 (67%)]	Loss: 0.528680
19:38:03: Train Epoch: 97 [40000/45000 (89%)]	Loss: 0.459105
19:38:03: Train Epoch: 97 [40000/45000 (89%)]	Loss: 0.459105
19:38:03: Train Epoch: 97 [40000/45000 (89%)]	Loss: 0.459105
19:38:08: 
Evaluation: Average loss: 0.5780, Accuracy: 4006/5000 (80.120%)

19:38:08: 
Evaluation: Average loss: 0.5780, Accuracy: 4006/5000 (80.120%)

19:38:08: 
Evaluation: Average loss: 0.5780, Accuracy: 4006/5000 (80.120%)

19:38:08: Current learning rate: 0.010000000000000002. Time taken for epoch: 28.25 seconds.

19:38:08: Current learning rate: 0.010000000000000002. Time taken for epoch: 28.25 seconds.

19:38:08: Current learning rate: 0.010000000000000002. Time taken for epoch: 28.25 seconds.

19:38:09: Train Epoch: 98 [0/45000 (0%)]	Loss: 0.577683
19:38:09: Train Epoch: 98 [0/45000 (0%)]	Loss: 0.577683
19:38:09: Train Epoch: 98 [0/45000 (0%)]	Loss: 0.577683
19:38:15: Train Epoch: 98 [10000/45000 (22%)]	Loss: 0.489823
19:38:15: Train Epoch: 98 [10000/45000 (22%)]	Loss: 0.489823
19:38:15: Train Epoch: 98 [10000/45000 (22%)]	Loss: 0.489823
19:38:20: Train Epoch: 98 [20000/45000 (44%)]	Loss: 0.450913
19:38:20: Train Epoch: 98 [20000/45000 (44%)]	Loss: 0.450913
19:38:20: Train Epoch: 98 [20000/45000 (44%)]	Loss: 0.450913
19:38:26: Train Epoch: 98 [30000/45000 (67%)]	Loss: 0.601681
19:38:26: Train Epoch: 98 [30000/45000 (67%)]	Loss: 0.601681
19:38:26: Train Epoch: 98 [30000/45000 (67%)]	Loss: 0.601681
19:38:31: Train Epoch: 98 [40000/45000 (89%)]	Loss: 0.598612
19:38:31: Train Epoch: 98 [40000/45000 (89%)]	Loss: 0.598612
19:38:31: Train Epoch: 98 [40000/45000 (89%)]	Loss: 0.598612
19:38:35: 
Evaluation: Average loss: 0.6544, Accuracy: 3877/5000 (77.540%)

19:38:35: 
Evaluation: Average loss: 0.6544, Accuracy: 3877/5000 (77.540%)

19:38:35: 
Evaluation: Average loss: 0.6544, Accuracy: 3877/5000 (77.540%)

19:38:36: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.42 seconds.

19:38:36: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.42 seconds.

19:38:36: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.42 seconds.

19:38:36: Train Epoch: 99 [0/45000 (0%)]	Loss: 0.507860
19:38:36: Train Epoch: 99 [0/45000 (0%)]	Loss: 0.507860
19:38:36: Train Epoch: 99 [0/45000 (0%)]	Loss: 0.507860
19:38:42: Train Epoch: 99 [10000/45000 (22%)]	Loss: 0.389380
19:38:42: Train Epoch: 99 [10000/45000 (22%)]	Loss: 0.389380
19:38:42: Train Epoch: 99 [10000/45000 (22%)]	Loss: 0.389380
19:38:47: Train Epoch: 99 [20000/45000 (44%)]	Loss: 0.473329
19:38:47: Train Epoch: 99 [20000/45000 (44%)]	Loss: 0.473329
19:38:47: Train Epoch: 99 [20000/45000 (44%)]	Loss: 0.473329
19:38:53: Train Epoch: 99 [30000/45000 (67%)]	Loss: 0.457497
19:38:53: Train Epoch: 99 [30000/45000 (67%)]	Loss: 0.457497
19:38:53: Train Epoch: 99 [30000/45000 (67%)]	Loss: 0.457497
19:38:58: Train Epoch: 99 [40000/45000 (89%)]	Loss: 0.482036
19:38:58: Train Epoch: 99 [40000/45000 (89%)]	Loss: 0.482036
19:38:58: Train Epoch: 99 [40000/45000 (89%)]	Loss: 0.482036
19:39:03: 
Evaluation: Average loss: 0.5732, Accuracy: 4017/5000 (80.340%)

19:39:03: 
Evaluation: Average loss: 0.5732, Accuracy: 4017/5000 (80.340%)

19:39:03: 
Evaluation: Average loss: 0.5732, Accuracy: 4017/5000 (80.340%)

19:39:03: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.05 seconds.

19:39:03: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.05 seconds.

19:39:03: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.05 seconds.

19:39:03: Train Epoch: 100 [0/45000 (0%)]	Loss: 0.529248
19:39:03: Train Epoch: 100 [0/45000 (0%)]	Loss: 0.529248
19:39:03: Train Epoch: 100 [0/45000 (0%)]	Loss: 0.529248
19:39:09: Train Epoch: 100 [10000/45000 (22%)]	Loss: 0.487777
19:39:09: Train Epoch: 100 [10000/45000 (22%)]	Loss: 0.487777
19:39:09: Train Epoch: 100 [10000/45000 (22%)]	Loss: 0.487777
19:39:15: Train Epoch: 100 [20000/45000 (44%)]	Loss: 0.437973
19:39:15: Train Epoch: 100 [20000/45000 (44%)]	Loss: 0.437973
19:39:15: Train Epoch: 100 [20000/45000 (44%)]	Loss: 0.437973
19:39:20: Train Epoch: 100 [30000/45000 (67%)]	Loss: 0.551521
19:39:20: Train Epoch: 100 [30000/45000 (67%)]	Loss: 0.551521
19:39:20: Train Epoch: 100 [30000/45000 (67%)]	Loss: 0.551521
19:39:25: Train Epoch: 100 [40000/45000 (89%)]	Loss: 0.560876
19:39:25: Train Epoch: 100 [40000/45000 (89%)]	Loss: 0.560876
19:39:25: Train Epoch: 100 [40000/45000 (89%)]	Loss: 0.560876
19:39:30: 
Evaluation: Average loss: 0.5460, Accuracy: 4065/5000 (81.300%)

19:39:30: 
Evaluation: Average loss: 0.5460, Accuracy: 4065/5000 (81.300%)

19:39:30: 
Evaluation: Average loss: 0.5460, Accuracy: 4065/5000 (81.300%)

19:39:30: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.27 seconds.

19:39:30: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.27 seconds.

19:39:30: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.27 seconds.

19:39:32: 
Test evaluation: Average loss: 0.5228, Accuracy: 8218/10000 (82.180%)

19:39:32: 
Test evaluation: Average loss: 0.5228, Accuracy: 8218/10000 (82.180%)

19:39:32: 
Test evaluation: Average loss: 0.5228, Accuracy: 8218/10000 (82.180%)

19:39:32: 
Iteration end: 1/1

19:39:32: 
Iteration end: 1/1

19:39:32: 
Iteration end: 1/1

19:44:17: Namespace(batch_size=100, bench=False, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=6, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='MobileNet', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.5, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=False)
19:44:17: Namespace(batch_size=100, bench=False, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=6, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='MobileNet', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.5, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=False)
19:44:17: Namespace(batch_size=100, bench=False, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=6, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='MobileNet', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.5, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=False)
19:44:17: 


19:44:17: 


19:44:17: 


19:44:17: ================================================================================
19:44:17: ================================================================================
19:44:17: ================================================================================
19:44:17: 
Iteration start: 1/1

19:44:17: 
Iteration start: 1/1

19:44:17: 
Iteration start: 1/1

19:44:18: MobileNet(
  (features): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): ReLU(inplace=True)
    (12): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU(inplace=True)
    (15): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
    (16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (17): ReLU(inplace=True)
    (18): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (19): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): ReLU(inplace=True)
    (21): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
    (22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (23): ReLU(inplace=True)
    (24): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (25): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
    (28): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (31): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
    (34): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (35): ReLU(inplace=True)
    (36): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): ReLU(inplace=True)
    (39): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (40): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (41): ReLU(inplace=True)
    (42): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (43): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): ReLU(inplace=True)
    (45): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (46): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (47): ReLU(inplace=True)
    (48): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (49): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): ReLU(inplace=True)
    (51): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (52): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (53): ReLU(inplace=True)
    (54): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (55): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): ReLU(inplace=True)
    (57): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (58): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (59): ReLU(inplace=True)
    (60): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (61): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): ReLU(inplace=True)
    (63): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (64): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (65): ReLU(inplace=True)
    (66): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (67): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): ReLU(inplace=True)
    (69): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)
    (70): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (71): ReLU(inplace=True)
    (72): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (73): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): ReLU(inplace=True)
    (75): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)
    (76): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (77): ReLU(inplace=True)
    (78): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (79): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): ReLU(inplace=True)
    (81): AvgPool2d(kernel_size=1, stride=1, padding=0)
  )
  (fc): Linear(in_features=1024, out_features=100, bias=True)
)
19:44:18: MobileNet(
  (features): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): ReLU(inplace=True)
    (12): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU(inplace=True)
    (15): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
    (16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (17): ReLU(inplace=True)
    (18): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (19): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): ReLU(inplace=True)
    (21): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
    (22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (23): ReLU(inplace=True)
    (24): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (25): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
    (28): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (31): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
    (34): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (35): ReLU(inplace=True)
    (36): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): ReLU(inplace=True)
    (39): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (40): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (41): ReLU(inplace=True)
    (42): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (43): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): ReLU(inplace=True)
    (45): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (46): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (47): ReLU(inplace=True)
    (48): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (49): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): ReLU(inplace=True)
    (51): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (52): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (53): ReLU(inplace=True)
    (54): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (55): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): ReLU(inplace=True)
    (57): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (58): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (59): ReLU(inplace=True)
    (60): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (61): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): ReLU(inplace=True)
    (63): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (64): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (65): ReLU(inplace=True)
    (66): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (67): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): ReLU(inplace=True)
    (69): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)
    (70): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (71): ReLU(inplace=True)
    (72): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (73): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): ReLU(inplace=True)
    (75): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)
    (76): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (77): ReLU(inplace=True)
    (78): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (79): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): ReLU(inplace=True)
    (81): AvgPool2d(kernel_size=1, stride=1, padding=0)
  )
  (fc): Linear(in_features=1024, out_features=100, bias=True)
)
19:44:18: MobileNet(
  (features): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): ReLU(inplace=True)
    (12): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU(inplace=True)
    (15): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
    (16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (17): ReLU(inplace=True)
    (18): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (19): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): ReLU(inplace=True)
    (21): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
    (22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (23): ReLU(inplace=True)
    (24): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (25): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
    (28): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (31): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
    (34): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (35): ReLU(inplace=True)
    (36): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): ReLU(inplace=True)
    (39): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (40): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (41): ReLU(inplace=True)
    (42): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (43): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): ReLU(inplace=True)
    (45): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (46): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (47): ReLU(inplace=True)
    (48): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (49): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): ReLU(inplace=True)
    (51): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (52): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (53): ReLU(inplace=True)
    (54): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (55): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): ReLU(inplace=True)
    (57): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (58): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (59): ReLU(inplace=True)
    (60): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (61): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): ReLU(inplace=True)
    (63): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (64): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (65): ReLU(inplace=True)
    (66): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (67): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): ReLU(inplace=True)
    (69): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)
    (70): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (71): ReLU(inplace=True)
    (72): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (73): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): ReLU(inplace=True)
    (75): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)
    (76): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (77): ReLU(inplace=True)
    (78): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (79): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): ReLU(inplace=True)
    (81): AvgPool2d(kernel_size=1, stride=1, padding=0)
  )
  (fc): Linear(in_features=1024, out_features=100, bias=True)
)
19:44:18: ============================================================
19:44:18: ============================================================
19:44:18: ============================================================
19:44:18: MobileNet
19:44:18: MobileNet
19:44:18: MobileNet
19:44:18: ============================================================
19:44:18: ============================================================
19:44:18: ============================================================
19:44:18: ============================================================
19:44:18: ============================================================
19:44:18: ============================================================
19:44:18: Prune mode: magnitude
19:44:18: Prune mode: magnitude
19:44:18: Prune mode: magnitude
19:44:18: Growth mode: momentum
19:44:18: Growth mode: momentum
19:44:18: Growth mode: momentum
19:44:18: Redistribution mode: momentum
19:44:18: Redistribution mode: momentum
19:44:18: Redistribution mode: momentum
19:44:18: ============================================================
19:44:18: ============================================================
19:44:18: ============================================================
19:44:19: Train Epoch: 1 [0/45000 (0%)]	Loss: 4.641055
19:44:19: Train Epoch: 1 [0/45000 (0%)]	Loss: 4.641055
19:44:19: Train Epoch: 1 [0/45000 (0%)]	Loss: 4.641055
19:44:25: Train Epoch: 1 [10000/45000 (22%)]	Loss: 2.070999
19:44:25: Train Epoch: 1 [10000/45000 (22%)]	Loss: 2.070999
19:44:25: Train Epoch: 1 [10000/45000 (22%)]	Loss: 2.070999
19:44:31: Train Epoch: 1 [20000/45000 (44%)]	Loss: 2.191387
19:44:31: Train Epoch: 1 [20000/45000 (44%)]	Loss: 2.191387
19:44:31: Train Epoch: 1 [20000/45000 (44%)]	Loss: 2.191387
19:44:37: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.572804
19:44:37: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.572804
19:44:37: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.572804
19:44:42: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.645447
19:44:42: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.645447
19:44:42: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.645447
19:44:47: 
Evaluation: Average loss: 1.6791, Accuracy: 1916/5000 (38.320%)

19:44:47: 
Evaluation: Average loss: 1.6791, Accuracy: 1916/5000 (38.320%)

19:44:47: 
Evaluation: Average loss: 1.6791, Accuracy: 1916/5000 (38.320%)

19:46:08: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=False, density=0.05, epochs=6, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='MobileNet', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.5, redistribution='momentum', resume='model_best.pth.tar', save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=False)
19:46:08: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=False, density=0.05, epochs=6, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='MobileNet', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.5, redistribution='momentum', resume='model_best.pth.tar', save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=False)
19:46:08: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=False, density=0.05, epochs=6, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='MobileNet', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.5, redistribution='momentum', resume='model_best.pth.tar', save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=False)
19:46:08: 


19:46:08: 


19:46:08: 


19:46:08: ================================================================================
19:46:08: ================================================================================
19:46:08: ================================================================================
19:46:08: 
Iteration start: 1/1

19:46:08: 
Iteration start: 1/1

19:46:08: 
Iteration start: 1/1

19:46:09: MobileNet(
  (features): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): ReLU(inplace=True)
    (12): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU(inplace=True)
    (15): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
    (16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (17): ReLU(inplace=True)
    (18): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (19): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): ReLU(inplace=True)
    (21): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
    (22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (23): ReLU(inplace=True)
    (24): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (25): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
    (28): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (31): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
    (34): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (35): ReLU(inplace=True)
    (36): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): ReLU(inplace=True)
    (39): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (40): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (41): ReLU(inplace=True)
    (42): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (43): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): ReLU(inplace=True)
    (45): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (46): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (47): ReLU(inplace=True)
    (48): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (49): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): ReLU(inplace=True)
    (51): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (52): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (53): ReLU(inplace=True)
    (54): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (55): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): ReLU(inplace=True)
    (57): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (58): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (59): ReLU(inplace=True)
    (60): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (61): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): ReLU(inplace=True)
    (63): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (64): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (65): ReLU(inplace=True)
    (66): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (67): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): ReLU(inplace=True)
    (69): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)
    (70): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (71): ReLU(inplace=True)
    (72): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (73): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): ReLU(inplace=True)
    (75): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)
    (76): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (77): ReLU(inplace=True)
    (78): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (79): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): ReLU(inplace=True)
    (81): AvgPool2d(kernel_size=1, stride=1, padding=0)
  )
  (fc): Linear(in_features=1024, out_features=100, bias=True)
)
19:46:09: MobileNet(
  (features): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): ReLU(inplace=True)
    (12): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU(inplace=True)
    (15): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
    (16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (17): ReLU(inplace=True)
    (18): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (19): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): ReLU(inplace=True)
    (21): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
    (22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (23): ReLU(inplace=True)
    (24): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (25): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
    (28): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (31): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
    (34): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (35): ReLU(inplace=True)
    (36): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): ReLU(inplace=True)
    (39): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (40): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (41): ReLU(inplace=True)
    (42): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (43): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): ReLU(inplace=True)
    (45): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (46): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (47): ReLU(inplace=True)
    (48): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (49): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): ReLU(inplace=True)
    (51): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (52): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (53): ReLU(inplace=True)
    (54): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (55): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): ReLU(inplace=True)
    (57): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (58): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (59): ReLU(inplace=True)
    (60): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (61): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): ReLU(inplace=True)
    (63): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (64): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (65): ReLU(inplace=True)
    (66): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (67): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): ReLU(inplace=True)
    (69): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)
    (70): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (71): ReLU(inplace=True)
    (72): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (73): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): ReLU(inplace=True)
    (75): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)
    (76): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (77): ReLU(inplace=True)
    (78): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (79): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): ReLU(inplace=True)
    (81): AvgPool2d(kernel_size=1, stride=1, padding=0)
  )
  (fc): Linear(in_features=1024, out_features=100, bias=True)
)
19:46:09: MobileNet(
  (features): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): ReLU(inplace=True)
    (12): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU(inplace=True)
    (15): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
    (16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (17): ReLU(inplace=True)
    (18): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (19): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): ReLU(inplace=True)
    (21): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
    (22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (23): ReLU(inplace=True)
    (24): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (25): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
    (28): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (31): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
    (34): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (35): ReLU(inplace=True)
    (36): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): ReLU(inplace=True)
    (39): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (40): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (41): ReLU(inplace=True)
    (42): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (43): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): ReLU(inplace=True)
    (45): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (46): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (47): ReLU(inplace=True)
    (48): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (49): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): ReLU(inplace=True)
    (51): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (52): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (53): ReLU(inplace=True)
    (54): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (55): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): ReLU(inplace=True)
    (57): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (58): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (59): ReLU(inplace=True)
    (60): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (61): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): ReLU(inplace=True)
    (63): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (64): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (65): ReLU(inplace=True)
    (66): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (67): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): ReLU(inplace=True)
    (69): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)
    (70): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (71): ReLU(inplace=True)
    (72): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (73): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): ReLU(inplace=True)
    (75): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)
    (76): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (77): ReLU(inplace=True)
    (78): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (79): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): ReLU(inplace=True)
    (81): AvgPool2d(kernel_size=1, stride=1, padding=0)
  )
  (fc): Linear(in_features=1024, out_features=100, bias=True)
)
19:46:09: ============================================================
19:46:09: ============================================================
19:46:09: ============================================================
19:46:09: MobileNet
19:46:09: MobileNet
19:46:09: MobileNet
19:46:09: ============================================================
19:46:09: ============================================================
19:46:09: ============================================================
19:46:09: ============================================================
19:46:09: ============================================================
19:46:09: ============================================================
19:46:09: Prune mode: magnitude
19:46:09: Prune mode: magnitude
19:46:09: Prune mode: magnitude
19:46:09: Growth mode: momentum
19:46:09: Growth mode: momentum
19:46:09: Growth mode: momentum
19:46:09: Redistribution mode: momentum
19:46:09: Redistribution mode: momentum
19:46:09: Redistribution mode: momentum
19:46:09: ============================================================
19:46:09: ============================================================
19:46:09: ============================================================
19:46:09: => loading checkpoint: 'checkpoint/MobileNet/model_best.pth.tar'
19:46:09: => loading checkpoint: 'checkpoint/MobileNet/model_best.pth.tar'
19:46:09: => loading checkpoint: 'checkpoint/MobileNet/model_best.pth.tar'
19:46:09: => loaded checkpoint 'checkpoint/MobileNet/model_best.pth.tar' (epoch 2)
19:46:09: => loaded checkpoint 'checkpoint/MobileNet/model_best.pth.tar' (epoch 2)
19:46:09: => loaded checkpoint 'checkpoint/MobileNet/model_best.pth.tar' (epoch 2)
19:46:09: Testing...
19:46:09: Testing...
19:46:09: Testing...
19:46:14: 
Evaluation: Average loss: 1.6214, Accuracy: 4107/10000 (41.070%)

19:46:14: 
Evaluation: Average loss: 1.6214, Accuracy: 4107/10000 (41.070%)

19:46:14: 
Evaluation: Average loss: 1.6214, Accuracy: 4107/10000 (41.070%)

19:48:01: Train Epoch: 1 [0/45000 (0%)]	Loss: 3.608593
19:48:01: Train Epoch: 1 [0/45000 (0%)]	Loss: 3.608593
19:48:01: Train Epoch: 1 [0/45000 (0%)]	Loss: 3.608593
19:48:08: Train Epoch: 1 [10000/45000 (22%)]	Loss: 2.404832
19:48:08: Train Epoch: 1 [10000/45000 (22%)]	Loss: 2.404832
19:48:08: Train Epoch: 1 [10000/45000 (22%)]	Loss: 2.404832
19:48:15: Train Epoch: 1 [20000/45000 (44%)]	Loss: 2.352512
19:48:15: Train Epoch: 1 [20000/45000 (44%)]	Loss: 2.352512
19:48:15: Train Epoch: 1 [20000/45000 (44%)]	Loss: 2.352512
19:48:22: Train Epoch: 1 [30000/45000 (67%)]	Loss: 2.351837
19:48:22: Train Epoch: 1 [30000/45000 (67%)]	Loss: 2.351837
19:48:22: Train Epoch: 1 [30000/45000 (67%)]	Loss: 2.351837
19:48:29: Train Epoch: 1 [40000/45000 (89%)]	Loss: nan
19:48:29: Train Epoch: 1 [40000/45000 (89%)]	Loss: nan
19:48:29: Train Epoch: 1 [40000/45000 (89%)]	Loss: nan
19:48:35: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

19:48:35: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

19:48:35: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

