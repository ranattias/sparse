19:44:17: Namespace(batch_size=100, bench=False, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=6, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='MobileNet', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.5, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=False)
19:44:17: 


19:44:17: ================================================================================
19:44:17: 
Iteration start: 1/1

19:44:18: MobileNet(
  (features): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): ReLU(inplace=True)
    (12): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU(inplace=True)
    (15): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
    (16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (17): ReLU(inplace=True)
    (18): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (19): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): ReLU(inplace=True)
    (21): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
    (22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (23): ReLU(inplace=True)
    (24): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (25): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
    (28): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (31): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
    (34): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (35): ReLU(inplace=True)
    (36): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): ReLU(inplace=True)
    (39): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (40): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (41): ReLU(inplace=True)
    (42): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (43): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): ReLU(inplace=True)
    (45): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (46): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (47): ReLU(inplace=True)
    (48): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (49): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): ReLU(inplace=True)
    (51): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (52): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (53): ReLU(inplace=True)
    (54): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (55): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): ReLU(inplace=True)
    (57): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (58): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (59): ReLU(inplace=True)
    (60): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (61): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): ReLU(inplace=True)
    (63): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (64): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (65): ReLU(inplace=True)
    (66): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (67): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): ReLU(inplace=True)
    (69): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)
    (70): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (71): ReLU(inplace=True)
    (72): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (73): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): ReLU(inplace=True)
    (75): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)
    (76): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (77): ReLU(inplace=True)
    (78): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (79): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): ReLU(inplace=True)
    (81): AvgPool2d(kernel_size=1, stride=1, padding=0)
  )
  (fc): Linear(in_features=1024, out_features=100, bias=True)
)
19:44:18: ============================================================
19:44:18: MobileNet
19:44:18: ============================================================
19:44:18: ============================================================
19:44:18: Prune mode: magnitude
19:44:18: Growth mode: momentum
19:44:18: Redistribution mode: momentum
19:44:18: ============================================================
19:44:19: Train Epoch: 1 [0/45000 (0%)]	Loss: 4.641055
19:44:25: Train Epoch: 1 [10000/45000 (22%)]	Loss: 2.070999
19:44:31: Train Epoch: 1 [20000/45000 (44%)]	Loss: 2.191387
19:44:37: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.572804
19:44:42: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.645447
19:44:47: 
Evaluation: Average loss: 1.6791, Accuracy: 1916/5000 (38.320%)

19:46:08: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=False, density=0.05, epochs=6, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='MobileNet', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.5, redistribution='momentum', resume='model_best.pth.tar', save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=False)
19:46:08: 


19:46:08: ================================================================================
19:46:08: 
Iteration start: 1/1

19:46:09: MobileNet(
  (features): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): ReLU(inplace=True)
    (12): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU(inplace=True)
    (15): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
    (16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (17): ReLU(inplace=True)
    (18): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (19): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): ReLU(inplace=True)
    (21): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
    (22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (23): ReLU(inplace=True)
    (24): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (25): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
    (28): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (31): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
    (34): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (35): ReLU(inplace=True)
    (36): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): ReLU(inplace=True)
    (39): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (40): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (41): ReLU(inplace=True)
    (42): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (43): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): ReLU(inplace=True)
    (45): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (46): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (47): ReLU(inplace=True)
    (48): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (49): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): ReLU(inplace=True)
    (51): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (52): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (53): ReLU(inplace=True)
    (54): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (55): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): ReLU(inplace=True)
    (57): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (58): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (59): ReLU(inplace=True)
    (60): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (61): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): ReLU(inplace=True)
    (63): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (64): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (65): ReLU(inplace=True)
    (66): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (67): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): ReLU(inplace=True)
    (69): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)
    (70): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (71): ReLU(inplace=True)
    (72): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (73): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): ReLU(inplace=True)
    (75): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)
    (76): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (77): ReLU(inplace=True)
    (78): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (79): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): ReLU(inplace=True)
    (81): AvgPool2d(kernel_size=1, stride=1, padding=0)
  )
  (fc): Linear(in_features=1024, out_features=100, bias=True)
)
19:46:09: ============================================================
19:46:09: MobileNet
19:46:09: ============================================================
19:46:09: ============================================================
19:46:09: Prune mode: magnitude
19:46:09: Growth mode: momentum
19:46:09: Redistribution mode: momentum
19:46:09: ============================================================
19:46:09: => loading checkpoint: 'checkpoint/MobileNet/model_best.pth.tar'
19:46:09: => loaded checkpoint 'checkpoint/MobileNet/model_best.pth.tar' (epoch 2)
19:46:09: Testing...
19:46:14: 
Evaluation: Average loss: 1.6214, Accuracy: 4107/10000 (41.070%)

19:48:01: Train Epoch: 1 [0/45000 (0%)]	Loss: 3.608593
19:48:08: Train Epoch: 1 [10000/45000 (22%)]	Loss: 2.404832
19:48:15: Train Epoch: 1 [20000/45000 (44%)]	Loss: 2.352512
19:48:22: Train Epoch: 1 [30000/45000 (67%)]	Loss: 2.351837
19:48:29: Train Epoch: 1 [40000/45000 (89%)]	Loss: nan
19:48:35: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

