19:28:08: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='vgg-d', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
19:28:08: 


19:28:08: ================================================================================
19:28:08: 
Iteration start: 1/1

19:28:27: VGG16(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
19:28:27: ============================================================
19:28:27: vgg-d
19:28:27: ============================================================
19:28:27: ============================================================
19:28:27: Prune mode: magnitude
19:28:27: Growth mode: momentum
19:28:27: Redistribution mode: momentum
19:28:27: ============================================================
19:28:28: Train Epoch: 1 [0/45000 (0%)]	Loss: 2.493264
19:28:33: Train Epoch: 1 [10000/45000 (22%)]	Loss: 2.738365
19:28:38: Train Epoch: 1 [20000/45000 (44%)]	Loss: 2.167743
19:28:43: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.905293
19:28:48: Train Epoch: 1 [40000/45000 (89%)]	Loss: 2.082934
19:28:53: 
Evaluation: Average loss: 1.8016, Accuracy: 1380/5000 (27.600%)

19:28:53: Current learning rate: 0.1. Time taken for epoch: 26.72 seconds.

19:28:54: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.963365
19:29:00: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.778294
19:29:05: Train Epoch: 2 [20000/45000 (44%)]	Loss: 1.846153
19:29:10: Train Epoch: 2 [30000/45000 (67%)]	Loss: 1.707611
19:29:15: Train Epoch: 2 [40000/45000 (89%)]	Loss: 1.485055
19:29:20: 
Evaluation: Average loss: 1.5862, Accuracy: 1896/5000 (37.920%)

19:29:20: Current learning rate: 0.1. Time taken for epoch: 26.50 seconds.

19:29:20: Train Epoch: 3 [0/45000 (0%)]	Loss: 1.751657
19:29:26: Train Epoch: 3 [10000/45000 (22%)]	Loss: 1.451386
19:29:31: Train Epoch: 3 [20000/45000 (44%)]	Loss: 1.523886
19:29:36: Train Epoch: 3 [30000/45000 (67%)]	Loss: 1.360425
19:29:41: Train Epoch: 3 [40000/45000 (89%)]	Loss: 1.441209
19:29:46: 
Evaluation: Average loss: 1.4708, Accuracy: 2321/5000 (46.420%)

19:29:46: Current learning rate: 0.1. Time taken for epoch: 26.11 seconds.

19:29:47: Train Epoch: 4 [0/45000 (0%)]	Loss: 1.335889
19:29:52: Train Epoch: 4 [10000/45000 (22%)]	Loss: 1.214372
19:29:57: Train Epoch: 4 [20000/45000 (44%)]	Loss: 1.326009
19:30:03: Train Epoch: 4 [30000/45000 (67%)]	Loss: 1.140544
19:30:08: Train Epoch: 4 [40000/45000 (89%)]	Loss: 1.482177
19:30:12: 
Evaluation: Average loss: 1.4156, Accuracy: 2502/5000 (50.040%)

19:30:12: Current learning rate: 0.1. Time taken for epoch: 26.35 seconds.

19:30:13: Train Epoch: 5 [0/45000 (0%)]	Loss: 0.961799
19:30:18: Train Epoch: 5 [10000/45000 (22%)]	Loss: 1.221135
19:30:23: Train Epoch: 5 [20000/45000 (44%)]	Loss: 1.167456
19:30:28: Train Epoch: 5 [30000/45000 (67%)]	Loss: 0.968255
19:30:34: Train Epoch: 5 [40000/45000 (89%)]	Loss: 1.132036
19:30:38: 
Evaluation: Average loss: 1.2306, Accuracy: 2884/5000 (57.680%)

19:30:38: Current learning rate: 0.1. Time taken for epoch: 25.89 seconds.

19:30:39: Train Epoch: 6 [0/45000 (0%)]	Loss: 0.949157
19:30:44: Train Epoch: 6 [10000/45000 (22%)]	Loss: 1.067495
19:30:49: Train Epoch: 6 [20000/45000 (44%)]	Loss: 0.831528
19:30:55: Train Epoch: 6 [30000/45000 (67%)]	Loss: 0.812659
19:31:00: Train Epoch: 6 [40000/45000 (89%)]	Loss: 0.916204
19:31:05: 
Evaluation: Average loss: 0.9318, Accuracy: 3399/5000 (67.980%)

19:31:05: Current learning rate: 0.1. Time taken for epoch: 26.83 seconds.

19:31:06: Train Epoch: 7 [0/45000 (0%)]	Loss: 1.020432
19:31:11: Train Epoch: 7 [10000/45000 (22%)]	Loss: 0.943190
19:31:16: Train Epoch: 7 [20000/45000 (44%)]	Loss: 0.812050
19:31:21: Train Epoch: 7 [30000/45000 (67%)]	Loss: 0.786579
19:31:26: Train Epoch: 7 [40000/45000 (89%)]	Loss: 0.844572
19:31:31: 
Evaluation: Average loss: 1.1472, Accuracy: 3060/5000 (61.200%)

19:31:31: Current learning rate: 0.1. Time taken for epoch: 25.95 seconds.

19:31:32: Train Epoch: 8 [0/45000 (0%)]	Loss: 0.824685
19:31:37: Train Epoch: 8 [10000/45000 (22%)]	Loss: 0.654951
19:31:42: Train Epoch: 8 [20000/45000 (44%)]	Loss: 0.881126
19:31:47: Train Epoch: 8 [30000/45000 (67%)]	Loss: 1.029469
19:31:53: Train Epoch: 8 [40000/45000 (89%)]	Loss: 0.794186
19:31:57: 
Evaluation: Average loss: 0.8877, Accuracy: 3558/5000 (71.160%)

19:31:58: Current learning rate: 0.1. Time taken for epoch: 26.65 seconds.

19:31:58: Train Epoch: 9 [0/45000 (0%)]	Loss: 0.743898
19:32:04: Train Epoch: 9 [10000/45000 (22%)]	Loss: 0.914530
19:32:09: Train Epoch: 9 [20000/45000 (44%)]	Loss: 0.716129
19:32:14: Train Epoch: 9 [30000/45000 (67%)]	Loss: 0.685407
19:32:19: Train Epoch: 9 [40000/45000 (89%)]	Loss: 0.694855
19:32:24: 
Evaluation: Average loss: 0.7867, Accuracy: 3705/5000 (74.100%)

19:32:24: Current learning rate: 0.1. Time taken for epoch: 26.39 seconds.

19:32:24: Train Epoch: 10 [0/45000 (0%)]	Loss: 0.758604
19:32:30: Train Epoch: 10 [10000/45000 (22%)]	Loss: 0.733068
19:32:35: Train Epoch: 10 [20000/45000 (44%)]	Loss: 0.870073
19:32:40: Train Epoch: 10 [30000/45000 (67%)]	Loss: 1.005277
19:32:45: Train Epoch: 10 [40000/45000 (89%)]	Loss: 0.851800
19:32:50: 
Evaluation: Average loss: 0.9543, Accuracy: 3459/5000 (69.180%)

19:32:50: Current learning rate: 0.1. Time taken for epoch: 26.17 seconds.

19:32:51: Train Epoch: 11 [0/45000 (0%)]	Loss: 0.680628
19:32:56: Train Epoch: 11 [10000/45000 (22%)]	Loss: 0.834070
19:33:02: Train Epoch: 11 [20000/45000 (44%)]	Loss: 0.732154
19:33:07: Train Epoch: 11 [30000/45000 (67%)]	Loss: 0.533085
19:33:12: Train Epoch: 11 [40000/45000 (89%)]	Loss: 0.669626
19:33:17: 
Evaluation: Average loss: 1.0216, Accuracy: 3336/5000 (66.720%)

19:33:17: Current learning rate: 0.1. Time taken for epoch: 26.70 seconds.

19:33:17: Train Epoch: 12 [0/45000 (0%)]	Loss: 0.712650
19:33:23: Train Epoch: 12 [10000/45000 (22%)]	Loss: 0.631942
19:33:28: Train Epoch: 12 [20000/45000 (44%)]	Loss: 0.727243
19:33:33: Train Epoch: 12 [30000/45000 (67%)]	Loss: 0.717468
19:33:38: Train Epoch: 12 [40000/45000 (89%)]	Loss: 0.808683
19:33:43: 
Evaluation: Average loss: 0.8370, Accuracy: 3662/5000 (73.240%)

19:33:43: Current learning rate: 0.1. Time taken for epoch: 26.40 seconds.

19:33:44: Train Epoch: 13 [0/45000 (0%)]	Loss: 0.693306
19:33:49: Train Epoch: 13 [10000/45000 (22%)]	Loss: 0.706110
19:33:55: Train Epoch: 13 [20000/45000 (44%)]	Loss: 0.818164
19:34:00: Train Epoch: 13 [30000/45000 (67%)]	Loss: 0.884984
19:34:05: Train Epoch: 13 [40000/45000 (89%)]	Loss: 0.536444
19:34:10: 
Evaluation: Average loss: 0.7781, Accuracy: 3695/5000 (73.900%)

19:34:10: Current learning rate: 0.1. Time taken for epoch: 26.61 seconds.

19:34:11: Train Epoch: 14 [0/45000 (0%)]	Loss: 0.561677
19:34:16: Train Epoch: 14 [10000/45000 (22%)]	Loss: 0.791149
19:34:21: Train Epoch: 14 [20000/45000 (44%)]	Loss: 0.559130
19:34:26: Train Epoch: 14 [30000/45000 (67%)]	Loss: 0.565443
19:34:31: Train Epoch: 14 [40000/45000 (89%)]	Loss: 0.552625
19:34:36: 
Evaluation: Average loss: 0.8967, Accuracy: 3448/5000 (68.960%)

19:34:36: Current learning rate: 0.1. Time taken for epoch: 26.10 seconds.

19:34:37: Train Epoch: 15 [0/45000 (0%)]	Loss: 0.605419
19:34:42: Train Epoch: 15 [10000/45000 (22%)]	Loss: 0.637814
19:34:47: Train Epoch: 15 [20000/45000 (44%)]	Loss: 0.453116
19:34:53: Train Epoch: 15 [30000/45000 (67%)]	Loss: 0.576446
19:34:58: Train Epoch: 15 [40000/45000 (89%)]	Loss: 0.605671
19:35:03: 
Evaluation: Average loss: 0.8644, Accuracy: 3549/5000 (70.980%)

19:35:03: Current learning rate: 0.1. Time taken for epoch: 26.90 seconds.

19:35:04: Train Epoch: 16 [0/45000 (0%)]	Loss: 0.577202
19:35:09: Train Epoch: 16 [10000/45000 (22%)]	Loss: 0.597375
19:35:14: Train Epoch: 16 [20000/45000 (44%)]	Loss: 0.586226
19:35:19: Train Epoch: 16 [30000/45000 (67%)]	Loss: 0.601786
19:35:24: Train Epoch: 16 [40000/45000 (89%)]	Loss: 0.787172
19:35:29: 
Evaluation: Average loss: 0.8669, Accuracy: 3620/5000 (72.400%)

19:35:29: Current learning rate: 0.1. Time taken for epoch: 26.11 seconds.

19:35:30: Train Epoch: 17 [0/45000 (0%)]	Loss: 0.571058
19:35:35: Train Epoch: 17 [10000/45000 (22%)]	Loss: 0.606778
19:35:40: Train Epoch: 17 [20000/45000 (44%)]	Loss: 0.552147
19:35:45: Train Epoch: 17 [30000/45000 (67%)]	Loss: 0.610719
19:35:50: Train Epoch: 17 [40000/45000 (89%)]	Loss: 0.614529
19:35:55: 
Evaluation: Average loss: 0.7492, Accuracy: 3771/5000 (75.420%)

19:35:55: Current learning rate: 0.1. Time taken for epoch: 26.30 seconds.

19:35:56: Train Epoch: 18 [0/45000 (0%)]	Loss: 0.617111
19:36:02: Train Epoch: 18 [10000/45000 (22%)]	Loss: 0.510923
19:36:07: Train Epoch: 18 [20000/45000 (44%)]	Loss: 0.559936
19:36:12: Train Epoch: 18 [30000/45000 (67%)]	Loss: 0.774619
19:36:17: Train Epoch: 18 [40000/45000 (89%)]	Loss: 0.594095
19:36:22: 
Evaluation: Average loss: 0.8835, Accuracy: 3587/5000 (71.740%)

19:36:22: Current learning rate: 0.1. Time taken for epoch: 26.73 seconds.

19:36:23: Train Epoch: 19 [0/45000 (0%)]	Loss: 0.578244
19:36:28: Train Epoch: 19 [10000/45000 (22%)]	Loss: 0.408513
19:36:33: Train Epoch: 19 [20000/45000 (44%)]	Loss: 0.813416
19:36:38: Train Epoch: 19 [30000/45000 (67%)]	Loss: 0.589641
19:36:43: Train Epoch: 19 [40000/45000 (89%)]	Loss: 0.504046
19:36:48: 
Evaluation: Average loss: 0.7187, Accuracy: 3856/5000 (77.120%)

19:36:48: Current learning rate: 0.1. Time taken for epoch: 26.23 seconds.

19:36:49: Train Epoch: 20 [0/45000 (0%)]	Loss: 0.655626
19:36:54: Train Epoch: 20 [10000/45000 (22%)]	Loss: 0.424118
19:37:00: Train Epoch: 20 [20000/45000 (44%)]	Loss: 0.694585
19:37:05: Train Epoch: 20 [30000/45000 (67%)]	Loss: 0.515053
19:37:10: Train Epoch: 20 [40000/45000 (89%)]	Loss: 0.674632
19:37:15: 
Evaluation: Average loss: 0.7334, Accuracy: 3817/5000 (76.340%)

19:37:15: Current learning rate: 0.1. Time taken for epoch: 26.62 seconds.

19:37:15: Train Epoch: 21 [0/45000 (0%)]	Loss: 0.675015
19:37:21: Train Epoch: 21 [10000/45000 (22%)]	Loss: 0.675165
19:37:26: Train Epoch: 21 [20000/45000 (44%)]	Loss: 0.544697
19:37:31: Train Epoch: 21 [30000/45000 (67%)]	Loss: 0.832709
19:37:36: Train Epoch: 21 [40000/45000 (89%)]	Loss: 0.654217
19:37:41: 
Evaluation: Average loss: 0.6747, Accuracy: 3898/5000 (77.960%)

19:37:41: Current learning rate: 0.1. Time taken for epoch: 26.33 seconds.

19:37:42: Train Epoch: 22 [0/45000 (0%)]	Loss: 0.520183
19:37:47: Train Epoch: 22 [10000/45000 (22%)]	Loss: 0.514409
19:37:53: Train Epoch: 22 [20000/45000 (44%)]	Loss: 0.617631
19:37:58: Train Epoch: 22 [30000/45000 (67%)]	Loss: 0.578194
19:38:03: Train Epoch: 22 [40000/45000 (89%)]	Loss: 0.628963
19:38:08: 
Evaluation: Average loss: 0.7535, Accuracy: 3799/5000 (75.980%)

19:38:08: Current learning rate: 0.1. Time taken for epoch: 26.97 seconds.

19:38:09: Train Epoch: 23 [0/45000 (0%)]	Loss: 0.622728
19:38:14: Train Epoch: 23 [10000/45000 (22%)]	Loss: 0.630768
19:38:19: Train Epoch: 23 [20000/45000 (44%)]	Loss: 0.664174
19:38:25: Train Epoch: 23 [30000/45000 (67%)]	Loss: 0.542975
19:38:30: Train Epoch: 23 [40000/45000 (89%)]	Loss: 0.488577
19:38:34: 
Evaluation: Average loss: 0.6968, Accuracy: 3871/5000 (77.420%)

19:38:35: Current learning rate: 0.1. Time taken for epoch: 26.26 seconds.

19:38:35: Train Epoch: 24 [0/45000 (0%)]	Loss: 0.513802
19:38:40: Train Epoch: 24 [10000/45000 (22%)]	Loss: 0.490813
19:38:46: Train Epoch: 24 [20000/45000 (44%)]	Loss: 0.538498
19:38:51: Train Epoch: 24 [30000/45000 (67%)]	Loss: 0.435380
19:38:56: Train Epoch: 24 [40000/45000 (89%)]	Loss: 0.612956
19:39:01: 
Evaluation: Average loss: 0.7226, Accuracy: 3820/5000 (76.400%)

19:39:01: Current learning rate: 0.1. Time taken for epoch: 26.91 seconds.

19:39:02: Train Epoch: 25 [0/45000 (0%)]	Loss: 0.557977
19:39:07: Train Epoch: 25 [10000/45000 (22%)]	Loss: 0.633355
19:39:13: Train Epoch: 25 [20000/45000 (44%)]	Loss: 0.490038
19:39:18: Train Epoch: 25 [30000/45000 (67%)]	Loss: 0.618815
19:39:23: Train Epoch: 25 [40000/45000 (89%)]	Loss: 0.434685
19:39:28: 
Evaluation: Average loss: 0.7921, Accuracy: 3721/5000 (74.420%)

19:39:28: Current learning rate: 0.1. Time taken for epoch: 26.44 seconds.

19:39:28: Train Epoch: 26 [0/45000 (0%)]	Loss: 0.562804
19:39:34: Train Epoch: 26 [10000/45000 (22%)]	Loss: 0.768419
19:39:39: Train Epoch: 26 [20000/45000 (44%)]	Loss: 0.460446
19:39:44: Train Epoch: 26 [30000/45000 (67%)]	Loss: 0.742818
19:39:49: Train Epoch: 26 [40000/45000 (89%)]	Loss: 0.685259
19:39:54: 
Evaluation: Average loss: 0.7530, Accuracy: 3777/5000 (75.540%)

19:39:54: Current learning rate: 0.1. Time taken for epoch: 26.51 seconds.

19:39:55: Train Epoch: 27 [0/45000 (0%)]	Loss: 0.461147
19:40:01: Train Epoch: 27 [10000/45000 (22%)]	Loss: 0.635155
19:40:06: Train Epoch: 27 [20000/45000 (44%)]	Loss: 0.627344
19:40:11: Train Epoch: 27 [30000/45000 (67%)]	Loss: 0.660746
19:40:16: Train Epoch: 27 [40000/45000 (89%)]	Loss: 0.503107
19:40:21: 
Evaluation: Average loss: 0.7214, Accuracy: 3837/5000 (76.740%)

19:40:21: Current learning rate: 0.1. Time taken for epoch: 26.73 seconds.

19:40:22: Train Epoch: 28 [0/45000 (0%)]	Loss: 0.691393
19:40:27: Train Epoch: 28 [10000/45000 (22%)]	Loss: 0.563081
19:40:32: Train Epoch: 28 [20000/45000 (44%)]	Loss: 0.410928
19:40:38: Train Epoch: 28 [30000/45000 (67%)]	Loss: 0.589348
19:40:43: Train Epoch: 28 [40000/45000 (89%)]	Loss: 0.481074
19:40:47: 
Evaluation: Average loss: 0.7329, Accuracy: 3784/5000 (75.680%)

19:40:48: Current learning rate: 0.1. Time taken for epoch: 26.56 seconds.

19:40:48: Train Epoch: 29 [0/45000 (0%)]	Loss: 0.423425
19:40:54: Train Epoch: 29 [10000/45000 (22%)]	Loss: 0.564791
19:40:59: Train Epoch: 29 [20000/45000 (44%)]	Loss: 0.512702
19:41:05: Train Epoch: 29 [30000/45000 (67%)]	Loss: 0.609033
19:41:10: Train Epoch: 29 [40000/45000 (89%)]	Loss: 0.634735
19:41:14: 
Evaluation: Average loss: 0.8910, Accuracy: 3479/5000 (69.580%)

19:41:14: Current learning rate: 0.1. Time taken for epoch: 26.79 seconds.

19:41:15: Train Epoch: 30 [0/45000 (0%)]	Loss: 0.550075
19:41:20: Train Epoch: 30 [10000/45000 (22%)]	Loss: 0.775420
19:41:26: Train Epoch: 30 [20000/45000 (44%)]	Loss: 0.553968
19:41:31: Train Epoch: 30 [30000/45000 (67%)]	Loss: 0.729862
19:41:36: Train Epoch: 30 [40000/45000 (89%)]	Loss: 0.662097
19:41:41: 
Evaluation: Average loss: 0.6541, Accuracy: 3952/5000 (79.040%)

19:41:41: Current learning rate: 0.1. Time taken for epoch: 26.51 seconds.

19:41:42: Train Epoch: 31 [0/45000 (0%)]	Loss: 0.771778
19:41:47: Train Epoch: 31 [10000/45000 (22%)]	Loss: 0.514604
19:41:53: Train Epoch: 31 [20000/45000 (44%)]	Loss: 0.403601
19:41:58: Train Epoch: 31 [30000/45000 (67%)]	Loss: 0.495670
19:42:03: Train Epoch: 31 [40000/45000 (89%)]	Loss: 0.663564
19:42:08: 
Evaluation: Average loss: 0.7410, Accuracy: 3840/5000 (76.800%)

19:42:08: Current learning rate: 0.1. Time taken for epoch: 27.13 seconds.

19:42:09: Train Epoch: 32 [0/45000 (0%)]	Loss: 0.431618
19:42:14: Train Epoch: 32 [10000/45000 (22%)]	Loss: 0.650993
19:42:19: Train Epoch: 32 [20000/45000 (44%)]	Loss: 0.404506
19:42:24: Train Epoch: 32 [30000/45000 (67%)]	Loss: 0.522452
19:42:30: Train Epoch: 32 [40000/45000 (89%)]	Loss: 0.325610
19:42:34: 
Evaluation: Average loss: 0.6919, Accuracy: 3909/5000 (78.180%)

19:42:34: Current learning rate: 0.1. Time taken for epoch: 26.36 seconds.

19:42:35: Train Epoch: 33 [0/45000 (0%)]	Loss: 0.391515
19:42:40: Train Epoch: 33 [10000/45000 (22%)]	Loss: 0.591015
19:42:46: Train Epoch: 33 [20000/45000 (44%)]	Loss: 0.532971
19:42:51: Train Epoch: 33 [30000/45000 (67%)]	Loss: 0.474166
19:42:56: Train Epoch: 33 [40000/45000 (89%)]	Loss: 0.678126
19:43:01: 
Evaluation: Average loss: 0.8101, Accuracy: 3756/5000 (75.120%)

19:43:02: Current learning rate: 0.1. Time taken for epoch: 27.17 seconds.

19:43:02: Train Epoch: 34 [0/45000 (0%)]	Loss: 0.655395
19:43:08: Train Epoch: 34 [10000/45000 (22%)]	Loss: 0.538464
19:43:13: Train Epoch: 34 [20000/45000 (44%)]	Loss: 0.640904
19:43:18: Train Epoch: 34 [30000/45000 (67%)]	Loss: 0.397328
19:43:23: Train Epoch: 34 [40000/45000 (89%)]	Loss: 0.604788
19:43:28: 
Evaluation: Average loss: 0.7064, Accuracy: 3925/5000 (78.500%)

19:43:28: Current learning rate: 0.1. Time taken for epoch: 26.53 seconds.

19:43:29: Train Epoch: 35 [0/45000 (0%)]	Loss: 0.461705
19:43:34: Train Epoch: 35 [10000/45000 (22%)]	Loss: 0.622514
19:43:39: Train Epoch: 35 [20000/45000 (44%)]	Loss: 0.601327
19:43:45: Train Epoch: 35 [30000/45000 (67%)]	Loss: 0.416607
19:43:50: Train Epoch: 35 [40000/45000 (89%)]	Loss: 0.416740
19:43:55: 
Evaluation: Average loss: 0.8832, Accuracy: 3583/5000 (71.660%)

19:43:55: Current learning rate: 0.1. Time taken for epoch: 26.68 seconds.

19:43:55: Train Epoch: 36 [0/45000 (0%)]	Loss: 0.410348
19:44:01: Train Epoch: 36 [10000/45000 (22%)]	Loss: 0.588602
19:44:06: Train Epoch: 36 [20000/45000 (44%)]	Loss: 0.436902
19:44:12: Train Epoch: 36 [30000/45000 (67%)]	Loss: 0.491088
19:44:17: Train Epoch: 36 [40000/45000 (89%)]	Loss: 0.620781
19:44:21: 
Evaluation: Average loss: 0.8045, Accuracy: 3756/5000 (75.120%)

19:44:22: Current learning rate: 0.1. Time taken for epoch: 26.77 seconds.

19:44:22: Train Epoch: 37 [0/45000 (0%)]	Loss: 0.564511
19:44:28: Train Epoch: 37 [10000/45000 (22%)]	Loss: 0.587036
19:44:33: Train Epoch: 37 [20000/45000 (44%)]	Loss: 0.433252
19:44:38: Train Epoch: 37 [30000/45000 (67%)]	Loss: 0.600356
19:44:44: Train Epoch: 37 [40000/45000 (89%)]	Loss: 0.417604
19:44:48: 
Evaluation: Average loss: 0.7155, Accuracy: 3875/5000 (77.500%)

19:44:48: Current learning rate: 0.1. Time taken for epoch: 26.86 seconds.

19:44:49: Train Epoch: 38 [0/45000 (0%)]	Loss: 0.643673
19:44:55: Train Epoch: 38 [10000/45000 (22%)]	Loss: 0.414572
19:45:00: Train Epoch: 38 [20000/45000 (44%)]	Loss: 0.486018
19:45:05: Train Epoch: 38 [30000/45000 (67%)]	Loss: 0.501603
19:45:11: Train Epoch: 38 [40000/45000 (89%)]	Loss: 0.434206
19:45:15: 
Evaluation: Average loss: 0.6449, Accuracy: 3953/5000 (79.060%)

19:45:15: Current learning rate: 0.1. Time taken for epoch: 26.90 seconds.

19:45:16: Train Epoch: 39 [0/45000 (0%)]	Loss: 0.434180
19:45:21: Train Epoch: 39 [10000/45000 (22%)]	Loss: 0.440408
19:45:27: Train Epoch: 39 [20000/45000 (44%)]	Loss: 0.588286
19:45:32: Train Epoch: 39 [30000/45000 (67%)]	Loss: 0.623798
19:45:37: Train Epoch: 39 [40000/45000 (89%)]	Loss: 0.407333
19:45:42: 
Evaluation: Average loss: 0.6815, Accuracy: 3947/5000 (78.940%)

19:45:42: Current learning rate: 0.1. Time taken for epoch: 26.40 seconds.

19:45:42: Train Epoch: 40 [0/45000 (0%)]	Loss: 0.324913
19:45:48: Train Epoch: 40 [10000/45000 (22%)]	Loss: 0.545465
19:45:53: Train Epoch: 40 [20000/45000 (44%)]	Loss: 0.475454
19:45:59: Train Epoch: 40 [30000/45000 (67%)]	Loss: 0.379956
19:46:04: Train Epoch: 40 [40000/45000 (89%)]	Loss: 0.651712
19:46:09: 
Evaluation: Average loss: 0.8258, Accuracy: 3685/5000 (73.700%)

19:46:09: Current learning rate: 0.1. Time taken for epoch: 27.18 seconds.

19:46:10: Train Epoch: 41 [0/45000 (0%)]	Loss: 0.532223
19:46:15: Train Epoch: 41 [10000/45000 (22%)]	Loss: 0.374010
19:46:20: Train Epoch: 41 [20000/45000 (44%)]	Loss: 0.442320
19:46:25: Train Epoch: 41 [30000/45000 (67%)]	Loss: 0.476988
19:46:31: Train Epoch: 41 [40000/45000 (89%)]	Loss: 0.658300
19:46:35: 
Evaluation: Average loss: 0.7879, Accuracy: 3792/5000 (75.840%)

19:46:35: Current learning rate: 0.1. Time taken for epoch: 26.37 seconds.

19:46:36: Train Epoch: 42 [0/45000 (0%)]	Loss: 0.503543
19:46:41: Train Epoch: 42 [10000/45000 (22%)]	Loss: 0.571443
19:46:47: Train Epoch: 42 [20000/45000 (44%)]	Loss: 0.438378
19:46:52: Train Epoch: 42 [30000/45000 (67%)]	Loss: 0.451502
19:46:57: Train Epoch: 42 [40000/45000 (89%)]	Loss: 0.760240
19:47:02: 
Evaluation: Average loss: 0.9150, Accuracy: 3596/5000 (71.920%)

19:47:03: Current learning rate: 0.1. Time taken for epoch: 27.22 seconds.

19:47:03: Train Epoch: 43 [0/45000 (0%)]	Loss: 0.542723
19:47:09: Train Epoch: 43 [10000/45000 (22%)]	Loss: 0.756185
19:47:14: Train Epoch: 43 [20000/45000 (44%)]	Loss: 0.481475
19:47:19: Train Epoch: 43 [30000/45000 (67%)]	Loss: 0.352988
19:47:24: Train Epoch: 43 [40000/45000 (89%)]	Loss: 0.426310
19:47:29: 
Evaluation: Average loss: 0.7140, Accuracy: 3885/5000 (77.700%)

19:47:29: Current learning rate: 0.1. Time taken for epoch: 26.28 seconds.

19:47:29: Train Epoch: 44 [0/45000 (0%)]	Loss: 0.485714
19:47:35: Train Epoch: 44 [10000/45000 (22%)]	Loss: 0.757217
19:47:40: Train Epoch: 44 [20000/45000 (44%)]	Loss: 0.563468
19:47:45: Train Epoch: 44 [30000/45000 (67%)]	Loss: 0.591509
19:47:50: Train Epoch: 44 [40000/45000 (89%)]	Loss: 0.423791
19:47:55: 
Evaluation: Average loss: 0.8064, Accuracy: 3724/5000 (74.480%)

19:47:56: Current learning rate: 0.1. Time taken for epoch: 26.72 seconds.

19:47:56: Train Epoch: 45 [0/45000 (0%)]	Loss: 0.453180
19:48:02: Train Epoch: 45 [10000/45000 (22%)]	Loss: 0.324073
19:48:07: Train Epoch: 45 [20000/45000 (44%)]	Loss: 0.530193
19:48:12: Train Epoch: 45 [30000/45000 (67%)]	Loss: 0.464921
19:48:17: Train Epoch: 45 [40000/45000 (89%)]	Loss: 0.454517
19:48:22: 
Evaluation: Average loss: 0.8540, Accuracy: 3644/5000 (72.880%)

19:48:22: Current learning rate: 0.1. Time taken for epoch: 26.85 seconds.

19:48:23: Train Epoch: 46 [0/45000 (0%)]	Loss: 0.437140
19:48:29: Train Epoch: 46 [10000/45000 (22%)]	Loss: 0.283888
19:48:34: Train Epoch: 46 [20000/45000 (44%)]	Loss: 0.407466
19:48:39: Train Epoch: 46 [30000/45000 (67%)]	Loss: 0.583597
19:48:44: Train Epoch: 46 [40000/45000 (89%)]	Loss: 0.402294
19:48:49: 
Evaluation: Average loss: 0.6267, Accuracy: 4004/5000 (80.080%)

19:48:49: Current learning rate: 0.1. Time taken for epoch: 26.73 seconds.

19:48:50: Train Epoch: 47 [0/45000 (0%)]	Loss: 0.388796
19:48:55: Train Epoch: 47 [10000/45000 (22%)]	Loss: 0.552594
19:49:01: Train Epoch: 47 [20000/45000 (44%)]	Loss: 0.591502
19:49:06: Train Epoch: 47 [30000/45000 (67%)]	Loss: 0.502781
19:49:11: Train Epoch: 47 [40000/45000 (89%)]	Loss: 0.473004
19:49:16: 
Evaluation: Average loss: 0.6634, Accuracy: 3928/5000 (78.560%)

19:49:16: Current learning rate: 0.1. Time taken for epoch: 26.94 seconds.

19:49:17: Train Epoch: 48 [0/45000 (0%)]	Loss: 0.588897
19:49:22: Train Epoch: 48 [10000/45000 (22%)]	Loss: 0.632419
19:49:27: Train Epoch: 48 [20000/45000 (44%)]	Loss: 0.513613
19:49:32: Train Epoch: 48 [30000/45000 (67%)]	Loss: 0.439476
19:49:38: Train Epoch: 48 [40000/45000 (89%)]	Loss: 0.571517
19:49:43: 
Evaluation: Average loss: 0.6880, Accuracy: 3857/5000 (77.140%)

19:49:43: Current learning rate: 0.1. Time taken for epoch: 26.72 seconds.

19:49:43: Train Epoch: 49 [0/45000 (0%)]	Loss: 0.494711
19:49:49: Train Epoch: 49 [10000/45000 (22%)]	Loss: 0.389176
19:49:54: Train Epoch: 49 [20000/45000 (44%)]	Loss: 0.288203
19:50:00: Train Epoch: 49 [30000/45000 (67%)]	Loss: 0.636332
19:50:05: Train Epoch: 49 [40000/45000 (89%)]	Loss: 0.495779
19:50:10: 
Evaluation: Average loss: 0.7137, Accuracy: 3870/5000 (77.400%)

19:50:10: Current learning rate: 0.1. Time taken for epoch: 27.10 seconds.

19:50:10: Train Epoch: 50 [0/45000 (0%)]	Loss: 0.396432
19:50:16: Train Epoch: 50 [10000/45000 (22%)]	Loss: 0.494774
19:50:21: Train Epoch: 50 [20000/45000 (44%)]	Loss: 0.366170
19:50:26: Train Epoch: 50 [30000/45000 (67%)]	Loss: 0.612155
19:50:32: Train Epoch: 50 [40000/45000 (89%)]	Loss: 0.569686
19:50:36: 
Evaluation: Average loss: 0.7897, Accuracy: 3764/5000 (75.280%)

19:50:36: Current learning rate: 0.1. Time taken for epoch: 26.53 seconds.

19:50:37: Train Epoch: 51 [0/45000 (0%)]	Loss: 0.527204
19:50:43: Train Epoch: 51 [10000/45000 (22%)]	Loss: 0.488856
19:50:48: Train Epoch: 51 [20000/45000 (44%)]	Loss: 0.643502
19:50:53: Train Epoch: 51 [30000/45000 (67%)]	Loss: 0.382344
19:50:58: Train Epoch: 51 [40000/45000 (89%)]	Loss: 0.607961
19:51:03: 
Evaluation: Average loss: 0.7487, Accuracy: 3851/5000 (77.020%)

19:51:04: Current learning rate: 0.1. Time taken for epoch: 27.12 seconds.

19:51:04: Train Epoch: 52 [0/45000 (0%)]	Loss: 0.423782
19:51:10: Train Epoch: 52 [10000/45000 (22%)]	Loss: 0.467963
19:51:15: Train Epoch: 52 [20000/45000 (44%)]	Loss: 0.466358
19:51:20: Train Epoch: 52 [30000/45000 (67%)]	Loss: 0.523340
19:51:25: Train Epoch: 52 [40000/45000 (89%)]	Loss: 0.424672
19:51:30: 
Evaluation: Average loss: 0.6430, Accuracy: 3958/5000 (79.160%)

19:51:30: Current learning rate: 0.1. Time taken for epoch: 26.60 seconds.

19:51:31: Train Epoch: 53 [0/45000 (0%)]	Loss: 0.630442
19:51:36: Train Epoch: 53 [10000/45000 (22%)]	Loss: 0.542686
19:51:41: Train Epoch: 53 [20000/45000 (44%)]	Loss: 0.473857
19:51:47: Train Epoch: 53 [30000/45000 (67%)]	Loss: 0.518329
19:51:52: Train Epoch: 53 [40000/45000 (89%)]	Loss: 0.629640
19:51:57: 
Evaluation: Average loss: 0.6981, Accuracy: 3901/5000 (78.020%)

19:51:57: Current learning rate: 0.1. Time taken for epoch: 26.88 seconds.

19:51:58: Train Epoch: 54 [0/45000 (0%)]	Loss: 0.459808
19:52:03: Train Epoch: 54 [10000/45000 (22%)]	Loss: 0.585447
19:52:09: Train Epoch: 54 [20000/45000 (44%)]	Loss: 0.613035
19:52:14: Train Epoch: 54 [30000/45000 (67%)]	Loss: 0.686377
19:52:19: Train Epoch: 54 [40000/45000 (89%)]	Loss: 0.531025
19:52:24: 
Evaluation: Average loss: 0.6108, Accuracy: 4020/5000 (80.400%)

19:52:24: Current learning rate: 0.1. Time taken for epoch: 26.85 seconds.

19:52:25: Train Epoch: 55 [0/45000 (0%)]	Loss: 0.461751
19:52:30: Train Epoch: 55 [10000/45000 (22%)]	Loss: 0.450263
19:52:35: Train Epoch: 55 [20000/45000 (44%)]	Loss: 0.641395
19:52:40: Train Epoch: 55 [30000/45000 (67%)]	Loss: 0.535713
19:52:46: Train Epoch: 55 [40000/45000 (89%)]	Loss: 0.583221
19:52:50: 
Evaluation: Average loss: 0.8184, Accuracy: 3752/5000 (75.040%)

19:52:51: Current learning rate: 0.1. Time taken for epoch: 26.78 seconds.

19:52:52: Train Epoch: 56 [0/45000 (0%)]	Loss: 0.637814
19:52:57: Train Epoch: 56 [10000/45000 (22%)]	Loss: 0.675442
19:53:03: Train Epoch: 56 [20000/45000 (44%)]	Loss: 0.624259
19:53:08: Train Epoch: 56 [30000/45000 (67%)]	Loss: 0.442422
19:53:13: Train Epoch: 56 [40000/45000 (89%)]	Loss: 0.327921
19:53:18: 
Evaluation: Average loss: 0.3618, Accuracy: 4413/5000 (88.260%)

19:53:18: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.48 seconds.

19:53:19: Train Epoch: 57 [0/45000 (0%)]	Loss: 0.413992
19:53:24: Train Epoch: 57 [10000/45000 (22%)]	Loss: 0.302298
19:53:30: Train Epoch: 57 [20000/45000 (44%)]	Loss: 0.217336
19:53:35: Train Epoch: 57 [30000/45000 (67%)]	Loss: 0.249647
19:53:40: Train Epoch: 57 [40000/45000 (89%)]	Loss: 0.256847
19:53:45: 
Evaluation: Average loss: 0.3061, Accuracy: 4505/5000 (90.100%)

19:53:45: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.00 seconds.

19:53:46: Train Epoch: 58 [0/45000 (0%)]	Loss: 0.239046
19:53:51: Train Epoch: 58 [10000/45000 (22%)]	Loss: 0.214281
19:53:57: Train Epoch: 58 [20000/45000 (44%)]	Loss: 0.268195
19:54:02: Train Epoch: 58 [30000/45000 (67%)]	Loss: 0.383276
19:54:08: Train Epoch: 58 [40000/45000 (89%)]	Loss: 0.224920
19:54:12: 
Evaluation: Average loss: 0.3077, Accuracy: 4496/5000 (89.920%)

19:54:12: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.35 seconds.

19:54:13: Train Epoch: 59 [0/45000 (0%)]	Loss: 0.221585
19:54:18: Train Epoch: 59 [10000/45000 (22%)]	Loss: 0.273591
19:54:24: Train Epoch: 59 [20000/45000 (44%)]	Loss: 0.192742
19:54:29: Train Epoch: 59 [30000/45000 (67%)]	Loss: 0.256204
19:54:34: Train Epoch: 59 [40000/45000 (89%)]	Loss: 0.215788
19:54:39: 
Evaluation: Average loss: 0.2999, Accuracy: 4512/5000 (90.240%)

19:54:39: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.62 seconds.

19:54:40: Train Epoch: 60 [0/45000 (0%)]	Loss: 0.181613
19:54:45: Train Epoch: 60 [10000/45000 (22%)]	Loss: 0.258289
19:54:51: Train Epoch: 60 [20000/45000 (44%)]	Loss: 0.308584
19:54:56: Train Epoch: 60 [30000/45000 (67%)]	Loss: 0.141906
19:55:02: Train Epoch: 60 [40000/45000 (89%)]	Loss: 0.228982
19:55:07: 
Evaluation: Average loss: 0.2917, Accuracy: 4545/5000 (90.900%)

19:55:07: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.85 seconds.

19:55:08: Train Epoch: 61 [0/45000 (0%)]	Loss: 0.196472
19:55:13: Train Epoch: 61 [10000/45000 (22%)]	Loss: 0.229545
19:55:18: Train Epoch: 61 [20000/45000 (44%)]	Loss: 0.216667
19:55:24: Train Epoch: 61 [30000/45000 (67%)]	Loss: 0.194583
19:55:29: Train Epoch: 61 [40000/45000 (89%)]	Loss: 0.200591
19:55:34: 
Evaluation: Average loss: 0.2818, Accuracy: 4558/5000 (91.160%)

19:55:34: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.88 seconds.

19:55:34: Train Epoch: 62 [0/45000 (0%)]	Loss: 0.193022
19:55:40: Train Epoch: 62 [10000/45000 (22%)]	Loss: 0.088977
19:55:45: Train Epoch: 62 [20000/45000 (44%)]	Loss: 0.197569
19:55:50: Train Epoch: 62 [30000/45000 (67%)]	Loss: 0.185181
19:55:56: Train Epoch: 62 [40000/45000 (89%)]	Loss: 0.117557
19:56:01: 
Evaluation: Average loss: 0.2981, Accuracy: 4531/5000 (90.620%)

19:56:01: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.32 seconds.

19:56:02: Train Epoch: 63 [0/45000 (0%)]	Loss: 0.289091
19:56:07: Train Epoch: 63 [10000/45000 (22%)]	Loss: 0.170296
19:56:12: Train Epoch: 63 [20000/45000 (44%)]	Loss: 0.052890
19:56:18: Train Epoch: 63 [30000/45000 (67%)]	Loss: 0.089323
19:56:23: Train Epoch: 63 [40000/45000 (89%)]	Loss: 0.280601
19:56:28: 
Evaluation: Average loss: 0.2876, Accuracy: 4556/5000 (91.120%)

19:56:28: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.80 seconds.

19:56:28: Train Epoch: 64 [0/45000 (0%)]	Loss: 0.114707
19:56:34: Train Epoch: 64 [10000/45000 (22%)]	Loss: 0.150043
19:56:39: Train Epoch: 64 [20000/45000 (44%)]	Loss: 0.290646
19:56:45: Train Epoch: 64 [30000/45000 (67%)]	Loss: 0.331193
19:56:50: Train Epoch: 64 [40000/45000 (89%)]	Loss: 0.158294
19:56:55: 
Evaluation: Average loss: 0.3089, Accuracy: 4524/5000 (90.480%)

19:56:55: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.10 seconds.

19:56:56: Train Epoch: 65 [0/45000 (0%)]	Loss: 0.074704
19:57:02: Train Epoch: 65 [10000/45000 (22%)]	Loss: 0.230376
19:57:07: Train Epoch: 65 [20000/45000 (44%)]	Loss: 0.296496
19:57:12: Train Epoch: 65 [30000/45000 (67%)]	Loss: 0.125784
19:57:17: Train Epoch: 65 [40000/45000 (89%)]	Loss: 0.104356
19:57:22: 
Evaluation: Average loss: 0.3018, Accuracy: 4545/5000 (90.900%)

19:57:22: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.32 seconds.

19:57:23: Train Epoch: 66 [0/45000 (0%)]	Loss: 0.176284
19:57:29: Train Epoch: 66 [10000/45000 (22%)]	Loss: 0.106874
19:57:34: Train Epoch: 66 [20000/45000 (44%)]	Loss: 0.175179
19:57:39: Train Epoch: 66 [30000/45000 (67%)]	Loss: 0.130881
19:57:45: Train Epoch: 66 [40000/45000 (89%)]	Loss: 0.084574
19:57:49: 
Evaluation: Average loss: 0.3070, Accuracy: 4543/5000 (90.860%)

19:57:49: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.14 seconds.

19:57:50: Train Epoch: 67 [0/45000 (0%)]	Loss: 0.145313
19:57:56: Train Epoch: 67 [10000/45000 (22%)]	Loss: 0.115402
19:58:01: Train Epoch: 67 [20000/45000 (44%)]	Loss: 0.119154
19:58:07: Train Epoch: 67 [30000/45000 (67%)]	Loss: 0.150913
19:58:12: Train Epoch: 67 [40000/45000 (89%)]	Loss: 0.158067
19:58:17: 
Evaluation: Average loss: 0.3306, Accuracy: 4511/5000 (90.220%)

19:58:17: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.33 seconds.

19:58:18: Train Epoch: 68 [0/45000 (0%)]	Loss: 0.079986
19:58:23: Train Epoch: 68 [10000/45000 (22%)]	Loss: 0.050295
19:58:28: Train Epoch: 68 [20000/45000 (44%)]	Loss: 0.135058
19:58:33: Train Epoch: 68 [30000/45000 (67%)]	Loss: 0.128665
19:58:39: Train Epoch: 68 [40000/45000 (89%)]	Loss: 0.180326
19:58:44: 
Evaluation: Average loss: 0.3041, Accuracy: 4543/5000 (90.860%)

19:58:44: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.92 seconds.

19:58:44: Train Epoch: 69 [0/45000 (0%)]	Loss: 0.156882
19:58:50: Train Epoch: 69 [10000/45000 (22%)]	Loss: 0.134820
19:58:55: Train Epoch: 69 [20000/45000 (44%)]	Loss: 0.066632
19:59:01: Train Epoch: 69 [30000/45000 (67%)]	Loss: 0.185595
19:59:06: Train Epoch: 69 [40000/45000 (89%)]	Loss: 0.184252
19:59:11: 
Evaluation: Average loss: 0.3077, Accuracy: 4529/5000 (90.580%)

19:59:11: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.44 seconds.

19:59:12: Train Epoch: 70 [0/45000 (0%)]	Loss: 0.124426
19:59:17: Train Epoch: 70 [10000/45000 (22%)]	Loss: 0.068650
19:59:23: Train Epoch: 70 [20000/45000 (44%)]	Loss: 0.096816
19:59:28: Train Epoch: 70 [30000/45000 (67%)]	Loss: 0.217930
19:59:33: Train Epoch: 70 [40000/45000 (89%)]	Loss: 0.194906
19:59:38: 
Evaluation: Average loss: 0.3192, Accuracy: 4543/5000 (90.860%)

19:59:38: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.75 seconds.

19:59:38: Train Epoch: 71 [0/45000 (0%)]	Loss: 0.064314
19:59:44: Train Epoch: 71 [10000/45000 (22%)]	Loss: 0.128483
19:59:49: Train Epoch: 71 [20000/45000 (44%)]	Loss: 0.206686
19:59:55: Train Epoch: 71 [30000/45000 (67%)]	Loss: 0.097301
20:00:00: Train Epoch: 71 [40000/45000 (89%)]	Loss: 0.158627
20:00:05: 
Evaluation: Average loss: 0.3330, Accuracy: 4514/5000 (90.280%)

20:00:06: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.67 seconds.

20:00:06: Train Epoch: 72 [0/45000 (0%)]	Loss: 0.141755
20:00:12: Train Epoch: 72 [10000/45000 (22%)]	Loss: 0.074210
20:00:17: Train Epoch: 72 [20000/45000 (44%)]	Loss: 0.150084
20:00:22: Train Epoch: 72 [30000/45000 (67%)]	Loss: 0.185867
20:00:28: Train Epoch: 72 [40000/45000 (89%)]	Loss: 0.160620
20:00:32: 
Evaluation: Average loss: 0.2934, Accuracy: 4569/5000 (91.380%)

20:00:32: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.88 seconds.

20:00:33: Train Epoch: 73 [0/45000 (0%)]	Loss: 0.163775
20:00:39: Train Epoch: 73 [10000/45000 (22%)]	Loss: 0.149893
20:00:44: Train Epoch: 73 [20000/45000 (44%)]	Loss: 0.121068
20:00:49: Train Epoch: 73 [30000/45000 (67%)]	Loss: 0.184968
20:00:55: Train Epoch: 73 [40000/45000 (89%)]	Loss: 0.135747
20:00:59: 
Evaluation: Average loss: 0.3363, Accuracy: 4504/5000 (90.080%)

20:01:00: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.16 seconds.

20:01:00: Train Epoch: 74 [0/45000 (0%)]	Loss: 0.086918
20:01:06: Train Epoch: 74 [10000/45000 (22%)]	Loss: 0.110528
20:01:11: Train Epoch: 74 [20000/45000 (44%)]	Loss: 0.174686
20:01:17: Train Epoch: 74 [30000/45000 (67%)]	Loss: 0.245355
20:01:22: Train Epoch: 74 [40000/45000 (89%)]	Loss: 0.172846
20:01:27: 
Evaluation: Average loss: 0.3364, Accuracy: 4521/5000 (90.420%)

20:01:27: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.19 seconds.

20:01:27: Train Epoch: 75 [0/45000 (0%)]	Loss: 0.165906
20:01:33: Train Epoch: 75 [10000/45000 (22%)]	Loss: 0.127111
20:01:38: Train Epoch: 75 [20000/45000 (44%)]	Loss: 0.089944
20:01:44: Train Epoch: 75 [30000/45000 (67%)]	Loss: 0.112981
20:01:49: Train Epoch: 75 [40000/45000 (89%)]	Loss: 0.262544
20:01:54: 
Evaluation: Average loss: 0.3741, Accuracy: 4479/5000 (89.580%)

20:01:54: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.21 seconds.

20:01:55: Train Epoch: 76 [0/45000 (0%)]	Loss: 0.086939
20:02:00: Train Epoch: 76 [10000/45000 (22%)]	Loss: 0.136121
20:02:06: Train Epoch: 76 [20000/45000 (44%)]	Loss: 0.114531
20:02:11: Train Epoch: 76 [30000/45000 (67%)]	Loss: 0.186075
20:02:16: Train Epoch: 76 [40000/45000 (89%)]	Loss: 0.138094
20:02:21: 
Evaluation: Average loss: 0.3211, Accuracy: 4538/5000 (90.760%)

20:02:21: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.86 seconds.

20:02:21: Train Epoch: 77 [0/45000 (0%)]	Loss: 0.037132
20:02:27: Train Epoch: 77 [10000/45000 (22%)]	Loss: 0.208990
20:02:32: Train Epoch: 77 [20000/45000 (44%)]	Loss: 0.112435
20:02:37: Train Epoch: 77 [30000/45000 (67%)]	Loss: 0.080345
20:02:43: Train Epoch: 77 [40000/45000 (89%)]	Loss: 0.200050
20:02:48: 
Evaluation: Average loss: 0.3729, Accuracy: 4451/5000 (89.020%)

20:02:48: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.81 seconds.

20:02:48: Train Epoch: 78 [0/45000 (0%)]	Loss: 0.217175
20:02:54: Train Epoch: 78 [10000/45000 (22%)]	Loss: 0.143766
20:02:59: Train Epoch: 78 [20000/45000 (44%)]	Loss: 0.085597
20:03:05: Train Epoch: 78 [30000/45000 (67%)]	Loss: 0.194936
20:03:10: Train Epoch: 78 [40000/45000 (89%)]	Loss: 0.088715
20:03:15: 
Evaluation: Average loss: 0.3527, Accuracy: 4515/5000 (90.300%)

20:03:15: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.22 seconds.

20:03:16: Train Epoch: 79 [0/45000 (0%)]	Loss: 0.092269
20:03:21: Train Epoch: 79 [10000/45000 (22%)]	Loss: 0.160737
20:03:26: Train Epoch: 79 [20000/45000 (44%)]	Loss: 0.117367
20:03:31: Train Epoch: 79 [30000/45000 (67%)]	Loss: 0.114900
20:03:37: Train Epoch: 79 [40000/45000 (89%)]	Loss: 0.103430
20:03:41: 
Evaluation: Average loss: 0.3411, Accuracy: 4517/5000 (90.340%)

20:03:42: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.65 seconds.

20:03:42: Train Epoch: 80 [0/45000 (0%)]	Loss: 0.112353
20:03:48: Train Epoch: 80 [10000/45000 (22%)]	Loss: 0.135690
20:03:53: Train Epoch: 80 [20000/45000 (44%)]	Loss: 0.048623
20:03:59: Train Epoch: 80 [30000/45000 (67%)]	Loss: 0.090794
20:04:04: Train Epoch: 80 [40000/45000 (89%)]	Loss: 0.157976
20:04:09: 
Evaluation: Average loss: 0.3646, Accuracy: 4481/5000 (89.620%)

20:04:09: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.29 seconds.

20:04:10: Train Epoch: 81 [0/45000 (0%)]	Loss: 0.076106
20:04:15: Train Epoch: 81 [10000/45000 (22%)]	Loss: 0.146995
20:04:20: Train Epoch: 81 [20000/45000 (44%)]	Loss: 0.203159
20:04:25: Train Epoch: 81 [30000/45000 (67%)]	Loss: 0.115008
20:04:31: Train Epoch: 81 [40000/45000 (89%)]	Loss: 0.142165
20:04:35: 
Evaluation: Average loss: 0.3613, Accuracy: 4495/5000 (89.900%)

20:04:35: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.56 seconds.

20:04:36: Train Epoch: 82 [0/45000 (0%)]	Loss: 0.101119
20:04:42: Train Epoch: 82 [10000/45000 (22%)]	Loss: 0.110308
20:04:47: Train Epoch: 82 [20000/45000 (44%)]	Loss: 0.129099
20:04:52: Train Epoch: 82 [30000/45000 (67%)]	Loss: 0.093282
20:04:58: Train Epoch: 82 [40000/45000 (89%)]	Loss: 0.200002
20:05:03: 
Evaluation: Average loss: 0.3602, Accuracy: 4479/5000 (89.580%)

20:05:03: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.29 seconds.

20:05:03: Train Epoch: 83 [0/45000 (0%)]	Loss: 0.178920
20:05:09: Train Epoch: 83 [10000/45000 (22%)]	Loss: 0.137117
20:05:14: Train Epoch: 83 [20000/45000 (44%)]	Loss: 0.078538
20:05:19: Train Epoch: 83 [30000/45000 (67%)]	Loss: 0.122842
20:05:25: Train Epoch: 83 [40000/45000 (89%)]	Loss: 0.152772
20:05:29: 
Evaluation: Average loss: 0.3583, Accuracy: 4492/5000 (89.840%)

20:05:29: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.70 seconds.

20:05:30: Train Epoch: 84 [0/45000 (0%)]	Loss: 0.159186
20:05:35: Train Epoch: 84 [10000/45000 (22%)]	Loss: 0.114966
20:05:41: Train Epoch: 84 [20000/45000 (44%)]	Loss: 0.108040
20:05:46: Train Epoch: 84 [30000/45000 (67%)]	Loss: 0.117340
20:05:51: Train Epoch: 84 [40000/45000 (89%)]	Loss: 0.140518
20:05:56: 
Evaluation: Average loss: 0.4105, Accuracy: 4408/5000 (88.160%)

20:05:57: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.10 seconds.

20:05:57: Train Epoch: 85 [0/45000 (0%)]	Loss: 0.156487
20:06:03: Train Epoch: 85 [10000/45000 (22%)]	Loss: 0.153541
20:06:08: Train Epoch: 85 [20000/45000 (44%)]	Loss: 0.192729
20:06:13: Train Epoch: 85 [30000/45000 (67%)]	Loss: 0.086936
20:06:18: Train Epoch: 85 [40000/45000 (89%)]	Loss: 0.174442
20:06:23: 
Evaluation: Average loss: 0.3790, Accuracy: 4470/5000 (89.400%)

20:06:23: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.75 seconds.

20:06:24: Train Epoch: 86 [0/45000 (0%)]	Loss: 0.140819
20:06:29: Train Epoch: 86 [10000/45000 (22%)]	Loss: 0.120136
20:06:34: Train Epoch: 86 [20000/45000 (44%)]	Loss: 0.067781
20:06:40: Train Epoch: 86 [30000/45000 (67%)]	Loss: 0.082783
20:06:45: Train Epoch: 86 [40000/45000 (89%)]	Loss: 0.116719
20:06:50: 
Evaluation: Average loss: 0.3452, Accuracy: 4488/5000 (89.760%)

20:06:50: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.60 seconds.

20:06:51: Train Epoch: 87 [0/45000 (0%)]	Loss: 0.155248
20:06:56: Train Epoch: 87 [10000/45000 (22%)]	Loss: 0.154050
20:07:02: Train Epoch: 87 [20000/45000 (44%)]	Loss: 0.076583
20:07:07: Train Epoch: 87 [30000/45000 (67%)]	Loss: 0.175631
20:07:12: Train Epoch: 87 [40000/45000 (89%)]	Loss: 0.083028
20:07:17: 
Evaluation: Average loss: 0.3889, Accuracy: 4446/5000 (88.920%)

20:07:17: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.99 seconds.

20:07:18: Train Epoch: 88 [0/45000 (0%)]	Loss: 0.095340
20:07:23: Train Epoch: 88 [10000/45000 (22%)]	Loss: 0.137911
20:07:28: Train Epoch: 88 [20000/45000 (44%)]	Loss: 0.136747
20:07:33: Train Epoch: 88 [30000/45000 (67%)]	Loss: 0.119529
20:07:39: Train Epoch: 88 [40000/45000 (89%)]	Loss: 0.113745
20:07:43: 
Evaluation: Average loss: 0.3635, Accuracy: 4462/5000 (89.240%)

20:07:44: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.79 seconds.

20:07:44: Train Epoch: 89 [0/45000 (0%)]	Loss: 0.244031
20:07:50: Train Epoch: 89 [10000/45000 (22%)]	Loss: 0.147150
20:07:55: Train Epoch: 89 [20000/45000 (44%)]	Loss: 0.035435
20:08:01: Train Epoch: 89 [30000/45000 (67%)]	Loss: 0.115779
20:08:06: Train Epoch: 89 [40000/45000 (89%)]	Loss: 0.044979
20:08:11: 
Evaluation: Average loss: 0.3520, Accuracy: 4490/5000 (89.800%)

20:08:11: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.09 seconds.

20:08:11: Train Epoch: 90 [0/45000 (0%)]	Loss: 0.145704
20:08:17: Train Epoch: 90 [10000/45000 (22%)]	Loss: 0.084717
20:08:22: Train Epoch: 90 [20000/45000 (44%)]	Loss: 0.212210
20:08:27: Train Epoch: 90 [30000/45000 (67%)]	Loss: 0.047164
20:08:33: Train Epoch: 90 [40000/45000 (89%)]	Loss: 0.267232
20:08:37: 
Evaluation: Average loss: 0.3763, Accuracy: 4450/5000 (89.000%)

20:08:37: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.64 seconds.

20:08:38: Train Epoch: 91 [0/45000 (0%)]	Loss: 0.141627
20:08:44: Train Epoch: 91 [10000/45000 (22%)]	Loss: 0.122304
20:08:49: Train Epoch: 91 [20000/45000 (44%)]	Loss: 0.074090
20:08:54: Train Epoch: 91 [30000/45000 (67%)]	Loss: 0.131645
20:09:00: Train Epoch: 91 [40000/45000 (89%)]	Loss: 0.104203
20:09:05: 
Evaluation: Average loss: 0.3719, Accuracy: 4469/5000 (89.380%)

20:09:05: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.35 seconds.

20:09:05: Train Epoch: 92 [0/45000 (0%)]	Loss: 0.139920
20:09:11: Train Epoch: 92 [10000/45000 (22%)]	Loss: 0.235709
20:09:16: Train Epoch: 92 [20000/45000 (44%)]	Loss: 0.246682
20:09:21: Train Epoch: 92 [30000/45000 (67%)]	Loss: 0.081241
20:09:26: Train Epoch: 92 [40000/45000 (89%)]	Loss: 0.207255
20:09:31: 
Evaluation: Average loss: 0.3532, Accuracy: 4492/5000 (89.840%)

20:09:31: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.45 seconds.

20:09:32: Train Epoch: 93 [0/45000 (0%)]	Loss: 0.111881
20:09:37: Train Epoch: 93 [10000/45000 (22%)]	Loss: 0.134479
20:09:43: Train Epoch: 93 [20000/45000 (44%)]	Loss: 0.120982
20:09:48: Train Epoch: 93 [30000/45000 (67%)]	Loss: 0.250710
20:09:53: Train Epoch: 93 [40000/45000 (89%)]	Loss: 0.128662
20:09:58: 
Evaluation: Average loss: 0.3395, Accuracy: 4531/5000 (90.620%)

20:09:58: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.01 seconds.

20:09:59: Train Epoch: 94 [0/45000 (0%)]	Loss: 0.174298
20:10:04: Train Epoch: 94 [10000/45000 (22%)]	Loss: 0.130619
20:10:10: Train Epoch: 94 [20000/45000 (44%)]	Loss: 0.085170
20:10:15: Train Epoch: 94 [30000/45000 (67%)]	Loss: 0.247319
20:10:20: Train Epoch: 94 [40000/45000 (89%)]	Loss: 0.157927
20:10:25: 
Evaluation: Average loss: 0.4082, Accuracy: 4424/5000 (88.480%)

20:10:25: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.69 seconds.

20:10:26: Train Epoch: 95 [0/45000 (0%)]	Loss: 0.160525
20:10:31: Train Epoch: 95 [10000/45000 (22%)]	Loss: 0.075903
20:10:36: Train Epoch: 95 [20000/45000 (44%)]	Loss: 0.093766
20:10:42: Train Epoch: 95 [30000/45000 (67%)]	Loss: 0.270487
20:10:47: Train Epoch: 95 [40000/45000 (89%)]	Loss: 0.113505
20:10:52: 
Evaluation: Average loss: 0.3755, Accuracy: 4461/5000 (89.220%)

20:10:52: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.06 seconds.

20:10:53: Train Epoch: 96 [0/45000 (0%)]	Loss: 0.081204
20:10:58: Train Epoch: 96 [10000/45000 (22%)]	Loss: 0.156840
20:11:04: Train Epoch: 96 [20000/45000 (44%)]	Loss: 0.207298
20:11:09: Train Epoch: 96 [30000/45000 (67%)]	Loss: 0.153152
20:11:14: Train Epoch: 96 [40000/45000 (89%)]	Loss: 0.067051
20:11:19: 
Evaluation: Average loss: 0.3466, Accuracy: 4502/5000 (90.040%)

20:11:19: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.83 seconds.

20:11:19: Train Epoch: 97 [0/45000 (0%)]	Loss: 0.121082
20:11:25: Train Epoch: 97 [10000/45000 (22%)]	Loss: 0.173964
20:11:30: Train Epoch: 97 [20000/45000 (44%)]	Loss: 0.096766
20:11:35: Train Epoch: 97 [30000/45000 (67%)]	Loss: 0.177435
20:11:40: Train Epoch: 97 [40000/45000 (89%)]	Loss: 0.284810
20:11:45: 
Evaluation: Average loss: 0.3982, Accuracy: 4437/5000 (88.740%)

20:11:45: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.36 seconds.

20:11:46: Train Epoch: 98 [0/45000 (0%)]	Loss: 0.139684
20:11:51: Train Epoch: 98 [10000/45000 (22%)]	Loss: 0.052674
20:11:57: Train Epoch: 98 [20000/45000 (44%)]	Loss: 0.083091
20:12:02: Train Epoch: 98 [30000/45000 (67%)]	Loss: 0.104312
20:12:07: Train Epoch: 98 [40000/45000 (89%)]	Loss: 0.083716
20:12:12: 
Evaluation: Average loss: 0.3570, Accuracy: 4503/5000 (90.060%)

20:12:12: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.12 seconds.

20:12:13: Train Epoch: 99 [0/45000 (0%)]	Loss: 0.143674
20:12:18: Train Epoch: 99 [10000/45000 (22%)]	Loss: 0.091350
20:12:23: Train Epoch: 99 [20000/45000 (44%)]	Loss: 0.128466
20:12:29: Train Epoch: 99 [30000/45000 (67%)]	Loss: 0.163016
20:12:34: Train Epoch: 99 [40000/45000 (89%)]	Loss: 0.115704
20:12:38: 
Evaluation: Average loss: 0.4322, Accuracy: 4389/5000 (87.780%)

20:12:39: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.37 seconds.

20:12:39: Train Epoch: 100 [0/45000 (0%)]	Loss: 0.151441
20:12:45: Train Epoch: 100 [10000/45000 (22%)]	Loss: 0.105974
20:12:50: Train Epoch: 100 [20000/45000 (44%)]	Loss: 0.085467
20:12:55: Train Epoch: 100 [30000/45000 (67%)]	Loss: 0.170572
20:13:01: Train Epoch: 100 [40000/45000 (89%)]	Loss: 0.123524
20:13:05: 
Evaluation: Average loss: 0.3672, Accuracy: 4491/5000 (89.820%)

20:13:06: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.91 seconds.

20:13:08: 
Test evaluation: Average loss: 0.3431, Accuracy: 9030/10000 (90.300%)

20:13:08: 
Iteration end: 1/1

07:57:09: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='vgg-d', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
07:57:09: 


07:57:09: ================================================================================
07:57:09: 
Iteration start: 1/1

07:57:11: VGG16(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
07:57:11: ============================================================
07:57:11: vgg-d
07:57:11: ============================================================
07:57:11: ============================================================
07:57:11: Prune mode: magnitude
07:57:11: Growth mode: momentum
07:57:11: Redistribution mode: momentum
07:57:11: ============================================================
07:57:12: Train Epoch: 1 [0/45000 (0%)]	Loss: 2.493264
07:57:18: Train Epoch: 1 [10000/45000 (22%)]	Loss: 3.639517
07:57:23: Train Epoch: 1 [20000/45000 (44%)]	Loss: 2.018746
07:57:28: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.932082
07:57:33: Train Epoch: 1 [40000/45000 (89%)]	Loss: 2.012815
07:57:38: 
Evaluation: Average loss: 1.8303, Accuracy: 1346/5000 (26.920%)

07:57:38: Current learning rate: 0.1. Time taken for epoch: 27.31 seconds.

07:57:39: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.845160
07:57:44: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.781784
07:57:50: Train Epoch: 2 [20000/45000 (44%)]	Loss: 1.733384
07:57:55: Train Epoch: 2 [30000/45000 (67%)]	Loss: 1.690782
07:58:00: Train Epoch: 2 [40000/45000 (89%)]	Loss: 1.524694
07:58:05: 
Evaluation: Average loss: 1.7786, Accuracy: 1698/5000 (33.960%)

07:58:05: Current learning rate: 0.1. Time taken for epoch: 26.69 seconds.

07:58:06: Train Epoch: 3 [0/45000 (0%)]	Loss: 1.785818
07:58:12: Train Epoch: 3 [10000/45000 (22%)]	Loss: 1.493472
07:58:17: Train Epoch: 3 [20000/45000 (44%)]	Loss: 1.539985
07:58:23: Train Epoch: 3 [30000/45000 (67%)]	Loss: 1.395514
07:58:28: Train Epoch: 3 [40000/45000 (89%)]	Loss: 1.524172
07:58:33: 
Evaluation: Average loss: 1.4722, Accuracy: 2261/5000 (45.220%)

07:58:33: Current learning rate: 0.1. Time taken for epoch: 27.70 seconds.

07:58:33: Train Epoch: 4 [0/45000 (0%)]	Loss: 1.201546
07:58:39: Train Epoch: 4 [10000/45000 (22%)]	Loss: 1.205553
07:58:44: Train Epoch: 4 [20000/45000 (44%)]	Loss: 1.199323
07:58:49: Train Epoch: 4 [30000/45000 (67%)]	Loss: 1.001965
07:58:55: Train Epoch: 4 [40000/45000 (89%)]	Loss: 1.210490
07:58:59: 
Evaluation: Average loss: 1.1834, Accuracy: 2866/5000 (57.320%)

07:58:59: Current learning rate: 0.1. Time taken for epoch: 26.66 seconds.

07:59:00: Train Epoch: 5 [0/45000 (0%)]	Loss: 0.975851
07:59:05: Train Epoch: 5 [10000/45000 (22%)]	Loss: 0.945539
07:59:11: Train Epoch: 5 [20000/45000 (44%)]	Loss: 1.011603
07:59:17: Train Epoch: 5 [30000/45000 (67%)]	Loss: 0.965838
07:59:22: Train Epoch: 5 [40000/45000 (89%)]	Loss: 0.889485
07:59:27: 
Evaluation: Average loss: 1.2257, Accuracy: 2941/5000 (58.820%)

07:59:27: Current learning rate: 0.1. Time taken for epoch: 27.43 seconds.

07:59:28: Train Epoch: 6 [0/45000 (0%)]	Loss: 0.819616
07:59:33: Train Epoch: 6 [10000/45000 (22%)]	Loss: 1.004282
07:59:38: Train Epoch: 6 [20000/45000 (44%)]	Loss: 0.845259
07:59:43: Train Epoch: 6 [30000/45000 (67%)]	Loss: 0.715742
07:59:49: Train Epoch: 6 [40000/45000 (89%)]	Loss: 0.986529
07:59:53: 
Evaluation: Average loss: 1.0149, Accuracy: 3246/5000 (64.920%)

07:59:53: Current learning rate: 0.1. Time taken for epoch: 26.58 seconds.

07:59:54: Train Epoch: 7 [0/45000 (0%)]	Loss: 0.949193
07:59:59: Train Epoch: 7 [10000/45000 (22%)]	Loss: 0.875560
08:00:05: Train Epoch: 7 [20000/45000 (44%)]	Loss: 0.677762
08:00:10: Train Epoch: 7 [30000/45000 (67%)]	Loss: 0.793513
08:00:16: Train Epoch: 7 [40000/45000 (89%)]	Loss: 0.786481
08:00:21: 
Evaluation: Average loss: 1.2133, Accuracy: 3145/5000 (62.900%)

08:00:21: Current learning rate: 0.1. Time taken for epoch: 27.36 seconds.

08:00:21: Train Epoch: 8 [0/45000 (0%)]	Loss: 0.835096
08:00:27: Train Epoch: 8 [10000/45000 (22%)]	Loss: 0.782218
08:00:32: Train Epoch: 8 [20000/45000 (44%)]	Loss: 0.897443
08:00:37: Train Epoch: 8 [30000/45000 (67%)]	Loss: 1.056038
08:00:43: Train Epoch: 8 [40000/45000 (89%)]	Loss: 1.007685
08:00:47: 
Evaluation: Average loss: 1.0900, Accuracy: 3318/5000 (66.360%)

08:00:48: Current learning rate: 0.1. Time taken for epoch: 26.74 seconds.

08:00:48: Train Epoch: 9 [0/45000 (0%)]	Loss: 0.821800
08:00:54: Train Epoch: 9 [10000/45000 (22%)]	Loss: 0.960743
08:00:59: Train Epoch: 9 [20000/45000 (44%)]	Loss: 0.738937
08:01:04: Train Epoch: 9 [30000/45000 (67%)]	Loss: 0.649374
08:01:10: Train Epoch: 9 [40000/45000 (89%)]	Loss: 0.673402
08:01:15: 
Evaluation: Average loss: 1.3154, Accuracy: 2895/5000 (57.900%)

08:01:15: Current learning rate: 0.1. Time taken for epoch: 27.21 seconds.

08:01:15: Train Epoch: 10 [0/45000 (0%)]	Loss: 0.879161
08:01:21: Train Epoch: 10 [10000/45000 (22%)]	Loss: 0.794844
08:01:26: Train Epoch: 10 [20000/45000 (44%)]	Loss: 0.711223
08:01:31: Train Epoch: 10 [30000/45000 (67%)]	Loss: 0.759160
08:01:37: Train Epoch: 10 [40000/45000 (89%)]	Loss: 0.841709
08:01:41: 
Evaluation: Average loss: 0.9865, Accuracy: 3365/5000 (67.300%)

08:01:42: Current learning rate: 0.1. Time taken for epoch: 26.94 seconds.

08:01:42: Train Epoch: 11 [0/45000 (0%)]	Loss: 0.682426
08:01:48: Train Epoch: 11 [10000/45000 (22%)]	Loss: 0.766715
08:01:53: Train Epoch: 11 [20000/45000 (44%)]	Loss: 0.630745
08:01:58: Train Epoch: 11 [30000/45000 (67%)]	Loss: 0.650690
08:02:04: Train Epoch: 11 [40000/45000 (89%)]	Loss: 0.622387
08:02:08: 
Evaluation: Average loss: 0.8543, Accuracy: 3621/5000 (72.420%)

08:02:09: Current learning rate: 0.1. Time taken for epoch: 26.93 seconds.

08:02:10: Train Epoch: 12 [0/45000 (0%)]	Loss: 0.675180
08:02:15: Train Epoch: 12 [10000/45000 (22%)]	Loss: 0.609536
08:02:20: Train Epoch: 12 [20000/45000 (44%)]	Loss: 0.700065
08:02:26: Train Epoch: 12 [30000/45000 (67%)]	Loss: 0.704427
08:02:31: Train Epoch: 12 [40000/45000 (89%)]	Loss: 0.567458
08:02:36: 
Evaluation: Average loss: 0.9706, Accuracy: 3460/5000 (69.200%)

08:02:36: Current learning rate: 0.1. Time taken for epoch: 27.25 seconds.

08:02:36: Train Epoch: 13 [0/45000 (0%)]	Loss: 0.670705
08:02:42: Train Epoch: 13 [10000/45000 (22%)]	Loss: 0.699781
08:02:47: Train Epoch: 13 [20000/45000 (44%)]	Loss: 0.793094
08:02:52: Train Epoch: 13 [30000/45000 (67%)]	Loss: 0.874030
08:02:58: Train Epoch: 13 [40000/45000 (89%)]	Loss: 0.490116
08:03:02: 
Evaluation: Average loss: 0.8011, Accuracy: 3704/5000 (74.080%)

08:03:02: Current learning rate: 0.1. Time taken for epoch: 26.65 seconds.

08:03:03: Train Epoch: 14 [0/45000 (0%)]	Loss: 0.573290
08:03:09: Train Epoch: 14 [10000/45000 (22%)]	Loss: 0.719389
08:03:14: Train Epoch: 14 [20000/45000 (44%)]	Loss: 0.706594
08:03:20: Train Epoch: 14 [30000/45000 (67%)]	Loss: 0.567995
08:03:25: Train Epoch: 14 [40000/45000 (89%)]	Loss: 0.578710
08:03:30: 
Evaluation: Average loss: 1.2405, Accuracy: 3160/5000 (63.200%)

08:03:30: Current learning rate: 0.1. Time taken for epoch: 27.56 seconds.

08:03:31: Train Epoch: 15 [0/45000 (0%)]	Loss: 0.652712
08:03:36: Train Epoch: 15 [10000/45000 (22%)]	Loss: 0.551219
08:03:41: Train Epoch: 15 [20000/45000 (44%)]	Loss: 0.473792
08:03:47: Train Epoch: 15 [30000/45000 (67%)]	Loss: 0.489630
08:03:52: Train Epoch: 15 [40000/45000 (89%)]	Loss: 0.601680
08:03:57: 
Evaluation: Average loss: 0.8531, Accuracy: 3640/5000 (72.800%)

08:03:57: Current learning rate: 0.1. Time taken for epoch: 26.69 seconds.

08:03:57: Train Epoch: 16 [0/45000 (0%)]	Loss: 0.664551
08:04:03: Train Epoch: 16 [10000/45000 (22%)]	Loss: 0.679887
08:04:08: Train Epoch: 16 [20000/45000 (44%)]	Loss: 0.528526
08:04:14: Train Epoch: 16 [30000/45000 (67%)]	Loss: 0.561960
08:04:19: Train Epoch: 16 [40000/45000 (89%)]	Loss: 0.706037
08:04:24: 
Evaluation: Average loss: 0.9184, Accuracy: 3562/5000 (71.240%)

08:04:24: Current learning rate: 0.1. Time taken for epoch: 27.28 seconds.

08:04:25: Train Epoch: 17 [0/45000 (0%)]	Loss: 0.555278
08:04:30: Train Epoch: 17 [10000/45000 (22%)]	Loss: 0.505933
08:04:35: Train Epoch: 17 [20000/45000 (44%)]	Loss: 0.641564
08:04:41: Train Epoch: 17 [30000/45000 (67%)]	Loss: 0.634329
08:04:46: Train Epoch: 17 [40000/45000 (89%)]	Loss: 0.508584
08:04:50: 
Evaluation: Average loss: 0.8274, Accuracy: 3669/5000 (73.380%)

08:04:51: Current learning rate: 0.1. Time taken for epoch: 26.55 seconds.

08:04:51: Train Epoch: 18 [0/45000 (0%)]	Loss: 0.506962
08:04:57: Train Epoch: 18 [10000/45000 (22%)]	Loss: 0.511444
08:05:02: Train Epoch: 18 [20000/45000 (44%)]	Loss: 0.577553
08:05:07: Train Epoch: 18 [30000/45000 (67%)]	Loss: 0.624673
08:05:13: Train Epoch: 18 [40000/45000 (89%)]	Loss: 0.558389
08:05:17: 
Evaluation: Average loss: 0.7223, Accuracy: 3836/5000 (76.720%)

08:05:18: Current learning rate: 0.1. Time taken for epoch: 26.98 seconds.

08:05:18: Train Epoch: 19 [0/45000 (0%)]	Loss: 0.600864
08:05:24: Train Epoch: 19 [10000/45000 (22%)]	Loss: 0.381285
08:05:29: Train Epoch: 19 [20000/45000 (44%)]	Loss: 0.753983
08:05:34: Train Epoch: 19 [30000/45000 (67%)]	Loss: 0.510513
08:05:39: Train Epoch: 19 [40000/45000 (89%)]	Loss: 0.516051
08:05:44: 
Evaluation: Average loss: 0.8138, Accuracy: 3714/5000 (74.280%)

08:05:44: Current learning rate: 0.1. Time taken for epoch: 26.69 seconds.

08:05:45: Train Epoch: 20 [0/45000 (0%)]	Loss: 0.739417
08:05:50: Train Epoch: 20 [10000/45000 (22%)]	Loss: 0.397185
08:05:56: Train Epoch: 20 [20000/45000 (44%)]	Loss: 0.632714
08:06:01: Train Epoch: 20 [30000/45000 (67%)]	Loss: 0.576465
08:06:06: Train Epoch: 20 [40000/45000 (89%)]	Loss: 0.675985
08:06:11: 
Evaluation: Average loss: 0.7113, Accuracy: 3841/5000 (76.820%)

08:06:11: Current learning rate: 0.1. Time taken for epoch: 27.23 seconds.

08:06:12: Train Epoch: 21 [0/45000 (0%)]	Loss: 0.481537
08:06:17: Train Epoch: 21 [10000/45000 (22%)]	Loss: 0.748119
08:06:23: Train Epoch: 21 [20000/45000 (44%)]	Loss: 0.503421
08:06:28: Train Epoch: 21 [30000/45000 (67%)]	Loss: 0.825375
08:06:33: Train Epoch: 21 [40000/45000 (89%)]	Loss: 0.485899
08:06:38: 
Evaluation: Average loss: 0.7797, Accuracy: 3849/5000 (76.980%)

08:06:38: Current learning rate: 0.1. Time taken for epoch: 26.73 seconds.

08:06:39: Train Epoch: 22 [0/45000 (0%)]	Loss: 0.555203
08:06:44: Train Epoch: 22 [10000/45000 (22%)]	Loss: 0.611686
08:06:49: Train Epoch: 22 [20000/45000 (44%)]	Loss: 0.603991
08:06:55: Train Epoch: 22 [30000/45000 (67%)]	Loss: 0.569669
08:07:00: Train Epoch: 22 [40000/45000 (89%)]	Loss: 0.689736
08:07:04: 
Evaluation: Average loss: 0.6126, Accuracy: 4039/5000 (80.780%)

08:07:05: Current learning rate: 0.1. Time taken for epoch: 26.43 seconds.

08:07:05: Train Epoch: 23 [0/45000 (0%)]	Loss: 0.634906
08:07:11: Train Epoch: 23 [10000/45000 (22%)]	Loss: 0.567963
08:07:17: Train Epoch: 23 [20000/45000 (44%)]	Loss: 0.555132
08:07:22: Train Epoch: 23 [30000/45000 (67%)]	Loss: 0.656668
08:07:27: Train Epoch: 23 [40000/45000 (89%)]	Loss: 0.610982
08:07:32: 
Evaluation: Average loss: 0.8249, Accuracy: 3779/5000 (75.580%)

08:07:32: Current learning rate: 0.1. Time taken for epoch: 27.41 seconds.

08:07:33: Train Epoch: 24 [0/45000 (0%)]	Loss: 0.376170
08:07:38: Train Epoch: 24 [10000/45000 (22%)]	Loss: 0.445076
08:07:43: Train Epoch: 24 [20000/45000 (44%)]	Loss: 0.463489
08:07:48: Train Epoch: 24 [30000/45000 (67%)]	Loss: 0.437112
08:07:54: Train Epoch: 24 [40000/45000 (89%)]	Loss: 0.410309
08:07:58: 
Evaluation: Average loss: 0.7826, Accuracy: 3761/5000 (75.220%)

08:07:59: Current learning rate: 0.1. Time taken for epoch: 26.48 seconds.

08:07:59: Train Epoch: 25 [0/45000 (0%)]	Loss: 0.500153
08:08:05: Train Epoch: 25 [10000/45000 (22%)]	Loss: 0.527749
08:08:10: Train Epoch: 25 [20000/45000 (44%)]	Loss: 0.578326
08:08:15: Train Epoch: 25 [30000/45000 (67%)]	Loss: 0.618504
08:08:21: Train Epoch: 25 [40000/45000 (89%)]	Loss: 0.418163
08:08:26: 
Evaluation: Average loss: 0.8983, Accuracy: 3619/5000 (72.380%)

08:08:26: Current learning rate: 0.1. Time taken for epoch: 27.24 seconds.

08:08:26: Train Epoch: 26 [0/45000 (0%)]	Loss: 0.635494
08:08:32: Train Epoch: 26 [10000/45000 (22%)]	Loss: 0.776339
08:08:37: Train Epoch: 26 [20000/45000 (44%)]	Loss: 0.520849
08:08:42: Train Epoch: 26 [30000/45000 (67%)]	Loss: 0.656251
08:08:48: Train Epoch: 26 [40000/45000 (89%)]	Loss: 0.733057
08:08:52: 
Evaluation: Average loss: 0.6901, Accuracy: 3893/5000 (77.860%)

08:08:53: Current learning rate: 0.1. Time taken for epoch: 26.87 seconds.

08:08:53: Train Epoch: 27 [0/45000 (0%)]	Loss: 0.617721
08:08:59: Train Epoch: 27 [10000/45000 (22%)]	Loss: 0.498559
08:09:04: Train Epoch: 27 [20000/45000 (44%)]	Loss: 0.521538
08:09:09: Train Epoch: 27 [30000/45000 (67%)]	Loss: 0.763266
08:09:15: Train Epoch: 27 [40000/45000 (89%)]	Loss: 0.483717
08:09:20: 
Evaluation: Average loss: 0.7183, Accuracy: 3819/5000 (76.380%)

08:09:20: Current learning rate: 0.1. Time taken for epoch: 27.06 seconds.

08:09:21: Train Epoch: 28 [0/45000 (0%)]	Loss: 0.692816
08:09:26: Train Epoch: 28 [10000/45000 (22%)]	Loss: 0.504240
08:09:31: Train Epoch: 28 [20000/45000 (44%)]	Loss: 0.517766
08:09:36: Train Epoch: 28 [30000/45000 (67%)]	Loss: 0.607235
08:09:42: Train Epoch: 28 [40000/45000 (89%)]	Loss: 0.435268
08:09:46: 
Evaluation: Average loss: 0.9920, Accuracy: 3547/5000 (70.940%)

08:09:46: Current learning rate: 0.1. Time taken for epoch: 26.69 seconds.

08:09:47: Train Epoch: 29 [0/45000 (0%)]	Loss: 0.457424
08:09:52: Train Epoch: 29 [10000/45000 (22%)]	Loss: 0.463818
08:09:58: Train Epoch: 29 [20000/45000 (44%)]	Loss: 0.413487
08:10:03: Train Epoch: 29 [30000/45000 (67%)]	Loss: 0.580511
08:10:08: Train Epoch: 29 [40000/45000 (89%)]	Loss: 0.599171
08:10:13: 
Evaluation: Average loss: 0.8577, Accuracy: 3633/5000 (72.660%)

08:10:13: Current learning rate: 0.1. Time taken for epoch: 27.04 seconds.

08:10:14: Train Epoch: 30 [0/45000 (0%)]	Loss: 0.424006
08:10:19: Train Epoch: 30 [10000/45000 (22%)]	Loss: 0.587915
08:10:25: Train Epoch: 30 [20000/45000 (44%)]	Loss: 0.459410
08:10:30: Train Epoch: 30 [30000/45000 (67%)]	Loss: 0.853866
08:10:35: Train Epoch: 30 [40000/45000 (89%)]	Loss: 0.707884
08:10:40: 
Evaluation: Average loss: 0.6372, Accuracy: 3945/5000 (78.900%)

08:10:40: Current learning rate: 0.1. Time taken for epoch: 26.62 seconds.

08:10:41: Train Epoch: 31 [0/45000 (0%)]	Loss: 0.893226
08:10:46: Train Epoch: 31 [10000/45000 (22%)]	Loss: 0.551904
08:10:51: Train Epoch: 31 [20000/45000 (44%)]	Loss: 0.534022
08:10:56: Train Epoch: 31 [30000/45000 (67%)]	Loss: 0.480709
08:11:02: Train Epoch: 31 [40000/45000 (89%)]	Loss: 0.632305
08:11:06: 
Evaluation: Average loss: 0.8360, Accuracy: 3716/5000 (74.320%)

08:11:07: Current learning rate: 0.1. Time taken for epoch: 26.60 seconds.

08:11:07: Train Epoch: 32 [0/45000 (0%)]	Loss: 0.386579
08:11:13: Train Epoch: 32 [10000/45000 (22%)]	Loss: 0.644195
08:11:18: Train Epoch: 32 [20000/45000 (44%)]	Loss: 0.359025
08:11:24: Train Epoch: 32 [30000/45000 (67%)]	Loss: 0.576378
08:11:29: Train Epoch: 32 [40000/45000 (89%)]	Loss: 0.421953
08:11:34: 
Evaluation: Average loss: 0.7729, Accuracy: 3766/5000 (75.320%)

08:11:34: Current learning rate: 0.1. Time taken for epoch: 27.09 seconds.

08:11:34: Train Epoch: 33 [0/45000 (0%)]	Loss: 0.337295
08:11:40: Train Epoch: 33 [10000/45000 (22%)]	Loss: 0.666380
08:11:45: Train Epoch: 33 [20000/45000 (44%)]	Loss: 0.530978
08:11:50: Train Epoch: 33 [30000/45000 (67%)]	Loss: 0.467244
08:11:55: Train Epoch: 33 [40000/45000 (89%)]	Loss: 0.556884
08:12:00: 
Evaluation: Average loss: 0.7715, Accuracy: 3747/5000 (74.940%)

08:12:00: Current learning rate: 0.1. Time taken for epoch: 26.49 seconds.

08:12:01: Train Epoch: 34 [0/45000 (0%)]	Loss: 0.572551
08:12:06: Train Epoch: 34 [10000/45000 (22%)]	Loss: 0.654208
08:12:12: Train Epoch: 34 [20000/45000 (44%)]	Loss: 0.525995
08:12:17: Train Epoch: 34 [30000/45000 (67%)]	Loss: 0.497917
08:12:23: Train Epoch: 34 [40000/45000 (89%)]	Loss: 0.593822
08:12:27: 
Evaluation: Average loss: 0.6020, Accuracy: 4028/5000 (80.560%)

08:12:28: Current learning rate: 0.1. Time taken for epoch: 27.29 seconds.

08:12:28: Train Epoch: 35 [0/45000 (0%)]	Loss: 0.412813
08:12:34: Train Epoch: 35 [10000/45000 (22%)]	Loss: 0.768439
08:12:39: Train Epoch: 35 [20000/45000 (44%)]	Loss: 0.476859
08:12:44: Train Epoch: 35 [30000/45000 (67%)]	Loss: 0.442731
08:12:49: Train Epoch: 35 [40000/45000 (89%)]	Loss: 0.495838
08:12:54: 
Evaluation: Average loss: 1.3142, Accuracy: 2952/5000 (59.040%)

08:12:54: Current learning rate: 0.1. Time taken for epoch: 26.62 seconds.

08:12:55: Train Epoch: 36 [0/45000 (0%)]	Loss: 0.467449
08:13:00: Train Epoch: 36 [10000/45000 (22%)]	Loss: 0.527210
08:13:05: Train Epoch: 36 [20000/45000 (44%)]	Loss: 0.536495
08:13:11: Train Epoch: 36 [30000/45000 (67%)]	Loss: 0.515839
08:13:16: Train Epoch: 36 [40000/45000 (89%)]	Loss: 0.569755
08:13:21: 
Evaluation: Average loss: 0.6441, Accuracy: 3950/5000 (79.000%)

08:13:21: Current learning rate: 0.1. Time taken for epoch: 27.28 seconds.

08:13:22: Train Epoch: 37 [0/45000 (0%)]	Loss: 0.568988
08:13:27: Train Epoch: 37 [10000/45000 (22%)]	Loss: 0.687568
08:13:33: Train Epoch: 37 [20000/45000 (44%)]	Loss: 0.469367
08:13:38: Train Epoch: 37 [30000/45000 (67%)]	Loss: 0.482258
08:13:43: Train Epoch: 37 [40000/45000 (89%)]	Loss: 0.410895
08:13:48: 
Evaluation: Average loss: 0.5853, Accuracy: 4065/5000 (81.300%)

08:13:48: Current learning rate: 0.1. Time taken for epoch: 26.51 seconds.

08:13:49: Train Epoch: 38 [0/45000 (0%)]	Loss: 0.733684
08:13:54: Train Epoch: 38 [10000/45000 (22%)]	Loss: 0.444513
08:14:00: Train Epoch: 38 [20000/45000 (44%)]	Loss: 0.472979
08:14:05: Train Epoch: 38 [30000/45000 (67%)]	Loss: 0.545098
08:14:10: Train Epoch: 38 [40000/45000 (89%)]	Loss: 0.456972
08:14:15: 
Evaluation: Average loss: 0.8715, Accuracy: 3677/5000 (73.540%)

08:14:15: Current learning rate: 0.1. Time taken for epoch: 27.47 seconds.

08:14:16: Train Epoch: 39 [0/45000 (0%)]	Loss: 0.543871
08:14:22: Train Epoch: 39 [10000/45000 (22%)]	Loss: 0.527635
08:14:27: Train Epoch: 39 [20000/45000 (44%)]	Loss: 0.517098
08:14:32: Train Epoch: 39 [30000/45000 (67%)]	Loss: 0.662802
08:14:37: Train Epoch: 39 [40000/45000 (89%)]	Loss: 0.434696
08:14:42: 
Evaluation: Average loss: 0.6765, Accuracy: 3932/5000 (78.640%)

08:14:42: Current learning rate: 0.1. Time taken for epoch: 26.66 seconds.

08:14:43: Train Epoch: 40 [0/45000 (0%)]	Loss: 0.452665
08:14:48: Train Epoch: 40 [10000/45000 (22%)]	Loss: 0.577546
08:14:53: Train Epoch: 40 [20000/45000 (44%)]	Loss: 0.505996
08:14:58: Train Epoch: 40 [30000/45000 (67%)]	Loss: 0.515462
08:15:04: Train Epoch: 40 [40000/45000 (89%)]	Loss: 0.705799
08:15:08: 
Evaluation: Average loss: 0.6755, Accuracy: 3890/5000 (77.800%)

08:15:09: Current learning rate: 0.1. Time taken for epoch: 26.60 seconds.

08:15:10: Train Epoch: 41 [0/45000 (0%)]	Loss: 0.537429
08:15:15: Train Epoch: 41 [10000/45000 (22%)]	Loss: 0.552127
08:15:21: Train Epoch: 41 [20000/45000 (44%)]	Loss: 0.505309
08:15:26: Train Epoch: 41 [30000/45000 (67%)]	Loss: 0.533184
08:15:31: Train Epoch: 41 [40000/45000 (89%)]	Loss: 0.622896
08:15:36: 
Evaluation: Average loss: 0.7114, Accuracy: 3856/5000 (77.120%)

08:15:36: Current learning rate: 0.1. Time taken for epoch: 27.05 seconds.

08:15:36: Train Epoch: 42 [0/45000 (0%)]	Loss: 0.523879
08:15:42: Train Epoch: 42 [10000/45000 (22%)]	Loss: 0.444523
08:15:47: Train Epoch: 42 [20000/45000 (44%)]	Loss: 0.416621
08:15:52: Train Epoch: 42 [30000/45000 (67%)]	Loss: 0.365525
08:15:57: Train Epoch: 42 [40000/45000 (89%)]	Loss: 0.724692
08:16:02: 
Evaluation: Average loss: 0.7654, Accuracy: 3739/5000 (74.780%)

08:16:02: Current learning rate: 0.1. Time taken for epoch: 26.49 seconds.

08:16:03: Train Epoch: 43 [0/45000 (0%)]	Loss: 0.510346
08:16:08: Train Epoch: 43 [10000/45000 (22%)]	Loss: 0.739114
08:16:14: Train Epoch: 43 [20000/45000 (44%)]	Loss: 0.452920
08:16:19: Train Epoch: 43 [30000/45000 (67%)]	Loss: 0.393229
08:16:25: Train Epoch: 43 [40000/45000 (89%)]	Loss: 0.547082
08:16:29: 
Evaluation: Average loss: 0.7462, Accuracy: 3828/5000 (76.560%)

08:16:29: Current learning rate: 0.1. Time taken for epoch: 27.26 seconds.

08:16:30: Train Epoch: 44 [0/45000 (0%)]	Loss: 0.473409
08:16:35: Train Epoch: 44 [10000/45000 (22%)]	Loss: 0.590957
08:16:41: Train Epoch: 44 [20000/45000 (44%)]	Loss: 0.520796
08:16:46: Train Epoch: 44 [30000/45000 (67%)]	Loss: 0.494472
08:16:51: Train Epoch: 44 [40000/45000 (89%)]	Loss: 0.385067
08:16:56: 
Evaluation: Average loss: 0.6302, Accuracy: 4016/5000 (80.320%)

08:16:56: Current learning rate: 0.1. Time taken for epoch: 26.44 seconds.

08:16:57: Train Epoch: 45 [0/45000 (0%)]	Loss: 0.427388
08:17:02: Train Epoch: 45 [10000/45000 (22%)]	Loss: 0.298909
08:17:07: Train Epoch: 45 [20000/45000 (44%)]	Loss: 0.660041
08:17:13: Train Epoch: 45 [30000/45000 (67%)]	Loss: 0.522432
08:17:18: Train Epoch: 45 [40000/45000 (89%)]	Loss: 0.558208
08:17:23: 
Evaluation: Average loss: 0.7481, Accuracy: 3847/5000 (76.940%)

08:17:23: Current learning rate: 0.1. Time taken for epoch: 27.04 seconds.

08:17:24: Train Epoch: 46 [0/45000 (0%)]	Loss: 0.471856
08:17:29: Train Epoch: 46 [10000/45000 (22%)]	Loss: 0.329058
08:17:34: Train Epoch: 46 [20000/45000 (44%)]	Loss: 0.427915
08:17:39: Train Epoch: 46 [30000/45000 (67%)]	Loss: 0.595648
08:17:44: Train Epoch: 46 [40000/45000 (89%)]	Loss: 0.399528
08:17:49: 
Evaluation: Average loss: 0.6420, Accuracy: 3918/5000 (78.360%)

08:17:49: Current learning rate: 0.1. Time taken for epoch: 26.18 seconds.

08:17:50: Train Epoch: 47 [0/45000 (0%)]	Loss: 0.564280
08:17:55: Train Epoch: 47 [10000/45000 (22%)]	Loss: 0.507635
08:18:00: Train Epoch: 47 [20000/45000 (44%)]	Loss: 0.497667
08:18:06: Train Epoch: 47 [30000/45000 (67%)]	Loss: 0.417214
08:18:11: Train Epoch: 47 [40000/45000 (89%)]	Loss: 0.399790
08:18:16: 
Evaluation: Average loss: 0.6620, Accuracy: 3953/5000 (79.060%)

08:18:16: Current learning rate: 0.1. Time taken for epoch: 26.98 seconds.

08:18:17: Train Epoch: 48 [0/45000 (0%)]	Loss: 0.507219
08:18:22: Train Epoch: 48 [10000/45000 (22%)]	Loss: 0.488343
08:18:27: Train Epoch: 48 [20000/45000 (44%)]	Loss: 0.518114
08:18:33: Train Epoch: 48 [30000/45000 (67%)]	Loss: 0.440114
08:18:38: Train Epoch: 48 [40000/45000 (89%)]	Loss: 0.630393
08:18:42: 
Evaluation: Average loss: 0.6674, Accuracy: 3917/5000 (78.340%)

08:18:42: Current learning rate: 0.1. Time taken for epoch: 26.38 seconds.

08:18:43: Train Epoch: 49 [0/45000 (0%)]	Loss: 0.604706
08:18:49: Train Epoch: 49 [10000/45000 (22%)]	Loss: 0.497504
08:18:54: Train Epoch: 49 [20000/45000 (44%)]	Loss: 0.413950
08:18:59: Train Epoch: 49 [30000/45000 (67%)]	Loss: 0.474003
08:19:04: Train Epoch: 49 [40000/45000 (89%)]	Loss: 0.632887
08:19:09: 
Evaluation: Average loss: 0.5976, Accuracy: 4075/5000 (81.500%)

08:19:09: Current learning rate: 0.1. Time taken for epoch: 26.96 seconds.

08:19:10: Train Epoch: 50 [0/45000 (0%)]	Loss: 0.376945
08:19:16: Train Epoch: 50 [10000/45000 (22%)]	Loss: 0.612953
08:19:21: Train Epoch: 50 [20000/45000 (44%)]	Loss: 0.422275
08:19:26: Train Epoch: 50 [30000/45000 (67%)]	Loss: 0.614436
08:19:31: Train Epoch: 50 [40000/45000 (89%)]	Loss: 0.568232
08:19:36: 
Evaluation: Average loss: 0.7846, Accuracy: 3795/5000 (75.900%)

08:19:36: Current learning rate: 0.1. Time taken for epoch: 26.77 seconds.

08:19:37: Train Epoch: 51 [0/45000 (0%)]	Loss: 0.440687
08:19:42: Train Epoch: 51 [10000/45000 (22%)]	Loss: 0.458167
08:19:47: Train Epoch: 51 [20000/45000 (44%)]	Loss: 0.567092
08:19:53: Train Epoch: 51 [30000/45000 (67%)]	Loss: 0.484771
08:19:58: Train Epoch: 51 [40000/45000 (89%)]	Loss: 0.336899
08:20:02: 
Evaluation: Average loss: 0.6889, Accuracy: 3912/5000 (78.240%)

08:20:03: Current learning rate: 0.1. Time taken for epoch: 26.27 seconds.

08:20:03: Train Epoch: 52 [0/45000 (0%)]	Loss: 0.423184
08:20:09: Train Epoch: 52 [10000/45000 (22%)]	Loss: 0.497952
08:20:14: Train Epoch: 52 [20000/45000 (44%)]	Loss: 0.443330
08:20:19: Train Epoch: 52 [30000/45000 (67%)]	Loss: 0.567179
08:20:25: Train Epoch: 52 [40000/45000 (89%)]	Loss: 0.436216
08:20:30: 
Evaluation: Average loss: 0.6228, Accuracy: 4016/5000 (80.320%)

08:20:30: Current learning rate: 0.1. Time taken for epoch: 27.20 seconds.

08:20:30: Train Epoch: 53 [0/45000 (0%)]	Loss: 0.613125
08:20:36: Train Epoch: 53 [10000/45000 (22%)]	Loss: 0.532042
08:20:41: Train Epoch: 53 [20000/45000 (44%)]	Loss: 0.553155
08:20:46: Train Epoch: 53 [30000/45000 (67%)]	Loss: 0.446299
08:20:51: Train Epoch: 53 [40000/45000 (89%)]	Loss: 0.634260
08:20:56: 
Evaluation: Average loss: 0.6413, Accuracy: 3950/5000 (79.000%)

08:20:56: Current learning rate: 0.1. Time taken for epoch: 26.54 seconds.

08:20:57: Train Epoch: 54 [0/45000 (0%)]	Loss: 0.452620
08:21:02: Train Epoch: 54 [10000/45000 (22%)]	Loss: 0.555493
08:21:08: Train Epoch: 54 [20000/45000 (44%)]	Loss: 0.627998
08:21:13: Train Epoch: 54 [30000/45000 (67%)]	Loss: 0.593202
08:21:18: Train Epoch: 54 [40000/45000 (89%)]	Loss: 0.472045
08:21:23: 
Evaluation: Average loss: 0.7115, Accuracy: 3853/5000 (77.060%)

08:21:23: Current learning rate: 0.1. Time taken for epoch: 27.15 seconds.

08:21:24: Train Epoch: 55 [0/45000 (0%)]	Loss: 0.383962
08:21:29: Train Epoch: 55 [10000/45000 (22%)]	Loss: 0.291752
08:21:35: Train Epoch: 55 [20000/45000 (44%)]	Loss: 0.599914
08:21:40: Train Epoch: 55 [30000/45000 (67%)]	Loss: 0.386114
08:21:45: Train Epoch: 55 [40000/45000 (89%)]	Loss: 0.482195
08:21:50: 
Evaluation: Average loss: 0.7802, Accuracy: 3726/5000 (74.520%)

08:21:50: Current learning rate: 0.1. Time taken for epoch: 26.52 seconds.

08:21:51: Train Epoch: 56 [0/45000 (0%)]	Loss: 0.708794
08:21:56: Train Epoch: 56 [10000/45000 (22%)]	Loss: 0.685190
08:22:01: Train Epoch: 56 [20000/45000 (44%)]	Loss: 0.661619
08:22:07: Train Epoch: 56 [30000/45000 (67%)]	Loss: 0.379344
08:22:12: Train Epoch: 56 [40000/45000 (89%)]	Loss: 0.259519
08:22:17: 
Evaluation: Average loss: 0.3513, Accuracy: 4434/5000 (88.680%)

08:22:17: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.24 seconds.

08:22:18: Train Epoch: 57 [0/45000 (0%)]	Loss: 0.394818
08:22:23: Train Epoch: 57 [10000/45000 (22%)]	Loss: 0.267784
08:22:29: Train Epoch: 57 [20000/45000 (44%)]	Loss: 0.345340
08:22:34: Train Epoch: 57 [30000/45000 (67%)]	Loss: 0.177316
08:22:39: Train Epoch: 57 [40000/45000 (89%)]	Loss: 0.269798
08:22:44: 
Evaluation: Average loss: 0.3112, Accuracy: 4488/5000 (89.760%)

08:22:44: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.90 seconds.

08:22:45: Train Epoch: 58 [0/45000 (0%)]	Loss: 0.203940
08:22:50: Train Epoch: 58 [10000/45000 (22%)]	Loss: 0.228386
08:22:55: Train Epoch: 58 [20000/45000 (44%)]	Loss: 0.249028
08:23:01: Train Epoch: 58 [30000/45000 (67%)]	Loss: 0.383260
08:23:06: Train Epoch: 58 [40000/45000 (89%)]	Loss: 0.178931
08:23:11: 
Evaluation: Average loss: 0.3034, Accuracy: 4510/5000 (90.200%)

08:23:11: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.22 seconds.

08:23:12: Train Epoch: 59 [0/45000 (0%)]	Loss: 0.201916
08:23:17: Train Epoch: 59 [10000/45000 (22%)]	Loss: 0.299010
08:23:23: Train Epoch: 59 [20000/45000 (44%)]	Loss: 0.209729
08:23:28: Train Epoch: 59 [30000/45000 (67%)]	Loss: 0.212238
08:23:33: Train Epoch: 59 [40000/45000 (89%)]	Loss: 0.177227
08:23:38: 
Evaluation: Average loss: 0.3013, Accuracy: 4518/5000 (90.360%)

08:23:38: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.89 seconds.

08:23:39: Train Epoch: 60 [0/45000 (0%)]	Loss: 0.124099
08:23:44: Train Epoch: 60 [10000/45000 (22%)]	Loss: 0.320384
08:23:49: Train Epoch: 60 [20000/45000 (44%)]	Loss: 0.336295
08:23:55: Train Epoch: 60 [30000/45000 (67%)]	Loss: 0.187276
08:24:00: Train Epoch: 60 [40000/45000 (89%)]	Loss: 0.185966
08:24:05: 
Evaluation: Average loss: 0.3190, Accuracy: 4521/5000 (90.420%)

08:24:05: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.62 seconds.

08:24:05: Train Epoch: 61 [0/45000 (0%)]	Loss: 0.178702
08:24:12: Train Epoch: 61 [10000/45000 (22%)]	Loss: 0.276390
08:24:17: Train Epoch: 61 [20000/45000 (44%)]	Loss: 0.284321
08:24:23: Train Epoch: 61 [30000/45000 (67%)]	Loss: 0.206571
08:24:28: Train Epoch: 61 [40000/45000 (89%)]	Loss: 0.246550
08:24:33: 
Evaluation: Average loss: 0.3017, Accuracy: 4534/5000 (90.680%)

08:24:33: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.97 seconds.

08:24:33: Train Epoch: 62 [0/45000 (0%)]	Loss: 0.134192
08:24:39: Train Epoch: 62 [10000/45000 (22%)]	Loss: 0.076022
08:24:44: Train Epoch: 62 [20000/45000 (44%)]	Loss: 0.128565
08:24:50: Train Epoch: 62 [30000/45000 (67%)]	Loss: 0.208173
08:24:55: Train Epoch: 62 [40000/45000 (89%)]	Loss: 0.056653
08:24:59: 
Evaluation: Average loss: 0.3044, Accuracy: 4535/5000 (90.700%)

08:25:00: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.85 seconds.

08:25:00: Train Epoch: 63 [0/45000 (0%)]	Loss: 0.384601
08:25:06: Train Epoch: 63 [10000/45000 (22%)]	Loss: 0.097724
08:25:11: Train Epoch: 63 [20000/45000 (44%)]	Loss: 0.133174
08:25:16: Train Epoch: 63 [30000/45000 (67%)]	Loss: 0.074797
08:25:22: Train Epoch: 63 [40000/45000 (89%)]	Loss: 0.289028
08:25:27: 
Evaluation: Average loss: 0.2890, Accuracy: 4554/5000 (91.080%)

08:25:27: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.20 seconds.

08:25:27: Train Epoch: 64 [0/45000 (0%)]	Loss: 0.177178
08:25:33: Train Epoch: 64 [10000/45000 (22%)]	Loss: 0.095150
08:25:38: Train Epoch: 64 [20000/45000 (44%)]	Loss: 0.243648
08:25:43: Train Epoch: 64 [30000/45000 (67%)]	Loss: 0.348136
08:25:48: Train Epoch: 64 [40000/45000 (89%)]	Loss: 0.094567
08:25:53: 
Evaluation: Average loss: 0.3025, Accuracy: 4530/5000 (90.600%)

08:25:53: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.52 seconds.

08:25:54: Train Epoch: 65 [0/45000 (0%)]	Loss: 0.080704
08:25:59: Train Epoch: 65 [10000/45000 (22%)]	Loss: 0.283719
08:26:05: Train Epoch: 65 [20000/45000 (44%)]	Loss: 0.142710
08:26:10: Train Epoch: 65 [30000/45000 (67%)]	Loss: 0.056196
08:26:15: Train Epoch: 65 [40000/45000 (89%)]	Loss: 0.099208
08:26:20: 
Evaluation: Average loss: 0.3038, Accuracy: 4533/5000 (90.660%)

08:26:20: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.82 seconds.

08:26:21: Train Epoch: 66 [0/45000 (0%)]	Loss: 0.137492
08:26:26: Train Epoch: 66 [10000/45000 (22%)]	Loss: 0.074427
08:26:31: Train Epoch: 66 [20000/45000 (44%)]	Loss: 0.120808
08:26:37: Train Epoch: 66 [30000/45000 (67%)]	Loss: 0.112107
08:26:42: Train Epoch: 66 [40000/45000 (89%)]	Loss: 0.083501
08:26:46: 
Evaluation: Average loss: 0.3186, Accuracy: 4517/5000 (90.340%)

08:26:47: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.43 seconds.

08:26:47: Train Epoch: 67 [0/45000 (0%)]	Loss: 0.076108
08:26:53: Train Epoch: 67 [10000/45000 (22%)]	Loss: 0.065869
08:26:58: Train Epoch: 67 [20000/45000 (44%)]	Loss: 0.151531
08:27:03: Train Epoch: 67 [30000/45000 (67%)]	Loss: 0.155108
08:27:08: Train Epoch: 67 [40000/45000 (89%)]	Loss: 0.171632
08:27:13: 
Evaluation: Average loss: 0.3357, Accuracy: 4507/5000 (90.140%)

08:27:13: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.76 seconds.

08:27:14: Train Epoch: 68 [0/45000 (0%)]	Loss: 0.118023
08:27:19: Train Epoch: 68 [10000/45000 (22%)]	Loss: 0.082016
08:27:25: Train Epoch: 68 [20000/45000 (44%)]	Loss: 0.182265
08:27:30: Train Epoch: 68 [30000/45000 (67%)]	Loss: 0.148125
08:27:36: Train Epoch: 68 [40000/45000 (89%)]	Loss: 0.101612
08:27:40: 
Evaluation: Average loss: 0.3454, Accuracy: 4490/5000 (89.800%)

08:27:40: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.18 seconds.

08:27:41: Train Epoch: 69 [0/45000 (0%)]	Loss: 0.124139
08:27:47: Train Epoch: 69 [10000/45000 (22%)]	Loss: 0.091560
08:27:52: Train Epoch: 69 [20000/45000 (44%)]	Loss: 0.077207
08:27:57: Train Epoch: 69 [30000/45000 (67%)]	Loss: 0.114114
08:28:02: Train Epoch: 69 [40000/45000 (89%)]	Loss: 0.076249
08:28:07: 
Evaluation: Average loss: 0.3195, Accuracy: 4538/5000 (90.760%)

08:28:07: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.88 seconds.

08:28:08: Train Epoch: 70 [0/45000 (0%)]	Loss: 0.064275
08:28:14: Train Epoch: 70 [10000/45000 (22%)]	Loss: 0.098059
08:28:19: Train Epoch: 70 [20000/45000 (44%)]	Loss: 0.139828
08:28:24: Train Epoch: 70 [30000/45000 (67%)]	Loss: 0.192246
08:28:29: Train Epoch: 70 [40000/45000 (89%)]	Loss: 0.210678
08:28:34: 
Evaluation: Average loss: 0.3441, Accuracy: 4506/5000 (90.120%)

08:28:34: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.82 seconds.

08:28:35: Train Epoch: 71 [0/45000 (0%)]	Loss: 0.094148
08:28:40: Train Epoch: 71 [10000/45000 (22%)]	Loss: 0.197097
08:28:46: Train Epoch: 71 [20000/45000 (44%)]	Loss: 0.178017
08:28:51: Train Epoch: 71 [30000/45000 (67%)]	Loss: 0.143468
08:28:56: Train Epoch: 71 [40000/45000 (89%)]	Loss: 0.142472
08:29:01: 
Evaluation: Average loss: 0.3397, Accuracy: 4503/5000 (90.060%)

08:29:01: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.72 seconds.

08:29:01: Train Epoch: 72 [0/45000 (0%)]	Loss: 0.079489
08:29:07: Train Epoch: 72 [10000/45000 (22%)]	Loss: 0.174158
08:29:13: Train Epoch: 72 [20000/45000 (44%)]	Loss: 0.043175
08:29:18: Train Epoch: 72 [30000/45000 (67%)]	Loss: 0.171049
08:29:23: Train Epoch: 72 [40000/45000 (89%)]	Loss: 0.141321
08:29:28: 
Evaluation: Average loss: 0.3299, Accuracy: 4519/5000 (90.380%)

08:29:28: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.43 seconds.

08:29:29: Train Epoch: 73 [0/45000 (0%)]	Loss: 0.283342
08:29:34: Train Epoch: 73 [10000/45000 (22%)]	Loss: 0.117131
08:29:40: Train Epoch: 73 [20000/45000 (44%)]	Loss: 0.125856
08:29:45: Train Epoch: 73 [30000/45000 (67%)]	Loss: 0.214654
08:29:50: Train Epoch: 73 [40000/45000 (89%)]	Loss: 0.152413
08:29:55: 
Evaluation: Average loss: 0.3336, Accuracy: 4519/5000 (90.380%)

08:29:55: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.49 seconds.

08:29:56: Train Epoch: 74 [0/45000 (0%)]	Loss: 0.102952
08:30:01: Train Epoch: 74 [10000/45000 (22%)]	Loss: 0.177456
08:30:06: Train Epoch: 74 [20000/45000 (44%)]	Loss: 0.142445
08:30:12: Train Epoch: 74 [30000/45000 (67%)]	Loss: 0.180704
08:30:17: Train Epoch: 74 [40000/45000 (89%)]	Loss: 0.179250
08:30:22: 
Evaluation: Average loss: 0.3594, Accuracy: 4485/5000 (89.700%)

08:30:22: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.04 seconds.

08:30:23: Train Epoch: 75 [0/45000 (0%)]	Loss: 0.061077
08:30:28: Train Epoch: 75 [10000/45000 (22%)]	Loss: 0.094166
08:30:33: Train Epoch: 75 [20000/45000 (44%)]	Loss: 0.172703
08:30:38: Train Epoch: 75 [30000/45000 (67%)]	Loss: 0.047791
08:30:43: Train Epoch: 75 [40000/45000 (89%)]	Loss: 0.156613
08:30:48: 
Evaluation: Average loss: 0.3583, Accuracy: 4475/5000 (89.500%)

08:30:48: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.40 seconds.

08:30:49: Train Epoch: 76 [0/45000 (0%)]	Loss: 0.178430
08:30:54: Train Epoch: 76 [10000/45000 (22%)]	Loss: 0.060558
08:30:59: Train Epoch: 76 [20000/45000 (44%)]	Loss: 0.120467
08:31:05: Train Epoch: 76 [30000/45000 (67%)]	Loss: 0.194693
08:31:10: Train Epoch: 76 [40000/45000 (89%)]	Loss: 0.188352
08:31:15: 
Evaluation: Average loss: 0.3655, Accuracy: 4463/5000 (89.260%)

08:31:15: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.74 seconds.

08:31:16: Train Epoch: 77 [0/45000 (0%)]	Loss: 0.114034
08:31:21: Train Epoch: 77 [10000/45000 (22%)]	Loss: 0.155347
08:31:26: Train Epoch: 77 [20000/45000 (44%)]	Loss: 0.108522
08:31:32: Train Epoch: 77 [30000/45000 (67%)]	Loss: 0.137555
08:31:37: Train Epoch: 77 [40000/45000 (89%)]	Loss: 0.253341
08:31:41: 
Evaluation: Average loss: 0.3628, Accuracy: 4481/5000 (89.620%)

08:31:42: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.62 seconds.

08:31:42: Train Epoch: 78 [0/45000 (0%)]	Loss: 0.125817
08:31:48: Train Epoch: 78 [10000/45000 (22%)]	Loss: 0.275149
08:31:53: Train Epoch: 78 [20000/45000 (44%)]	Loss: 0.149784
08:31:58: Train Epoch: 78 [30000/45000 (67%)]	Loss: 0.198650
08:32:03: Train Epoch: 78 [40000/45000 (89%)]	Loss: 0.133056
08:32:08: 
Evaluation: Average loss: 0.3451, Accuracy: 4493/5000 (89.860%)

08:32:08: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.85 seconds.

08:32:09: Train Epoch: 79 [0/45000 (0%)]	Loss: 0.124383
08:32:15: Train Epoch: 79 [10000/45000 (22%)]	Loss: 0.143225
08:32:20: Train Epoch: 79 [20000/45000 (44%)]	Loss: 0.098226
08:32:25: Train Epoch: 79 [30000/45000 (67%)]	Loss: 0.087785
08:32:30: Train Epoch: 79 [40000/45000 (89%)]	Loss: 0.060275
08:32:35: 
Evaluation: Average loss: 0.3620, Accuracy: 4466/5000 (89.320%)

08:32:35: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.64 seconds.

08:32:36: Train Epoch: 80 [0/45000 (0%)]	Loss: 0.106345
08:32:41: Train Epoch: 80 [10000/45000 (22%)]	Loss: 0.221960
08:32:47: Train Epoch: 80 [20000/45000 (44%)]	Loss: 0.140047
08:32:52: Train Epoch: 80 [30000/45000 (67%)]	Loss: 0.044444
08:32:57: Train Epoch: 80 [40000/45000 (89%)]	Loss: 0.126621
08:33:02: 
Evaluation: Average loss: 0.3613, Accuracy: 4498/5000 (89.960%)

08:33:02: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.54 seconds.

08:33:02: Train Epoch: 81 [0/45000 (0%)]	Loss: 0.138724
08:33:08: Train Epoch: 81 [10000/45000 (22%)]	Loss: 0.125745
08:33:13: Train Epoch: 81 [20000/45000 (44%)]	Loss: 0.100949
08:33:18: Train Epoch: 81 [30000/45000 (67%)]	Loss: 0.344749
08:33:24: Train Epoch: 81 [40000/45000 (89%)]	Loss: 0.110434
08:33:28: 
Evaluation: Average loss: 0.3816, Accuracy: 4452/5000 (89.040%)

08:33:29: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.86 seconds.

08:33:29: Train Epoch: 82 [0/45000 (0%)]	Loss: 0.087102
08:33:35: Train Epoch: 82 [10000/45000 (22%)]	Loss: 0.143001
08:33:40: Train Epoch: 82 [20000/45000 (44%)]	Loss: 0.138004
08:33:45: Train Epoch: 82 [30000/45000 (67%)]	Loss: 0.071885
08:33:50: Train Epoch: 82 [40000/45000 (89%)]	Loss: 0.161361
08:33:55: 
Evaluation: Average loss: 0.3805, Accuracy: 4454/5000 (89.080%)

08:33:55: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.57 seconds.

08:33:56: Train Epoch: 83 [0/45000 (0%)]	Loss: 0.214048
08:34:01: Train Epoch: 83 [10000/45000 (22%)]	Loss: 0.127640
08:34:07: Train Epoch: 83 [20000/45000 (44%)]	Loss: 0.181686
08:34:12: Train Epoch: 83 [30000/45000 (67%)]	Loss: 0.113507
08:34:17: Train Epoch: 83 [40000/45000 (89%)]	Loss: 0.141364
08:34:22: 
Evaluation: Average loss: 0.4059, Accuracy: 4435/5000 (88.700%)

08:34:22: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.21 seconds.

08:34:23: Train Epoch: 84 [0/45000 (0%)]	Loss: 0.132075
08:34:28: Train Epoch: 84 [10000/45000 (22%)]	Loss: 0.111687
08:34:34: Train Epoch: 84 [20000/45000 (44%)]	Loss: 0.125683
08:34:39: Train Epoch: 84 [30000/45000 (67%)]	Loss: 0.248344
08:34:44: Train Epoch: 84 [40000/45000 (89%)]	Loss: 0.240042
08:34:49: 
Evaluation: Average loss: 0.3779, Accuracy: 4459/5000 (89.180%)

08:34:49: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.88 seconds.

08:34:50: Train Epoch: 85 [0/45000 (0%)]	Loss: 0.203815
08:34:55: Train Epoch: 85 [10000/45000 (22%)]	Loss: 0.132698
08:35:00: Train Epoch: 85 [20000/45000 (44%)]	Loss: 0.172848
08:35:06: Train Epoch: 85 [30000/45000 (67%)]	Loss: 0.095873
08:35:11: Train Epoch: 85 [40000/45000 (89%)]	Loss: 0.194146
08:35:16: 
Evaluation: Average loss: 0.3778, Accuracy: 4469/5000 (89.380%)

08:35:16: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.76 seconds.

08:35:17: Train Epoch: 86 [0/45000 (0%)]	Loss: 0.112324
08:35:22: Train Epoch: 86 [10000/45000 (22%)]	Loss: 0.096923
08:35:28: Train Epoch: 86 [20000/45000 (44%)]	Loss: 0.056561
08:35:33: Train Epoch: 86 [30000/45000 (67%)]	Loss: 0.125400
08:35:38: Train Epoch: 86 [40000/45000 (89%)]	Loss: 0.099076
08:35:43: 
Evaluation: Average loss: 0.3324, Accuracy: 4508/5000 (90.160%)

08:35:43: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.80 seconds.

08:35:43: Train Epoch: 87 [0/45000 (0%)]	Loss: 0.110458
08:35:49: Train Epoch: 87 [10000/45000 (22%)]	Loss: 0.044038
08:35:54: Train Epoch: 87 [20000/45000 (44%)]	Loss: 0.137366
08:35:59: Train Epoch: 87 [30000/45000 (67%)]	Loss: 0.095882
08:36:04: Train Epoch: 87 [40000/45000 (89%)]	Loss: 0.039756
08:36:09: 
Evaluation: Average loss: 0.3700, Accuracy: 4483/5000 (89.660%)

08:36:09: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.58 seconds.

08:36:10: Train Epoch: 88 [0/45000 (0%)]	Loss: 0.158950
08:36:16: Train Epoch: 88 [10000/45000 (22%)]	Loss: 0.088738
08:36:21: Train Epoch: 88 [20000/45000 (44%)]	Loss: 0.053599
08:36:26: Train Epoch: 88 [30000/45000 (67%)]	Loss: 0.178163
08:36:31: Train Epoch: 88 [40000/45000 (89%)]	Loss: 0.099391
08:36:36: 
Evaluation: Average loss: 0.3512, Accuracy: 4500/5000 (90.000%)

08:36:36: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.75 seconds.

08:36:37: Train Epoch: 89 [0/45000 (0%)]	Loss: 0.149706
08:36:42: Train Epoch: 89 [10000/45000 (22%)]	Loss: 0.063941
08:36:48: Train Epoch: 89 [20000/45000 (44%)]	Loss: 0.330052
08:36:53: Train Epoch: 89 [30000/45000 (67%)]	Loss: 0.097713
08:36:58: Train Epoch: 89 [40000/45000 (89%)]	Loss: 0.059054
08:37:03: 
Evaluation: Average loss: 0.3678, Accuracy: 4471/5000 (89.420%)

08:37:03: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.64 seconds.

08:37:03: Train Epoch: 90 [0/45000 (0%)]	Loss: 0.099875
08:37:09: Train Epoch: 90 [10000/45000 (22%)]	Loss: 0.101374
08:37:14: Train Epoch: 90 [20000/45000 (44%)]	Loss: 0.229943
08:37:19: Train Epoch: 90 [30000/45000 (67%)]	Loss: 0.047000
08:37:25: Train Epoch: 90 [40000/45000 (89%)]	Loss: 0.175823
08:37:30: 
Evaluation: Average loss: 0.3511, Accuracy: 4493/5000 (89.860%)

08:37:30: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.96 seconds.

08:37:30: Train Epoch: 91 [0/45000 (0%)]	Loss: 0.126928
08:37:36: Train Epoch: 91 [10000/45000 (22%)]	Loss: 0.103909
08:37:41: Train Epoch: 91 [20000/45000 (44%)]	Loss: 0.050473
08:37:46: Train Epoch: 91 [30000/45000 (67%)]	Loss: 0.089020
08:37:51: Train Epoch: 91 [40000/45000 (89%)]	Loss: 0.154228
08:37:56: 
Evaluation: Average loss: 0.3535, Accuracy: 4511/5000 (90.220%)

08:37:56: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.66 seconds.

08:37:57: Train Epoch: 92 [0/45000 (0%)]	Loss: 0.154676
08:38:02: Train Epoch: 92 [10000/45000 (22%)]	Loss: 0.184038
08:38:08: Train Epoch: 92 [20000/45000 (44%)]	Loss: 0.057103
08:38:13: Train Epoch: 92 [30000/45000 (67%)]	Loss: 0.143488
08:38:18: Train Epoch: 92 [40000/45000 (89%)]	Loss: 0.212887
08:38:23: 
Evaluation: Average loss: 0.3994, Accuracy: 4453/5000 (89.060%)

08:38:23: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.03 seconds.

08:38:24: Train Epoch: 93 [0/45000 (0%)]	Loss: 0.139780
08:38:30: Train Epoch: 93 [10000/45000 (22%)]	Loss: 0.122784
08:38:35: Train Epoch: 93 [20000/45000 (44%)]	Loss: 0.124938
08:38:40: Train Epoch: 93 [30000/45000 (67%)]	Loss: 0.060212
08:38:45: Train Epoch: 93 [40000/45000 (89%)]	Loss: 0.115430
08:38:50: 
Evaluation: Average loss: 0.3770, Accuracy: 4464/5000 (89.280%)

08:38:50: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.75 seconds.

08:38:51: Train Epoch: 94 [0/45000 (0%)]	Loss: 0.049930
08:38:56: Train Epoch: 94 [10000/45000 (22%)]	Loss: 0.089798
08:39:01: Train Epoch: 94 [20000/45000 (44%)]	Loss: 0.070936
08:39:07: Train Epoch: 94 [30000/45000 (67%)]	Loss: 0.098518
08:39:12: Train Epoch: 94 [40000/45000 (89%)]	Loss: 0.252733
08:39:17: 
Evaluation: Average loss: 0.4150, Accuracy: 4420/5000 (88.400%)

08:39:17: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.94 seconds.

08:39:18: Train Epoch: 95 [0/45000 (0%)]	Loss: 0.059082
08:39:23: Train Epoch: 95 [10000/45000 (22%)]	Loss: 0.097079
08:39:29: Train Epoch: 95 [20000/45000 (44%)]	Loss: 0.193829
08:39:34: Train Epoch: 95 [30000/45000 (67%)]	Loss: 0.158376
08:39:39: Train Epoch: 95 [40000/45000 (89%)]	Loss: 0.097300
08:39:44: 
Evaluation: Average loss: 0.4155, Accuracy: 4444/5000 (88.880%)

08:39:44: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.89 seconds.

08:39:45: Train Epoch: 96 [0/45000 (0%)]	Loss: 0.102630
08:39:50: Train Epoch: 96 [10000/45000 (22%)]	Loss: 0.168714
08:39:55: Train Epoch: 96 [20000/45000 (44%)]	Loss: 0.072964
08:40:01: Train Epoch: 96 [30000/45000 (67%)]	Loss: 0.113770
08:40:06: Train Epoch: 96 [40000/45000 (89%)]	Loss: 0.097799
08:40:11: 
Evaluation: Average loss: 0.4214, Accuracy: 4426/5000 (88.520%)

08:40:11: Current learning rate: 0.010000000000000002. Time taken for epoch: 27.08 seconds.

08:40:12: Train Epoch: 97 [0/45000 (0%)]	Loss: 0.194046
08:40:17: Train Epoch: 97 [10000/45000 (22%)]	Loss: 0.147533
08:40:22: Train Epoch: 97 [20000/45000 (44%)]	Loss: 0.136420
08:40:28: Train Epoch: 97 [30000/45000 (67%)]	Loss: 0.208559
08:40:33: Train Epoch: 97 [40000/45000 (89%)]	Loss: 0.211071
08:40:37: 
Evaluation: Average loss: 0.4185, Accuracy: 4418/5000 (88.360%)

08:40:38: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.48 seconds.

08:40:38: Train Epoch: 98 [0/45000 (0%)]	Loss: 0.048053
08:40:44: Train Epoch: 98 [10000/45000 (22%)]	Loss: 0.033845
08:40:49: Train Epoch: 98 [20000/45000 (44%)]	Loss: 0.067900
08:40:54: Train Epoch: 98 [30000/45000 (67%)]	Loss: 0.097167
08:40:59: Train Epoch: 98 [40000/45000 (89%)]	Loss: 0.077015
08:41:04: 
Evaluation: Average loss: 0.4231, Accuracy: 4411/5000 (88.220%)

08:41:04: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.77 seconds.

08:41:05: Train Epoch: 99 [0/45000 (0%)]	Loss: 0.128002
08:41:11: Train Epoch: 99 [10000/45000 (22%)]	Loss: 0.120102
08:41:16: Train Epoch: 99 [20000/45000 (44%)]	Loss: 0.179158
08:41:21: Train Epoch: 99 [30000/45000 (67%)]	Loss: 0.031430
08:41:26: Train Epoch: 99 [40000/45000 (89%)]	Loss: 0.156059
08:41:31: 
Evaluation: Average loss: 0.3820, Accuracy: 4457/5000 (89.140%)

08:41:31: Current learning rate: 0.010000000000000002. Time taken for epoch: 26.92 seconds.

08:41:32: Train Epoch: 100 [0/45000 (0%)]	Loss: 0.166437
08:41:37: Train Epoch: 100 [10000/45000 (22%)]	Loss: 0.143528
08:41:42: Train Epoch: 100 [20000/45000 (44%)]	Loss: 0.095417
08:58:40: Namespace(batch_size=100, bench=False, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=False, density=0.05, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='alexnet-s', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.5, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=False)
08:58:40: 


08:58:40: ================================================================================
08:58:40: 
Iteration start: 1/1

08:58:41: AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 96, kernel_size=(11, 11), stride=(2, 2), padding=(2, 2))
    (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(96, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))
    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (7): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (10): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): ReLU(inplace=True)
    (12): Conv2d(384, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU(inplace=True)
  )
  (classifier): Sequential(
    (0): Linear(in_features=256, out_features=1024, bias=True)
    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Linear(in_features=1024, out_features=1024, bias=True)
    (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Linear(in_features=1024, out_features=10, bias=True)
  )
)
08:58:41: ============================================================
08:58:41: alexnet-s
08:58:41: ============================================================
08:58:41: ============================================================
08:58:41: Prune mode: magnitude
08:58:41: Growth mode: momentum
08:58:41: Redistribution mode: momentum
08:58:41: ============================================================
08:58:42: Train Epoch: 1 [0/45000 (0%)]	Loss: 2.292673
21:52:49: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='vgg-d', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
21:52:49: 


21:52:49: ================================================================================
21:52:49: 
Iteration start: 1/1

21:52:50: VGG16(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
21:52:50: ============================================================
21:52:50: vgg-d
21:52:50: ============================================================
21:52:50: ============================================================
21:52:50: Prune mode: magnitude
21:52:50: Growth mode: momentum
21:52:50: Redistribution mode: momentum
21:52:50: ============================================================
21:52:52: Train Epoch: 1 [0/45000 (0%)]	Loss: 2.493264
21:52:58: Train Epoch: 1 [10000/45000 (22%)]	Loss: 3.538699
21:53:05: Train Epoch: 1 [20000/45000 (44%)]	Loss: 1.976608
21:53:11: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.881186
21:53:18: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.843703
21:53:24: 
Evaluation: Average loss: 1.8959, Accuracy: 1242/5000 (24.840%)

21:53:24: Current learning rate: 0.1. Time taken for epoch: 33.84 seconds.

21:53:25: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.915445
21:53:31: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.863323
21:53:38: Train Epoch: 2 [20000/45000 (44%)]	Loss: 1.873123
21:53:44: Train Epoch: 2 [30000/45000 (67%)]	Loss: 1.695018
21:53:51: Train Epoch: 2 [40000/45000 (89%)]	Loss: 1.553206
21:53:57: 
Evaluation: Average loss: 1.6408, Accuracy: 1828/5000 (36.560%)

21:53:57: Current learning rate: 0.1. Time taken for epoch: 33.16 seconds.

21:53:58: Train Epoch: 3 [0/45000 (0%)]	Loss: 1.825549
22:10:52: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=0.05, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='MobileNet', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.5, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:10:52: 


22:10:52: ================================================================================
22:10:52: 
Iteration start: 1/1

22:10:53: MobileNet(
  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (dw2_1): DepthWiseBlock(
    (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
    (bn_dw): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw2_2): DepthWiseBlock(
    (conv_dw): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
    (bn_dw): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw3_1): DepthWiseBlock(
    (conv_dw): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
    (bn_dw): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw3_2): DepthWiseBlock(
    (conv_dw): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
    (bn_dw): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw4_1): DepthWiseBlock(
    (conv_dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
    (bn_dw): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw4_2): DepthWiseBlock(
    (conv_dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
    (bn_dw): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_1): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_2): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_3): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_4): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_5): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_6): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw6): DepthWiseBlock(
    (conv_dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)
    (bn_dw): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=1)
  (fc): Linear(in_features=1024, out_features=100, bias=True)
)
22:10:53: ============================================================
22:10:53: MobileNet
22:10:53: ============================================================
22:10:53: ============================================================
22:10:53: Prune mode: magnitude
22:10:53: Growth mode: momentum
22:10:53: Redistribution mode: momentum
22:10:53: ============================================================
22:10:54: Train Epoch: 1 [0/45000 (0%)]	Loss: 4.641055
22:10:59: Train Epoch: 1 [10000/45000 (22%)]	Loss: 2.070999
22:11:04: Train Epoch: 1 [20000/45000 (44%)]	Loss: 2.191387
22:11:08: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.572804
22:11:13: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.645447
22:11:17: 
Evaluation: Average loss: 0.0168, Accuracy: 1916/5000 (38.320%)

22:11:17: Current learning rate: 0.1. Time taken for epoch: 24.05 seconds.

22:11:18: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.539217
22:11:23: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.506656
22:11:27: Train Epoch: 2 [20000/45000 (44%)]	Loss: 1.660257
22:11:32: Train Epoch: 2 [30000/45000 (67%)]	Loss: 1.391268
22:11:37: Train Epoch: 2 [40000/45000 (89%)]	Loss: 1.605617
22:11:41: 
Evaluation: Average loss: 0.0155, Accuracy: 2206/5000 (44.120%)

22:11:41: Current learning rate: 0.1. Time taken for epoch: 23.91 seconds.

22:11:42: Train Epoch: 3 [0/45000 (0%)]	Loss: 1.405193
22:11:46: Train Epoch: 3 [10000/45000 (22%)]	Loss: 1.692926
22:11:51: Train Epoch: 3 [20000/45000 (44%)]	Loss: 1.380153
22:11:56: Train Epoch: 3 [30000/45000 (67%)]	Loss: 1.360908
22:12:00: Train Epoch: 3 [40000/45000 (89%)]	Loss: 1.352115
22:12:04: 
Evaluation: Average loss: 0.0138, Accuracy: 2511/5000 (50.220%)

22:12:05: Current learning rate: 0.1. Time taken for epoch: 23.65 seconds.

22:12:05: Train Epoch: 4 [0/45000 (0%)]	Loss: 1.296323
22:12:10: Train Epoch: 4 [10000/45000 (22%)]	Loss: 1.222319
22:12:15: Train Epoch: 4 [20000/45000 (44%)]	Loss: 1.121193
22:12:19: Train Epoch: 4 [30000/45000 (67%)]	Loss: 1.495911
22:12:24: Train Epoch: 4 [40000/45000 (89%)]	Loss: 1.157913
22:12:28: 
Evaluation: Average loss: 0.0132, Accuracy: 2618/5000 (52.360%)

22:12:28: Current learning rate: 0.1. Time taken for epoch: 23.31 seconds.

22:12:29: Train Epoch: 5 [0/45000 (0%)]	Loss: 1.220667
22:12:34: Train Epoch: 5 [10000/45000 (22%)]	Loss: 1.145001
22:12:39: Train Epoch: 5 [20000/45000 (44%)]	Loss: 1.251591
22:12:43: Train Epoch: 5 [30000/45000 (67%)]	Loss: 1.225516
22:12:48: Train Epoch: 5 [40000/45000 (89%)]	Loss: 1.051940
22:12:52: 
Evaluation: Average loss: 0.0121, Accuracy: 2835/5000 (56.700%)

22:12:52: Current learning rate: 0.1. Time taken for epoch: 24.34 seconds.

22:12:53: Train Epoch: 6 [0/45000 (0%)]	Loss: 1.173297
22:12:58: Train Epoch: 6 [10000/45000 (22%)]	Loss: 1.195373
22:13:03: Train Epoch: 6 [20000/45000 (44%)]	Loss: 1.166446
22:13:08: Train Epoch: 6 [30000/45000 (67%)]	Loss: 1.066273
22:13:13: Train Epoch: 6 [40000/45000 (89%)]	Loss: 1.092280
22:13:17: 
Evaluation: Average loss: 0.0118, Accuracy: 2941/5000 (58.820%)

22:13:17: Current learning rate: 0.1. Time taken for epoch: 24.38 seconds.

22:13:17: Train Epoch: 7 [0/45000 (0%)]	Loss: 1.209516
22:13:22: Train Epoch: 7 [10000/45000 (22%)]	Loss: 1.300370
22:13:27: Train Epoch: 7 [20000/45000 (44%)]	Loss: 1.019166
22:13:32: Train Epoch: 7 [30000/45000 (67%)]	Loss: 1.229778
22:13:37: Train Epoch: 7 [40000/45000 (89%)]	Loss: 0.902035
22:13:40: 
Evaluation: Average loss: 0.0120, Accuracy: 2861/5000 (57.220%)

22:13:40: Current learning rate: 0.1. Time taken for epoch: 23.90 seconds.

22:13:41: Train Epoch: 8 [0/45000 (0%)]	Loss: 1.122509
22:13:46: Train Epoch: 8 [10000/45000 (22%)]	Loss: 1.098168
22:13:51: Train Epoch: 8 [20000/45000 (44%)]	Loss: 1.152307
22:13:55: Train Epoch: 8 [30000/45000 (67%)]	Loss: 0.939621
22:14:00: Train Epoch: 8 [40000/45000 (89%)]	Loss: 0.934100
22:14:04: 
Evaluation: Average loss: 0.0102, Accuracy: 3246/5000 (64.920%)

22:14:04: Current learning rate: 0.1. Time taken for epoch: 23.74 seconds.

22:14:05: Train Epoch: 9 [0/45000 (0%)]	Loss: 1.052353
22:14:10: Train Epoch: 9 [10000/45000 (22%)]	Loss: 0.864117
22:14:15: Train Epoch: 9 [20000/45000 (44%)]	Loss: 0.877453
22:14:19: Train Epoch: 9 [30000/45000 (67%)]	Loss: 0.865385
22:14:24: Train Epoch: 9 [40000/45000 (89%)]	Loss: 1.255493
22:14:28: 
Evaluation: Average loss: 0.0104, Accuracy: 3197/5000 (63.940%)

22:14:28: Current learning rate: 0.1. Time taken for epoch: 23.89 seconds.

22:14:29: Train Epoch: 10 [0/45000 (0%)]	Loss: 1.041793
22:14:34: Train Epoch: 10 [10000/45000 (22%)]	Loss: 1.026022
22:14:38: Train Epoch: 10 [20000/45000 (44%)]	Loss: 0.984909
22:14:43: Train Epoch: 10 [30000/45000 (67%)]	Loss: 1.070504
22:14:48: Train Epoch: 10 [40000/45000 (89%)]	Loss: 1.037909
22:14:52: 
Evaluation: Average loss: 0.0120, Accuracy: 2935/5000 (58.700%)

22:14:52: Current learning rate: 0.1. Time taken for epoch: 23.65 seconds.

22:14:52: Train Epoch: 11 [0/45000 (0%)]	Loss: 0.903475
22:14:57: Train Epoch: 11 [10000/45000 (22%)]	Loss: 0.917096
22:15:02: Train Epoch: 11 [20000/45000 (44%)]	Loss: 1.066228
22:15:07: Train Epoch: 11 [30000/45000 (67%)]	Loss: 1.015116
22:15:12: Train Epoch: 11 [40000/45000 (89%)]	Loss: 0.892001
22:15:15: 
Evaluation: Average loss: 0.0103, Accuracy: 3232/5000 (64.640%)

22:15:16: Current learning rate: 0.1. Time taken for epoch: 23.79 seconds.

22:15:16: Train Epoch: 12 [0/45000 (0%)]	Loss: 0.896391
22:15:21: Train Epoch: 12 [10000/45000 (22%)]	Loss: 1.040409
22:15:26: Train Epoch: 12 [20000/45000 (44%)]	Loss: 0.872414
22:15:31: Train Epoch: 12 [30000/45000 (67%)]	Loss: 0.968072
22:15:35: Train Epoch: 12 [40000/45000 (89%)]	Loss: 0.936087
22:15:39: 
Evaluation: Average loss: 0.0102, Accuracy: 3245/5000 (64.900%)

22:15:39: Current learning rate: 0.1. Time taken for epoch: 23.70 seconds.

22:15:40: Train Epoch: 13 [0/45000 (0%)]	Loss: 0.952147
22:15:45: Train Epoch: 13 [10000/45000 (22%)]	Loss: 1.037147
22:15:49: Train Epoch: 13 [20000/45000 (44%)]	Loss: 0.859045
22:15:54: Train Epoch: 13 [30000/45000 (67%)]	Loss: 0.726019
22:15:59: Train Epoch: 13 [40000/45000 (89%)]	Loss: 0.897180
22:16:03: 
Evaluation: Average loss: 0.0111, Accuracy: 3078/5000 (61.560%)

22:16:03: Current learning rate: 0.1. Time taken for epoch: 23.88 seconds.

22:16:04: Train Epoch: 14 [0/45000 (0%)]	Loss: 1.077231
22:16:08: Train Epoch: 14 [10000/45000 (22%)]	Loss: 0.973345
22:16:13: Train Epoch: 14 [20000/45000 (44%)]	Loss: 0.934396
22:16:18: Train Epoch: 14 [30000/45000 (67%)]	Loss: 0.761494
22:16:23: Train Epoch: 14 [40000/45000 (89%)]	Loss: 0.946728
22:16:26: 
Evaluation: Average loss: 0.0097, Accuracy: 3311/5000 (66.220%)

22:16:26: Current learning rate: 0.1. Time taken for epoch: 23.38 seconds.

22:16:27: Train Epoch: 15 [0/45000 (0%)]	Loss: 0.837940
22:16:32: Train Epoch: 15 [10000/45000 (22%)]	Loss: 0.951340
22:16:37: Train Epoch: 15 [20000/45000 (44%)]	Loss: 0.859055
22:16:41: Train Epoch: 15 [30000/45000 (67%)]	Loss: 0.914733
22:16:46: Train Epoch: 15 [40000/45000 (89%)]	Loss: 0.820461
22:16:50: 
Evaluation: Average loss: 0.0108, Accuracy: 3138/5000 (62.760%)

22:16:50: Current learning rate: 0.1. Time taken for epoch: 23.35 seconds.

22:16:51: Train Epoch: 16 [0/45000 (0%)]	Loss: 0.949087
22:16:55: Train Epoch: 16 [10000/45000 (22%)]	Loss: 1.030977
22:17:00: Train Epoch: 16 [20000/45000 (44%)]	Loss: 1.101172
22:17:05: Train Epoch: 16 [30000/45000 (67%)]	Loss: 0.774793
22:17:09: Train Epoch: 16 [40000/45000 (89%)]	Loss: 1.014955
22:17:13: 
Evaluation: Average loss: 0.0106, Accuracy: 3270/5000 (65.400%)

22:17:13: Current learning rate: 0.1. Time taken for epoch: 23.42 seconds.

22:17:14: Train Epoch: 17 [0/45000 (0%)]	Loss: 0.911990
22:17:19: Train Epoch: 17 [10000/45000 (22%)]	Loss: 1.022918
22:17:23: Train Epoch: 17 [20000/45000 (44%)]	Loss: 0.746091
22:17:28: Train Epoch: 17 [30000/45000 (67%)]	Loss: 1.168708
22:17:32: Train Epoch: 17 [40000/45000 (89%)]	Loss: 0.960175
22:17:37: 
Evaluation: Average loss: 0.0102, Accuracy: 3340/5000 (66.800%)

22:17:37: Current learning rate: 0.1. Time taken for epoch: 23.46 seconds.

22:17:37: Train Epoch: 18 [0/45000 (0%)]	Loss: 0.910733
22:17:42: Train Epoch: 18 [10000/45000 (22%)]	Loss: 0.963349
22:17:47: Train Epoch: 18 [20000/45000 (44%)]	Loss: 0.970611
22:17:52: Train Epoch: 18 [30000/45000 (67%)]	Loss: 0.635672
22:17:56: Train Epoch: 18 [40000/45000 (89%)]	Loss: 0.885292
22:18:01: 
Evaluation: Average loss: 0.0109, Accuracy: 3197/5000 (63.940%)

22:18:01: Current learning rate: 0.1. Time taken for epoch: 23.84 seconds.

22:18:01: Train Epoch: 19 [0/45000 (0%)]	Loss: 0.665436
22:18:06: Train Epoch: 19 [10000/45000 (22%)]	Loss: 0.843730
22:18:11: Train Epoch: 19 [20000/45000 (44%)]	Loss: 1.012961
22:18:15: Train Epoch: 19 [30000/45000 (67%)]	Loss: 1.097223
22:18:20: Namespace(batch_size=100, bench=True, data='mnist', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='lenet300-100', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:18:20: 


22:18:20: ================================================================================
22:18:20: 
Iteration start: 1/1

22:18:22: LeNet_300_100(
  (fc1): Linear(in_features=784, out_features=300, bias=True)
  (fc2): Linear(in_features=300, out_features=100, bias=True)
  (fc3): Linear(in_features=100, out_features=10, bias=True)
)
22:18:22: ============================================================
22:18:22: lenet300-100
22:18:22: ============================================================
22:18:22: ============================================================
22:18:22: Prune mode: magnitude
22:18:22: Growth mode: momentum
22:18:22: Redistribution mode: momentum
22:18:22: ============================================================
22:18:22: Train Epoch: 1 [0/54000 (0%)]	Loss: 2.304187
22:18:23: Train Epoch: 1 [10000/54000 (19%)]	Loss: 0.241723
22:18:25: Train Epoch: 1 [20000/54000 (37%)]	Loss: 0.240182
22:18:42: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='vgg-d', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:18:42: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='vgg-d', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:18:42: 


22:18:42: 


22:18:42: ================================================================================
22:18:42: ================================================================================
22:18:42: 
Iteration start: 1/1

22:18:42: 
Iteration start: 1/1

22:18:44: VGG16(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
22:18:44: VGG16(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
22:18:44: ============================================================
22:18:44: ============================================================
22:18:44: vgg-d
22:18:44: vgg-d
22:18:44: ============================================================
22:18:44: ============================================================
22:18:44: ============================================================
22:18:44: ============================================================
22:18:44: Prune mode: magnitude
22:18:44: Prune mode: magnitude
22:18:44: Growth mode: momentum
22:18:44: Growth mode: momentum
22:18:44: Redistribution mode: momentum
22:18:44: Redistribution mode: momentum
22:18:44: ============================================================
22:18:44: ============================================================
22:18:44: Train Epoch: 1 [0/45000 (0%)]	Loss: 2.493264
22:18:44: Train Epoch: 1 [0/45000 (0%)]	Loss: 2.493264
22:18:51: Train Epoch: 1 [10000/45000 (22%)]	Loss: 3.538699
22:18:51: Train Epoch: 1 [10000/45000 (22%)]	Loss: 3.538699
22:18:57: Train Epoch: 1 [20000/45000 (44%)]	Loss: 1.976608
22:18:57: Train Epoch: 1 [20000/45000 (44%)]	Loss: 1.976608
22:19:04: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.881186
22:19:04: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.881186
22:19:11: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.843703
22:19:11: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.843703
22:19:17: 
Evaluation: Average loss: 0.0190, Accuracy: 1242/5000 (24.840%)

22:19:17: 
Evaluation: Average loss: 0.0190, Accuracy: 1242/5000 (24.840%)

22:19:17: Current learning rate: 0.1. Time taken for epoch: 33.04 seconds.

22:19:17: Current learning rate: 0.1. Time taken for epoch: 33.04 seconds.

22:19:17: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.915445
22:19:17: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.915445
22:19:24: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.863323
22:19:24: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.863323
22:19:31: Train Epoch: 2 [20000/45000 (44%)]	Loss: 1.873123
22:19:31: Train Epoch: 2 [20000/45000 (44%)]	Loss: 1.873123
22:19:37: Train Epoch: 2 [30000/45000 (67%)]	Loss: 1.695018
22:19:37: Train Epoch: 2 [30000/45000 (67%)]	Loss: 1.695018
22:19:44: Train Epoch: 2 [40000/45000 (89%)]	Loss: 1.553206
22:19:44: Train Epoch: 2 [40000/45000 (89%)]	Loss: 1.553206
22:19:49: 
Evaluation: Average loss: 0.0164, Accuracy: 1828/5000 (36.560%)

22:19:49: 
Evaluation: Average loss: 0.0164, Accuracy: 1828/5000 (36.560%)

22:19:50: Current learning rate: 0.1. Time taken for epoch: 32.83 seconds.

22:19:50: Current learning rate: 0.1. Time taken for epoch: 32.83 seconds.

22:19:50: Train Epoch: 3 [0/45000 (0%)]	Loss: 1.825549
22:19:50: Train Epoch: 3 [0/45000 (0%)]	Loss: 1.825549
22:19:57: Train Epoch: 3 [10000/45000 (22%)]	Loss: 1.526147
22:19:57: Train Epoch: 3 [10000/45000 (22%)]	Loss: 1.526147
22:20:04: Train Epoch: 3 [20000/45000 (44%)]	Loss: 1.675588
22:20:04: Train Epoch: 3 [20000/45000 (44%)]	Loss: 1.675588
22:20:10: Train Epoch: 3 [30000/45000 (67%)]	Loss: 1.463606
22:20:10: Train Epoch: 3 [30000/45000 (67%)]	Loss: 1.463606
22:20:16: Train Epoch: 3 [40000/45000 (89%)]	Loss: 1.686426
22:20:16: Train Epoch: 3 [40000/45000 (89%)]	Loss: 1.686426
22:20:22: 
Evaluation: Average loss: 0.0155, Accuracy: 2021/5000 (40.420%)

22:20:22: 
Evaluation: Average loss: 0.0155, Accuracy: 2021/5000 (40.420%)

22:20:22: Current learning rate: 0.1. Time taken for epoch: 32.87 seconds.

22:20:22: Current learning rate: 0.1. Time taken for epoch: 32.87 seconds.

22:20:23: Train Epoch: 4 [0/45000 (0%)]	Loss: 1.457540
22:20:23: Train Epoch: 4 [0/45000 (0%)]	Loss: 1.457540
22:20:30: Train Epoch: 4 [10000/45000 (22%)]	Loss: 1.472508
22:20:30: Train Epoch: 4 [10000/45000 (22%)]	Loss: 1.472508
22:20:36: Train Epoch: 4 [20000/45000 (44%)]	Loss: 1.503165
22:20:36: Train Epoch: 4 [20000/45000 (44%)]	Loss: 1.503165
22:20:43: Train Epoch: 4 [30000/45000 (67%)]	Loss: 1.230379
22:20:43: Train Epoch: 4 [30000/45000 (67%)]	Loss: 1.230379
22:20:49: Train Epoch: 4 [40000/45000 (89%)]	Loss: 1.479682
22:20:49: Train Epoch: 4 [40000/45000 (89%)]	Loss: 1.479682
22:20:55: 
Evaluation: Average loss: 0.0139, Accuracy: 2413/5000 (48.260%)

22:20:55: 
Evaluation: Average loss: 0.0139, Accuracy: 2413/5000 (48.260%)

22:20:55: Current learning rate: 0.1. Time taken for epoch: 32.81 seconds.

22:20:55: Current learning rate: 0.1. Time taken for epoch: 32.81 seconds.

22:20:56: Train Epoch: 5 [0/45000 (0%)]	Loss: 1.192894
22:20:56: Train Epoch: 5 [0/45000 (0%)]	Loss: 1.192894
22:25:07: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='vgg-d', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:25:07: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='vgg-d', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:25:07: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='vgg-d', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:25:07: 


22:25:07: 


22:25:07: 


22:25:07: ================================================================================
22:25:07: ================================================================================
22:25:07: ================================================================================
22:25:07: 
Iteration start: 1/1

22:25:07: 
Iteration start: 1/1

22:25:07: 
Iteration start: 1/1

22:25:08: VGG16(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
22:25:08: VGG16(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
22:25:08: VGG16(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
22:25:08: ============================================================
22:25:08: ============================================================
22:25:08: ============================================================
22:25:08: vgg-d
22:25:08: vgg-d
22:25:08: vgg-d
22:25:08: ============================================================
22:25:08: ============================================================
22:25:08: ============================================================
22:25:08: ============================================================
22:25:08: ============================================================
22:25:08: ============================================================
22:25:08: Prune mode: magnitude
22:25:08: Prune mode: magnitude
22:25:08: Prune mode: magnitude
22:25:08: Growth mode: momentum
22:25:08: Growth mode: momentum
22:25:08: Growth mode: momentum
22:25:08: Redistribution mode: momentum
22:25:08: Redistribution mode: momentum
22:25:08: Redistribution mode: momentum
22:25:08: ============================================================
22:25:08: ============================================================
22:25:08: ============================================================
22:25:09: Train Epoch: 1 [0/45000 (0%)]	Loss: 2.493264
22:25:09: Train Epoch: 1 [0/45000 (0%)]	Loss: 2.493264
22:25:09: Train Epoch: 1 [0/45000 (0%)]	Loss: 2.493264
22:25:15: Train Epoch: 1 [10000/45000 (22%)]	Loss: 3.538699
22:25:15: Train Epoch: 1 [10000/45000 (22%)]	Loss: 3.538699
22:25:15: Train Epoch: 1 [10000/45000 (22%)]	Loss: 3.538699
22:25:22: Train Epoch: 1 [20000/45000 (44%)]	Loss: 1.976608
22:25:22: Train Epoch: 1 [20000/45000 (44%)]	Loss: 1.976608
22:25:22: Train Epoch: 1 [20000/45000 (44%)]	Loss: 1.976608
22:25:28: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.881186
22:25:28: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.881186
22:25:28: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.881186
22:25:35: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.843703
22:25:35: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.843703
22:25:35: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.843703
22:25:41: 
Evaluation: Average loss: 0.0190, Accuracy: 1242/5000 (24.840%)

22:25:41: 
Evaluation: Average loss: 0.0190, Accuracy: 1242/5000 (24.840%)

22:25:41: 
Evaluation: Average loss: 0.0190, Accuracy: 1242/5000 (24.840%)

22:25:41: Current learning rate: 0.1. Time taken for epoch: 32.85 seconds.

22:25:41: Current learning rate: 0.1. Time taken for epoch: 32.85 seconds.

22:25:41: Current learning rate: 0.1. Time taken for epoch: 32.85 seconds.

22:25:42: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.915445
22:25:42: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.915445
22:25:42: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.915445
22:25:48: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.863323
22:25:48: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.863323
22:25:48: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.863323
22:25:55: Train Epoch: 2 [20000/45000 (44%)]	Loss: 1.873123
22:25:55: Train Epoch: 2 [20000/45000 (44%)]	Loss: 1.873123
22:25:55: Train Epoch: 2 [20000/45000 (44%)]	Loss: 1.873123
22:26:02: Train Epoch: 2 [30000/45000 (67%)]	Loss: 1.695018
22:26:02: Train Epoch: 2 [30000/45000 (67%)]	Loss: 1.695018
22:26:02: Train Epoch: 2 [30000/45000 (67%)]	Loss: 1.695018
22:26:08: Train Epoch: 2 [40000/45000 (89%)]	Loss: 1.553206
22:26:08: Train Epoch: 2 [40000/45000 (89%)]	Loss: 1.553206
22:26:08: Train Epoch: 2 [40000/45000 (89%)]	Loss: 1.553206
22:26:14: 
Evaluation: Average loss: 0.0164, Accuracy: 1828/5000 (36.560%)

22:26:14: 
Evaluation: Average loss: 0.0164, Accuracy: 1828/5000 (36.560%)

22:26:14: 
Evaluation: Average loss: 0.0164, Accuracy: 1828/5000 (36.560%)

22:26:14: Current learning rate: 0.1. Time taken for epoch: 33.36 seconds.

22:26:14: Current learning rate: 0.1. Time taken for epoch: 33.36 seconds.

22:26:14: Current learning rate: 0.1. Time taken for epoch: 33.36 seconds.

22:26:15: Train Epoch: 3 [0/45000 (0%)]	Loss: 1.825549
22:26:15: Train Epoch: 3 [0/45000 (0%)]	Loss: 1.825549
22:26:15: Train Epoch: 3 [0/45000 (0%)]	Loss: 1.825549
22:26:58: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='vgg-d', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:26:58: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='vgg-d', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:26:58: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='vgg-d', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:26:58: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='vgg-d', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:26:58: 


22:26:58: 


22:26:58: 


22:26:58: 


22:26:58: ================================================================================
22:26:58: ================================================================================
22:26:58: ================================================================================
22:26:58: ================================================================================
22:26:58: 
Iteration start: 1/1

22:26:58: 
Iteration start: 1/1

22:26:58: 
Iteration start: 1/1

22:26:58: 
Iteration start: 1/1

22:27:00: VGG16(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
22:27:00: VGG16(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
22:27:00: VGG16(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
22:27:00: VGG16(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
22:27:00: ============================================================
22:27:00: ============================================================
22:27:00: ============================================================
22:27:00: ============================================================
22:27:00: vgg-d
22:27:00: vgg-d
22:27:00: vgg-d
22:27:00: vgg-d
22:27:00: ============================================================
22:27:00: ============================================================
22:27:00: ============================================================
22:27:00: ============================================================
22:27:00: ============================================================
22:27:00: ============================================================
22:27:00: ============================================================
22:27:00: ============================================================
22:27:00: Prune mode: magnitude
22:27:00: Prune mode: magnitude
22:27:00: Prune mode: magnitude
22:27:00: Prune mode: magnitude
22:27:00: Growth mode: momentum
22:27:00: Growth mode: momentum
22:27:00: Growth mode: momentum
22:27:00: Growth mode: momentum
22:27:00: Redistribution mode: momentum
22:27:00: Redistribution mode: momentum
22:27:00: Redistribution mode: momentum
22:27:00: Redistribution mode: momentum
22:27:00: ============================================================
22:27:00: ============================================================
22:27:00: ============================================================
22:27:00: ============================================================
22:27:00: Train Epoch: 1 [0/45000 (0%)]	Loss: 2.493264
22:27:00: Train Epoch: 1 [0/45000 (0%)]	Loss: 2.493264
22:27:00: Train Epoch: 1 [0/45000 (0%)]	Loss: 2.493264
22:27:00: Train Epoch: 1 [0/45000 (0%)]	Loss: 2.493264
22:27:07: Train Epoch: 1 [10000/45000 (22%)]	Loss: 3.538699
22:27:07: Train Epoch: 1 [10000/45000 (22%)]	Loss: 3.538699
22:27:07: Train Epoch: 1 [10000/45000 (22%)]	Loss: 3.538699
22:27:07: Train Epoch: 1 [10000/45000 (22%)]	Loss: 3.538699
22:27:14: Train Epoch: 1 [20000/45000 (44%)]	Loss: 1.976608
22:27:14: Train Epoch: 1 [20000/45000 (44%)]	Loss: 1.976608
22:27:14: Train Epoch: 1 [20000/45000 (44%)]	Loss: 1.976608
22:27:14: Train Epoch: 1 [20000/45000 (44%)]	Loss: 1.976608
22:27:20: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.881186
22:27:20: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.881186
22:27:20: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.881186
22:27:20: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.881186
22:27:27: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.843703
22:27:27: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.843703
22:27:27: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.843703
22:27:27: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.843703
22:27:32: 
Evaluation: Average loss: 1.8959, Accuracy: 1242/5000 (24.840%)

22:27:32: 
Evaluation: Average loss: 1.8959, Accuracy: 1242/5000 (24.840%)

22:27:32: 
Evaluation: Average loss: 1.8959, Accuracy: 1242/5000 (24.840%)

22:27:32: 
Evaluation: Average loss: 1.8959, Accuracy: 1242/5000 (24.840%)

22:27:33: Current learning rate: 0.1. Time taken for epoch: 33.06 seconds.

22:27:33: Current learning rate: 0.1. Time taken for epoch: 33.06 seconds.

22:27:33: Current learning rate: 0.1. Time taken for epoch: 33.06 seconds.

22:27:33: Current learning rate: 0.1. Time taken for epoch: 33.06 seconds.

22:27:33: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.915445
22:27:33: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.915445
22:27:33: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.915445
22:27:33: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.915445
22:27:40: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.863323
22:27:40: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.863323
22:27:40: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.863323
22:27:40: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.863323
22:27:47: Train Epoch: 2 [20000/45000 (44%)]	Loss: 1.873123
22:27:47: Train Epoch: 2 [20000/45000 (44%)]	Loss: 1.873123
22:27:47: Train Epoch: 2 [20000/45000 (44%)]	Loss: 1.873123
22:27:47: Train Epoch: 2 [20000/45000 (44%)]	Loss: 1.873123
22:27:53: Train Epoch: 2 [30000/45000 (67%)]	Loss: 1.695018
22:27:53: Train Epoch: 2 [30000/45000 (67%)]	Loss: 1.695018
22:27:53: Train Epoch: 2 [30000/45000 (67%)]	Loss: 1.695018
22:27:53: Train Epoch: 2 [30000/45000 (67%)]	Loss: 1.695018
22:28:00: Train Epoch: 2 [40000/45000 (89%)]	Loss: 1.553206
22:28:00: Train Epoch: 2 [40000/45000 (89%)]	Loss: 1.553206
22:28:00: Train Epoch: 2 [40000/45000 (89%)]	Loss: 1.553206
22:28:00: Train Epoch: 2 [40000/45000 (89%)]	Loss: 1.553206
22:28:06: 
Evaluation: Average loss: 1.6408, Accuracy: 1828/5000 (36.560%)

22:28:06: 
Evaluation: Average loss: 1.6408, Accuracy: 1828/5000 (36.560%)

22:28:06: 
Evaluation: Average loss: 1.6408, Accuracy: 1828/5000 (36.560%)

22:28:06: 
Evaluation: Average loss: 1.6408, Accuracy: 1828/5000 (36.560%)

22:28:06: Current learning rate: 0.1. Time taken for epoch: 33.20 seconds.

22:28:06: Current learning rate: 0.1. Time taken for epoch: 33.20 seconds.

22:28:06: Current learning rate: 0.1. Time taken for epoch: 33.20 seconds.

22:28:06: Current learning rate: 0.1. Time taken for epoch: 33.20 seconds.

22:28:07: Train Epoch: 3 [0/45000 (0%)]	Loss: 1.825549
22:28:07: Train Epoch: 3 [0/45000 (0%)]	Loss: 1.825549
22:28:07: Train Epoch: 3 [0/45000 (0%)]	Loss: 1.825549
22:28:07: Train Epoch: 3 [0/45000 (0%)]	Loss: 1.825549
22:29:22: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='vgg-d', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:29:22: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='vgg-d', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:29:22: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='vgg-d', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:29:22: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='vgg-d', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:29:22: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='vgg-d', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:29:22: 


22:29:22: 


22:29:22: 


22:29:22: 


22:29:22: 


22:29:22: ================================================================================
22:29:22: ================================================================================
22:29:22: ================================================================================
22:29:22: ================================================================================
22:29:22: ================================================================================
22:29:22: 
Iteration start: 1/1

22:29:22: 
Iteration start: 1/1

22:29:22: 
Iteration start: 1/1

22:29:22: 
Iteration start: 1/1

22:29:22: 
Iteration start: 1/1

22:29:24: VGG16(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
22:29:24: VGG16(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
22:29:24: VGG16(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
22:29:24: VGG16(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
22:29:24: VGG16(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
22:29:24: ============================================================
22:29:24: ============================================================
22:29:24: ============================================================
22:29:24: ============================================================
22:29:24: ============================================================
22:29:24: vgg-d
22:29:24: vgg-d
22:29:24: vgg-d
22:29:24: vgg-d
22:29:24: vgg-d
22:29:24: ============================================================
22:29:24: ============================================================
22:29:24: ============================================================
22:29:24: ============================================================
22:29:24: ============================================================
22:29:24: ============================================================
22:29:24: ============================================================
22:29:24: ============================================================
22:29:24: ============================================================
22:29:24: ============================================================
22:29:24: Prune mode: magnitude
22:29:24: Prune mode: magnitude
22:29:24: Prune mode: magnitude
22:29:24: Prune mode: magnitude
22:29:24: Prune mode: magnitude
22:29:24: Growth mode: momentum
22:29:24: Growth mode: momentum
22:29:24: Growth mode: momentum
22:29:24: Growth mode: momentum
22:29:24: Growth mode: momentum
22:29:24: Redistribution mode: momentum
22:29:24: Redistribution mode: momentum
22:29:24: Redistribution mode: momentum
22:29:24: Redistribution mode: momentum
22:29:24: Redistribution mode: momentum
22:29:24: ============================================================
22:29:24: ============================================================
22:29:24: ============================================================
22:29:24: ============================================================
22:29:24: ============================================================
22:29:24: Train Epoch: 1 [0/45000 (0%)]	Loss: 2.493264
22:29:24: Train Epoch: 1 [0/45000 (0%)]	Loss: 2.493264
22:29:24: Train Epoch: 1 [0/45000 (0%)]	Loss: 2.493264
22:29:24: Train Epoch: 1 [0/45000 (0%)]	Loss: 2.493264
22:29:24: Train Epoch: 1 [0/45000 (0%)]	Loss: 2.493264
22:29:31: Train Epoch: 1 [10000/45000 (22%)]	Loss: 3.538699
22:29:31: Train Epoch: 1 [10000/45000 (22%)]	Loss: 3.538699
22:29:31: Train Epoch: 1 [10000/45000 (22%)]	Loss: 3.538699
22:29:31: Train Epoch: 1 [10000/45000 (22%)]	Loss: 3.538699
22:29:31: Train Epoch: 1 [10000/45000 (22%)]	Loss: 3.538699
22:29:38: Train Epoch: 1 [20000/45000 (44%)]	Loss: 1.976608
22:29:38: Train Epoch: 1 [20000/45000 (44%)]	Loss: 1.976608
22:29:38: Train Epoch: 1 [20000/45000 (44%)]	Loss: 1.976608
22:29:38: Train Epoch: 1 [20000/45000 (44%)]	Loss: 1.976608
22:29:38: Train Epoch: 1 [20000/45000 (44%)]	Loss: 1.976608
22:29:44: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.881186
22:29:44: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.881186
22:29:44: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.881186
22:29:44: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.881186
22:29:44: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.881186
22:29:51: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.843703
22:29:51: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.843703
22:29:51: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.843703
22:29:51: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.843703
22:29:51: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.843703
22:30:34: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='vgg-d', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:30:34: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='vgg-d', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:30:34: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='vgg-d', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:30:34: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='vgg-d', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:30:34: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='vgg-d', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:30:34: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='vgg-d', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:30:34: 


22:30:34: 


22:30:34: 


22:30:34: 


22:30:34: 


22:30:34: 


22:30:34: ================================================================================
22:30:34: ================================================================================
22:30:34: ================================================================================
22:30:34: ================================================================================
22:30:34: ================================================================================
22:30:34: ================================================================================
22:30:34: 
Iteration start: 1/1

22:30:34: 
Iteration start: 1/1

22:30:34: 
Iteration start: 1/1

22:30:34: 
Iteration start: 1/1

22:30:34: 
Iteration start: 1/1

22:30:34: 
Iteration start: 1/1

22:30:36: VGG16(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
22:30:36: VGG16(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
22:30:36: VGG16(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
22:30:36: VGG16(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
22:30:36: VGG16(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
22:30:36: VGG16(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
22:30:36: ============================================================
22:30:36: ============================================================
22:30:36: ============================================================
22:30:36: ============================================================
22:30:36: ============================================================
22:30:36: ============================================================
22:30:36: vgg-d
22:30:36: vgg-d
22:30:36: vgg-d
22:30:36: vgg-d
22:30:36: vgg-d
22:30:36: vgg-d
22:30:36: ============================================================
22:30:36: ============================================================
22:30:36: ============================================================
22:30:36: ============================================================
22:30:36: ============================================================
22:30:36: ============================================================
22:30:36: ============================================================
22:30:36: ============================================================
22:30:36: ============================================================
22:30:36: ============================================================
22:30:36: ============================================================
22:30:36: ============================================================
22:30:36: Prune mode: magnitude
22:30:36: Prune mode: magnitude
22:30:36: Prune mode: magnitude
22:30:36: Prune mode: magnitude
22:30:36: Prune mode: magnitude
22:30:36: Prune mode: magnitude
22:30:36: Growth mode: momentum
22:30:36: Growth mode: momentum
22:30:36: Growth mode: momentum
22:30:36: Growth mode: momentum
22:30:36: Growth mode: momentum
22:30:36: Growth mode: momentum
22:30:36: Redistribution mode: momentum
22:30:36: Redistribution mode: momentum
22:30:36: Redistribution mode: momentum
22:30:36: Redistribution mode: momentum
22:30:36: Redistribution mode: momentum
22:30:36: Redistribution mode: momentum
22:30:36: ============================================================
22:30:36: ============================================================
22:30:36: ============================================================
22:30:36: ============================================================
22:30:36: ============================================================
22:30:36: ============================================================
22:30:37: Train Epoch: 1 [0/45000 (0%)]	Loss: 2.493264
22:30:37: Train Epoch: 1 [0/45000 (0%)]	Loss: 2.493264
22:30:37: Train Epoch: 1 [0/45000 (0%)]	Loss: 2.493264
22:30:37: Train Epoch: 1 [0/45000 (0%)]	Loss: 2.493264
22:30:37: Train Epoch: 1 [0/45000 (0%)]	Loss: 2.493264
22:30:37: Train Epoch: 1 [0/45000 (0%)]	Loss: 2.493264
22:30:43: Train Epoch: 1 [10000/45000 (22%)]	Loss: 3.538699
22:30:43: Train Epoch: 1 [10000/45000 (22%)]	Loss: 3.538699
22:30:43: Train Epoch: 1 [10000/45000 (22%)]	Loss: 3.538699
22:30:43: Train Epoch: 1 [10000/45000 (22%)]	Loss: 3.538699
22:30:43: Train Epoch: 1 [10000/45000 (22%)]	Loss: 3.538699
22:30:43: Train Epoch: 1 [10000/45000 (22%)]	Loss: 3.538699
22:30:50: Train Epoch: 1 [20000/45000 (44%)]	Loss: 1.976608
22:30:50: Train Epoch: 1 [20000/45000 (44%)]	Loss: 1.976608
22:30:50: Train Epoch: 1 [20000/45000 (44%)]	Loss: 1.976608
22:30:50: Train Epoch: 1 [20000/45000 (44%)]	Loss: 1.976608
22:30:50: Train Epoch: 1 [20000/45000 (44%)]	Loss: 1.976608
22:30:50: Train Epoch: 1 [20000/45000 (44%)]	Loss: 1.976608
22:30:56: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.881186
22:30:56: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.881186
22:30:56: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.881186
22:30:56: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.881186
22:30:56: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.881186
22:30:56: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.881186
22:31:03: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.843703
22:31:03: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.843703
22:31:03: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.843703
22:31:03: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.843703
22:31:03: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.843703
22:31:03: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.843703
22:31:09: 
Evaluation: Average loss: 1.8959, Accuracy: 1242/5000 (24.840%)

22:31:09: 
Evaluation: Average loss: 1.8959, Accuracy: 1242/5000 (24.840%)

22:31:09: 
Evaluation: Average loss: 1.8959, Accuracy: 1242/5000 (24.840%)

22:31:09: 
Evaluation: Average loss: 1.8959, Accuracy: 1242/5000 (24.840%)

22:31:09: 
Evaluation: Average loss: 1.8959, Accuracy: 1242/5000 (24.840%)

22:31:09: 
Evaluation: Average loss: 1.8959, Accuracy: 1242/5000 (24.840%)

22:31:09: Current learning rate: 0.1. Time taken for epoch: 33.45 seconds.

22:31:09: Current learning rate: 0.1. Time taken for epoch: 33.45 seconds.

22:31:09: Current learning rate: 0.1. Time taken for epoch: 33.45 seconds.

22:31:09: Current learning rate: 0.1. Time taken for epoch: 33.45 seconds.

22:31:09: Current learning rate: 0.1. Time taken for epoch: 33.45 seconds.

22:31:09: Current learning rate: 0.1. Time taken for epoch: 33.45 seconds.

22:31:10: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.915445
22:31:10: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.915445
22:31:10: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.915445
22:31:10: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.915445
22:31:10: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.915445
22:31:10: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.915445
22:31:17: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.863323
22:31:17: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.863323
22:31:17: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.863323
22:31:17: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.863323
22:31:17: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.863323
22:31:17: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.863323
22:31:23: Train Epoch: 2 [20000/45000 (44%)]	Loss: 1.873123
22:31:23: Train Epoch: 2 [20000/45000 (44%)]	Loss: 1.873123
22:31:23: Train Epoch: 2 [20000/45000 (44%)]	Loss: 1.873123
22:31:23: Train Epoch: 2 [20000/45000 (44%)]	Loss: 1.873123
22:31:23: Train Epoch: 2 [20000/45000 (44%)]	Loss: 1.873123
22:31:23: Train Epoch: 2 [20000/45000 (44%)]	Loss: 1.873123
22:31:30: Train Epoch: 2 [30000/45000 (67%)]	Loss: 1.695018
22:31:30: Train Epoch: 2 [30000/45000 (67%)]	Loss: 1.695018
22:31:30: Train Epoch: 2 [30000/45000 (67%)]	Loss: 1.695018
22:31:30: Train Epoch: 2 [30000/45000 (67%)]	Loss: 1.695018
22:31:30: Train Epoch: 2 [30000/45000 (67%)]	Loss: 1.695018
22:31:30: Train Epoch: 2 [30000/45000 (67%)]	Loss: 1.695018
22:31:36: Train Epoch: 2 [40000/45000 (89%)]	Loss: 1.553206
22:31:36: Train Epoch: 2 [40000/45000 (89%)]	Loss: 1.553206
22:31:36: Train Epoch: 2 [40000/45000 (89%)]	Loss: 1.553206
22:31:36: Train Epoch: 2 [40000/45000 (89%)]	Loss: 1.553206
22:31:36: Train Epoch: 2 [40000/45000 (89%)]	Loss: 1.553206
22:31:36: Train Epoch: 2 [40000/45000 (89%)]	Loss: 1.553206
22:31:42: 
Evaluation: Average loss: 1.6408, Accuracy: 1828/5000 (36.560%)

22:31:42: 
Evaluation: Average loss: 1.6408, Accuracy: 1828/5000 (36.560%)

22:31:42: 
Evaluation: Average loss: 1.6408, Accuracy: 1828/5000 (36.560%)

22:31:42: 
Evaluation: Average loss: 1.6408, Accuracy: 1828/5000 (36.560%)

22:31:42: 
Evaluation: Average loss: 1.6408, Accuracy: 1828/5000 (36.560%)

22:31:42: 
Evaluation: Average loss: 1.6408, Accuracy: 1828/5000 (36.560%)

22:31:42: Current learning rate: 0.1. Time taken for epoch: 33.35 seconds.

22:31:42: Current learning rate: 0.1. Time taken for epoch: 33.35 seconds.

22:31:42: Current learning rate: 0.1. Time taken for epoch: 33.35 seconds.

22:31:42: Current learning rate: 0.1. Time taken for epoch: 33.35 seconds.

22:31:42: Current learning rate: 0.1. Time taken for epoch: 33.35 seconds.

22:31:42: Current learning rate: 0.1. Time taken for epoch: 33.35 seconds.

22:31:43: Train Epoch: 3 [0/45000 (0%)]	Loss: 1.825549
22:31:43: Train Epoch: 3 [0/45000 (0%)]	Loss: 1.825549
22:31:43: Train Epoch: 3 [0/45000 (0%)]	Loss: 1.825549
22:31:43: Train Epoch: 3 [0/45000 (0%)]	Loss: 1.825549
22:31:43: Train Epoch: 3 [0/45000 (0%)]	Loss: 1.825549
22:31:43: Train Epoch: 3 [0/45000 (0%)]	Loss: 1.825549
22:31:50: Train Epoch: 3 [10000/45000 (22%)]	Loss: 1.526147
22:31:50: Train Epoch: 3 [10000/45000 (22%)]	Loss: 1.526147
22:31:50: Train Epoch: 3 [10000/45000 (22%)]	Loss: 1.526147
22:31:50: Train Epoch: 3 [10000/45000 (22%)]	Loss: 1.526147
22:31:50: Train Epoch: 3 [10000/45000 (22%)]	Loss: 1.526147
22:31:50: Train Epoch: 3 [10000/45000 (22%)]	Loss: 1.526147
22:31:56: Train Epoch: 3 [20000/45000 (44%)]	Loss: 1.675588
22:31:56: Train Epoch: 3 [20000/45000 (44%)]	Loss: 1.675588
22:31:56: Train Epoch: 3 [20000/45000 (44%)]	Loss: 1.675588
22:31:56: Train Epoch: 3 [20000/45000 (44%)]	Loss: 1.675588
22:31:56: Train Epoch: 3 [20000/45000 (44%)]	Loss: 1.675588
22:31:56: Train Epoch: 3 [20000/45000 (44%)]	Loss: 1.675588
22:32:03: Train Epoch: 3 [30000/45000 (67%)]	Loss: 1.463606
22:32:03: Train Epoch: 3 [30000/45000 (67%)]	Loss: 1.463606
22:32:03: Train Epoch: 3 [30000/45000 (67%)]	Loss: 1.463606
22:32:03: Train Epoch: 3 [30000/45000 (67%)]	Loss: 1.463606
22:32:03: Train Epoch: 3 [30000/45000 (67%)]	Loss: 1.463606
22:32:03: Train Epoch: 3 [30000/45000 (67%)]	Loss: 1.463606
22:32:09: Train Epoch: 3 [40000/45000 (89%)]	Loss: 1.686426
22:32:09: Train Epoch: 3 [40000/45000 (89%)]	Loss: 1.686426
22:32:09: Train Epoch: 3 [40000/45000 (89%)]	Loss: 1.686426
22:32:09: Train Epoch: 3 [40000/45000 (89%)]	Loss: 1.686426
22:32:09: Train Epoch: 3 [40000/45000 (89%)]	Loss: 1.686426
22:32:09: Train Epoch: 3 [40000/45000 (89%)]	Loss: 1.686426
22:32:15: 
Evaluation: Average loss: 1.5538, Accuracy: 2021/5000 (40.420%)

22:32:15: 
Evaluation: Average loss: 1.5538, Accuracy: 2021/5000 (40.420%)

22:32:15: 
Evaluation: Average loss: 1.5538, Accuracy: 2021/5000 (40.420%)

22:32:15: 
Evaluation: Average loss: 1.5538, Accuracy: 2021/5000 (40.420%)

22:32:15: 
Evaluation: Average loss: 1.5538, Accuracy: 2021/5000 (40.420%)

22:32:15: 
Evaluation: Average loss: 1.5538, Accuracy: 2021/5000 (40.420%)

22:32:15: Current learning rate: 0.1. Time taken for epoch: 32.99 seconds.

22:32:15: Current learning rate: 0.1. Time taken for epoch: 32.99 seconds.

22:32:15: Current learning rate: 0.1. Time taken for epoch: 32.99 seconds.

22:32:15: Current learning rate: 0.1. Time taken for epoch: 32.99 seconds.

22:32:15: Current learning rate: 0.1. Time taken for epoch: 32.99 seconds.

22:32:15: Current learning rate: 0.1. Time taken for epoch: 32.99 seconds.

22:32:16: Train Epoch: 4 [0/45000 (0%)]	Loss: 1.457540
22:32:16: Train Epoch: 4 [0/45000 (0%)]	Loss: 1.457540
22:32:16: Train Epoch: 4 [0/45000 (0%)]	Loss: 1.457540
22:32:16: Train Epoch: 4 [0/45000 (0%)]	Loss: 1.457540
22:32:16: Train Epoch: 4 [0/45000 (0%)]	Loss: 1.457540
22:32:16: Train Epoch: 4 [0/45000 (0%)]	Loss: 1.457540
22:32:23: Train Epoch: 4 [10000/45000 (22%)]	Loss: 1.472508
22:32:23: Train Epoch: 4 [10000/45000 (22%)]	Loss: 1.472508
22:32:23: Train Epoch: 4 [10000/45000 (22%)]	Loss: 1.472508
22:32:23: Train Epoch: 4 [10000/45000 (22%)]	Loss: 1.472508
22:32:23: Train Epoch: 4 [10000/45000 (22%)]	Loss: 1.472508
22:32:23: Train Epoch: 4 [10000/45000 (22%)]	Loss: 1.472508
22:32:29: Train Epoch: 4 [20000/45000 (44%)]	Loss: 1.503165
22:32:29: Train Epoch: 4 [20000/45000 (44%)]	Loss: 1.503165
22:32:29: Train Epoch: 4 [20000/45000 (44%)]	Loss: 1.503165
22:32:29: Train Epoch: 4 [20000/45000 (44%)]	Loss: 1.503165
22:32:29: Train Epoch: 4 [20000/45000 (44%)]	Loss: 1.503165
22:32:29: Train Epoch: 4 [20000/45000 (44%)]	Loss: 1.503165
22:32:36: Train Epoch: 4 [30000/45000 (67%)]	Loss: 1.230379
22:32:36: Train Epoch: 4 [30000/45000 (67%)]	Loss: 1.230379
22:32:36: Train Epoch: 4 [30000/45000 (67%)]	Loss: 1.230379
22:32:36: Train Epoch: 4 [30000/45000 (67%)]	Loss: 1.230379
22:32:36: Train Epoch: 4 [30000/45000 (67%)]	Loss: 1.230379
22:32:36: Train Epoch: 4 [30000/45000 (67%)]	Loss: 1.230379
22:32:42: Train Epoch: 4 [40000/45000 (89%)]	Loss: 1.479682
22:32:42: Train Epoch: 4 [40000/45000 (89%)]	Loss: 1.479682
22:32:42: Train Epoch: 4 [40000/45000 (89%)]	Loss: 1.479682
22:32:42: Train Epoch: 4 [40000/45000 (89%)]	Loss: 1.479682
22:32:42: Train Epoch: 4 [40000/45000 (89%)]	Loss: 1.479682
22:32:42: Train Epoch: 4 [40000/45000 (89%)]	Loss: 1.479682
22:32:48: 
Evaluation: Average loss: 1.3853, Accuracy: 2413/5000 (48.260%)

22:32:48: 
Evaluation: Average loss: 1.3853, Accuracy: 2413/5000 (48.260%)

22:32:48: 
Evaluation: Average loss: 1.3853, Accuracy: 2413/5000 (48.260%)

22:32:48: 
Evaluation: Average loss: 1.3853, Accuracy: 2413/5000 (48.260%)

22:32:48: 
Evaluation: Average loss: 1.3853, Accuracy: 2413/5000 (48.260%)

22:32:48: 
Evaluation: Average loss: 1.3853, Accuracy: 2413/5000 (48.260%)

22:32:48: Current learning rate: 0.1. Time taken for epoch: 32.90 seconds.

22:32:48: Current learning rate: 0.1. Time taken for epoch: 32.90 seconds.

22:32:48: Current learning rate: 0.1. Time taken for epoch: 32.90 seconds.

22:32:48: Current learning rate: 0.1. Time taken for epoch: 32.90 seconds.

22:32:48: Current learning rate: 0.1. Time taken for epoch: 32.90 seconds.

22:32:48: Current learning rate: 0.1. Time taken for epoch: 32.90 seconds.

22:32:49: Train Epoch: 5 [0/45000 (0%)]	Loss: 1.192894
22:32:49: Train Epoch: 5 [0/45000 (0%)]	Loss: 1.192894
22:32:49: Train Epoch: 5 [0/45000 (0%)]	Loss: 1.192894
22:32:49: Train Epoch: 5 [0/45000 (0%)]	Loss: 1.192894
22:32:49: Train Epoch: 5 [0/45000 (0%)]	Loss: 1.192894
22:32:49: Train Epoch: 5 [0/45000 (0%)]	Loss: 1.192894
22:32:56: Train Epoch: 5 [10000/45000 (22%)]	Loss: 1.375380
22:32:56: Train Epoch: 5 [10000/45000 (22%)]	Loss: 1.375380
22:32:56: Train Epoch: 5 [10000/45000 (22%)]	Loss: 1.375380
22:32:56: Train Epoch: 5 [10000/45000 (22%)]	Loss: 1.375380
22:32:56: Train Epoch: 5 [10000/45000 (22%)]	Loss: 1.375380
22:32:56: Train Epoch: 5 [10000/45000 (22%)]	Loss: 1.375380
22:33:02: Train Epoch: 5 [20000/45000 (44%)]	Loss: 1.329520
22:33:02: Train Epoch: 5 [20000/45000 (44%)]	Loss: 1.329520
22:33:02: Train Epoch: 5 [20000/45000 (44%)]	Loss: 1.329520
22:33:02: Train Epoch: 5 [20000/45000 (44%)]	Loss: 1.329520
22:33:02: Train Epoch: 5 [20000/45000 (44%)]	Loss: 1.329520
22:33:02: Train Epoch: 5 [20000/45000 (44%)]	Loss: 1.329520
22:33:09: Train Epoch: 5 [30000/45000 (67%)]	Loss: 1.107607
22:33:09: Train Epoch: 5 [30000/45000 (67%)]	Loss: 1.107607
22:33:09: Train Epoch: 5 [30000/45000 (67%)]	Loss: 1.107607
22:33:09: Train Epoch: 5 [30000/45000 (67%)]	Loss: 1.107607
22:33:09: Train Epoch: 5 [30000/45000 (67%)]	Loss: 1.107607
22:33:09: Train Epoch: 5 [30000/45000 (67%)]	Loss: 1.107607
22:33:16: Train Epoch: 5 [40000/45000 (89%)]	Loss: 1.187082
22:33:16: Train Epoch: 5 [40000/45000 (89%)]	Loss: 1.187082
22:33:16: Train Epoch: 5 [40000/45000 (89%)]	Loss: 1.187082
22:33:16: Train Epoch: 5 [40000/45000 (89%)]	Loss: 1.187082
22:33:16: Train Epoch: 5 [40000/45000 (89%)]	Loss: 1.187082
22:33:16: Train Epoch: 5 [40000/45000 (89%)]	Loss: 1.187082
22:33:21: 
Evaluation: Average loss: 1.5255, Accuracy: 2179/5000 (43.580%)

22:33:21: 
Evaluation: Average loss: 1.5255, Accuracy: 2179/5000 (43.580%)

22:33:21: 
Evaluation: Average loss: 1.5255, Accuracy: 2179/5000 (43.580%)

22:33:21: 
Evaluation: Average loss: 1.5255, Accuracy: 2179/5000 (43.580%)

22:33:21: 
Evaluation: Average loss: 1.5255, Accuracy: 2179/5000 (43.580%)

22:33:21: 
Evaluation: Average loss: 1.5255, Accuracy: 2179/5000 (43.580%)

22:33:21: Current learning rate: 0.1. Time taken for epoch: 33.05 seconds.

22:33:21: Current learning rate: 0.1. Time taken for epoch: 33.05 seconds.

22:33:21: Current learning rate: 0.1. Time taken for epoch: 33.05 seconds.

22:33:21: Current learning rate: 0.1. Time taken for epoch: 33.05 seconds.

22:33:21: Current learning rate: 0.1. Time taken for epoch: 33.05 seconds.

22:33:21: Current learning rate: 0.1. Time taken for epoch: 33.05 seconds.

22:33:22: Train Epoch: 6 [0/45000 (0%)]	Loss: 1.045071
22:33:22: Train Epoch: 6 [0/45000 (0%)]	Loss: 1.045071
22:33:22: Train Epoch: 6 [0/45000 (0%)]	Loss: 1.045071
22:33:22: Train Epoch: 6 [0/45000 (0%)]	Loss: 1.045071
22:33:22: Train Epoch: 6 [0/45000 (0%)]	Loss: 1.045071
22:33:22: Train Epoch: 6 [0/45000 (0%)]	Loss: 1.045071
22:33:29: Train Epoch: 6 [10000/45000 (22%)]	Loss: 1.316386
22:33:29: Train Epoch: 6 [10000/45000 (22%)]	Loss: 1.316386
22:33:29: Train Epoch: 6 [10000/45000 (22%)]	Loss: 1.316386
22:33:29: Train Epoch: 6 [10000/45000 (22%)]	Loss: 1.316386
22:33:29: Train Epoch: 6 [10000/45000 (22%)]	Loss: 1.316386
22:33:29: Train Epoch: 6 [10000/45000 (22%)]	Loss: 1.316386
22:33:35: Train Epoch: 6 [20000/45000 (44%)]	Loss: 0.935365
22:33:35: Train Epoch: 6 [20000/45000 (44%)]	Loss: 0.935365
22:33:35: Train Epoch: 6 [20000/45000 (44%)]	Loss: 0.935365
22:33:35: Train Epoch: 6 [20000/45000 (44%)]	Loss: 0.935365
22:33:35: Train Epoch: 6 [20000/45000 (44%)]	Loss: 0.935365
22:33:35: Train Epoch: 6 [20000/45000 (44%)]	Loss: 0.935365
22:33:42: Train Epoch: 6 [30000/45000 (67%)]	Loss: 0.956795
22:33:42: Train Epoch: 6 [30000/45000 (67%)]	Loss: 0.956795
22:33:42: Train Epoch: 6 [30000/45000 (67%)]	Loss: 0.956795
22:33:42: Train Epoch: 6 [30000/45000 (67%)]	Loss: 0.956795
22:33:42: Train Epoch: 6 [30000/45000 (67%)]	Loss: 0.956795
22:33:42: Train Epoch: 6 [30000/45000 (67%)]	Loss: 0.956795
22:33:48: Train Epoch: 6 [40000/45000 (89%)]	Loss: 1.162278
22:33:48: Train Epoch: 6 [40000/45000 (89%)]	Loss: 1.162278
22:33:48: Train Epoch: 6 [40000/45000 (89%)]	Loss: 1.162278
22:33:48: Train Epoch: 6 [40000/45000 (89%)]	Loss: 1.162278
22:33:48: Train Epoch: 6 [40000/45000 (89%)]	Loss: 1.162278
22:33:48: Train Epoch: 6 [40000/45000 (89%)]	Loss: 1.162278
22:33:54: 
Evaluation: Average loss: 1.0710, Accuracy: 3177/5000 (63.540%)

22:33:54: 
Evaluation: Average loss: 1.0710, Accuracy: 3177/5000 (63.540%)

22:33:54: 
Evaluation: Average loss: 1.0710, Accuracy: 3177/5000 (63.540%)

22:33:54: 
Evaluation: Average loss: 1.0710, Accuracy: 3177/5000 (63.540%)

22:33:54: 
Evaluation: Average loss: 1.0710, Accuracy: 3177/5000 (63.540%)

22:33:54: 
Evaluation: Average loss: 1.0710, Accuracy: 3177/5000 (63.540%)

22:33:54: Current learning rate: 0.1. Time taken for epoch: 32.85 seconds.

22:33:54: Current learning rate: 0.1. Time taken for epoch: 32.85 seconds.

22:33:54: Current learning rate: 0.1. Time taken for epoch: 32.85 seconds.

22:33:54: Current learning rate: 0.1. Time taken for epoch: 32.85 seconds.

22:33:54: Current learning rate: 0.1. Time taken for epoch: 32.85 seconds.

22:33:54: Current learning rate: 0.1. Time taken for epoch: 32.85 seconds.

22:33:55: Train Epoch: 7 [0/45000 (0%)]	Loss: 0.992776
22:33:55: Train Epoch: 7 [0/45000 (0%)]	Loss: 0.992776
22:33:55: Train Epoch: 7 [0/45000 (0%)]	Loss: 0.992776
22:33:55: Train Epoch: 7 [0/45000 (0%)]	Loss: 0.992776
22:33:55: Train Epoch: 7 [0/45000 (0%)]	Loss: 0.992776
22:33:55: Train Epoch: 7 [0/45000 (0%)]	Loss: 0.992776
22:34:02: Train Epoch: 7 [10000/45000 (22%)]	Loss: 0.955410
22:34:02: Train Epoch: 7 [10000/45000 (22%)]	Loss: 0.955410
22:34:02: Train Epoch: 7 [10000/45000 (22%)]	Loss: 0.955410
22:34:02: Train Epoch: 7 [10000/45000 (22%)]	Loss: 0.955410
22:34:02: Train Epoch: 7 [10000/45000 (22%)]	Loss: 0.955410
22:34:02: Train Epoch: 7 [10000/45000 (22%)]	Loss: 0.955410
22:34:08: Train Epoch: 7 [20000/45000 (44%)]	Loss: 0.818141
22:34:08: Train Epoch: 7 [20000/45000 (44%)]	Loss: 0.818141
22:34:08: Train Epoch: 7 [20000/45000 (44%)]	Loss: 0.818141
22:34:08: Train Epoch: 7 [20000/45000 (44%)]	Loss: 0.818141
22:34:08: Train Epoch: 7 [20000/45000 (44%)]	Loss: 0.818141
22:34:08: Train Epoch: 7 [20000/45000 (44%)]	Loss: 0.818141
22:34:15: Train Epoch: 7 [30000/45000 (67%)]	Loss: 0.800103
22:34:15: Train Epoch: 7 [30000/45000 (67%)]	Loss: 0.800103
22:34:15: Train Epoch: 7 [30000/45000 (67%)]	Loss: 0.800103
22:34:15: Train Epoch: 7 [30000/45000 (67%)]	Loss: 0.800103
22:34:15: Train Epoch: 7 [30000/45000 (67%)]	Loss: 0.800103
22:34:15: Train Epoch: 7 [30000/45000 (67%)]	Loss: 0.800103
22:34:21: Train Epoch: 7 [40000/45000 (89%)]	Loss: 0.695746
22:34:21: Train Epoch: 7 [40000/45000 (89%)]	Loss: 0.695746
22:34:21: Train Epoch: 7 [40000/45000 (89%)]	Loss: 0.695746
22:34:21: Train Epoch: 7 [40000/45000 (89%)]	Loss: 0.695746
22:34:21: Train Epoch: 7 [40000/45000 (89%)]	Loss: 0.695746
22:34:21: Train Epoch: 7 [40000/45000 (89%)]	Loss: 0.695746
22:34:27: 
Evaluation: Average loss: 1.0942, Accuracy: 3185/5000 (63.700%)

22:34:27: 
Evaluation: Average loss: 1.0942, Accuracy: 3185/5000 (63.700%)

22:34:27: 
Evaluation: Average loss: 1.0942, Accuracy: 3185/5000 (63.700%)

22:34:27: 
Evaluation: Average loss: 1.0942, Accuracy: 3185/5000 (63.700%)

22:34:27: 
Evaluation: Average loss: 1.0942, Accuracy: 3185/5000 (63.700%)

22:34:27: 
Evaluation: Average loss: 1.0942, Accuracy: 3185/5000 (63.700%)

22:34:27: Current learning rate: 0.1. Time taken for epoch: 32.93 seconds.

22:34:27: Current learning rate: 0.1. Time taken for epoch: 32.93 seconds.

22:34:27: Current learning rate: 0.1. Time taken for epoch: 32.93 seconds.

22:34:27: Current learning rate: 0.1. Time taken for epoch: 32.93 seconds.

22:34:27: Current learning rate: 0.1. Time taken for epoch: 32.93 seconds.

22:34:27: Current learning rate: 0.1. Time taken for epoch: 32.93 seconds.

22:34:28: Train Epoch: 8 [0/45000 (0%)]	Loss: 0.785956
22:34:28: Train Epoch: 8 [0/45000 (0%)]	Loss: 0.785956
22:34:28: Train Epoch: 8 [0/45000 (0%)]	Loss: 0.785956
22:34:28: Train Epoch: 8 [0/45000 (0%)]	Loss: 0.785956
22:34:28: Train Epoch: 8 [0/45000 (0%)]	Loss: 0.785956
22:34:28: Train Epoch: 8 [0/45000 (0%)]	Loss: 0.785956
22:34:35: Train Epoch: 8 [10000/45000 (22%)]	Loss: 0.770206
22:34:35: Train Epoch: 8 [10000/45000 (22%)]	Loss: 0.770206
22:34:35: Train Epoch: 8 [10000/45000 (22%)]	Loss: 0.770206
22:34:35: Train Epoch: 8 [10000/45000 (22%)]	Loss: 0.770206
22:34:35: Train Epoch: 8 [10000/45000 (22%)]	Loss: 0.770206
22:34:35: Train Epoch: 8 [10000/45000 (22%)]	Loss: 0.770206
22:34:41: Train Epoch: 8 [20000/45000 (44%)]	Loss: 0.909539
22:34:41: Train Epoch: 8 [20000/45000 (44%)]	Loss: 0.909539
22:34:41: Train Epoch: 8 [20000/45000 (44%)]	Loss: 0.909539
22:34:41: Train Epoch: 8 [20000/45000 (44%)]	Loss: 0.909539
22:34:41: Train Epoch: 8 [20000/45000 (44%)]	Loss: 0.909539
22:34:41: Train Epoch: 8 [20000/45000 (44%)]	Loss: 0.909539
22:34:48: Train Epoch: 8 [30000/45000 (67%)]	Loss: 1.017162
22:34:48: Train Epoch: 8 [30000/45000 (67%)]	Loss: 1.017162
22:34:48: Train Epoch: 8 [30000/45000 (67%)]	Loss: 1.017162
22:34:48: Train Epoch: 8 [30000/45000 (67%)]	Loss: 1.017162
22:34:48: Train Epoch: 8 [30000/45000 (67%)]	Loss: 1.017162
22:34:48: Train Epoch: 8 [30000/45000 (67%)]	Loss: 1.017162
22:34:54: Train Epoch: 8 [40000/45000 (89%)]	Loss: 0.929008
22:34:54: Train Epoch: 8 [40000/45000 (89%)]	Loss: 0.929008
22:34:54: Train Epoch: 8 [40000/45000 (89%)]	Loss: 0.929008
22:34:54: Train Epoch: 8 [40000/45000 (89%)]	Loss: 0.929008
22:34:54: Train Epoch: 8 [40000/45000 (89%)]	Loss: 0.929008
22:34:54: Train Epoch: 8 [40000/45000 (89%)]	Loss: 0.929008
22:35:00: 
Evaluation: Average loss: 0.9385, Accuracy: 3417/5000 (68.340%)

22:35:00: 
Evaluation: Average loss: 0.9385, Accuracy: 3417/5000 (68.340%)

22:35:00: 
Evaluation: Average loss: 0.9385, Accuracy: 3417/5000 (68.340%)

22:35:00: 
Evaluation: Average loss: 0.9385, Accuracy: 3417/5000 (68.340%)

22:35:00: 
Evaluation: Average loss: 0.9385, Accuracy: 3417/5000 (68.340%)

22:35:00: 
Evaluation: Average loss: 0.9385, Accuracy: 3417/5000 (68.340%)

22:35:00: Current learning rate: 0.1. Time taken for epoch: 32.94 seconds.

22:35:00: Current learning rate: 0.1. Time taken for epoch: 32.94 seconds.

22:35:00: Current learning rate: 0.1. Time taken for epoch: 32.94 seconds.

22:35:00: Current learning rate: 0.1. Time taken for epoch: 32.94 seconds.

22:35:00: Current learning rate: 0.1. Time taken for epoch: 32.94 seconds.

22:35:00: Current learning rate: 0.1. Time taken for epoch: 32.94 seconds.

22:35:01: Train Epoch: 9 [0/45000 (0%)]	Loss: 0.767262
22:35:01: Train Epoch: 9 [0/45000 (0%)]	Loss: 0.767262
22:35:01: Train Epoch: 9 [0/45000 (0%)]	Loss: 0.767262
22:35:01: Train Epoch: 9 [0/45000 (0%)]	Loss: 0.767262
22:35:01: Train Epoch: 9 [0/45000 (0%)]	Loss: 0.767262
22:35:01: Train Epoch: 9 [0/45000 (0%)]	Loss: 0.767262
22:35:08: Train Epoch: 9 [10000/45000 (22%)]	Loss: 0.850674
22:35:08: Train Epoch: 9 [10000/45000 (22%)]	Loss: 0.850674
22:35:08: Train Epoch: 9 [10000/45000 (22%)]	Loss: 0.850674
22:35:08: Train Epoch: 9 [10000/45000 (22%)]	Loss: 0.850674
22:35:08: Train Epoch: 9 [10000/45000 (22%)]	Loss: 0.850674
22:35:08: Train Epoch: 9 [10000/45000 (22%)]	Loss: 0.850674
22:35:14: Train Epoch: 9 [20000/45000 (44%)]	Loss: 0.866314
22:35:14: Train Epoch: 9 [20000/45000 (44%)]	Loss: 0.866314
22:35:14: Train Epoch: 9 [20000/45000 (44%)]	Loss: 0.866314
22:35:14: Train Epoch: 9 [20000/45000 (44%)]	Loss: 0.866314
22:35:14: Train Epoch: 9 [20000/45000 (44%)]	Loss: 0.866314
22:35:14: Train Epoch: 9 [20000/45000 (44%)]	Loss: 0.866314
22:35:21: Train Epoch: 9 [30000/45000 (67%)]	Loss: 0.684554
22:35:21: Train Epoch: 9 [30000/45000 (67%)]	Loss: 0.684554
22:35:21: Train Epoch: 9 [30000/45000 (67%)]	Loss: 0.684554
22:35:21: Train Epoch: 9 [30000/45000 (67%)]	Loss: 0.684554
22:35:21: Train Epoch: 9 [30000/45000 (67%)]	Loss: 0.684554
22:35:21: Train Epoch: 9 [30000/45000 (67%)]	Loss: 0.684554
22:35:27: Train Epoch: 9 [40000/45000 (89%)]	Loss: 0.675306
22:35:27: Train Epoch: 9 [40000/45000 (89%)]	Loss: 0.675306
22:35:27: Train Epoch: 9 [40000/45000 (89%)]	Loss: 0.675306
22:35:27: Train Epoch: 9 [40000/45000 (89%)]	Loss: 0.675306
22:35:27: Train Epoch: 9 [40000/45000 (89%)]	Loss: 0.675306
22:35:27: Train Epoch: 9 [40000/45000 (89%)]	Loss: 0.675306
22:35:33: 
Evaluation: Average loss: 1.5618, Accuracy: 2579/5000 (51.580%)

22:35:33: 
Evaluation: Average loss: 1.5618, Accuracy: 2579/5000 (51.580%)

22:35:33: 
Evaluation: Average loss: 1.5618, Accuracy: 2579/5000 (51.580%)

22:35:33: 
Evaluation: Average loss: 1.5618, Accuracy: 2579/5000 (51.580%)

22:35:33: 
Evaluation: Average loss: 1.5618, Accuracy: 2579/5000 (51.580%)

22:35:33: 
Evaluation: Average loss: 1.5618, Accuracy: 2579/5000 (51.580%)

22:35:33: Current learning rate: 0.1. Time taken for epoch: 33.18 seconds.

22:35:33: Current learning rate: 0.1. Time taken for epoch: 33.18 seconds.

22:35:33: Current learning rate: 0.1. Time taken for epoch: 33.18 seconds.

22:35:33: Current learning rate: 0.1. Time taken for epoch: 33.18 seconds.

22:35:33: Current learning rate: 0.1. Time taken for epoch: 33.18 seconds.

22:35:33: Current learning rate: 0.1. Time taken for epoch: 33.18 seconds.

22:35:34: Train Epoch: 10 [0/45000 (0%)]	Loss: 0.815384
22:35:34: Train Epoch: 10 [0/45000 (0%)]	Loss: 0.815384
22:35:34: Train Epoch: 10 [0/45000 (0%)]	Loss: 0.815384
22:35:34: Train Epoch: 10 [0/45000 (0%)]	Loss: 0.815384
22:35:34: Train Epoch: 10 [0/45000 (0%)]	Loss: 0.815384
22:35:34: Train Epoch: 10 [0/45000 (0%)]	Loss: 0.815384
22:36:37: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='vgg-d', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:36:37: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='vgg-d', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:36:37: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='vgg-d', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:36:37: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='vgg-d', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:36:37: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='vgg-d', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:36:37: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='vgg-d', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:36:37: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='vgg-d', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:36:37: 


22:36:37: 


22:36:37: 


22:36:37: 


22:36:37: 


22:36:37: 


22:36:37: 


22:36:37: ================================================================================
22:36:37: ================================================================================
22:36:37: ================================================================================
22:36:37: ================================================================================
22:36:37: ================================================================================
22:36:37: ================================================================================
22:36:37: ================================================================================
22:36:37: 
Iteration start: 1/1

22:36:37: 
Iteration start: 1/1

22:36:37: 
Iteration start: 1/1

22:36:37: 
Iteration start: 1/1

22:36:37: 
Iteration start: 1/1

22:36:37: 
Iteration start: 1/1

22:36:37: 
Iteration start: 1/1

22:36:38: VGG16(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
22:36:38: VGG16(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
22:36:38: VGG16(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
22:36:38: VGG16(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
22:36:38: VGG16(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
22:36:38: VGG16(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
22:36:38: VGG16(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
22:36:38: ============================================================
22:36:38: ============================================================
22:36:38: ============================================================
22:36:38: ============================================================
22:36:38: ============================================================
22:36:38: ============================================================
22:36:38: ============================================================
22:36:38: vgg-d
22:36:38: vgg-d
22:36:38: vgg-d
22:36:38: vgg-d
22:36:38: vgg-d
22:36:38: vgg-d
22:36:38: vgg-d
22:36:38: ============================================================
22:36:38: ============================================================
22:36:38: ============================================================
22:36:38: ============================================================
22:36:38: ============================================================
22:36:38: ============================================================
22:36:38: ============================================================
22:36:38: ============================================================
22:36:38: ============================================================
22:36:38: ============================================================
22:36:38: ============================================================
22:36:38: ============================================================
22:36:38: ============================================================
22:36:38: ============================================================
22:36:38: Prune mode: magnitude
22:36:38: Prune mode: magnitude
22:36:38: Prune mode: magnitude
22:36:38: Prune mode: magnitude
22:36:38: Prune mode: magnitude
22:36:38: Prune mode: magnitude
22:36:38: Prune mode: magnitude
22:36:38: Growth mode: momentum
22:36:38: Growth mode: momentum
22:36:38: Growth mode: momentum
22:36:38: Growth mode: momentum
22:36:38: Growth mode: momentum
22:36:38: Growth mode: momentum
22:36:38: Growth mode: momentum
22:36:38: Redistribution mode: momentum
22:36:38: Redistribution mode: momentum
22:36:38: Redistribution mode: momentum
22:36:38: Redistribution mode: momentum
22:36:38: Redistribution mode: momentum
22:36:38: Redistribution mode: momentum
22:36:38: Redistribution mode: momentum
22:36:38: ============================================================
22:36:38: ============================================================
22:36:38: ============================================================
22:36:38: ============================================================
22:36:38: ============================================================
22:36:38: ============================================================
22:36:38: ============================================================
22:36:39: Train Epoch: 1 [0/45000 (0%)]	Loss: 2.493264
22:36:39: Train Epoch: 1 [0/45000 (0%)]	Loss: 2.493264
22:36:39: Train Epoch: 1 [0/45000 (0%)]	Loss: 2.493264
22:36:39: Train Epoch: 1 [0/45000 (0%)]	Loss: 2.493264
22:36:39: Train Epoch: 1 [0/45000 (0%)]	Loss: 2.493264
22:36:39: Train Epoch: 1 [0/45000 (0%)]	Loss: 2.493264
22:36:39: Train Epoch: 1 [0/45000 (0%)]	Loss: 2.493264
22:36:46: Train Epoch: 1 [10000/45000 (22%)]	Loss: 3.538699
22:36:46: Train Epoch: 1 [10000/45000 (22%)]	Loss: 3.538699
22:36:46: Train Epoch: 1 [10000/45000 (22%)]	Loss: 3.538699
22:36:46: Train Epoch: 1 [10000/45000 (22%)]	Loss: 3.538699
22:36:46: Train Epoch: 1 [10000/45000 (22%)]	Loss: 3.538699
22:36:46: Train Epoch: 1 [10000/45000 (22%)]	Loss: 3.538699
22:36:46: Train Epoch: 1 [10000/45000 (22%)]	Loss: 3.538699
22:36:52: Train Epoch: 1 [20000/45000 (44%)]	Loss: 1.976608
22:36:52: Train Epoch: 1 [20000/45000 (44%)]	Loss: 1.976608
22:36:52: Train Epoch: 1 [20000/45000 (44%)]	Loss: 1.976608
22:36:52: Train Epoch: 1 [20000/45000 (44%)]	Loss: 1.976608
22:36:52: Train Epoch: 1 [20000/45000 (44%)]	Loss: 1.976608
22:36:52: Train Epoch: 1 [20000/45000 (44%)]	Loss: 1.976608
22:36:52: Train Epoch: 1 [20000/45000 (44%)]	Loss: 1.976608
22:36:59: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.881186
22:36:59: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.881186
22:36:59: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.881186
22:36:59: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.881186
22:36:59: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.881186
22:36:59: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.881186
22:36:59: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.881186
22:37:05: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.843703
22:37:05: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.843703
22:37:05: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.843703
22:37:05: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.843703
22:37:05: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.843703
22:37:05: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.843703
22:37:05: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.843703
22:37:11: 
Evaluation: Average loss: 1.8959, Accuracy: 1242/5000 (24.840%)

22:37:11: 
Evaluation: Average loss: 1.8959, Accuracy: 1242/5000 (24.840%)

22:37:11: 
Evaluation: Average loss: 1.8959, Accuracy: 1242/5000 (24.840%)

22:37:11: 
Evaluation: Average loss: 1.8959, Accuracy: 1242/5000 (24.840%)

22:37:11: 
Evaluation: Average loss: 1.8959, Accuracy: 1242/5000 (24.840%)

22:37:11: 
Evaluation: Average loss: 1.8959, Accuracy: 1242/5000 (24.840%)

22:37:11: 
Evaluation: Average loss: 1.8959, Accuracy: 1242/5000 (24.840%)

22:37:11: Current learning rate: 0.1. Time taken for epoch: 32.85 seconds.

22:37:11: Current learning rate: 0.1. Time taken for epoch: 32.85 seconds.

22:37:11: Current learning rate: 0.1. Time taken for epoch: 32.85 seconds.

22:37:11: Current learning rate: 0.1. Time taken for epoch: 32.85 seconds.

22:37:11: Current learning rate: 0.1. Time taken for epoch: 32.85 seconds.

22:37:11: Current learning rate: 0.1. Time taken for epoch: 32.85 seconds.

22:37:11: Current learning rate: 0.1. Time taken for epoch: 32.85 seconds.

22:37:12: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.915445
22:37:12: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.915445
22:37:12: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.915445
22:37:12: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.915445
22:37:12: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.915445
22:37:12: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.915445
22:37:12: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.915445
22:37:19: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.863323
22:37:19: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.863323
22:37:19: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.863323
22:37:19: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.863323
22:37:19: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.863323
22:37:19: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.863323
22:37:19: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.863323
