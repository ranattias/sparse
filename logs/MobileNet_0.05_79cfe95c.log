21:29:14: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=0.05, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='MobileNet', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.5, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
21:29:14: 


21:29:14: ================================================================================
21:29:14: 
Iteration start: 1/1

21:29:15: MobileNet(
  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (dw2_1): DepthWiseBlock(
    (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
    (bn_dw): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw2_2): DepthWiseBlock(
    (conv_dw): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
    (bn_dw): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw3_1): DepthWiseBlock(
    (conv_dw): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
    (bn_dw): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw3_2): DepthWiseBlock(
    (conv_dw): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
    (bn_dw): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw4_1): DepthWiseBlock(
    (conv_dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
    (bn_dw): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw4_2): DepthWiseBlock(
    (conv_dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
    (bn_dw): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_1): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_2): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_3): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_4): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_5): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_6): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw6): DepthWiseBlock(
    (conv_dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)
    (bn_dw): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=1)
  (fc): Linear(in_features=1024, out_features=100, bias=True)
)
21:29:15: ============================================================
21:29:15: MobileNet
21:29:15: ============================================================
21:29:15: ============================================================
21:29:15: Prune mode: magnitude
21:29:15: Growth mode: momentum
21:29:15: Redistribution mode: momentum
21:29:15: ============================================================
21:29:16: Train Epoch: 1 [0/45000 (0%)]	Loss: 4.641055
21:29:21: Train Epoch: 1 [10000/45000 (22%)]	Loss: 2.070999
21:29:26: Train Epoch: 1 [20000/45000 (44%)]	Loss: 2.191387
21:29:30: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.572804
21:29:35: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.645447
21:29:39: 
Evaluation: Average loss: -7.4973, Accuracy: 1916/5000 (38.320%)

21:29:39: Current learning rate: 0.1. Time taken for epoch: 23.74 seconds.

21:29:40: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.539217
21:29:50: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=False, density=0.05, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='MobileNet', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.5, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
21:29:50: 


21:29:50: ================================================================================
21:29:50: 
Iteration start: 1/1

21:29:51: MobileNet(
  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (dw2_1): DepthWiseBlock(
    (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
    (bn_dw): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw2_2): DepthWiseBlock(
    (conv_dw): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
    (bn_dw): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw3_1): DepthWiseBlock(
    (conv_dw): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
    (bn_dw): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw3_2): DepthWiseBlock(
    (conv_dw): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
    (bn_dw): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw4_1): DepthWiseBlock(
    (conv_dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
    (bn_dw): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw4_2): DepthWiseBlock(
    (conv_dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
    (bn_dw): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_1): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_2): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_3): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_4): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_5): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_6): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw6): DepthWiseBlock(
    (conv_dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)
    (bn_dw): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=1)
  (fc): Linear(in_features=1024, out_features=100, bias=True)
)
21:29:51: ============================================================
21:29:51: MobileNet
21:29:51: ============================================================
21:29:51: ============================================================
21:29:51: Prune mode: magnitude
21:29:51: Growth mode: momentum
21:29:51: Redistribution mode: momentum
21:29:51: ============================================================
21:29:52: Train Epoch: 1 [0/45000 (0%)]	Loss: 4.604723
21:29:57: Train Epoch: 1 [10000/45000 (22%)]	Loss: nan
21:30:02: Train Epoch: 1 [20000/45000 (44%)]	Loss: nan
21:30:07: Train Epoch: 1 [30000/45000 (67%)]	Loss: nan
21:30:12: Train Epoch: 1 [40000/45000 (89%)]	Loss: nan
21:30:16: 
Evaluation: Average loss: nan, Accuracy: 493/5000 (9.860%)

21:44:13: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=0.05, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='MobileNet', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.5, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
21:44:13: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=0.05, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='MobileNet', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.5, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
21:44:13: 


21:44:13: 


21:44:13: ================================================================================
21:44:13: ================================================================================
21:44:13: 
Iteration start: 1/1

21:44:13: 
Iteration start: 1/1

21:44:14: MobileNet(
  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (dw2_1): DepthWiseBlock(
    (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
    (bn_dw): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw2_2): DepthWiseBlock(
    (conv_dw): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
    (bn_dw): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw3_1): DepthWiseBlock(
    (conv_dw): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
    (bn_dw): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw3_2): DepthWiseBlock(
    (conv_dw): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
    (bn_dw): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw4_1): DepthWiseBlock(
    (conv_dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
    (bn_dw): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw4_2): DepthWiseBlock(
    (conv_dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
    (bn_dw): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_1): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_2): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_3): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_4): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_5): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_6): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw6): DepthWiseBlock(
    (conv_dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)
    (bn_dw): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=1)
  (fc): Linear(in_features=1024, out_features=100, bias=True)
)
21:44:14: MobileNet(
  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (dw2_1): DepthWiseBlock(
    (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
    (bn_dw): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw2_2): DepthWiseBlock(
    (conv_dw): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
    (bn_dw): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw3_1): DepthWiseBlock(
    (conv_dw): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
    (bn_dw): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw3_2): DepthWiseBlock(
    (conv_dw): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
    (bn_dw): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw4_1): DepthWiseBlock(
    (conv_dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
    (bn_dw): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw4_2): DepthWiseBlock(
    (conv_dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
    (bn_dw): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_1): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_2): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_3): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_4): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_5): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_6): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw6): DepthWiseBlock(
    (conv_dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)
    (bn_dw): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=1)
  (fc): Linear(in_features=1024, out_features=100, bias=True)
)
21:44:14: ============================================================
21:44:14: ============================================================
21:44:14: MobileNet
21:44:14: MobileNet
21:44:14: ============================================================
21:44:14: ============================================================
21:44:14: ============================================================
21:44:14: ============================================================
21:44:14: Prune mode: magnitude
21:44:14: Prune mode: magnitude
21:44:14: Growth mode: momentum
21:44:14: Growth mode: momentum
21:44:14: Redistribution mode: momentum
21:44:14: Redistribution mode: momentum
21:44:14: ============================================================
21:44:14: ============================================================
21:44:15: Train Epoch: 1 [0/45000 (0%)]	Loss: 4.641055
21:44:15: Train Epoch: 1 [0/45000 (0%)]	Loss: 4.641055
21:44:20: Train Epoch: 1 [10000/45000 (22%)]	Loss: 2.070999
21:44:20: Train Epoch: 1 [10000/45000 (22%)]	Loss: 2.070999
21:44:25: Train Epoch: 1 [20000/45000 (44%)]	Loss: 2.191387
21:44:25: Train Epoch: 1 [20000/45000 (44%)]	Loss: 2.191387
21:44:30: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.572804
21:44:30: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.572804
21:44:35: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.645447
21:44:35: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.645447
21:44:39: 
Evaluation: Average loss: -7.4973, Accuracy: 1916/5000 (38.320%)

21:44:39: 
Evaluation: Average loss: -7.4973, Accuracy: 1916/5000 (38.320%)

21:44:39: Current learning rate: 0.1. Time taken for epoch: 24.69 seconds.

21:44:39: Current learning rate: 0.1. Time taken for epoch: 24.69 seconds.

21:44:40: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.539217
21:44:40: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.539217
21:44:45: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.506656
21:44:45: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.506656
21:44:50: Train Epoch: 2 [20000/45000 (44%)]	Loss: 1.660257
21:44:50: Train Epoch: 2 [20000/45000 (44%)]	Loss: 1.660257
21:44:55: Train Epoch: 2 [30000/45000 (67%)]	Loss: 1.391268
21:44:55: Train Epoch: 2 [30000/45000 (67%)]	Loss: 1.391268
21:45:00: Train Epoch: 2 [40000/45000 (89%)]	Loss: 1.605617
21:45:00: Train Epoch: 2 [40000/45000 (89%)]	Loss: 1.605617
21:45:04: 
Evaluation: Average loss: -7.5427, Accuracy: 2206/5000 (44.120%)

21:45:04: 
Evaluation: Average loss: -7.5427, Accuracy: 2206/5000 (44.120%)

21:45:04: Current learning rate: 0.1. Time taken for epoch: 24.98 seconds.

21:45:04: Current learning rate: 0.1. Time taken for epoch: 24.98 seconds.

21:45:05: Train Epoch: 3 [0/45000 (0%)]	Loss: 1.405193
21:45:05: Train Epoch: 3 [0/45000 (0%)]	Loss: 1.405193
21:45:10: Train Epoch: 3 [10000/45000 (22%)]	Loss: 1.692926
21:45:10: Train Epoch: 3 [10000/45000 (22%)]	Loss: 1.692926
21:45:14: Train Epoch: 3 [20000/45000 (44%)]	Loss: 1.380153
21:45:14: Train Epoch: 3 [20000/45000 (44%)]	Loss: 1.380153
21:45:19: Train Epoch: 3 [30000/45000 (67%)]	Loss: 1.360908
21:45:19: Train Epoch: 3 [30000/45000 (67%)]	Loss: 1.360908
21:45:24: Train Epoch: 3 [40000/45000 (89%)]	Loss: 1.352115
21:45:24: Train Epoch: 3 [40000/45000 (89%)]	Loss: 1.352115
21:45:28: 
Evaluation: Average loss: -8.2287, Accuracy: 2511/5000 (50.220%)

21:45:28: 
Evaluation: Average loss: -8.2287, Accuracy: 2511/5000 (50.220%)

21:45:28: Current learning rate: 0.1. Time taken for epoch: 24.04 seconds.

21:45:28: Current learning rate: 0.1. Time taken for epoch: 24.04 seconds.

21:45:29: Train Epoch: 4 [0/45000 (0%)]	Loss: 1.296323
21:45:29: Train Epoch: 4 [0/45000 (0%)]	Loss: 1.296323
21:45:34: Train Epoch: 4 [10000/45000 (22%)]	Loss: 1.222319
21:45:34: Train Epoch: 4 [10000/45000 (22%)]	Loss: 1.222319
21:45:39: Train Epoch: 4 [20000/45000 (44%)]	Loss: 1.121193
21:45:39: Train Epoch: 4 [20000/45000 (44%)]	Loss: 1.121193
21:45:43: Train Epoch: 4 [30000/45000 (67%)]	Loss: 1.495911
21:45:43: Train Epoch: 4 [30000/45000 (67%)]	Loss: 1.495911
21:45:48: Train Epoch: 4 [40000/45000 (89%)]	Loss: 1.157913
21:45:48: Train Epoch: 4 [40000/45000 (89%)]	Loss: 1.157913
21:45:52: 
Evaluation: Average loss: -8.1894, Accuracy: 2618/5000 (52.360%)

21:45:52: 
Evaluation: Average loss: -8.1894, Accuracy: 2618/5000 (52.360%)

21:45:52: Current learning rate: 0.1. Time taken for epoch: 24.28 seconds.

21:45:52: Current learning rate: 0.1. Time taken for epoch: 24.28 seconds.

21:45:53: Train Epoch: 5 [0/45000 (0%)]	Loss: 1.220667
21:45:53: Train Epoch: 5 [0/45000 (0%)]	Loss: 1.220667
21:45:58: Train Epoch: 5 [10000/45000 (22%)]	Loss: 1.145001
21:45:58: Train Epoch: 5 [10000/45000 (22%)]	Loss: 1.145001
21:46:03: Train Epoch: 5 [20000/45000 (44%)]	Loss: 1.251591
21:46:03: Train Epoch: 5 [20000/45000 (44%)]	Loss: 1.251591
21:46:08: Train Epoch: 5 [30000/45000 (67%)]	Loss: 1.225516
21:46:08: Train Epoch: 5 [30000/45000 (67%)]	Loss: 1.225516
21:46:13: Train Epoch: 5 [40000/45000 (89%)]	Loss: 1.051940
21:46:13: Train Epoch: 5 [40000/45000 (89%)]	Loss: 1.051940
21:46:17: 
Evaluation: Average loss: -8.4317, Accuracy: 2835/5000 (56.700%)

21:46:17: 
Evaluation: Average loss: -8.4317, Accuracy: 2835/5000 (56.700%)

21:46:17: Current learning rate: 0.1. Time taken for epoch: 24.49 seconds.

21:46:17: Current learning rate: 0.1. Time taken for epoch: 24.49 seconds.

21:46:17: Train Epoch: 6 [0/45000 (0%)]	Loss: 1.173297
21:46:17: Train Epoch: 6 [0/45000 (0%)]	Loss: 1.173297
21:46:23: Train Epoch: 6 [10000/45000 (22%)]	Loss: 1.195373
21:46:23: Train Epoch: 6 [10000/45000 (22%)]	Loss: 1.195373
21:46:27: Train Epoch: 6 [20000/45000 (44%)]	Loss: 1.166446
21:46:27: Train Epoch: 6 [20000/45000 (44%)]	Loss: 1.166446
21:46:32: Train Epoch: 6 [30000/45000 (67%)]	Loss: 1.066273
21:46:32: Train Epoch: 6 [30000/45000 (67%)]	Loss: 1.066273
21:46:37: Train Epoch: 6 [40000/45000 (89%)]	Loss: 1.092280
21:46:37: Train Epoch: 6 [40000/45000 (89%)]	Loss: 1.092280
21:46:41: 
Evaluation: Average loss: -8.5108, Accuracy: 2941/5000 (58.820%)

21:46:41: 
Evaluation: Average loss: -8.5108, Accuracy: 2941/5000 (58.820%)

21:46:41: Current learning rate: 0.1. Time taken for epoch: 24.24 seconds.

21:46:41: Current learning rate: 0.1. Time taken for epoch: 24.24 seconds.

21:46:41: Train Epoch: 7 [0/45000 (0%)]	Loss: 1.209516
21:46:41: Train Epoch: 7 [0/45000 (0%)]	Loss: 1.209516
21:46:47: Train Epoch: 7 [10000/45000 (22%)]	Loss: 1.300370
21:46:47: Train Epoch: 7 [10000/45000 (22%)]	Loss: 1.300370
21:46:51: Train Epoch: 7 [20000/45000 (44%)]	Loss: 1.019166
21:46:51: Train Epoch: 7 [20000/45000 (44%)]	Loss: 1.019166
21:46:56: Train Epoch: 7 [30000/45000 (67%)]	Loss: 1.229778
21:46:56: Train Epoch: 7 [30000/45000 (67%)]	Loss: 1.229778
21:47:01: Train Epoch: 7 [40000/45000 (89%)]	Loss: 0.902035
21:47:01: Train Epoch: 7 [40000/45000 (89%)]	Loss: 0.902035
21:47:05: 
Evaluation: Average loss: -8.4379, Accuracy: 2861/5000 (57.220%)

21:47:05: 
Evaluation: Average loss: -8.4379, Accuracy: 2861/5000 (57.220%)

21:47:05: Current learning rate: 0.1. Time taken for epoch: 24.50 seconds.

21:47:05: Current learning rate: 0.1. Time taken for epoch: 24.50 seconds.

21:47:06: Train Epoch: 8 [0/45000 (0%)]	Loss: 1.122509
21:47:06: Train Epoch: 8 [0/45000 (0%)]	Loss: 1.122509
21:47:11: Train Epoch: 8 [10000/45000 (22%)]	Loss: 1.098168
21:47:11: Train Epoch: 8 [10000/45000 (22%)]	Loss: 1.098168
21:47:16: Train Epoch: 8 [20000/45000 (44%)]	Loss: 1.152307
21:47:16: Train Epoch: 8 [20000/45000 (44%)]	Loss: 1.152307
21:47:21: Train Epoch: 8 [30000/45000 (67%)]	Loss: 0.939621
21:47:21: Train Epoch: 8 [30000/45000 (67%)]	Loss: 0.939621
21:47:26: Train Epoch: 8 [40000/45000 (89%)]	Loss: 0.934100
21:47:26: Train Epoch: 8 [40000/45000 (89%)]	Loss: 0.934100
21:47:29: 
Evaluation: Average loss: -8.7891, Accuracy: 3246/5000 (64.920%)

21:47:29: 
Evaluation: Average loss: -8.7891, Accuracy: 3246/5000 (64.920%)

21:47:30: Current learning rate: 0.1. Time taken for epoch: 24.06 seconds.

21:47:30: Current learning rate: 0.1. Time taken for epoch: 24.06 seconds.

21:47:30: Train Epoch: 9 [0/45000 (0%)]	Loss: 1.052353
21:47:30: Train Epoch: 9 [0/45000 (0%)]	Loss: 1.052353
21:47:35: Train Epoch: 9 [10000/45000 (22%)]	Loss: 0.864117
21:47:35: Train Epoch: 9 [10000/45000 (22%)]	Loss: 0.864117
21:47:40: Train Epoch: 9 [20000/45000 (44%)]	Loss: 0.877453
21:47:40: Train Epoch: 9 [20000/45000 (44%)]	Loss: 0.877453
21:47:45: Train Epoch: 9 [30000/45000 (67%)]	Loss: 0.865385
21:47:45: Train Epoch: 9 [30000/45000 (67%)]	Loss: 0.865385
21:47:50: Train Epoch: 9 [40000/45000 (89%)]	Loss: 1.255493
21:47:50: Train Epoch: 9 [40000/45000 (89%)]	Loss: 1.255493
21:47:54: 
Evaluation: Average loss: -8.9968, Accuracy: 3197/5000 (63.940%)

21:47:54: 
Evaluation: Average loss: -8.9968, Accuracy: 3197/5000 (63.940%)

21:47:54: Current learning rate: 0.1. Time taken for epoch: 24.10 seconds.

21:47:54: Current learning rate: 0.1. Time taken for epoch: 24.10 seconds.

21:47:54: Train Epoch: 10 [0/45000 (0%)]	Loss: 1.041793
21:47:54: Train Epoch: 10 [0/45000 (0%)]	Loss: 1.041793
21:48:00: Train Epoch: 10 [10000/45000 (22%)]	Loss: 1.026022
21:48:00: Train Epoch: 10 [10000/45000 (22%)]	Loss: 1.026022
21:48:05: Train Epoch: 10 [20000/45000 (44%)]	Loss: 0.984909
21:48:05: Train Epoch: 10 [20000/45000 (44%)]	Loss: 0.984909
21:48:09: Train Epoch: 10 [30000/45000 (67%)]	Loss: 1.070504
21:48:09: Train Epoch: 10 [30000/45000 (67%)]	Loss: 1.070504
21:48:14: Train Epoch: 10 [40000/45000 (89%)]	Loss: 1.037909
21:48:14: Train Epoch: 10 [40000/45000 (89%)]	Loss: 1.037909
21:48:18: 
Evaluation: Average loss: -9.0468, Accuracy: 2935/5000 (58.700%)

21:48:18: 
Evaluation: Average loss: -9.0468, Accuracy: 2935/5000 (58.700%)

21:48:18: Current learning rate: 0.1. Time taken for epoch: 24.31 seconds.

21:48:18: Current learning rate: 0.1. Time taken for epoch: 24.31 seconds.

21:48:19: Train Epoch: 11 [0/45000 (0%)]	Loss: 0.903475
21:48:19: Train Epoch: 11 [0/45000 (0%)]	Loss: 0.903475
21:48:24: Train Epoch: 11 [10000/45000 (22%)]	Loss: 0.917096
21:48:24: Train Epoch: 11 [10000/45000 (22%)]	Loss: 0.917096
21:48:28: Train Epoch: 11 [20000/45000 (44%)]	Loss: 1.066228
21:48:28: Train Epoch: 11 [20000/45000 (44%)]	Loss: 1.066228
21:48:33: Train Epoch: 11 [30000/45000 (67%)]	Loss: 1.015116
21:48:33: Train Epoch: 11 [30000/45000 (67%)]	Loss: 1.015116
21:48:39: Train Epoch: 11 [40000/45000 (89%)]	Loss: 0.892001
21:48:39: Train Epoch: 11 [40000/45000 (89%)]	Loss: 0.892001
21:48:43: 
Evaluation: Average loss: -8.7921, Accuracy: 3232/5000 (64.640%)

21:48:43: 
Evaluation: Average loss: -8.7921, Accuracy: 3232/5000 (64.640%)

21:48:43: Current learning rate: 0.1. Time taken for epoch: 24.66 seconds.

21:48:43: Current learning rate: 0.1. Time taken for epoch: 24.66 seconds.

21:48:43: Train Epoch: 12 [0/45000 (0%)]	Loss: 0.896391
21:48:43: Train Epoch: 12 [0/45000 (0%)]	Loss: 0.896391
21:48:48: Train Epoch: 12 [10000/45000 (22%)]	Loss: 1.040409
21:48:48: Train Epoch: 12 [10000/45000 (22%)]	Loss: 1.040409
21:48:53: Train Epoch: 12 [20000/45000 (44%)]	Loss: 0.872414
21:48:53: Train Epoch: 12 [20000/45000 (44%)]	Loss: 0.872414
21:48:58: Train Epoch: 12 [30000/45000 (67%)]	Loss: 0.968072
21:48:58: Train Epoch: 12 [30000/45000 (67%)]	Loss: 0.968072
21:49:03: Train Epoch: 12 [40000/45000 (89%)]	Loss: 0.936087
21:49:03: Train Epoch: 12 [40000/45000 (89%)]	Loss: 0.936087
21:49:07: 
Evaluation: Average loss: -9.1224, Accuracy: 3245/5000 (64.900%)

21:49:07: 
Evaluation: Average loss: -9.1224, Accuracy: 3245/5000 (64.900%)

21:49:07: Current learning rate: 0.1. Time taken for epoch: 24.45 seconds.

21:49:07: Current learning rate: 0.1. Time taken for epoch: 24.45 seconds.

21:49:08: Train Epoch: 13 [0/45000 (0%)]	Loss: 0.952147
21:49:08: Train Epoch: 13 [0/45000 (0%)]	Loss: 0.952147
21:49:12: Train Epoch: 13 [10000/45000 (22%)]	Loss: 1.037147
21:49:12: Train Epoch: 13 [10000/45000 (22%)]	Loss: 1.037147
21:52:49: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='vgg-d', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
21:52:49: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='vgg-d', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
21:52:49: 


21:52:49: 


21:52:49: ================================================================================
21:52:49: ================================================================================
21:52:49: 
Iteration start: 1/1

21:52:49: 
Iteration start: 1/1

21:52:50: VGG16(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
21:52:50: VGG16(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
21:52:50: ============================================================
21:52:50: ============================================================
21:52:50: vgg-d
21:52:50: vgg-d
21:52:50: ============================================================
21:52:50: ============================================================
21:52:50: ============================================================
21:52:50: ============================================================
21:52:50: Prune mode: magnitude
21:52:50: Prune mode: magnitude
21:52:50: Growth mode: momentum
21:52:50: Growth mode: momentum
21:52:50: Redistribution mode: momentum
21:52:50: Redistribution mode: momentum
21:52:50: ============================================================
21:52:50: ============================================================
21:52:52: Train Epoch: 1 [0/45000 (0%)]	Loss: 2.493264
21:52:52: Train Epoch: 1 [0/45000 (0%)]	Loss: 2.493264
21:52:58: Train Epoch: 1 [10000/45000 (22%)]	Loss: 3.538699
21:52:58: Train Epoch: 1 [10000/45000 (22%)]	Loss: 3.538699
21:53:05: Train Epoch: 1 [20000/45000 (44%)]	Loss: 1.976608
21:53:05: Train Epoch: 1 [20000/45000 (44%)]	Loss: 1.976608
21:53:11: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.881186
21:53:11: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.881186
21:53:18: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.843703
21:53:18: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.843703
21:53:24: 
Evaluation: Average loss: 1.8959, Accuracy: 1242/5000 (24.840%)

21:53:24: 
Evaluation: Average loss: 1.8959, Accuracy: 1242/5000 (24.840%)

21:53:24: Current learning rate: 0.1. Time taken for epoch: 33.84 seconds.

21:53:24: Current learning rate: 0.1. Time taken for epoch: 33.84 seconds.

21:53:25: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.915445
21:53:25: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.915445
21:53:31: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.863323
21:53:31: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.863323
21:53:38: Train Epoch: 2 [20000/45000 (44%)]	Loss: 1.873123
21:53:38: Train Epoch: 2 [20000/45000 (44%)]	Loss: 1.873123
21:53:44: Train Epoch: 2 [30000/45000 (67%)]	Loss: 1.695018
21:53:44: Train Epoch: 2 [30000/45000 (67%)]	Loss: 1.695018
21:53:51: Train Epoch: 2 [40000/45000 (89%)]	Loss: 1.553206
21:53:51: Train Epoch: 2 [40000/45000 (89%)]	Loss: 1.553206
21:53:57: 
Evaluation: Average loss: 1.6408, Accuracy: 1828/5000 (36.560%)

21:53:57: 
Evaluation: Average loss: 1.6408, Accuracy: 1828/5000 (36.560%)

21:53:57: Current learning rate: 0.1. Time taken for epoch: 33.16 seconds.

21:53:57: Current learning rate: 0.1. Time taken for epoch: 33.16 seconds.

21:53:58: Train Epoch: 3 [0/45000 (0%)]	Loss: 1.825549
21:53:58: Train Epoch: 3 [0/45000 (0%)]	Loss: 1.825549
22:10:52: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=0.05, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='MobileNet', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.5, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:10:52: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=0.05, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='MobileNet', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.5, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:10:52: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=0.05, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='MobileNet', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.5, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:10:52: 


22:10:52: 


22:10:52: 


22:10:52: ================================================================================
22:10:52: ================================================================================
22:10:52: ================================================================================
22:10:52: 
Iteration start: 1/1

22:10:52: 
Iteration start: 1/1

22:10:52: 
Iteration start: 1/1

22:10:53: MobileNet(
  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (dw2_1): DepthWiseBlock(
    (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
    (bn_dw): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw2_2): DepthWiseBlock(
    (conv_dw): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
    (bn_dw): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw3_1): DepthWiseBlock(
    (conv_dw): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
    (bn_dw): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw3_2): DepthWiseBlock(
    (conv_dw): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
    (bn_dw): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw4_1): DepthWiseBlock(
    (conv_dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
    (bn_dw): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw4_2): DepthWiseBlock(
    (conv_dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
    (bn_dw): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_1): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_2): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_3): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_4): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_5): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_6): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw6): DepthWiseBlock(
    (conv_dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)
    (bn_dw): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=1)
  (fc): Linear(in_features=1024, out_features=100, bias=True)
)
22:10:53: MobileNet(
  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (dw2_1): DepthWiseBlock(
    (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
    (bn_dw): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw2_2): DepthWiseBlock(
    (conv_dw): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
    (bn_dw): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw3_1): DepthWiseBlock(
    (conv_dw): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
    (bn_dw): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw3_2): DepthWiseBlock(
    (conv_dw): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
    (bn_dw): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw4_1): DepthWiseBlock(
    (conv_dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
    (bn_dw): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw4_2): DepthWiseBlock(
    (conv_dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
    (bn_dw): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_1): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_2): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_3): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_4): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_5): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_6): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw6): DepthWiseBlock(
    (conv_dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)
    (bn_dw): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=1)
  (fc): Linear(in_features=1024, out_features=100, bias=True)
)
22:10:53: MobileNet(
  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (dw2_1): DepthWiseBlock(
    (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
    (bn_dw): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw2_2): DepthWiseBlock(
    (conv_dw): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
    (bn_dw): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw3_1): DepthWiseBlock(
    (conv_dw): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
    (bn_dw): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw3_2): DepthWiseBlock(
    (conv_dw): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
    (bn_dw): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw4_1): DepthWiseBlock(
    (conv_dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
    (bn_dw): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw4_2): DepthWiseBlock(
    (conv_dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
    (bn_dw): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_1): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_2): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_3): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_4): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_5): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw5_6): DepthWiseBlock(
    (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)
    (bn_dw): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (dw6): DepthWiseBlock(
    (conv_dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)
    (bn_dw): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv_sep): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn_sep): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=1)
  (fc): Linear(in_features=1024, out_features=100, bias=True)
)
22:10:53: ============================================================
22:10:53: ============================================================
22:10:53: ============================================================
22:10:53: MobileNet
22:10:53: MobileNet
22:10:53: MobileNet
22:10:53: ============================================================
22:10:53: ============================================================
22:10:53: ============================================================
22:10:53: ============================================================
22:10:53: ============================================================
22:10:53: ============================================================
22:10:53: Prune mode: magnitude
22:10:53: Prune mode: magnitude
22:10:53: Prune mode: magnitude
22:10:53: Growth mode: momentum
22:10:53: Growth mode: momentum
22:10:53: Growth mode: momentum
22:10:53: Redistribution mode: momentum
22:10:53: Redistribution mode: momentum
22:10:53: Redistribution mode: momentum
22:10:53: ============================================================
22:10:53: ============================================================
22:10:53: ============================================================
22:10:54: Train Epoch: 1 [0/45000 (0%)]	Loss: 4.641055
22:10:54: Train Epoch: 1 [0/45000 (0%)]	Loss: 4.641055
22:10:54: Train Epoch: 1 [0/45000 (0%)]	Loss: 4.641055
22:10:59: Train Epoch: 1 [10000/45000 (22%)]	Loss: 2.070999
22:10:59: Train Epoch: 1 [10000/45000 (22%)]	Loss: 2.070999
22:10:59: Train Epoch: 1 [10000/45000 (22%)]	Loss: 2.070999
22:11:04: Train Epoch: 1 [20000/45000 (44%)]	Loss: 2.191387
22:11:04: Train Epoch: 1 [20000/45000 (44%)]	Loss: 2.191387
22:11:04: Train Epoch: 1 [20000/45000 (44%)]	Loss: 2.191387
22:11:08: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.572804
22:11:08: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.572804
22:11:08: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.572804
22:11:13: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.645447
22:11:13: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.645447
22:11:13: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.645447
22:11:17: 
Evaluation: Average loss: 0.0168, Accuracy: 1916/5000 (38.320%)

22:11:17: 
Evaluation: Average loss: 0.0168, Accuracy: 1916/5000 (38.320%)

22:11:17: 
Evaluation: Average loss: 0.0168, Accuracy: 1916/5000 (38.320%)

22:11:17: Current learning rate: 0.1. Time taken for epoch: 24.05 seconds.

22:11:17: Current learning rate: 0.1. Time taken for epoch: 24.05 seconds.

22:11:17: Current learning rate: 0.1. Time taken for epoch: 24.05 seconds.

22:11:18: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.539217
22:11:18: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.539217
22:11:18: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.539217
22:11:23: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.506656
22:11:23: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.506656
22:11:23: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.506656
22:11:27: Train Epoch: 2 [20000/45000 (44%)]	Loss: 1.660257
22:11:27: Train Epoch: 2 [20000/45000 (44%)]	Loss: 1.660257
22:11:27: Train Epoch: 2 [20000/45000 (44%)]	Loss: 1.660257
22:11:32: Train Epoch: 2 [30000/45000 (67%)]	Loss: 1.391268
22:11:32: Train Epoch: 2 [30000/45000 (67%)]	Loss: 1.391268
22:11:32: Train Epoch: 2 [30000/45000 (67%)]	Loss: 1.391268
22:11:37: Train Epoch: 2 [40000/45000 (89%)]	Loss: 1.605617
22:11:37: Train Epoch: 2 [40000/45000 (89%)]	Loss: 1.605617
22:11:37: Train Epoch: 2 [40000/45000 (89%)]	Loss: 1.605617
22:11:41: 
Evaluation: Average loss: 0.0155, Accuracy: 2206/5000 (44.120%)

22:11:41: 
Evaluation: Average loss: 0.0155, Accuracy: 2206/5000 (44.120%)

22:11:41: 
Evaluation: Average loss: 0.0155, Accuracy: 2206/5000 (44.120%)

22:11:41: Current learning rate: 0.1. Time taken for epoch: 23.91 seconds.

22:11:41: Current learning rate: 0.1. Time taken for epoch: 23.91 seconds.

22:11:41: Current learning rate: 0.1. Time taken for epoch: 23.91 seconds.

22:11:42: Train Epoch: 3 [0/45000 (0%)]	Loss: 1.405193
22:11:42: Train Epoch: 3 [0/45000 (0%)]	Loss: 1.405193
22:11:42: Train Epoch: 3 [0/45000 (0%)]	Loss: 1.405193
22:11:46: Train Epoch: 3 [10000/45000 (22%)]	Loss: 1.692926
22:11:46: Train Epoch: 3 [10000/45000 (22%)]	Loss: 1.692926
22:11:46: Train Epoch: 3 [10000/45000 (22%)]	Loss: 1.692926
22:11:51: Train Epoch: 3 [20000/45000 (44%)]	Loss: 1.380153
22:11:51: Train Epoch: 3 [20000/45000 (44%)]	Loss: 1.380153
22:11:51: Train Epoch: 3 [20000/45000 (44%)]	Loss: 1.380153
22:11:56: Train Epoch: 3 [30000/45000 (67%)]	Loss: 1.360908
22:11:56: Train Epoch: 3 [30000/45000 (67%)]	Loss: 1.360908
22:11:56: Train Epoch: 3 [30000/45000 (67%)]	Loss: 1.360908
22:12:00: Train Epoch: 3 [40000/45000 (89%)]	Loss: 1.352115
22:12:00: Train Epoch: 3 [40000/45000 (89%)]	Loss: 1.352115
22:12:00: Train Epoch: 3 [40000/45000 (89%)]	Loss: 1.352115
22:12:04: 
Evaluation: Average loss: 0.0138, Accuracy: 2511/5000 (50.220%)

22:12:04: 
Evaluation: Average loss: 0.0138, Accuracy: 2511/5000 (50.220%)

22:12:04: 
Evaluation: Average loss: 0.0138, Accuracy: 2511/5000 (50.220%)

22:12:05: Current learning rate: 0.1. Time taken for epoch: 23.65 seconds.

22:12:05: Current learning rate: 0.1. Time taken for epoch: 23.65 seconds.

22:12:05: Current learning rate: 0.1. Time taken for epoch: 23.65 seconds.

22:12:05: Train Epoch: 4 [0/45000 (0%)]	Loss: 1.296323
22:12:05: Train Epoch: 4 [0/45000 (0%)]	Loss: 1.296323
22:12:05: Train Epoch: 4 [0/45000 (0%)]	Loss: 1.296323
22:12:10: Train Epoch: 4 [10000/45000 (22%)]	Loss: 1.222319
22:12:10: Train Epoch: 4 [10000/45000 (22%)]	Loss: 1.222319
22:12:10: Train Epoch: 4 [10000/45000 (22%)]	Loss: 1.222319
22:12:15: Train Epoch: 4 [20000/45000 (44%)]	Loss: 1.121193
22:12:15: Train Epoch: 4 [20000/45000 (44%)]	Loss: 1.121193
22:12:15: Train Epoch: 4 [20000/45000 (44%)]	Loss: 1.121193
22:12:19: Train Epoch: 4 [30000/45000 (67%)]	Loss: 1.495911
22:12:19: Train Epoch: 4 [30000/45000 (67%)]	Loss: 1.495911
22:12:19: Train Epoch: 4 [30000/45000 (67%)]	Loss: 1.495911
22:12:24: Train Epoch: 4 [40000/45000 (89%)]	Loss: 1.157913
22:12:24: Train Epoch: 4 [40000/45000 (89%)]	Loss: 1.157913
22:12:24: Train Epoch: 4 [40000/45000 (89%)]	Loss: 1.157913
22:12:28: 
Evaluation: Average loss: 0.0132, Accuracy: 2618/5000 (52.360%)

22:12:28: 
Evaluation: Average loss: 0.0132, Accuracy: 2618/5000 (52.360%)

22:12:28: 
Evaluation: Average loss: 0.0132, Accuracy: 2618/5000 (52.360%)

22:12:28: Current learning rate: 0.1. Time taken for epoch: 23.31 seconds.

22:12:28: Current learning rate: 0.1. Time taken for epoch: 23.31 seconds.

22:12:28: Current learning rate: 0.1. Time taken for epoch: 23.31 seconds.

22:12:29: Train Epoch: 5 [0/45000 (0%)]	Loss: 1.220667
22:12:29: Train Epoch: 5 [0/45000 (0%)]	Loss: 1.220667
22:12:29: Train Epoch: 5 [0/45000 (0%)]	Loss: 1.220667
22:12:34: Train Epoch: 5 [10000/45000 (22%)]	Loss: 1.145001
22:12:34: Train Epoch: 5 [10000/45000 (22%)]	Loss: 1.145001
22:12:34: Train Epoch: 5 [10000/45000 (22%)]	Loss: 1.145001
22:12:39: Train Epoch: 5 [20000/45000 (44%)]	Loss: 1.251591
22:12:39: Train Epoch: 5 [20000/45000 (44%)]	Loss: 1.251591
22:12:39: Train Epoch: 5 [20000/45000 (44%)]	Loss: 1.251591
22:12:43: Train Epoch: 5 [30000/45000 (67%)]	Loss: 1.225516
22:12:43: Train Epoch: 5 [30000/45000 (67%)]	Loss: 1.225516
22:12:43: Train Epoch: 5 [30000/45000 (67%)]	Loss: 1.225516
22:12:48: Train Epoch: 5 [40000/45000 (89%)]	Loss: 1.051940
22:12:48: Train Epoch: 5 [40000/45000 (89%)]	Loss: 1.051940
22:12:48: Train Epoch: 5 [40000/45000 (89%)]	Loss: 1.051940
22:12:52: 
Evaluation: Average loss: 0.0121, Accuracy: 2835/5000 (56.700%)

22:12:52: 
Evaluation: Average loss: 0.0121, Accuracy: 2835/5000 (56.700%)

22:12:52: 
Evaluation: Average loss: 0.0121, Accuracy: 2835/5000 (56.700%)

22:12:52: Current learning rate: 0.1. Time taken for epoch: 24.34 seconds.

22:12:52: Current learning rate: 0.1. Time taken for epoch: 24.34 seconds.

22:12:52: Current learning rate: 0.1. Time taken for epoch: 24.34 seconds.

22:12:53: Train Epoch: 6 [0/45000 (0%)]	Loss: 1.173297
22:12:53: Train Epoch: 6 [0/45000 (0%)]	Loss: 1.173297
22:12:53: Train Epoch: 6 [0/45000 (0%)]	Loss: 1.173297
22:12:58: Train Epoch: 6 [10000/45000 (22%)]	Loss: 1.195373
22:12:58: Train Epoch: 6 [10000/45000 (22%)]	Loss: 1.195373
22:12:58: Train Epoch: 6 [10000/45000 (22%)]	Loss: 1.195373
22:13:03: Train Epoch: 6 [20000/45000 (44%)]	Loss: 1.166446
22:13:03: Train Epoch: 6 [20000/45000 (44%)]	Loss: 1.166446
22:13:03: Train Epoch: 6 [20000/45000 (44%)]	Loss: 1.166446
22:13:08: Train Epoch: 6 [30000/45000 (67%)]	Loss: 1.066273
22:13:08: Train Epoch: 6 [30000/45000 (67%)]	Loss: 1.066273
22:13:08: Train Epoch: 6 [30000/45000 (67%)]	Loss: 1.066273
22:13:13: Train Epoch: 6 [40000/45000 (89%)]	Loss: 1.092280
22:13:13: Train Epoch: 6 [40000/45000 (89%)]	Loss: 1.092280
22:13:13: Train Epoch: 6 [40000/45000 (89%)]	Loss: 1.092280
22:13:17: 
Evaluation: Average loss: 0.0118, Accuracy: 2941/5000 (58.820%)

22:13:17: 
Evaluation: Average loss: 0.0118, Accuracy: 2941/5000 (58.820%)

22:13:17: 
Evaluation: Average loss: 0.0118, Accuracy: 2941/5000 (58.820%)

22:13:17: Current learning rate: 0.1. Time taken for epoch: 24.38 seconds.

22:13:17: Current learning rate: 0.1. Time taken for epoch: 24.38 seconds.

22:13:17: Current learning rate: 0.1. Time taken for epoch: 24.38 seconds.

22:13:17: Train Epoch: 7 [0/45000 (0%)]	Loss: 1.209516
22:13:17: Train Epoch: 7 [0/45000 (0%)]	Loss: 1.209516
22:13:17: Train Epoch: 7 [0/45000 (0%)]	Loss: 1.209516
22:13:22: Train Epoch: 7 [10000/45000 (22%)]	Loss: 1.300370
22:13:22: Train Epoch: 7 [10000/45000 (22%)]	Loss: 1.300370
22:13:22: Train Epoch: 7 [10000/45000 (22%)]	Loss: 1.300370
22:13:27: Train Epoch: 7 [20000/45000 (44%)]	Loss: 1.019166
22:13:27: Train Epoch: 7 [20000/45000 (44%)]	Loss: 1.019166
22:13:27: Train Epoch: 7 [20000/45000 (44%)]	Loss: 1.019166
22:13:32: Train Epoch: 7 [30000/45000 (67%)]	Loss: 1.229778
22:13:32: Train Epoch: 7 [30000/45000 (67%)]	Loss: 1.229778
22:13:32: Train Epoch: 7 [30000/45000 (67%)]	Loss: 1.229778
22:13:37: Train Epoch: 7 [40000/45000 (89%)]	Loss: 0.902035
22:13:37: Train Epoch: 7 [40000/45000 (89%)]	Loss: 0.902035
22:13:37: Train Epoch: 7 [40000/45000 (89%)]	Loss: 0.902035
22:13:40: 
Evaluation: Average loss: 0.0120, Accuracy: 2861/5000 (57.220%)

22:13:40: 
Evaluation: Average loss: 0.0120, Accuracy: 2861/5000 (57.220%)

22:13:40: 
Evaluation: Average loss: 0.0120, Accuracy: 2861/5000 (57.220%)

22:13:40: Current learning rate: 0.1. Time taken for epoch: 23.90 seconds.

22:13:40: Current learning rate: 0.1. Time taken for epoch: 23.90 seconds.

22:13:40: Current learning rate: 0.1. Time taken for epoch: 23.90 seconds.

22:13:41: Train Epoch: 8 [0/45000 (0%)]	Loss: 1.122509
22:13:41: Train Epoch: 8 [0/45000 (0%)]	Loss: 1.122509
22:13:41: Train Epoch: 8 [0/45000 (0%)]	Loss: 1.122509
22:13:46: Train Epoch: 8 [10000/45000 (22%)]	Loss: 1.098168
22:13:46: Train Epoch: 8 [10000/45000 (22%)]	Loss: 1.098168
22:13:46: Train Epoch: 8 [10000/45000 (22%)]	Loss: 1.098168
22:13:51: Train Epoch: 8 [20000/45000 (44%)]	Loss: 1.152307
22:13:51: Train Epoch: 8 [20000/45000 (44%)]	Loss: 1.152307
22:13:51: Train Epoch: 8 [20000/45000 (44%)]	Loss: 1.152307
22:13:55: Train Epoch: 8 [30000/45000 (67%)]	Loss: 0.939621
22:13:55: Train Epoch: 8 [30000/45000 (67%)]	Loss: 0.939621
22:13:55: Train Epoch: 8 [30000/45000 (67%)]	Loss: 0.939621
22:14:00: Train Epoch: 8 [40000/45000 (89%)]	Loss: 0.934100
22:14:00: Train Epoch: 8 [40000/45000 (89%)]	Loss: 0.934100
22:14:00: Train Epoch: 8 [40000/45000 (89%)]	Loss: 0.934100
22:14:04: 
Evaluation: Average loss: 0.0102, Accuracy: 3246/5000 (64.920%)

22:14:04: 
Evaluation: Average loss: 0.0102, Accuracy: 3246/5000 (64.920%)

22:14:04: 
Evaluation: Average loss: 0.0102, Accuracy: 3246/5000 (64.920%)

22:14:04: Current learning rate: 0.1. Time taken for epoch: 23.74 seconds.

22:14:04: Current learning rate: 0.1. Time taken for epoch: 23.74 seconds.

22:14:04: Current learning rate: 0.1. Time taken for epoch: 23.74 seconds.

22:14:05: Train Epoch: 9 [0/45000 (0%)]	Loss: 1.052353
22:14:05: Train Epoch: 9 [0/45000 (0%)]	Loss: 1.052353
22:14:05: Train Epoch: 9 [0/45000 (0%)]	Loss: 1.052353
22:14:10: Train Epoch: 9 [10000/45000 (22%)]	Loss: 0.864117
22:14:10: Train Epoch: 9 [10000/45000 (22%)]	Loss: 0.864117
22:14:10: Train Epoch: 9 [10000/45000 (22%)]	Loss: 0.864117
22:14:15: Train Epoch: 9 [20000/45000 (44%)]	Loss: 0.877453
22:14:15: Train Epoch: 9 [20000/45000 (44%)]	Loss: 0.877453
22:14:15: Train Epoch: 9 [20000/45000 (44%)]	Loss: 0.877453
22:14:19: Train Epoch: 9 [30000/45000 (67%)]	Loss: 0.865385
22:14:19: Train Epoch: 9 [30000/45000 (67%)]	Loss: 0.865385
22:14:19: Train Epoch: 9 [30000/45000 (67%)]	Loss: 0.865385
22:14:24: Train Epoch: 9 [40000/45000 (89%)]	Loss: 1.255493
22:14:24: Train Epoch: 9 [40000/45000 (89%)]	Loss: 1.255493
22:14:24: Train Epoch: 9 [40000/45000 (89%)]	Loss: 1.255493
22:14:28: 
Evaluation: Average loss: 0.0104, Accuracy: 3197/5000 (63.940%)

22:14:28: 
Evaluation: Average loss: 0.0104, Accuracy: 3197/5000 (63.940%)

22:14:28: 
Evaluation: Average loss: 0.0104, Accuracy: 3197/5000 (63.940%)

22:14:28: Current learning rate: 0.1. Time taken for epoch: 23.89 seconds.

22:14:28: Current learning rate: 0.1. Time taken for epoch: 23.89 seconds.

22:14:28: Current learning rate: 0.1. Time taken for epoch: 23.89 seconds.

22:14:29: Train Epoch: 10 [0/45000 (0%)]	Loss: 1.041793
22:14:29: Train Epoch: 10 [0/45000 (0%)]	Loss: 1.041793
22:14:29: Train Epoch: 10 [0/45000 (0%)]	Loss: 1.041793
22:14:34: Train Epoch: 10 [10000/45000 (22%)]	Loss: 1.026022
22:14:34: Train Epoch: 10 [10000/45000 (22%)]	Loss: 1.026022
22:14:34: Train Epoch: 10 [10000/45000 (22%)]	Loss: 1.026022
22:14:38: Train Epoch: 10 [20000/45000 (44%)]	Loss: 0.984909
22:14:38: Train Epoch: 10 [20000/45000 (44%)]	Loss: 0.984909
22:14:38: Train Epoch: 10 [20000/45000 (44%)]	Loss: 0.984909
22:14:43: Train Epoch: 10 [30000/45000 (67%)]	Loss: 1.070504
22:14:43: Train Epoch: 10 [30000/45000 (67%)]	Loss: 1.070504
22:14:43: Train Epoch: 10 [30000/45000 (67%)]	Loss: 1.070504
22:14:48: Train Epoch: 10 [40000/45000 (89%)]	Loss: 1.037909
22:14:48: Train Epoch: 10 [40000/45000 (89%)]	Loss: 1.037909
22:14:48: Train Epoch: 10 [40000/45000 (89%)]	Loss: 1.037909
22:14:52: 
Evaluation: Average loss: 0.0120, Accuracy: 2935/5000 (58.700%)

22:14:52: 
Evaluation: Average loss: 0.0120, Accuracy: 2935/5000 (58.700%)

22:14:52: 
Evaluation: Average loss: 0.0120, Accuracy: 2935/5000 (58.700%)

22:14:52: Current learning rate: 0.1. Time taken for epoch: 23.65 seconds.

22:14:52: Current learning rate: 0.1. Time taken for epoch: 23.65 seconds.

22:14:52: Current learning rate: 0.1. Time taken for epoch: 23.65 seconds.

22:14:52: Train Epoch: 11 [0/45000 (0%)]	Loss: 0.903475
22:14:52: Train Epoch: 11 [0/45000 (0%)]	Loss: 0.903475
22:14:52: Train Epoch: 11 [0/45000 (0%)]	Loss: 0.903475
22:14:57: Train Epoch: 11 [10000/45000 (22%)]	Loss: 0.917096
22:14:57: Train Epoch: 11 [10000/45000 (22%)]	Loss: 0.917096
22:14:57: Train Epoch: 11 [10000/45000 (22%)]	Loss: 0.917096
22:15:02: Train Epoch: 11 [20000/45000 (44%)]	Loss: 1.066228
22:15:02: Train Epoch: 11 [20000/45000 (44%)]	Loss: 1.066228
22:15:02: Train Epoch: 11 [20000/45000 (44%)]	Loss: 1.066228
22:15:07: Train Epoch: 11 [30000/45000 (67%)]	Loss: 1.015116
22:15:07: Train Epoch: 11 [30000/45000 (67%)]	Loss: 1.015116
22:15:07: Train Epoch: 11 [30000/45000 (67%)]	Loss: 1.015116
22:15:12: Train Epoch: 11 [40000/45000 (89%)]	Loss: 0.892001
22:15:12: Train Epoch: 11 [40000/45000 (89%)]	Loss: 0.892001
22:15:12: Train Epoch: 11 [40000/45000 (89%)]	Loss: 0.892001
22:15:15: 
Evaluation: Average loss: 0.0103, Accuracy: 3232/5000 (64.640%)

22:15:15: 
Evaluation: Average loss: 0.0103, Accuracy: 3232/5000 (64.640%)

22:15:15: 
Evaluation: Average loss: 0.0103, Accuracy: 3232/5000 (64.640%)

22:15:16: Current learning rate: 0.1. Time taken for epoch: 23.79 seconds.

22:15:16: Current learning rate: 0.1. Time taken for epoch: 23.79 seconds.

22:15:16: Current learning rate: 0.1. Time taken for epoch: 23.79 seconds.

22:15:16: Train Epoch: 12 [0/45000 (0%)]	Loss: 0.896391
22:15:16: Train Epoch: 12 [0/45000 (0%)]	Loss: 0.896391
22:15:16: Train Epoch: 12 [0/45000 (0%)]	Loss: 0.896391
22:15:21: Train Epoch: 12 [10000/45000 (22%)]	Loss: 1.040409
22:15:21: Train Epoch: 12 [10000/45000 (22%)]	Loss: 1.040409
22:15:21: Train Epoch: 12 [10000/45000 (22%)]	Loss: 1.040409
22:15:26: Train Epoch: 12 [20000/45000 (44%)]	Loss: 0.872414
22:15:26: Train Epoch: 12 [20000/45000 (44%)]	Loss: 0.872414
22:15:26: Train Epoch: 12 [20000/45000 (44%)]	Loss: 0.872414
22:15:31: Train Epoch: 12 [30000/45000 (67%)]	Loss: 0.968072
22:15:31: Train Epoch: 12 [30000/45000 (67%)]	Loss: 0.968072
22:15:31: Train Epoch: 12 [30000/45000 (67%)]	Loss: 0.968072
22:15:35: Train Epoch: 12 [40000/45000 (89%)]	Loss: 0.936087
22:15:35: Train Epoch: 12 [40000/45000 (89%)]	Loss: 0.936087
22:15:35: Train Epoch: 12 [40000/45000 (89%)]	Loss: 0.936087
22:15:39: 
Evaluation: Average loss: 0.0102, Accuracy: 3245/5000 (64.900%)

22:15:39: 
Evaluation: Average loss: 0.0102, Accuracy: 3245/5000 (64.900%)

22:15:39: 
Evaluation: Average loss: 0.0102, Accuracy: 3245/5000 (64.900%)

22:15:39: Current learning rate: 0.1. Time taken for epoch: 23.70 seconds.

22:15:39: Current learning rate: 0.1. Time taken for epoch: 23.70 seconds.

22:15:39: Current learning rate: 0.1. Time taken for epoch: 23.70 seconds.

22:15:40: Train Epoch: 13 [0/45000 (0%)]	Loss: 0.952147
22:15:40: Train Epoch: 13 [0/45000 (0%)]	Loss: 0.952147
22:15:40: Train Epoch: 13 [0/45000 (0%)]	Loss: 0.952147
22:15:45: Train Epoch: 13 [10000/45000 (22%)]	Loss: 1.037147
22:15:45: Train Epoch: 13 [10000/45000 (22%)]	Loss: 1.037147
22:15:45: Train Epoch: 13 [10000/45000 (22%)]	Loss: 1.037147
22:15:49: Train Epoch: 13 [20000/45000 (44%)]	Loss: 0.859045
22:15:49: Train Epoch: 13 [20000/45000 (44%)]	Loss: 0.859045
22:15:49: Train Epoch: 13 [20000/45000 (44%)]	Loss: 0.859045
22:15:54: Train Epoch: 13 [30000/45000 (67%)]	Loss: 0.726019
22:15:54: Train Epoch: 13 [30000/45000 (67%)]	Loss: 0.726019
22:15:54: Train Epoch: 13 [30000/45000 (67%)]	Loss: 0.726019
22:15:59: Train Epoch: 13 [40000/45000 (89%)]	Loss: 0.897180
22:15:59: Train Epoch: 13 [40000/45000 (89%)]	Loss: 0.897180
22:15:59: Train Epoch: 13 [40000/45000 (89%)]	Loss: 0.897180
22:16:03: 
Evaluation: Average loss: 0.0111, Accuracy: 3078/5000 (61.560%)

22:16:03: 
Evaluation: Average loss: 0.0111, Accuracy: 3078/5000 (61.560%)

22:16:03: 
Evaluation: Average loss: 0.0111, Accuracy: 3078/5000 (61.560%)

22:16:03: Current learning rate: 0.1. Time taken for epoch: 23.88 seconds.

22:16:03: Current learning rate: 0.1. Time taken for epoch: 23.88 seconds.

22:16:03: Current learning rate: 0.1. Time taken for epoch: 23.88 seconds.

22:16:04: Train Epoch: 14 [0/45000 (0%)]	Loss: 1.077231
22:16:04: Train Epoch: 14 [0/45000 (0%)]	Loss: 1.077231
22:16:04: Train Epoch: 14 [0/45000 (0%)]	Loss: 1.077231
22:16:08: Train Epoch: 14 [10000/45000 (22%)]	Loss: 0.973345
22:16:08: Train Epoch: 14 [10000/45000 (22%)]	Loss: 0.973345
22:16:08: Train Epoch: 14 [10000/45000 (22%)]	Loss: 0.973345
22:16:13: Train Epoch: 14 [20000/45000 (44%)]	Loss: 0.934396
22:16:13: Train Epoch: 14 [20000/45000 (44%)]	Loss: 0.934396
22:16:13: Train Epoch: 14 [20000/45000 (44%)]	Loss: 0.934396
22:16:18: Train Epoch: 14 [30000/45000 (67%)]	Loss: 0.761494
22:16:18: Train Epoch: 14 [30000/45000 (67%)]	Loss: 0.761494
22:16:18: Train Epoch: 14 [30000/45000 (67%)]	Loss: 0.761494
22:16:23: Train Epoch: 14 [40000/45000 (89%)]	Loss: 0.946728
22:16:23: Train Epoch: 14 [40000/45000 (89%)]	Loss: 0.946728
22:16:23: Train Epoch: 14 [40000/45000 (89%)]	Loss: 0.946728
22:16:26: 
Evaluation: Average loss: 0.0097, Accuracy: 3311/5000 (66.220%)

22:16:26: 
Evaluation: Average loss: 0.0097, Accuracy: 3311/5000 (66.220%)

22:16:26: 
Evaluation: Average loss: 0.0097, Accuracy: 3311/5000 (66.220%)

22:16:26: Current learning rate: 0.1. Time taken for epoch: 23.38 seconds.

22:16:26: Current learning rate: 0.1. Time taken for epoch: 23.38 seconds.

22:16:26: Current learning rate: 0.1. Time taken for epoch: 23.38 seconds.

22:16:27: Train Epoch: 15 [0/45000 (0%)]	Loss: 0.837940
22:16:27: Train Epoch: 15 [0/45000 (0%)]	Loss: 0.837940
22:16:27: Train Epoch: 15 [0/45000 (0%)]	Loss: 0.837940
22:16:32: Train Epoch: 15 [10000/45000 (22%)]	Loss: 0.951340
22:16:32: Train Epoch: 15 [10000/45000 (22%)]	Loss: 0.951340
22:16:32: Train Epoch: 15 [10000/45000 (22%)]	Loss: 0.951340
22:16:37: Train Epoch: 15 [20000/45000 (44%)]	Loss: 0.859055
22:16:37: Train Epoch: 15 [20000/45000 (44%)]	Loss: 0.859055
22:16:37: Train Epoch: 15 [20000/45000 (44%)]	Loss: 0.859055
22:16:41: Train Epoch: 15 [30000/45000 (67%)]	Loss: 0.914733
22:16:41: Train Epoch: 15 [30000/45000 (67%)]	Loss: 0.914733
22:16:41: Train Epoch: 15 [30000/45000 (67%)]	Loss: 0.914733
22:16:46: Train Epoch: 15 [40000/45000 (89%)]	Loss: 0.820461
22:16:46: Train Epoch: 15 [40000/45000 (89%)]	Loss: 0.820461
22:16:46: Train Epoch: 15 [40000/45000 (89%)]	Loss: 0.820461
22:16:50: 
Evaluation: Average loss: 0.0108, Accuracy: 3138/5000 (62.760%)

22:16:50: 
Evaluation: Average loss: 0.0108, Accuracy: 3138/5000 (62.760%)

22:16:50: 
Evaluation: Average loss: 0.0108, Accuracy: 3138/5000 (62.760%)

22:16:50: Current learning rate: 0.1. Time taken for epoch: 23.35 seconds.

22:16:50: Current learning rate: 0.1. Time taken for epoch: 23.35 seconds.

22:16:50: Current learning rate: 0.1. Time taken for epoch: 23.35 seconds.

22:16:51: Train Epoch: 16 [0/45000 (0%)]	Loss: 0.949087
22:16:51: Train Epoch: 16 [0/45000 (0%)]	Loss: 0.949087
22:16:51: Train Epoch: 16 [0/45000 (0%)]	Loss: 0.949087
22:16:55: Train Epoch: 16 [10000/45000 (22%)]	Loss: 1.030977
22:16:55: Train Epoch: 16 [10000/45000 (22%)]	Loss: 1.030977
22:16:55: Train Epoch: 16 [10000/45000 (22%)]	Loss: 1.030977
22:17:00: Train Epoch: 16 [20000/45000 (44%)]	Loss: 1.101172
22:17:00: Train Epoch: 16 [20000/45000 (44%)]	Loss: 1.101172
22:17:00: Train Epoch: 16 [20000/45000 (44%)]	Loss: 1.101172
22:17:05: Train Epoch: 16 [30000/45000 (67%)]	Loss: 0.774793
22:17:05: Train Epoch: 16 [30000/45000 (67%)]	Loss: 0.774793
22:17:05: Train Epoch: 16 [30000/45000 (67%)]	Loss: 0.774793
22:17:09: Train Epoch: 16 [40000/45000 (89%)]	Loss: 1.014955
22:17:09: Train Epoch: 16 [40000/45000 (89%)]	Loss: 1.014955
22:17:09: Train Epoch: 16 [40000/45000 (89%)]	Loss: 1.014955
22:17:13: 
Evaluation: Average loss: 0.0106, Accuracy: 3270/5000 (65.400%)

22:17:13: 
Evaluation: Average loss: 0.0106, Accuracy: 3270/5000 (65.400%)

22:17:13: 
Evaluation: Average loss: 0.0106, Accuracy: 3270/5000 (65.400%)

22:17:13: Current learning rate: 0.1. Time taken for epoch: 23.42 seconds.

22:17:13: Current learning rate: 0.1. Time taken for epoch: 23.42 seconds.

22:17:13: Current learning rate: 0.1. Time taken for epoch: 23.42 seconds.

22:17:14: Train Epoch: 17 [0/45000 (0%)]	Loss: 0.911990
22:17:14: Train Epoch: 17 [0/45000 (0%)]	Loss: 0.911990
22:17:14: Train Epoch: 17 [0/45000 (0%)]	Loss: 0.911990
22:17:19: Train Epoch: 17 [10000/45000 (22%)]	Loss: 1.022918
22:17:19: Train Epoch: 17 [10000/45000 (22%)]	Loss: 1.022918
22:17:19: Train Epoch: 17 [10000/45000 (22%)]	Loss: 1.022918
22:17:23: Train Epoch: 17 [20000/45000 (44%)]	Loss: 0.746091
22:17:23: Train Epoch: 17 [20000/45000 (44%)]	Loss: 0.746091
22:17:23: Train Epoch: 17 [20000/45000 (44%)]	Loss: 0.746091
22:17:28: Train Epoch: 17 [30000/45000 (67%)]	Loss: 1.168708
22:17:28: Train Epoch: 17 [30000/45000 (67%)]	Loss: 1.168708
22:17:28: Train Epoch: 17 [30000/45000 (67%)]	Loss: 1.168708
22:17:32: Train Epoch: 17 [40000/45000 (89%)]	Loss: 0.960175
22:17:32: Train Epoch: 17 [40000/45000 (89%)]	Loss: 0.960175
22:17:32: Train Epoch: 17 [40000/45000 (89%)]	Loss: 0.960175
22:17:37: 
Evaluation: Average loss: 0.0102, Accuracy: 3340/5000 (66.800%)

22:17:37: 
Evaluation: Average loss: 0.0102, Accuracy: 3340/5000 (66.800%)

22:17:37: 
Evaluation: Average loss: 0.0102, Accuracy: 3340/5000 (66.800%)

22:17:37: Current learning rate: 0.1. Time taken for epoch: 23.46 seconds.

22:17:37: Current learning rate: 0.1. Time taken for epoch: 23.46 seconds.

22:17:37: Current learning rate: 0.1. Time taken for epoch: 23.46 seconds.

22:17:37: Train Epoch: 18 [0/45000 (0%)]	Loss: 0.910733
22:17:37: Train Epoch: 18 [0/45000 (0%)]	Loss: 0.910733
22:17:37: Train Epoch: 18 [0/45000 (0%)]	Loss: 0.910733
22:17:42: Train Epoch: 18 [10000/45000 (22%)]	Loss: 0.963349
22:17:42: Train Epoch: 18 [10000/45000 (22%)]	Loss: 0.963349
22:17:42: Train Epoch: 18 [10000/45000 (22%)]	Loss: 0.963349
22:17:47: Train Epoch: 18 [20000/45000 (44%)]	Loss: 0.970611
22:17:47: Train Epoch: 18 [20000/45000 (44%)]	Loss: 0.970611
22:17:47: Train Epoch: 18 [20000/45000 (44%)]	Loss: 0.970611
22:17:52: Train Epoch: 18 [30000/45000 (67%)]	Loss: 0.635672
22:17:52: Train Epoch: 18 [30000/45000 (67%)]	Loss: 0.635672
22:17:52: Train Epoch: 18 [30000/45000 (67%)]	Loss: 0.635672
22:17:56: Train Epoch: 18 [40000/45000 (89%)]	Loss: 0.885292
22:17:56: Train Epoch: 18 [40000/45000 (89%)]	Loss: 0.885292
22:17:56: Train Epoch: 18 [40000/45000 (89%)]	Loss: 0.885292
22:18:01: 
Evaluation: Average loss: 0.0109, Accuracy: 3197/5000 (63.940%)

22:18:01: 
Evaluation: Average loss: 0.0109, Accuracy: 3197/5000 (63.940%)

22:18:01: 
Evaluation: Average loss: 0.0109, Accuracy: 3197/5000 (63.940%)

22:18:01: Current learning rate: 0.1. Time taken for epoch: 23.84 seconds.

22:18:01: Current learning rate: 0.1. Time taken for epoch: 23.84 seconds.

22:18:01: Current learning rate: 0.1. Time taken for epoch: 23.84 seconds.

22:18:01: Train Epoch: 19 [0/45000 (0%)]	Loss: 0.665436
22:18:01: Train Epoch: 19 [0/45000 (0%)]	Loss: 0.665436
22:18:01: Train Epoch: 19 [0/45000 (0%)]	Loss: 0.665436
22:18:06: Train Epoch: 19 [10000/45000 (22%)]	Loss: 0.843730
22:18:06: Train Epoch: 19 [10000/45000 (22%)]	Loss: 0.843730
22:18:06: Train Epoch: 19 [10000/45000 (22%)]	Loss: 0.843730
22:18:11: Train Epoch: 19 [20000/45000 (44%)]	Loss: 1.012961
22:18:11: Train Epoch: 19 [20000/45000 (44%)]	Loss: 1.012961
22:18:11: Train Epoch: 19 [20000/45000 (44%)]	Loss: 1.012961
22:18:15: Train Epoch: 19 [30000/45000 (67%)]	Loss: 1.097223
22:18:15: Train Epoch: 19 [30000/45000 (67%)]	Loss: 1.097223
22:18:15: Train Epoch: 19 [30000/45000 (67%)]	Loss: 1.097223
22:18:20: Namespace(batch_size=100, bench=True, data='mnist', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='lenet300-100', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:18:20: Namespace(batch_size=100, bench=True, data='mnist', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='lenet300-100', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:18:20: Namespace(batch_size=100, bench=True, data='mnist', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='lenet300-100', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:18:20: 


22:18:20: 


22:18:20: 


22:18:20: ================================================================================
22:18:20: ================================================================================
22:18:20: ================================================================================
22:18:20: 
Iteration start: 1/1

22:18:20: 
Iteration start: 1/1

22:18:20: 
Iteration start: 1/1

22:18:22: LeNet_300_100(
  (fc1): Linear(in_features=784, out_features=300, bias=True)
  (fc2): Linear(in_features=300, out_features=100, bias=True)
  (fc3): Linear(in_features=100, out_features=10, bias=True)
)
22:18:22: LeNet_300_100(
  (fc1): Linear(in_features=784, out_features=300, bias=True)
  (fc2): Linear(in_features=300, out_features=100, bias=True)
  (fc3): Linear(in_features=100, out_features=10, bias=True)
)
22:18:22: LeNet_300_100(
  (fc1): Linear(in_features=784, out_features=300, bias=True)
  (fc2): Linear(in_features=300, out_features=100, bias=True)
  (fc3): Linear(in_features=100, out_features=10, bias=True)
)
22:18:22: ============================================================
22:18:22: ============================================================
22:18:22: ============================================================
22:18:22: lenet300-100
22:18:22: lenet300-100
22:18:22: lenet300-100
22:18:22: ============================================================
22:18:22: ============================================================
22:18:22: ============================================================
22:18:22: ============================================================
22:18:22: ============================================================
22:18:22: ============================================================
22:18:22: Prune mode: magnitude
22:18:22: Prune mode: magnitude
22:18:22: Prune mode: magnitude
22:18:22: Growth mode: momentum
22:18:22: Growth mode: momentum
22:18:22: Growth mode: momentum
22:18:22: Redistribution mode: momentum
22:18:22: Redistribution mode: momentum
22:18:22: Redistribution mode: momentum
22:18:22: ============================================================
22:18:22: ============================================================
22:18:22: ============================================================
22:18:22: Train Epoch: 1 [0/54000 (0%)]	Loss: 2.304187
22:18:22: Train Epoch: 1 [0/54000 (0%)]	Loss: 2.304187
22:18:22: Train Epoch: 1 [0/54000 (0%)]	Loss: 2.304187
22:18:23: Train Epoch: 1 [10000/54000 (19%)]	Loss: 0.241723
22:18:23: Train Epoch: 1 [10000/54000 (19%)]	Loss: 0.241723
22:18:23: Train Epoch: 1 [10000/54000 (19%)]	Loss: 0.241723
22:18:25: Train Epoch: 1 [20000/54000 (37%)]	Loss: 0.240182
22:18:25: Train Epoch: 1 [20000/54000 (37%)]	Loss: 0.240182
22:18:25: Train Epoch: 1 [20000/54000 (37%)]	Loss: 0.240182
22:18:42: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='vgg-d', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:18:42: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='vgg-d', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:18:42: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='vgg-d', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:18:42: 


22:18:42: 


22:18:42: 


22:18:42: ================================================================================
22:18:42: ================================================================================
22:18:42: ================================================================================
22:18:42: 
Iteration start: 1/1

22:18:42: 
Iteration start: 1/1

22:18:42: 
Iteration start: 1/1

22:18:44: VGG16(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
22:18:44: VGG16(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
22:18:44: VGG16(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
22:18:44: ============================================================
22:18:44: ============================================================
22:18:44: ============================================================
22:18:44: vgg-d
22:18:44: vgg-d
22:18:44: vgg-d
22:18:44: ============================================================
22:18:44: ============================================================
22:18:44: ============================================================
22:18:44: ============================================================
22:18:44: ============================================================
22:18:44: ============================================================
22:18:44: Prune mode: magnitude
22:18:44: Prune mode: magnitude
22:18:44: Prune mode: magnitude
22:18:44: Growth mode: momentum
22:18:44: Growth mode: momentum
22:18:44: Growth mode: momentum
22:18:44: Redistribution mode: momentum
22:18:44: Redistribution mode: momentum
22:18:44: Redistribution mode: momentum
22:18:44: ============================================================
22:18:44: ============================================================
22:18:44: ============================================================
22:18:44: Train Epoch: 1 [0/45000 (0%)]	Loss: 2.493264
22:18:44: Train Epoch: 1 [0/45000 (0%)]	Loss: 2.493264
22:18:44: Train Epoch: 1 [0/45000 (0%)]	Loss: 2.493264
22:18:51: Train Epoch: 1 [10000/45000 (22%)]	Loss: 3.538699
22:18:51: Train Epoch: 1 [10000/45000 (22%)]	Loss: 3.538699
22:18:51: Train Epoch: 1 [10000/45000 (22%)]	Loss: 3.538699
22:18:57: Train Epoch: 1 [20000/45000 (44%)]	Loss: 1.976608
22:18:57: Train Epoch: 1 [20000/45000 (44%)]	Loss: 1.976608
22:18:57: Train Epoch: 1 [20000/45000 (44%)]	Loss: 1.976608
22:19:04: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.881186
22:19:04: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.881186
22:19:04: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.881186
22:19:11: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.843703
22:19:11: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.843703
22:19:11: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.843703
22:19:17: 
Evaluation: Average loss: 0.0190, Accuracy: 1242/5000 (24.840%)

22:19:17: 
Evaluation: Average loss: 0.0190, Accuracy: 1242/5000 (24.840%)

22:19:17: 
Evaluation: Average loss: 0.0190, Accuracy: 1242/5000 (24.840%)

22:19:17: Current learning rate: 0.1. Time taken for epoch: 33.04 seconds.

22:19:17: Current learning rate: 0.1. Time taken for epoch: 33.04 seconds.

22:19:17: Current learning rate: 0.1. Time taken for epoch: 33.04 seconds.

22:19:17: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.915445
22:19:17: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.915445
22:19:17: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.915445
22:19:24: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.863323
22:19:24: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.863323
22:19:24: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.863323
22:19:31: Train Epoch: 2 [20000/45000 (44%)]	Loss: 1.873123
22:19:31: Train Epoch: 2 [20000/45000 (44%)]	Loss: 1.873123
22:19:31: Train Epoch: 2 [20000/45000 (44%)]	Loss: 1.873123
22:19:37: Train Epoch: 2 [30000/45000 (67%)]	Loss: 1.695018
22:19:37: Train Epoch: 2 [30000/45000 (67%)]	Loss: 1.695018
22:19:37: Train Epoch: 2 [30000/45000 (67%)]	Loss: 1.695018
22:19:44: Train Epoch: 2 [40000/45000 (89%)]	Loss: 1.553206
22:19:44: Train Epoch: 2 [40000/45000 (89%)]	Loss: 1.553206
22:19:44: Train Epoch: 2 [40000/45000 (89%)]	Loss: 1.553206
22:19:49: 
Evaluation: Average loss: 0.0164, Accuracy: 1828/5000 (36.560%)

22:19:49: 
Evaluation: Average loss: 0.0164, Accuracy: 1828/5000 (36.560%)

22:19:49: 
Evaluation: Average loss: 0.0164, Accuracy: 1828/5000 (36.560%)

22:19:50: Current learning rate: 0.1. Time taken for epoch: 32.83 seconds.

22:19:50: Current learning rate: 0.1. Time taken for epoch: 32.83 seconds.

22:19:50: Current learning rate: 0.1. Time taken for epoch: 32.83 seconds.

22:19:50: Train Epoch: 3 [0/45000 (0%)]	Loss: 1.825549
22:19:50: Train Epoch: 3 [0/45000 (0%)]	Loss: 1.825549
22:19:50: Train Epoch: 3 [0/45000 (0%)]	Loss: 1.825549
22:19:57: Train Epoch: 3 [10000/45000 (22%)]	Loss: 1.526147
22:19:57: Train Epoch: 3 [10000/45000 (22%)]	Loss: 1.526147
22:19:57: Train Epoch: 3 [10000/45000 (22%)]	Loss: 1.526147
22:20:04: Train Epoch: 3 [20000/45000 (44%)]	Loss: 1.675588
22:20:04: Train Epoch: 3 [20000/45000 (44%)]	Loss: 1.675588
22:20:04: Train Epoch: 3 [20000/45000 (44%)]	Loss: 1.675588
22:20:10: Train Epoch: 3 [30000/45000 (67%)]	Loss: 1.463606
22:20:10: Train Epoch: 3 [30000/45000 (67%)]	Loss: 1.463606
22:20:10: Train Epoch: 3 [30000/45000 (67%)]	Loss: 1.463606
22:20:16: Train Epoch: 3 [40000/45000 (89%)]	Loss: 1.686426
22:20:16: Train Epoch: 3 [40000/45000 (89%)]	Loss: 1.686426
22:20:16: Train Epoch: 3 [40000/45000 (89%)]	Loss: 1.686426
22:20:22: 
Evaluation: Average loss: 0.0155, Accuracy: 2021/5000 (40.420%)

22:20:22: 
Evaluation: Average loss: 0.0155, Accuracy: 2021/5000 (40.420%)

22:20:22: 
Evaluation: Average loss: 0.0155, Accuracy: 2021/5000 (40.420%)

22:20:22: Current learning rate: 0.1. Time taken for epoch: 32.87 seconds.

22:20:22: Current learning rate: 0.1. Time taken for epoch: 32.87 seconds.

22:20:22: Current learning rate: 0.1. Time taken for epoch: 32.87 seconds.

22:20:23: Train Epoch: 4 [0/45000 (0%)]	Loss: 1.457540
22:20:23: Train Epoch: 4 [0/45000 (0%)]	Loss: 1.457540
22:20:23: Train Epoch: 4 [0/45000 (0%)]	Loss: 1.457540
22:20:30: Train Epoch: 4 [10000/45000 (22%)]	Loss: 1.472508
22:20:30: Train Epoch: 4 [10000/45000 (22%)]	Loss: 1.472508
22:20:30: Train Epoch: 4 [10000/45000 (22%)]	Loss: 1.472508
22:20:36: Train Epoch: 4 [20000/45000 (44%)]	Loss: 1.503165
22:20:36: Train Epoch: 4 [20000/45000 (44%)]	Loss: 1.503165
22:20:36: Train Epoch: 4 [20000/45000 (44%)]	Loss: 1.503165
22:20:43: Train Epoch: 4 [30000/45000 (67%)]	Loss: 1.230379
22:20:43: Train Epoch: 4 [30000/45000 (67%)]	Loss: 1.230379
22:20:43: Train Epoch: 4 [30000/45000 (67%)]	Loss: 1.230379
22:20:49: Train Epoch: 4 [40000/45000 (89%)]	Loss: 1.479682
22:20:49: Train Epoch: 4 [40000/45000 (89%)]	Loss: 1.479682
22:20:49: Train Epoch: 4 [40000/45000 (89%)]	Loss: 1.479682
22:20:55: 
Evaluation: Average loss: 0.0139, Accuracy: 2413/5000 (48.260%)

22:20:55: 
Evaluation: Average loss: 0.0139, Accuracy: 2413/5000 (48.260%)

22:20:55: 
Evaluation: Average loss: 0.0139, Accuracy: 2413/5000 (48.260%)

22:20:55: Current learning rate: 0.1. Time taken for epoch: 32.81 seconds.

22:20:55: Current learning rate: 0.1. Time taken for epoch: 32.81 seconds.

22:20:55: Current learning rate: 0.1. Time taken for epoch: 32.81 seconds.

22:20:56: Train Epoch: 5 [0/45000 (0%)]	Loss: 1.192894
22:20:56: Train Epoch: 5 [0/45000 (0%)]	Loss: 1.192894
22:20:56: Train Epoch: 5 [0/45000 (0%)]	Loss: 1.192894
22:25:07: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='vgg-d', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:25:07: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='vgg-d', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:25:07: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='vgg-d', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:25:07: 


22:25:07: 


22:25:07: 


22:25:07: ================================================================================
22:25:07: ================================================================================
22:25:07: ================================================================================
22:25:07: 
Iteration start: 1/1

22:25:07: 
Iteration start: 1/1

22:25:07: 
Iteration start: 1/1

22:25:08: VGG16(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
22:25:08: VGG16(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
22:25:08: VGG16(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
22:25:08: ============================================================
22:25:08: ============================================================
22:25:08: ============================================================
22:25:08: vgg-d
22:25:08: vgg-d
22:25:08: vgg-d
22:25:08: ============================================================
22:25:08: ============================================================
22:25:08: ============================================================
22:25:08: ============================================================
22:25:08: ============================================================
22:25:08: ============================================================
22:25:08: Prune mode: magnitude
22:25:08: Prune mode: magnitude
22:25:08: Prune mode: magnitude
22:25:08: Growth mode: momentum
22:25:08: Growth mode: momentum
22:25:08: Growth mode: momentum
22:25:08: Redistribution mode: momentum
22:25:08: Redistribution mode: momentum
22:25:08: Redistribution mode: momentum
22:25:08: ============================================================
22:25:08: ============================================================
22:25:08: ============================================================
22:25:09: Train Epoch: 1 [0/45000 (0%)]	Loss: 2.493264
22:25:09: Train Epoch: 1 [0/45000 (0%)]	Loss: 2.493264
22:25:09: Train Epoch: 1 [0/45000 (0%)]	Loss: 2.493264
22:25:15: Train Epoch: 1 [10000/45000 (22%)]	Loss: 3.538699
22:25:15: Train Epoch: 1 [10000/45000 (22%)]	Loss: 3.538699
22:25:15: Train Epoch: 1 [10000/45000 (22%)]	Loss: 3.538699
22:25:22: Train Epoch: 1 [20000/45000 (44%)]	Loss: 1.976608
22:25:22: Train Epoch: 1 [20000/45000 (44%)]	Loss: 1.976608
22:25:22: Train Epoch: 1 [20000/45000 (44%)]	Loss: 1.976608
22:25:28: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.881186
22:25:28: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.881186
22:25:28: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.881186
22:25:35: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.843703
22:25:35: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.843703
22:25:35: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.843703
22:25:41: 
Evaluation: Average loss: 0.0190, Accuracy: 1242/5000 (24.840%)

22:25:41: 
Evaluation: Average loss: 0.0190, Accuracy: 1242/5000 (24.840%)

22:25:41: 
Evaluation: Average loss: 0.0190, Accuracy: 1242/5000 (24.840%)

22:25:41: Current learning rate: 0.1. Time taken for epoch: 32.85 seconds.

22:25:41: Current learning rate: 0.1. Time taken for epoch: 32.85 seconds.

22:25:41: Current learning rate: 0.1. Time taken for epoch: 32.85 seconds.

22:25:42: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.915445
22:25:42: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.915445
22:25:42: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.915445
22:25:48: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.863323
22:25:48: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.863323
22:25:48: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.863323
22:25:55: Train Epoch: 2 [20000/45000 (44%)]	Loss: 1.873123
22:25:55: Train Epoch: 2 [20000/45000 (44%)]	Loss: 1.873123
22:25:55: Train Epoch: 2 [20000/45000 (44%)]	Loss: 1.873123
22:26:02: Train Epoch: 2 [30000/45000 (67%)]	Loss: 1.695018
22:26:02: Train Epoch: 2 [30000/45000 (67%)]	Loss: 1.695018
22:26:02: Train Epoch: 2 [30000/45000 (67%)]	Loss: 1.695018
22:26:08: Train Epoch: 2 [40000/45000 (89%)]	Loss: 1.553206
22:26:08: Train Epoch: 2 [40000/45000 (89%)]	Loss: 1.553206
22:26:08: Train Epoch: 2 [40000/45000 (89%)]	Loss: 1.553206
22:26:14: 
Evaluation: Average loss: 0.0164, Accuracy: 1828/5000 (36.560%)

22:26:14: 
Evaluation: Average loss: 0.0164, Accuracy: 1828/5000 (36.560%)

22:26:14: 
Evaluation: Average loss: 0.0164, Accuracy: 1828/5000 (36.560%)

22:26:14: Current learning rate: 0.1. Time taken for epoch: 33.36 seconds.

22:26:14: Current learning rate: 0.1. Time taken for epoch: 33.36 seconds.

22:26:14: Current learning rate: 0.1. Time taken for epoch: 33.36 seconds.

22:26:15: Train Epoch: 3 [0/45000 (0%)]	Loss: 1.825549
22:26:15: Train Epoch: 3 [0/45000 (0%)]	Loss: 1.825549
22:26:15: Train Epoch: 3 [0/45000 (0%)]	Loss: 1.825549
22:26:58: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='vgg-d', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:26:58: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='vgg-d', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:26:58: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='vgg-d', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:26:58: 


22:26:58: 


22:26:58: 


22:26:58: ================================================================================
22:26:58: ================================================================================
22:26:58: ================================================================================
22:26:58: 
Iteration start: 1/1

22:26:58: 
Iteration start: 1/1

22:26:58: 
Iteration start: 1/1

22:27:00: VGG16(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
22:27:00: VGG16(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
22:27:00: VGG16(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
22:27:00: ============================================================
22:27:00: ============================================================
22:27:00: ============================================================
22:27:00: vgg-d
22:27:00: vgg-d
22:27:00: vgg-d
22:27:00: ============================================================
22:27:00: ============================================================
22:27:00: ============================================================
22:27:00: ============================================================
22:27:00: ============================================================
22:27:00: ============================================================
22:27:00: Prune mode: magnitude
22:27:00: Prune mode: magnitude
22:27:00: Prune mode: magnitude
22:27:00: Growth mode: momentum
22:27:00: Growth mode: momentum
22:27:00: Growth mode: momentum
22:27:00: Redistribution mode: momentum
22:27:00: Redistribution mode: momentum
22:27:00: Redistribution mode: momentum
22:27:00: ============================================================
22:27:00: ============================================================
22:27:00: ============================================================
22:27:00: Train Epoch: 1 [0/45000 (0%)]	Loss: 2.493264
22:27:00: Train Epoch: 1 [0/45000 (0%)]	Loss: 2.493264
22:27:00: Train Epoch: 1 [0/45000 (0%)]	Loss: 2.493264
22:27:07: Train Epoch: 1 [10000/45000 (22%)]	Loss: 3.538699
22:27:07: Train Epoch: 1 [10000/45000 (22%)]	Loss: 3.538699
22:27:07: Train Epoch: 1 [10000/45000 (22%)]	Loss: 3.538699
22:27:14: Train Epoch: 1 [20000/45000 (44%)]	Loss: 1.976608
22:27:14: Train Epoch: 1 [20000/45000 (44%)]	Loss: 1.976608
22:27:14: Train Epoch: 1 [20000/45000 (44%)]	Loss: 1.976608
22:27:20: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.881186
22:27:20: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.881186
22:27:20: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.881186
22:27:27: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.843703
22:27:27: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.843703
22:27:27: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.843703
22:27:32: 
Evaluation: Average loss: 1.8959, Accuracy: 1242/5000 (24.840%)

22:27:32: 
Evaluation: Average loss: 1.8959, Accuracy: 1242/5000 (24.840%)

22:27:32: 
Evaluation: Average loss: 1.8959, Accuracy: 1242/5000 (24.840%)

22:27:33: Current learning rate: 0.1. Time taken for epoch: 33.06 seconds.

22:27:33: Current learning rate: 0.1. Time taken for epoch: 33.06 seconds.

22:27:33: Current learning rate: 0.1. Time taken for epoch: 33.06 seconds.

22:27:33: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.915445
22:27:33: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.915445
22:27:33: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.915445
22:27:40: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.863323
22:27:40: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.863323
22:27:40: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.863323
22:27:47: Train Epoch: 2 [20000/45000 (44%)]	Loss: 1.873123
22:27:47: Train Epoch: 2 [20000/45000 (44%)]	Loss: 1.873123
22:27:47: Train Epoch: 2 [20000/45000 (44%)]	Loss: 1.873123
22:27:53: Train Epoch: 2 [30000/45000 (67%)]	Loss: 1.695018
22:27:53: Train Epoch: 2 [30000/45000 (67%)]	Loss: 1.695018
22:27:53: Train Epoch: 2 [30000/45000 (67%)]	Loss: 1.695018
22:28:00: Train Epoch: 2 [40000/45000 (89%)]	Loss: 1.553206
22:28:00: Train Epoch: 2 [40000/45000 (89%)]	Loss: 1.553206
22:28:00: Train Epoch: 2 [40000/45000 (89%)]	Loss: 1.553206
22:28:06: 
Evaluation: Average loss: 1.6408, Accuracy: 1828/5000 (36.560%)

22:28:06: 
Evaluation: Average loss: 1.6408, Accuracy: 1828/5000 (36.560%)

22:28:06: 
Evaluation: Average loss: 1.6408, Accuracy: 1828/5000 (36.560%)

22:28:06: Current learning rate: 0.1. Time taken for epoch: 33.20 seconds.

22:28:06: Current learning rate: 0.1. Time taken for epoch: 33.20 seconds.

22:28:06: Current learning rate: 0.1. Time taken for epoch: 33.20 seconds.

22:28:07: Train Epoch: 3 [0/45000 (0%)]	Loss: 1.825549
22:28:07: Train Epoch: 3 [0/45000 (0%)]	Loss: 1.825549
22:28:07: Train Epoch: 3 [0/45000 (0%)]	Loss: 1.825549
22:29:22: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='vgg-d', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:29:22: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='vgg-d', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:29:22: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='vgg-d', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:29:22: 


22:29:22: 


22:29:22: 


22:29:22: ================================================================================
22:29:22: ================================================================================
22:29:22: ================================================================================
22:29:22: 
Iteration start: 1/1

22:29:22: 
Iteration start: 1/1

22:29:22: 
Iteration start: 1/1

22:29:24: VGG16(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
22:29:24: VGG16(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
22:29:24: VGG16(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
22:29:24: ============================================================
22:29:24: ============================================================
22:29:24: ============================================================
22:29:24: vgg-d
22:29:24: vgg-d
22:29:24: vgg-d
22:29:24: ============================================================
22:29:24: ============================================================
22:29:24: ============================================================
22:29:24: ============================================================
22:29:24: ============================================================
22:29:24: ============================================================
22:29:24: Prune mode: magnitude
22:29:24: Prune mode: magnitude
22:29:24: Prune mode: magnitude
22:29:24: Growth mode: momentum
22:29:24: Growth mode: momentum
22:29:24: Growth mode: momentum
22:29:24: Redistribution mode: momentum
22:29:24: Redistribution mode: momentum
22:29:24: Redistribution mode: momentum
22:29:24: ============================================================
22:29:24: ============================================================
22:29:24: ============================================================
22:29:24: Train Epoch: 1 [0/45000 (0%)]	Loss: 2.493264
22:29:24: Train Epoch: 1 [0/45000 (0%)]	Loss: 2.493264
22:29:24: Train Epoch: 1 [0/45000 (0%)]	Loss: 2.493264
22:29:31: Train Epoch: 1 [10000/45000 (22%)]	Loss: 3.538699
22:29:31: Train Epoch: 1 [10000/45000 (22%)]	Loss: 3.538699
22:29:31: Train Epoch: 1 [10000/45000 (22%)]	Loss: 3.538699
22:29:38: Train Epoch: 1 [20000/45000 (44%)]	Loss: 1.976608
22:29:38: Train Epoch: 1 [20000/45000 (44%)]	Loss: 1.976608
22:29:38: Train Epoch: 1 [20000/45000 (44%)]	Loss: 1.976608
22:29:44: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.881186
22:29:44: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.881186
22:29:44: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.881186
22:29:51: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.843703
22:29:51: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.843703
22:29:51: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.843703
22:30:34: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='vgg-d', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:30:34: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='vgg-d', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:30:34: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='vgg-d', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:30:34: 


22:30:34: 


22:30:34: 


22:30:34: ================================================================================
22:30:34: ================================================================================
22:30:34: ================================================================================
22:30:34: 
Iteration start: 1/1

22:30:34: 
Iteration start: 1/1

22:30:34: 
Iteration start: 1/1

22:30:36: VGG16(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
22:30:36: VGG16(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
22:30:36: VGG16(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
22:30:36: ============================================================
22:30:36: ============================================================
22:30:36: ============================================================
22:30:36: vgg-d
22:30:36: vgg-d
22:30:36: vgg-d
22:30:36: ============================================================
22:30:36: ============================================================
22:30:36: ============================================================
22:30:36: ============================================================
22:30:36: ============================================================
22:30:36: ============================================================
22:30:36: Prune mode: magnitude
22:30:36: Prune mode: magnitude
22:30:36: Prune mode: magnitude
22:30:36: Growth mode: momentum
22:30:36: Growth mode: momentum
22:30:36: Growth mode: momentum
22:30:36: Redistribution mode: momentum
22:30:36: Redistribution mode: momentum
22:30:36: Redistribution mode: momentum
22:30:36: ============================================================
22:30:36: ============================================================
22:30:36: ============================================================
22:30:37: Train Epoch: 1 [0/45000 (0%)]	Loss: 2.493264
22:30:37: Train Epoch: 1 [0/45000 (0%)]	Loss: 2.493264
22:30:37: Train Epoch: 1 [0/45000 (0%)]	Loss: 2.493264
22:30:43: Train Epoch: 1 [10000/45000 (22%)]	Loss: 3.538699
22:30:43: Train Epoch: 1 [10000/45000 (22%)]	Loss: 3.538699
22:30:43: Train Epoch: 1 [10000/45000 (22%)]	Loss: 3.538699
22:30:50: Train Epoch: 1 [20000/45000 (44%)]	Loss: 1.976608
22:30:50: Train Epoch: 1 [20000/45000 (44%)]	Loss: 1.976608
22:30:50: Train Epoch: 1 [20000/45000 (44%)]	Loss: 1.976608
22:30:56: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.881186
22:30:56: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.881186
22:30:56: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.881186
22:31:03: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.843703
22:31:03: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.843703
22:31:03: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.843703
22:31:09: 
Evaluation: Average loss: 1.8959, Accuracy: 1242/5000 (24.840%)

22:31:09: 
Evaluation: Average loss: 1.8959, Accuracy: 1242/5000 (24.840%)

22:31:09: 
Evaluation: Average loss: 1.8959, Accuracy: 1242/5000 (24.840%)

22:31:09: Current learning rate: 0.1. Time taken for epoch: 33.45 seconds.

22:31:09: Current learning rate: 0.1. Time taken for epoch: 33.45 seconds.

22:31:09: Current learning rate: 0.1. Time taken for epoch: 33.45 seconds.

22:31:10: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.915445
22:31:10: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.915445
22:31:10: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.915445
22:31:17: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.863323
22:31:17: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.863323
22:31:17: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.863323
22:31:23: Train Epoch: 2 [20000/45000 (44%)]	Loss: 1.873123
22:31:23: Train Epoch: 2 [20000/45000 (44%)]	Loss: 1.873123
22:31:23: Train Epoch: 2 [20000/45000 (44%)]	Loss: 1.873123
22:31:30: Train Epoch: 2 [30000/45000 (67%)]	Loss: 1.695018
22:31:30: Train Epoch: 2 [30000/45000 (67%)]	Loss: 1.695018
22:31:30: Train Epoch: 2 [30000/45000 (67%)]	Loss: 1.695018
22:31:36: Train Epoch: 2 [40000/45000 (89%)]	Loss: 1.553206
22:31:36: Train Epoch: 2 [40000/45000 (89%)]	Loss: 1.553206
22:31:36: Train Epoch: 2 [40000/45000 (89%)]	Loss: 1.553206
22:31:42: 
Evaluation: Average loss: 1.6408, Accuracy: 1828/5000 (36.560%)

22:31:42: 
Evaluation: Average loss: 1.6408, Accuracy: 1828/5000 (36.560%)

22:31:42: 
Evaluation: Average loss: 1.6408, Accuracy: 1828/5000 (36.560%)

22:31:42: Current learning rate: 0.1. Time taken for epoch: 33.35 seconds.

22:31:42: Current learning rate: 0.1. Time taken for epoch: 33.35 seconds.

22:31:42: Current learning rate: 0.1. Time taken for epoch: 33.35 seconds.

22:31:43: Train Epoch: 3 [0/45000 (0%)]	Loss: 1.825549
22:31:43: Train Epoch: 3 [0/45000 (0%)]	Loss: 1.825549
22:31:43: Train Epoch: 3 [0/45000 (0%)]	Loss: 1.825549
22:31:50: Train Epoch: 3 [10000/45000 (22%)]	Loss: 1.526147
22:31:50: Train Epoch: 3 [10000/45000 (22%)]	Loss: 1.526147
22:31:50: Train Epoch: 3 [10000/45000 (22%)]	Loss: 1.526147
22:31:56: Train Epoch: 3 [20000/45000 (44%)]	Loss: 1.675588
22:31:56: Train Epoch: 3 [20000/45000 (44%)]	Loss: 1.675588
22:31:56: Train Epoch: 3 [20000/45000 (44%)]	Loss: 1.675588
22:32:03: Train Epoch: 3 [30000/45000 (67%)]	Loss: 1.463606
22:32:03: Train Epoch: 3 [30000/45000 (67%)]	Loss: 1.463606
22:32:03: Train Epoch: 3 [30000/45000 (67%)]	Loss: 1.463606
22:32:09: Train Epoch: 3 [40000/45000 (89%)]	Loss: 1.686426
22:32:09: Train Epoch: 3 [40000/45000 (89%)]	Loss: 1.686426
22:32:09: Train Epoch: 3 [40000/45000 (89%)]	Loss: 1.686426
22:32:15: 
Evaluation: Average loss: 1.5538, Accuracy: 2021/5000 (40.420%)

22:32:15: 
Evaluation: Average loss: 1.5538, Accuracy: 2021/5000 (40.420%)

22:32:15: 
Evaluation: Average loss: 1.5538, Accuracy: 2021/5000 (40.420%)

22:32:15: Current learning rate: 0.1. Time taken for epoch: 32.99 seconds.

22:32:15: Current learning rate: 0.1. Time taken for epoch: 32.99 seconds.

22:32:15: Current learning rate: 0.1. Time taken for epoch: 32.99 seconds.

22:32:16: Train Epoch: 4 [0/45000 (0%)]	Loss: 1.457540
22:32:16: Train Epoch: 4 [0/45000 (0%)]	Loss: 1.457540
22:32:16: Train Epoch: 4 [0/45000 (0%)]	Loss: 1.457540
22:32:23: Train Epoch: 4 [10000/45000 (22%)]	Loss: 1.472508
22:32:23: Train Epoch: 4 [10000/45000 (22%)]	Loss: 1.472508
22:32:23: Train Epoch: 4 [10000/45000 (22%)]	Loss: 1.472508
22:32:29: Train Epoch: 4 [20000/45000 (44%)]	Loss: 1.503165
22:32:29: Train Epoch: 4 [20000/45000 (44%)]	Loss: 1.503165
22:32:29: Train Epoch: 4 [20000/45000 (44%)]	Loss: 1.503165
22:32:36: Train Epoch: 4 [30000/45000 (67%)]	Loss: 1.230379
22:32:36: Train Epoch: 4 [30000/45000 (67%)]	Loss: 1.230379
22:32:36: Train Epoch: 4 [30000/45000 (67%)]	Loss: 1.230379
22:32:42: Train Epoch: 4 [40000/45000 (89%)]	Loss: 1.479682
22:32:42: Train Epoch: 4 [40000/45000 (89%)]	Loss: 1.479682
22:32:42: Train Epoch: 4 [40000/45000 (89%)]	Loss: 1.479682
22:32:48: 
Evaluation: Average loss: 1.3853, Accuracy: 2413/5000 (48.260%)

22:32:48: 
Evaluation: Average loss: 1.3853, Accuracy: 2413/5000 (48.260%)

22:32:48: 
Evaluation: Average loss: 1.3853, Accuracy: 2413/5000 (48.260%)

22:32:48: Current learning rate: 0.1. Time taken for epoch: 32.90 seconds.

22:32:48: Current learning rate: 0.1. Time taken for epoch: 32.90 seconds.

22:32:48: Current learning rate: 0.1. Time taken for epoch: 32.90 seconds.

22:32:49: Train Epoch: 5 [0/45000 (0%)]	Loss: 1.192894
22:32:49: Train Epoch: 5 [0/45000 (0%)]	Loss: 1.192894
22:32:49: Train Epoch: 5 [0/45000 (0%)]	Loss: 1.192894
22:32:56: Train Epoch: 5 [10000/45000 (22%)]	Loss: 1.375380
22:32:56: Train Epoch: 5 [10000/45000 (22%)]	Loss: 1.375380
22:32:56: Train Epoch: 5 [10000/45000 (22%)]	Loss: 1.375380
22:33:02: Train Epoch: 5 [20000/45000 (44%)]	Loss: 1.329520
22:33:02: Train Epoch: 5 [20000/45000 (44%)]	Loss: 1.329520
22:33:02: Train Epoch: 5 [20000/45000 (44%)]	Loss: 1.329520
22:33:09: Train Epoch: 5 [30000/45000 (67%)]	Loss: 1.107607
22:33:09: Train Epoch: 5 [30000/45000 (67%)]	Loss: 1.107607
22:33:09: Train Epoch: 5 [30000/45000 (67%)]	Loss: 1.107607
22:33:16: Train Epoch: 5 [40000/45000 (89%)]	Loss: 1.187082
22:33:16: Train Epoch: 5 [40000/45000 (89%)]	Loss: 1.187082
22:33:16: Train Epoch: 5 [40000/45000 (89%)]	Loss: 1.187082
22:33:21: 
Evaluation: Average loss: 1.5255, Accuracy: 2179/5000 (43.580%)

22:33:21: 
Evaluation: Average loss: 1.5255, Accuracy: 2179/5000 (43.580%)

22:33:21: 
Evaluation: Average loss: 1.5255, Accuracy: 2179/5000 (43.580%)

22:33:21: Current learning rate: 0.1. Time taken for epoch: 33.05 seconds.

22:33:21: Current learning rate: 0.1. Time taken for epoch: 33.05 seconds.

22:33:21: Current learning rate: 0.1. Time taken for epoch: 33.05 seconds.

22:33:22: Train Epoch: 6 [0/45000 (0%)]	Loss: 1.045071
22:33:22: Train Epoch: 6 [0/45000 (0%)]	Loss: 1.045071
22:33:22: Train Epoch: 6 [0/45000 (0%)]	Loss: 1.045071
22:33:29: Train Epoch: 6 [10000/45000 (22%)]	Loss: 1.316386
22:33:29: Train Epoch: 6 [10000/45000 (22%)]	Loss: 1.316386
22:33:29: Train Epoch: 6 [10000/45000 (22%)]	Loss: 1.316386
22:33:35: Train Epoch: 6 [20000/45000 (44%)]	Loss: 0.935365
22:33:35: Train Epoch: 6 [20000/45000 (44%)]	Loss: 0.935365
22:33:35: Train Epoch: 6 [20000/45000 (44%)]	Loss: 0.935365
22:33:42: Train Epoch: 6 [30000/45000 (67%)]	Loss: 0.956795
22:33:42: Train Epoch: 6 [30000/45000 (67%)]	Loss: 0.956795
22:33:42: Train Epoch: 6 [30000/45000 (67%)]	Loss: 0.956795
22:33:48: Train Epoch: 6 [40000/45000 (89%)]	Loss: 1.162278
22:33:48: Train Epoch: 6 [40000/45000 (89%)]	Loss: 1.162278
22:33:48: Train Epoch: 6 [40000/45000 (89%)]	Loss: 1.162278
22:33:54: 
Evaluation: Average loss: 1.0710, Accuracy: 3177/5000 (63.540%)

22:33:54: 
Evaluation: Average loss: 1.0710, Accuracy: 3177/5000 (63.540%)

22:33:54: 
Evaluation: Average loss: 1.0710, Accuracy: 3177/5000 (63.540%)

22:33:54: Current learning rate: 0.1. Time taken for epoch: 32.85 seconds.

22:33:54: Current learning rate: 0.1. Time taken for epoch: 32.85 seconds.

22:33:54: Current learning rate: 0.1. Time taken for epoch: 32.85 seconds.

22:33:55: Train Epoch: 7 [0/45000 (0%)]	Loss: 0.992776
22:33:55: Train Epoch: 7 [0/45000 (0%)]	Loss: 0.992776
22:33:55: Train Epoch: 7 [0/45000 (0%)]	Loss: 0.992776
22:34:02: Train Epoch: 7 [10000/45000 (22%)]	Loss: 0.955410
22:34:02: Train Epoch: 7 [10000/45000 (22%)]	Loss: 0.955410
22:34:02: Train Epoch: 7 [10000/45000 (22%)]	Loss: 0.955410
22:34:08: Train Epoch: 7 [20000/45000 (44%)]	Loss: 0.818141
22:34:08: Train Epoch: 7 [20000/45000 (44%)]	Loss: 0.818141
22:34:08: Train Epoch: 7 [20000/45000 (44%)]	Loss: 0.818141
22:34:15: Train Epoch: 7 [30000/45000 (67%)]	Loss: 0.800103
22:34:15: Train Epoch: 7 [30000/45000 (67%)]	Loss: 0.800103
22:34:15: Train Epoch: 7 [30000/45000 (67%)]	Loss: 0.800103
22:34:21: Train Epoch: 7 [40000/45000 (89%)]	Loss: 0.695746
22:34:21: Train Epoch: 7 [40000/45000 (89%)]	Loss: 0.695746
22:34:21: Train Epoch: 7 [40000/45000 (89%)]	Loss: 0.695746
22:34:27: 
Evaluation: Average loss: 1.0942, Accuracy: 3185/5000 (63.700%)

22:34:27: 
Evaluation: Average loss: 1.0942, Accuracy: 3185/5000 (63.700%)

22:34:27: 
Evaluation: Average loss: 1.0942, Accuracy: 3185/5000 (63.700%)

22:34:27: Current learning rate: 0.1. Time taken for epoch: 32.93 seconds.

22:34:27: Current learning rate: 0.1. Time taken for epoch: 32.93 seconds.

22:34:27: Current learning rate: 0.1. Time taken for epoch: 32.93 seconds.

22:34:28: Train Epoch: 8 [0/45000 (0%)]	Loss: 0.785956
22:34:28: Train Epoch: 8 [0/45000 (0%)]	Loss: 0.785956
22:34:28: Train Epoch: 8 [0/45000 (0%)]	Loss: 0.785956
22:34:35: Train Epoch: 8 [10000/45000 (22%)]	Loss: 0.770206
22:34:35: Train Epoch: 8 [10000/45000 (22%)]	Loss: 0.770206
22:34:35: Train Epoch: 8 [10000/45000 (22%)]	Loss: 0.770206
22:34:41: Train Epoch: 8 [20000/45000 (44%)]	Loss: 0.909539
22:34:41: Train Epoch: 8 [20000/45000 (44%)]	Loss: 0.909539
22:34:41: Train Epoch: 8 [20000/45000 (44%)]	Loss: 0.909539
22:34:48: Train Epoch: 8 [30000/45000 (67%)]	Loss: 1.017162
22:34:48: Train Epoch: 8 [30000/45000 (67%)]	Loss: 1.017162
22:34:48: Train Epoch: 8 [30000/45000 (67%)]	Loss: 1.017162
22:34:54: Train Epoch: 8 [40000/45000 (89%)]	Loss: 0.929008
22:34:54: Train Epoch: 8 [40000/45000 (89%)]	Loss: 0.929008
22:34:54: Train Epoch: 8 [40000/45000 (89%)]	Loss: 0.929008
22:35:00: 
Evaluation: Average loss: 0.9385, Accuracy: 3417/5000 (68.340%)

22:35:00: 
Evaluation: Average loss: 0.9385, Accuracy: 3417/5000 (68.340%)

22:35:00: 
Evaluation: Average loss: 0.9385, Accuracy: 3417/5000 (68.340%)

22:35:00: Current learning rate: 0.1. Time taken for epoch: 32.94 seconds.

22:35:00: Current learning rate: 0.1. Time taken for epoch: 32.94 seconds.

22:35:00: Current learning rate: 0.1. Time taken for epoch: 32.94 seconds.

22:35:01: Train Epoch: 9 [0/45000 (0%)]	Loss: 0.767262
22:35:01: Train Epoch: 9 [0/45000 (0%)]	Loss: 0.767262
22:35:01: Train Epoch: 9 [0/45000 (0%)]	Loss: 0.767262
22:35:08: Train Epoch: 9 [10000/45000 (22%)]	Loss: 0.850674
22:35:08: Train Epoch: 9 [10000/45000 (22%)]	Loss: 0.850674
22:35:08: Train Epoch: 9 [10000/45000 (22%)]	Loss: 0.850674
22:35:14: Train Epoch: 9 [20000/45000 (44%)]	Loss: 0.866314
22:35:14: Train Epoch: 9 [20000/45000 (44%)]	Loss: 0.866314
22:35:14: Train Epoch: 9 [20000/45000 (44%)]	Loss: 0.866314
22:35:21: Train Epoch: 9 [30000/45000 (67%)]	Loss: 0.684554
22:35:21: Train Epoch: 9 [30000/45000 (67%)]	Loss: 0.684554
22:35:21: Train Epoch: 9 [30000/45000 (67%)]	Loss: 0.684554
22:35:27: Train Epoch: 9 [40000/45000 (89%)]	Loss: 0.675306
22:35:27: Train Epoch: 9 [40000/45000 (89%)]	Loss: 0.675306
22:35:27: Train Epoch: 9 [40000/45000 (89%)]	Loss: 0.675306
22:35:33: 
Evaluation: Average loss: 1.5618, Accuracy: 2579/5000 (51.580%)

22:35:33: 
Evaluation: Average loss: 1.5618, Accuracy: 2579/5000 (51.580%)

22:35:33: 
Evaluation: Average loss: 1.5618, Accuracy: 2579/5000 (51.580%)

22:35:33: Current learning rate: 0.1. Time taken for epoch: 33.18 seconds.

22:35:33: Current learning rate: 0.1. Time taken for epoch: 33.18 seconds.

22:35:33: Current learning rate: 0.1. Time taken for epoch: 33.18 seconds.

22:35:34: Train Epoch: 10 [0/45000 (0%)]	Loss: 0.815384
22:35:34: Train Epoch: 10 [0/45000 (0%)]	Loss: 0.815384
22:35:34: Train Epoch: 10 [0/45000 (0%)]	Loss: 0.815384
22:36:37: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='vgg-d', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:36:37: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='vgg-d', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:36:37: Namespace(batch_size=100, bench=True, data='cifar', decay_frequency=25000, decay_schedule='cosine', dense=True, density=1.0, epochs=100, fp16=False, growth='momentum', iters=1, l1=0.0, l2=0.0005, log_interval=100, lr=0.1, max_threads=10, model='vgg-d', momentum=0.9, no_cuda=False, optimizer='sgd', prune='magnitude', prune_rate=0.7, redistribution='momentum', resume=None, save_features=False, save_model='./models/model.pt', seed=17, start_epoch=1, test_batch_size=100, valid_split=0.1, verbose=True)
22:36:37: 


22:36:37: 


22:36:37: 


22:36:37: ================================================================================
22:36:37: ================================================================================
22:36:37: ================================================================================
22:36:37: 
Iteration start: 1/1

22:36:37: 
Iteration start: 1/1

22:36:37: 
Iteration start: 1/1

22:36:38: VGG16(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
22:36:38: VGG16(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
22:36:38: VGG16(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
22:36:38: ============================================================
22:36:38: ============================================================
22:36:38: ============================================================
22:36:38: vgg-d
22:36:38: vgg-d
22:36:38: vgg-d
22:36:38: ============================================================
22:36:38: ============================================================
22:36:38: ============================================================
22:36:38: ============================================================
22:36:38: ============================================================
22:36:38: ============================================================
22:36:38: Prune mode: magnitude
22:36:38: Prune mode: magnitude
22:36:38: Prune mode: magnitude
22:36:38: Growth mode: momentum
22:36:38: Growth mode: momentum
22:36:38: Growth mode: momentum
22:36:38: Redistribution mode: momentum
22:36:38: Redistribution mode: momentum
22:36:38: Redistribution mode: momentum
22:36:38: ============================================================
22:36:38: ============================================================
22:36:38: ============================================================
22:36:39: Train Epoch: 1 [0/45000 (0%)]	Loss: 2.493264
22:36:39: Train Epoch: 1 [0/45000 (0%)]	Loss: 2.493264
22:36:39: Train Epoch: 1 [0/45000 (0%)]	Loss: 2.493264
22:36:46: Train Epoch: 1 [10000/45000 (22%)]	Loss: 3.538699
22:36:46: Train Epoch: 1 [10000/45000 (22%)]	Loss: 3.538699
22:36:46: Train Epoch: 1 [10000/45000 (22%)]	Loss: 3.538699
22:36:52: Train Epoch: 1 [20000/45000 (44%)]	Loss: 1.976608
22:36:52: Train Epoch: 1 [20000/45000 (44%)]	Loss: 1.976608
22:36:52: Train Epoch: 1 [20000/45000 (44%)]	Loss: 1.976608
22:36:59: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.881186
22:36:59: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.881186
22:36:59: Train Epoch: 1 [30000/45000 (67%)]	Loss: 1.881186
22:37:05: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.843703
22:37:05: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.843703
22:37:05: Train Epoch: 1 [40000/45000 (89%)]	Loss: 1.843703
22:37:11: 
Evaluation: Average loss: 1.8959, Accuracy: 1242/5000 (24.840%)

22:37:11: 
Evaluation: Average loss: 1.8959, Accuracy: 1242/5000 (24.840%)

22:37:11: 
Evaluation: Average loss: 1.8959, Accuracy: 1242/5000 (24.840%)

22:37:11: Current learning rate: 0.1. Time taken for epoch: 32.85 seconds.

22:37:11: Current learning rate: 0.1. Time taken for epoch: 32.85 seconds.

22:37:11: Current learning rate: 0.1. Time taken for epoch: 32.85 seconds.

22:37:12: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.915445
22:37:12: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.915445
22:37:12: Train Epoch: 2 [0/45000 (0%)]	Loss: 1.915445
22:37:19: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.863323
22:37:19: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.863323
22:37:19: Train Epoch: 2 [10000/45000 (22%)]	Loss: 1.863323
